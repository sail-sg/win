INFO:Namespace(aa='rand-m7-mstd0.5-inc1', acceleration_all=True, acceleration_mode='win2', amp=True, apex_amp=False, aug_repeats=3, aug_splits=0, batch_size=512, bce_loss=True, bias_decay=False, bn_eps=None, bn_momentum=None, channels_last=False, checkpoint_hist=2, clip_grad=None, clip_mode='norm', color_jitter=0.4, configure='job_lamb_res101_7.yaml', cooldown_epochs=10, crop_pct=None, cutmix=1.0, cutmix_minmax=None, dampening=0.0, data_dir='/dataset/imagenet', dataset='', decay_epochs=100, decay_rate=0.1, device='cuda:1', dist_bn='reduce', distributed=True, drop=0.0, drop_block=None, drop_connect=None, drop_path=0.1, epoch_repeats=0.0, epochs=300, eval_metric='top1', experiment='resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0', gp=None, hflip=0.5, img_size=None, initial_checkpoint='', input_size=None, interpolation='', jsd_loss=False, local_rank=1, log_interval=50, log_wandb=False, lr=0.008, lr_cycle_decay=0.5, lr_cycle_limit=1, lr_cycle_mul=1.0, lr_k_decay=1.0, lr_mode='cos', lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, max_grad_norm=1.0, mean=None, min_lr=5e-05, mixup=0.1, mixup_mode='batch', mixup_off_epoch=0, mixup_prob=1.0, mixup_switch_prob=0.5, model='resnet101', model_ema=False, model_ema_decay=0.9998, model_ema_force_cpu=False, momentum=0.9, native_amp=False, no_aug=False, no_prefetcher=False, no_prox=False, no_resume_opt=False, num_classes=None, opt='lamb4', opt_betas=[0.9, 0.999, 2.0, 8.0], opt_eps=None, output='./exp_lamb_resnet101_6/', p=0.5, patience_epochs=10, pin_mem=False, prefetcher=True, pretrained=False, rank=1, ratio=[0.75, 1.3333333333333333], recount=1, recovery_interval=0, remode='pixel', reprob=0.0, resplit=False, resume='last.pth.tar', save_images=False, scale=[0.08, 1.0], sched='cosine', seed=42, smoothing=0.1, split_bn=False, start_epoch=None, std=None, sync_bn=False, torchscript=False, train_interpolation='random', train_split='train', tta=0, update_mode='', use_multi_epochs_loader=False, val_split='validation', validation_batch_size=None, vflip=0.0, warmup_epochs=30, warmup_lr=1e-10, weight_decay=0.01, workers=10, world_size=4)
INFO:Namespace(aa='rand-m7-mstd0.5-inc1', acceleration_all=True, acceleration_mode='win2', amp=True, apex_amp=False, aug_repeats=3, aug_splits=0, batch_size=512, bce_loss=True, bias_decay=False, bn_eps=None, bn_momentum=None, channels_last=False, checkpoint_hist=2, clip_grad=None, clip_mode='norm', color_jitter=0.4, configure='job_lamb_res101_7.yaml', cooldown_epochs=10, crop_pct=None, cutmix=1.0, cutmix_minmax=None, dampening=0.0, data_dir='/dataset/imagenet', dataset='', decay_epochs=100, decay_rate=0.1, device='cuda:0', dist_bn='reduce', distributed=True, drop=0.0, drop_block=None, drop_connect=None, drop_path=0.1, epoch_repeats=0.0, epochs=300, eval_metric='top1', experiment='resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0', gp=None, hflip=0.5, img_size=None, initial_checkpoint='', input_size=None, interpolation='', jsd_loss=False, local_rank=0, log_interval=50, log_wandb=False, lr=0.008, lr_cycle_decay=0.5, lr_cycle_limit=1, lr_cycle_mul=1.0, lr_k_decay=1.0, lr_mode='cos', lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, max_grad_norm=1.0, mean=None, min_lr=5e-05, mixup=0.1, mixup_mode='batch', mixup_off_epoch=0, mixup_prob=1.0, mixup_switch_prob=0.5, model='resnet101', model_ema=False, model_ema_decay=0.9998, model_ema_force_cpu=False, momentum=0.9, native_amp=False, no_aug=False, no_prefetcher=False, no_prox=False, no_resume_opt=False, num_classes=None, opt='lamb4', opt_betas=[0.9, 0.999, 2.0, 8.0], opt_eps=None, output='./exp_lamb_resnet101_6/', p=0.5, patience_epochs=10, pin_mem=False, prefetcher=True, pretrained=False, rank=0, ratio=[0.75, 1.3333333333333333], recount=1, recovery_interval=0, remode='pixel', reprob=0.0, resplit=False, resume='last.pth.tar', save_images=False, scale=[0.08, 1.0], sched='cosine', seed=42, smoothing=0.1, split_bn=False, start_epoch=None, std=None, sync_bn=False, torchscript=False, train_interpolation='random', train_split='train', tta=0, update_mode='', use_multi_epochs_loader=False, val_split='validation', validation_batch_size=None, vflip=0.0, warmup_epochs=30, warmup_lr=1e-10, weight_decay=0.01, workers=10, world_size=4)
INFO:Namespace(aa='rand-m7-mstd0.5-inc1', acceleration_all=True, acceleration_mode='win2', amp=True, apex_amp=False, aug_repeats=3, aug_splits=0, batch_size=512, bce_loss=True, bias_decay=False, bn_eps=None, bn_momentum=None, channels_last=False, checkpoint_hist=2, clip_grad=None, clip_mode='norm', color_jitter=0.4, configure='job_lamb_res101_7.yaml', cooldown_epochs=10, crop_pct=None, cutmix=1.0, cutmix_minmax=None, dampening=0.0, data_dir='/dataset/imagenet', dataset='', decay_epochs=100, decay_rate=0.1, device='cuda:3', dist_bn='reduce', distributed=True, drop=0.0, drop_block=None, drop_connect=None, drop_path=0.1, epoch_repeats=0.0, epochs=300, eval_metric='top1', experiment='resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0', gp=None, hflip=0.5, img_size=None, initial_checkpoint='', input_size=None, interpolation='', jsd_loss=False, local_rank=3, log_interval=50, log_wandb=False, lr=0.008, lr_cycle_decay=0.5, lr_cycle_limit=1, lr_cycle_mul=1.0, lr_k_decay=1.0, lr_mode='cos', lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, max_grad_norm=1.0, mean=None, min_lr=5e-05, mixup=0.1, mixup_mode='batch', mixup_off_epoch=0, mixup_prob=1.0, mixup_switch_prob=0.5, model='resnet101', model_ema=False, model_ema_decay=0.9998, model_ema_force_cpu=False, momentum=0.9, native_amp=False, no_aug=False, no_prefetcher=False, no_prox=False, no_resume_opt=False, num_classes=None, opt='lamb4', opt_betas=[0.9, 0.999, 2.0, 8.0], opt_eps=None, output='./exp_lamb_resnet101_6/', p=0.5, patience_epochs=10, pin_mem=False, prefetcher=True, pretrained=False, rank=3, ratio=[0.75, 1.3333333333333333], recount=1, recovery_interval=0, remode='pixel', reprob=0.0, resplit=False, resume='last.pth.tar', save_images=False, scale=[0.08, 1.0], sched='cosine', seed=42, smoothing=0.1, split_bn=False, start_epoch=None, std=None, sync_bn=False, torchscript=False, train_interpolation='random', train_split='train', tta=0, update_mode='', use_multi_epochs_loader=False, val_split='validation', validation_batch_size=None, vflip=0.0, warmup_epochs=30, warmup_lr=1e-10, weight_decay=0.01, workers=10, world_size=4)
INFO:Namespace(aa='rand-m7-mstd0.5-inc1', acceleration_all=True, acceleration_mode='win2', amp=True, apex_amp=False, aug_repeats=3, aug_splits=0, batch_size=512, bce_loss=True, bias_decay=False, bn_eps=None, bn_momentum=None, channels_last=False, checkpoint_hist=2, clip_grad=None, clip_mode='norm', color_jitter=0.4, configure='job_lamb_res101_7.yaml', cooldown_epochs=10, crop_pct=None, cutmix=1.0, cutmix_minmax=None, dampening=0.0, data_dir='/dataset/imagenet', dataset='', decay_epochs=100, decay_rate=0.1, device='cuda:2', dist_bn='reduce', distributed=True, drop=0.0, drop_block=None, drop_connect=None, drop_path=0.1, epoch_repeats=0.0, epochs=300, eval_metric='top1', experiment='resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0', gp=None, hflip=0.5, img_size=None, initial_checkpoint='', input_size=None, interpolation='', jsd_loss=False, local_rank=2, log_interval=50, log_wandb=False, lr=0.008, lr_cycle_decay=0.5, lr_cycle_limit=1, lr_cycle_mul=1.0, lr_k_decay=1.0, lr_mode='cos', lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, max_grad_norm=1.0, mean=None, min_lr=5e-05, mixup=0.1, mixup_mode='batch', mixup_off_epoch=0, mixup_prob=1.0, mixup_switch_prob=0.5, model='resnet101', model_ema=False, model_ema_decay=0.9998, model_ema_force_cpu=False, momentum=0.9, native_amp=False, no_aug=False, no_prefetcher=False, no_prox=False, no_resume_opt=False, num_classes=None, opt='lamb4', opt_betas=[0.9, 0.999, 2.0, 8.0], opt_eps=None, output='./exp_lamb_resnet101_6/', p=0.5, patience_epochs=10, pin_mem=False, prefetcher=True, pretrained=False, rank=2, ratio=[0.75, 1.3333333333333333], recount=1, recovery_interval=0, remode='pixel', reprob=0.0, resplit=False, resume='last.pth.tar', save_images=False, scale=[0.08, 1.0], sched='cosine', seed=42, smoothing=0.1, split_bn=False, start_epoch=None, std=None, sync_bn=False, torchscript=False, train_interpolation='random', train_split='train', tta=0, update_mode='', use_multi_epochs_loader=False, val_split='validation', validation_batch_size=None, vflip=0.0, warmup_epochs=30, warmup_lr=1e-10, weight_decay=0.01, workers=10, world_size=4)
INFO:Model resnet101 created, param count:44549160
INFO:Data processing configuration for current model + dataset:
INFO:	input_size: (3, 224, 224)
INFO:	interpolation: bicubic
INFO:	mean: (0.485, 0.456, 0.406)
INFO:	std: (0.229, 0.224, 0.225)
INFO:	crop_pct: 0.95
INFO:Lamb4 (
Parameter Group 0
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: no_acceleration
    trust_clip: False
    weight_decay: 0.0

Parameter Group 1
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: acceleration
    trust_clip: False
    weight_decay: 0.01
)
INFO:Using native Torch AMP. Training in mixed precision.
INFO:Using native Torch DistributedDataParallel.
INFO:Lamb4 (
Parameter Group 0
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: no_acceleration
    trust_clip: False
    weight_decay: 0.0

Parameter Group 1
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: acceleration
    trust_clip: False
    weight_decay: 0.01
)
INFO:Lamb4 (
Parameter Group 0
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: no_acceleration
    trust_clip: False
    weight_decay: 0.0

Parameter Group 1
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: acceleration
    trust_clip: False
    weight_decay: 0.01
)
INFO:Lamb4 (
Parameter Group 0
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: no_acceleration
    trust_clip: False
    weight_decay: 0.0

Parameter Group 1
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: acceleration
    trust_clip: False
    weight_decay: 0.01
)
INFO:Scheduled epochs: 310
INFO:Train: 0 [   0/625 (  0%)]  Loss: 0.6997 (0.700)  Time: 14.986s,  136.66/s  (14.986s,  136.66/s)  avg LR: 1.000e-10  iter ratio: 0.0000  Data: 6.091 (6.091)
INFO:Reducer buckets have been rebuilt in this iteration.
INFO:Reducer buckets have been rebuilt in this iteration.
INFO:Reducer buckets have been rebuilt in this iteration.
INFO:Reducer buckets have been rebuilt in this iteration.
INFO:Train: 0 [  50/625 (  8%)]  Loss: 0.7002 (0.700)  Time: 0.702s, 2915.33/s  (0.980s, 2089.48/s)  avg LR: 1.000e-10  iter ratio: 0.0000  Data: 0.025 (0.144)
INFO:Train: 0 [ 100/625 ( 16%)]  Loss: 0.6998 (0.700)  Time: 0.704s, 2911.03/s  (0.841s, 2433.75/s)  avg LR: 1.000e-10  iter ratio: 0.0000  Data: 0.027 (0.085)
INFO:Train: 0 [ 150/625 ( 24%)]  Loss: 0.6998 (0.700)  Time: 0.703s, 2913.44/s  (0.795s, 2577.14/s)  avg LR: 1.000e-10  iter ratio: 0.0000  Data: 0.024 (0.065)
INFO:Train: 0 [ 200/625 ( 32%)]  Loss: 0.6998 (0.700)  Time: 0.706s, 2902.17/s  (0.772s, 2654.44/s)  avg LR: 1.000e-10  iter ratio: 0.0000  Data: 0.022 (0.055)
INFO:Train: 0 [ 250/625 ( 40%)]  Loss: 0.6999 (0.700)  Time: 0.705s, 2903.48/s  (0.758s, 2703.15/s)  avg LR: 1.000e-10  iter ratio: 0.0000  Data: 0.022 (0.049)
INFO:Train: 0 [ 300/625 ( 48%)]  Loss: 0.6995 (0.700)  Time: 0.704s, 2910.42/s  (0.749s, 2735.99/s)  avg LR: 1.000e-10  iter ratio: 0.0000  Data: 0.023 (0.045)
INFO:Train: 0 [ 350/625 ( 56%)]  Loss: 0.6998 (0.700)  Time: 0.704s, 2908.79/s  (0.742s, 2760.69/s)  avg LR: 1.000e-10  iter ratio: 0.0000  Data: 0.024 (0.042)
INFO:Train: 0 [ 400/625 ( 64%)]  Loss: 0.6996 (0.700)  Time: 0.702s, 2915.35/s  (0.737s, 2779.39/s)  avg LR: 1.000e-10  iter ratio: 0.0000  Data: 0.022 (0.040)
INFO:Train: 0 [ 450/625 ( 72%)]  Loss: 0.7002 (0.700)  Time: 0.706s, 2902.68/s  (0.733s, 2794.19/s)  avg LR: 1.000e-10  iter ratio: 0.0000  Data: 0.024 (0.038)
INFO:Train: 0 [ 500/625 ( 80%)]  Loss: 0.7002 (0.700)  Time: 0.701s, 2920.53/s  (0.730s, 2806.07/s)  avg LR: 1.000e-10  iter ratio: 0.0000  Data: 0.023 (0.037)
INFO:Train: 0 [ 550/625 ( 88%)]  Loss: 0.6999 (0.700)  Time: 0.704s, 2908.12/s  (0.727s, 2815.97/s)  avg LR: 1.000e-10  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 0 [ 600/625 ( 96%)]  Loss: 0.6993 (0.700)  Time: 0.704s, 2909.22/s  (0.725s, 2824.32/s)  avg LR: 1.000e-10  iter ratio: 0.0000  Data: 0.023 (0.035)
INFO:Train: 0 [ 624/625 (100%)]  Loss: 0.6997 (0.700)  Time: 0.672s, 3049.59/s  (0.724s, 2828.21/s)  avg LR: 1.000e-10  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 7.013 (7.013)  Loss:  6.8906 (6.8906)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  1.0254 ( 1.0254)
INFO:Test: [  24/24]  Time: 0.688 (0.625)  Loss:  7.0000 (6.9406)  Acc@1:  0.0000 ( 0.0840)  Acc@5:  0.0000 ( 0.3960)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-0.pth.tar', 0.084)

INFO:0-epoch: remaining time 40.47 h
INFO:Train: 1 [   0/625 (  0%)]  Loss: 0.6998 (0.700)  Time: 4.126s,  496.34/s  (4.126s,  496.34/s)  avg LR: 2.667e-04  iter ratio: 0.0000  Data: 3.433 (3.433)
INFO:Train: 1 [  50/625 (  8%)]  Loss: 0.6038 (0.652)  Time: 0.698s, 2932.65/s  (0.775s, 2642.62/s)  avg LR: 2.667e-04  iter ratio: 0.0000  Data: 0.026 (0.094)
INFO:Train: 1 [ 100/625 ( 16%)]  Loss: 0.4998 (0.601)  Time: 0.699s, 2928.55/s  (0.738s, 2776.95/s)  avg LR: 2.667e-04  iter ratio: 0.0000  Data: 0.028 (0.060)
INFO:Train: 1 [ 150/625 ( 24%)]  Loss: 0.3897 (0.548)  Time: 0.698s, 2935.41/s  (0.725s, 2825.52/s)  avg LR: 2.667e-04  iter ratio: 0.0000  Data: 0.026 (0.049)
INFO:Train: 1 [ 200/625 ( 32%)]  Loss: 0.2850 (0.496)  Time: 0.697s, 2937.05/s  (0.718s, 2850.73/s)  avg LR: 2.667e-04  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 1 [ 250/625 ( 40%)]  Loss: 0.1973 (0.446)  Time: 0.702s, 2915.66/s  (0.715s, 2865.91/s)  avg LR: 2.667e-04  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 1 [ 300/625 ( 48%)]  Loss: 0.1311 (0.401)  Time: 0.699s, 2931.70/s  (0.712s, 2875.57/s)  avg LR: 2.667e-04  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 1 [ 350/625 ( 56%)]  Loss: 0.08590 (0.362)  Time: 0.698s, 2932.07/s  (0.710s, 2882.97/s)  avg LR: 2.667e-04  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 1 [ 400/625 ( 64%)]  Loss: 0.05548 (0.328)  Time: 0.698s, 2933.75/s  (0.709s, 2888.67/s)  avg LR: 2.667e-04  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 1 [ 450/625 ( 72%)]  Loss: 0.03643 (0.298)  Time: 0.700s, 2926.94/s  (0.708s, 2893.16/s)  avg LR: 2.667e-04  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 1 [ 500/625 ( 80%)]  Loss: 0.02493 (0.274)  Time: 0.698s, 2935.09/s  (0.707s, 2896.72/s)  avg LR: 2.667e-04  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 1 [ 550/625 ( 88%)]  Loss: 0.01765 (0.252)  Time: 0.698s, 2932.80/s  (0.706s, 2899.73/s)  avg LR: 2.667e-04  iter ratio: 0.0000  Data: 0.027 (0.032)
INFO:Train: 1 [ 600/625 ( 96%)]  Loss: 0.01349 (0.234)  Time: 0.701s, 2922.07/s  (0.706s, 2902.23/s)  avg LR: 2.667e-04  iter ratio: 0.0000  Data: 0.029 (0.032)
INFO:Train: 1 [ 624/625 (100%)]  Loss: 0.01193 (0.218)  Time: 0.671s, 3053.50/s  (0.705s, 2903.72/s)  avg LR: 2.667e-04  iter ratio: 0.0000  Data: 0.000 (0.031)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.428 (4.428)  Loss:  6.8945 (6.8945)  Acc@1:  0.1465 ( 0.1465)  Acc@5:  1.5625 ( 1.5625)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  6.9453 (6.9292)  Acc@1:  0.0000 ( 0.1580)  Acc@5:  0.0000 ( 0.6000)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-1.pth.tar', 0.158)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-0.pth.tar', 0.084)

INFO:1-epoch: remaining time 39.06 h
INFO:Train: 2 [   0/625 (  0%)]  Loss: 0.01200 (0.0120)  Time: 4.498s,  455.27/s  (4.498s,  455.27/s)  avg LR: 5.333e-04  iter ratio: 0.0000  Data: 3.555 (3.555)
INFO:Train: 2 [  50/625 (  8%)]  Loss: 0.008876 (0.0104)  Time: 0.699s, 2930.23/s  (0.774s, 2644.76/s)  avg LR: 5.333e-04  iter ratio: 0.0000  Data: 0.027 (0.096)
INFO:Train: 2 [ 100/625 ( 16%)]  Loss: 0.008067 (0.00965)  Time: 0.700s, 2925.25/s  (0.737s, 2778.84/s)  avg LR: 5.333e-04  iter ratio: 0.0000  Data: 0.025 (0.062)
INFO:Train: 2 [ 150/625 ( 24%)]  Loss: 0.008004 (0.00924)  Time: 0.700s, 2927.25/s  (0.725s, 2826.09/s)  avg LR: 5.333e-04  iter ratio: 0.0000  Data: 0.026 (0.050)
INFO:Train: 2 [ 200/625 ( 32%)]  Loss: 0.008002 (0.00899)  Time: 0.701s, 2921.36/s  (0.718s, 2850.59/s)  avg LR: 5.333e-04  iter ratio: 0.0000  Data: 0.026 (0.044)
INFO:Train: 2 [ 250/625 ( 40%)]  Loss: 0.007948 (0.00882)  Time: 0.701s, 2922.10/s  (0.715s, 2864.22/s)  avg LR: 5.333e-04  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 2 [ 300/625 ( 48%)]  Loss: 0.007947 (0.00869)  Time: 0.697s, 2937.29/s  (0.712s, 2874.56/s)  avg LR: 5.333e-04  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 2 [ 350/625 ( 56%)]  Loss: 0.007936 (0.00860)  Time: 0.697s, 2936.83/s  (0.711s, 2881.88/s)  avg LR: 5.333e-04  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 2 [ 400/625 ( 64%)]  Loss: 0.007926 (0.00852)  Time: 0.698s, 2932.58/s  (0.709s, 2887.52/s)  avg LR: 5.333e-04  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 2 [ 450/625 ( 72%)]  Loss: 0.007935 (0.00846)  Time: 0.698s, 2934.23/s  (0.708s, 2891.83/s)  avg LR: 5.333e-04  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 2 [ 500/625 ( 80%)]  Loss: 0.007943 (0.00842)  Time: 0.698s, 2935.26/s  (0.707s, 2895.47/s)  avg LR: 5.333e-04  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 2 [ 550/625 ( 88%)]  Loss: 0.007879 (0.00837)  Time: 0.699s, 2929.01/s  (0.707s, 2898.33/s)  avg LR: 5.333e-04  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 2 [ 600/625 ( 96%)]  Loss: 0.007849 (0.00833)  Time: 0.698s, 2936.18/s  (0.706s, 2900.84/s)  avg LR: 5.333e-04  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 2 [ 624/625 (100%)]  Loss: 0.007818 (0.00829)  Time: 0.669s, 3059.75/s  (0.706s, 2902.28/s)  avg LR: 5.333e-04  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.284 (4.284)  Loss:  6.2773 (6.2773)  Acc@1:  0.8301 ( 0.8301)  Acc@5:  9.0332 ( 9.0332)
INFO:Test: [  24/24]  Time: 0.079 (0.493)  Loss:  5.8984 (6.5200)  Acc@1:  8.7264 ( 1.1420)  Acc@5: 13.6792 ( 4.3280)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-2.pth.tar', 1.1420000091552733)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-1.pth.tar', 0.158)

INFO:2-epoch: remaining time 38.96 h
INFO:Train: 3 [   0/625 (  0%)]  Loss: 0.007770 (0.00777)  Time: 4.460s,  459.17/s  (4.460s,  459.17/s)  avg LR: 8.000e-04  iter ratio: 0.0000  Data: 3.775 (3.775)
INFO:Train: 3 [  50/625 (  8%)]  Loss: 0.007837 (0.00780)  Time: 0.701s, 2921.55/s  (0.774s, 2645.00/s)  avg LR: 8.000e-04  iter ratio: 0.0000  Data: 0.029 (0.101)
INFO:Train: 3 [ 100/625 ( 16%)]  Loss: 0.007668 (0.00776)  Time: 0.700s, 2925.37/s  (0.738s, 2775.65/s)  avg LR: 8.000e-04  iter ratio: 0.0000  Data: 0.027 (0.065)
INFO:Train: 3 [ 150/625 ( 24%)]  Loss: 0.007689 (0.00774)  Time: 0.700s, 2927.58/s  (0.726s, 2822.73/s)  avg LR: 8.000e-04  iter ratio: 0.0000  Data: 0.027 (0.052)
INFO:Train: 3 [ 200/625 ( 32%)]  Loss: 0.007647 (0.00772)  Time: 0.699s, 2928.82/s  (0.719s, 2847.45/s)  avg LR: 8.000e-04  iter ratio: 0.0000  Data: 0.027 (0.046)
INFO:Train: 3 [ 250/625 ( 40%)]  Loss: 0.007690 (0.00772)  Time: 0.700s, 2927.57/s  (0.715s, 2862.67/s)  avg LR: 8.000e-04  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 3 [ 300/625 ( 48%)]  Loss: 0.007537 (0.00769)  Time: 0.699s, 2931.52/s  (0.713s, 2873.06/s)  avg LR: 8.000e-04  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 3 [ 350/625 ( 56%)]  Loss: 0.007637 (0.00768)  Time: 0.699s, 2929.41/s  (0.711s, 2880.43/s)  avg LR: 8.000e-04  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 3 [ 400/625 ( 64%)]  Loss: 0.007568 (0.00767)  Time: 0.700s, 2926.59/s  (0.710s, 2886.05/s)  avg LR: 8.000e-04  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 3 [ 450/625 ( 72%)]  Loss: 0.007626 (0.00767)  Time: 0.699s, 2930.20/s  (0.708s, 2890.78/s)  avg LR: 8.000e-04  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 3 [ 500/625 ( 80%)]  Loss: 0.007603 (0.00766)  Time: 0.701s, 2922.66/s  (0.708s, 2894.56/s)  avg LR: 8.000e-04  iter ratio: 0.0000  Data: 0.029 (0.034)
INFO:Train: 3 [ 550/625 ( 88%)]  Loss: 0.007555 (0.00765)  Time: 0.709s, 2886.90/s  (0.707s, 2897.21/s)  avg LR: 8.000e-04  iter ratio: 0.0000  Data: 0.035 (0.033)
INFO:Train: 3 [ 600/625 ( 96%)]  Loss: 0.007285 (0.00762)  Time: 0.702s, 2919.26/s  (0.707s, 2898.76/s)  avg LR: 8.000e-04  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 3 [ 624/625 (100%)]  Loss: 0.007390 (0.00761)  Time: 0.672s, 3047.94/s  (0.706s, 2900.00/s)  avg LR: 8.000e-04  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.359 (4.359)  Loss:  5.7148 (5.7148)  Acc@1:  4.0039 ( 4.0039)  Acc@5: 13.2812 (13.2812)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  5.2266 (5.7603)  Acc@1: 15.6840 ( 3.8920)  Acc@5: 26.5330 (12.2520)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-3.pth.tar', 3.892000009460449)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-2.pth.tar', 1.1420000091552733)

INFO:3-epoch: remaining time 38.90 h
INFO:Train: 4 [   0/625 (  0%)]  Loss: 0.007306 (0.00731)  Time: 4.336s,  472.35/s  (4.336s,  472.35/s)  avg LR: 1.067e-03  iter ratio: 0.0000  Data: 3.419 (3.419)
INFO:Train: 4 [  50/625 (  8%)]  Loss: 0.007436 (0.00737)  Time: 0.697s, 2936.84/s  (0.772s, 2654.11/s)  avg LR: 1.067e-03  iter ratio: 0.0000  Data: 0.025 (0.094)
INFO:Train: 4 [ 100/625 ( 16%)]  Loss: 0.007250 (0.00733)  Time: 0.707s, 2896.82/s  (0.736s, 2783.07/s)  avg LR: 1.067e-03  iter ratio: 0.0000  Data: 0.024 (0.060)
INFO:Train: 4 [ 150/625 ( 24%)]  Loss: 0.007369 (0.00734)  Time: 0.698s, 2933.56/s  (0.724s, 2829.39/s)  avg LR: 1.067e-03  iter ratio: 0.0000  Data: 0.024 (0.049)
INFO:Train: 4 [ 200/625 ( 32%)]  Loss: 0.007415 (0.00736)  Time: 0.699s, 2928.85/s  (0.718s, 2852.96/s)  avg LR: 1.067e-03  iter ratio: 0.0000  Data: 0.026 (0.043)
INFO:Train: 4 [ 250/625 ( 40%)]  Loss: 0.007233 (0.00733)  Time: 0.698s, 2932.94/s  (0.714s, 2867.21/s)  avg LR: 1.067e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 4 [ 300/625 ( 48%)]  Loss: 0.007407 (0.00735)  Time: 0.700s, 2926.04/s  (0.712s, 2876.32/s)  avg LR: 1.067e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 4 [ 350/625 ( 56%)]  Loss: 0.007301 (0.00734)  Time: 0.699s, 2931.03/s  (0.711s, 2881.98/s)  avg LR: 1.067e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 4 [ 400/625 ( 64%)]  Loss: 0.007294 (0.00733)  Time: 0.699s, 2931.97/s  (0.709s, 2886.93/s)  avg LR: 1.067e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 4 [ 450/625 ( 72%)]  Loss: 0.007461 (0.00735)  Time: 0.698s, 2933.32/s  (0.708s, 2890.88/s)  avg LR: 1.067e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 4 [ 500/625 ( 80%)]  Loss: 0.007352 (0.00735)  Time: 0.697s, 2937.75/s  (0.708s, 2894.08/s)  avg LR: 1.067e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 4 [ 550/625 ( 88%)]  Loss: 0.007128 (0.00733)  Time: 0.697s, 2936.52/s  (0.707s, 2896.75/s)  avg LR: 1.067e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 4 [ 600/625 ( 96%)]  Loss: 0.007189 (0.00732)  Time: 0.698s, 2935.36/s  (0.706s, 2898.88/s)  avg LR: 1.067e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 4 [ 624/625 (100%)]  Loss: 0.007113 (0.00730)  Time: 0.672s, 3049.38/s  (0.706s, 2900.25/s)  avg LR: 1.067e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.300 (4.300)  Loss:  5.3594 (5.3594)  Acc@1:  5.8105 ( 5.8105)  Acc@5: 18.7500 (18.7500)
INFO:Test: [  24/24]  Time: 0.080 (0.493)  Loss:  4.6836 (5.3222)  Acc@1: 19.6934 ( 6.9440)  Acc@5: 34.0802 (19.5120)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-4.pth.tar', 6.943999989624023)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-3.pth.tar', 3.892000009460449)

INFO:4-epoch: remaining time 38.73 h
INFO:Train: 5 [   0/625 (  0%)]  Loss: 0.007353 (0.00735)  Time: 4.116s,  497.56/s  (4.116s,  497.56/s)  avg LR: 1.333e-03  iter ratio: 0.0000  Data: 3.433 (3.433)
INFO:Train: 5 [  50/625 (  8%)]  Loss: 0.006982 (0.00717)  Time: 0.700s, 2927.21/s  (0.767s, 2668.43/s)  avg LR: 1.333e-03  iter ratio: 0.0000  Data: 0.026 (0.094)
INFO:Train: 5 [ 100/625 ( 16%)]  Loss: 0.007031 (0.00712)  Time: 0.701s, 2922.46/s  (0.734s, 2789.26/s)  avg LR: 1.333e-03  iter ratio: 0.0000  Data: 0.028 (0.061)
INFO:Train: 5 [ 150/625 ( 24%)]  Loss: 0.007191 (0.00714)  Time: 0.699s, 2929.94/s  (0.723s, 2831.99/s)  avg LR: 1.333e-03  iter ratio: 0.0000  Data: 0.025 (0.050)
INFO:Train: 5 [ 200/625 ( 32%)]  Loss: 0.007234 (0.00716)  Time: 0.701s, 2922.84/s  (0.718s, 2853.88/s)  avg LR: 1.333e-03  iter ratio: 0.0000  Data: 0.027 (0.044)
INFO:Train: 5 [ 250/625 ( 40%)]  Loss: 0.006886 (0.00711)  Time: 0.702s, 2916.80/s  (0.714s, 2866.64/s)  avg LR: 1.333e-03  iter ratio: 0.0000  Data: 0.029 (0.041)
INFO:Train: 5 [ 300/625 ( 48%)]  Loss: 0.007037 (0.00710)  Time: 0.703s, 2911.78/s  (0.713s, 2874.31/s)  avg LR: 1.333e-03  iter ratio: 0.0000  Data: 0.033 (0.039)
INFO:Train: 5 [ 350/625 ( 56%)]  Loss: 0.006742 (0.00706)  Time: 0.711s, 2882.23/s  (0.711s, 2879.86/s)  avg LR: 1.333e-03  iter ratio: 0.0000  Data: 0.039 (0.038)
INFO:Train: 5 [ 400/625 ( 64%)]  Loss: 0.007064 (0.00706)  Time: 0.701s, 2920.04/s  (0.710s, 2884.12/s)  avg LR: 1.333e-03  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 5 [ 450/625 ( 72%)]  Loss: 0.007073 (0.00706)  Time: 0.702s, 2917.60/s  (0.709s, 2887.40/s)  avg LR: 1.333e-03  iter ratio: 0.0000  Data: 0.031 (0.036)
INFO:Train: 5 [ 500/625 ( 80%)]  Loss: 0.007048 (0.00706)  Time: 0.701s, 2921.15/s  (0.709s, 2890.13/s)  avg LR: 1.333e-03  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 5 [ 550/625 ( 88%)]  Loss: 0.007142 (0.00707)  Time: 0.702s, 2915.76/s  (0.708s, 2892.33/s)  avg LR: 1.333e-03  iter ratio: 0.0000  Data: 0.030 (0.035)
INFO:Train: 5 [ 600/625 ( 96%)]  Loss: 0.006976 (0.00706)  Time: 0.703s, 2915.07/s  (0.708s, 2894.13/s)  avg LR: 1.333e-03  iter ratio: 0.0000  Data: 0.032 (0.035)
INFO:Train: 5 [ 624/625 (100%)]  Loss: 0.006849 (0.00704)  Time: 0.672s, 3048.84/s  (0.707s, 2895.35/s)  avg LR: 1.333e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.350 (4.350)  Loss:  4.5938 (4.5938)  Acc@1: 12.1582 (12.1582)  Acc@5: 32.6172 (32.6172)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  3.5898 (4.8607)  Acc@1: 33.4906 (10.5800)  Acc@5: 53.1840 (27.2520)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-5.pth.tar', 10.580000068359375)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-4.pth.tar', 6.943999989624023)

INFO:5-epoch: remaining time 38.70 h
INFO:Train: 6 [   0/625 (  0%)]  Loss: 0.007123 (0.00712)  Time: 4.371s,  468.52/s  (4.371s,  468.52/s)  avg LR: 1.600e-03  iter ratio: 0.0000  Data: 3.464 (3.464)
INFO:Train: 6 [  50/625 (  8%)]  Loss: 0.007109 (0.00712)  Time: 0.698s, 2932.67/s  (0.775s, 2642.27/s)  avg LR: 1.600e-03  iter ratio: 0.0000  Data: 0.022 (0.092)
INFO:Train: 6 [ 100/625 ( 16%)]  Loss: 0.006607 (0.00695)  Time: 0.706s, 2902.81/s  (0.739s, 2770.32/s)  avg LR: 1.600e-03  iter ratio: 0.0000  Data: 0.021 (0.058)
INFO:Train: 6 [ 150/625 ( 24%)]  Loss: 0.007060 (0.00697)  Time: 0.697s, 2937.34/s  (0.727s, 2815.46/s)  avg LR: 1.600e-03  iter ratio: 0.0000  Data: 0.026 (0.048)
INFO:Train: 6 [ 200/625 ( 32%)]  Loss: 0.006976 (0.00698)  Time: 0.697s, 2939.70/s  (0.721s, 2839.69/s)  avg LR: 1.600e-03  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 6 [ 250/625 ( 40%)]  Loss: 0.006807 (0.00695)  Time: 0.699s, 2930.17/s  (0.717s, 2855.03/s)  avg LR: 1.600e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 6 [ 300/625 ( 48%)]  Loss: 0.006968 (0.00695)  Time: 0.698s, 2934.42/s  (0.715s, 2865.03/s)  avg LR: 1.600e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 6 [ 350/625 ( 56%)]  Loss: 0.006677 (0.00692)  Time: 0.697s, 2938.04/s  (0.713s, 2872.24/s)  avg LR: 1.600e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 6 [ 400/625 ( 64%)]  Loss: 0.006633 (0.00688)  Time: 0.698s, 2932.92/s  (0.712s, 2877.89/s)  avg LR: 1.600e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 6 [ 450/625 ( 72%)]  Loss: 0.007019 (0.00690)  Time: 0.697s, 2938.13/s  (0.711s, 2882.29/s)  avg LR: 1.600e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 6 [ 500/625 ( 80%)]  Loss: 0.006697 (0.00688)  Time: 0.698s, 2936.16/s  (0.710s, 2885.90/s)  avg LR: 1.600e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 6 [ 550/625 ( 88%)]  Loss: 0.007107 (0.00690)  Time: 0.696s, 2941.36/s  (0.709s, 2888.79/s)  avg LR: 1.600e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 6 [ 600/625 ( 96%)]  Loss: 0.006816 (0.00689)  Time: 0.698s, 2933.00/s  (0.708s, 2891.14/s)  avg LR: 1.600e-03  iter ratio: 0.0000  Data: 0.027 (0.032)
INFO:Train: 6 [ 624/625 (100%)]  Loss: 0.006711 (0.00688)  Time: 0.672s, 3048.68/s  (0.708s, 2892.57/s)  avg LR: 1.600e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.280 (4.280)  Loss:  4.0156 (4.0156)  Acc@1: 20.7520 (20.7520)  Acc@5: 44.9707 (44.9707)
INFO:Test: [  24/24]  Time: 0.079 (0.493)  Loss:  3.3555 (4.3235)  Acc@1: 39.5047 (16.6640)  Acc@5: 57.6651 (38.0780)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-6.pth.tar', 16.664000030517577)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-5.pth.tar', 10.580000068359375)

INFO:6-epoch: remaining time 38.57 h
INFO:Train: 7 [   0/625 (  0%)]  Loss: 0.006799 (0.00680)  Time: 4.112s,  498.10/s  (4.112s,  498.10/s)  avg LR: 1.867e-03  iter ratio: 0.0000  Data: 3.424 (3.424)
INFO:Train: 7 [  50/625 (  8%)]  Loss: 0.006920 (0.00686)  Time: 0.698s, 2934.75/s  (0.769s, 2663.21/s)  avg LR: 1.867e-03  iter ratio: 0.0000  Data: 0.024 (0.095)
INFO:Train: 7 [ 100/625 ( 16%)]  Loss: 0.006589 (0.00677)  Time: 0.701s, 2922.46/s  (0.736s, 2783.18/s)  avg LR: 1.867e-03  iter ratio: 0.0000  Data: 0.026 (0.062)
INFO:Train: 7 [ 150/625 ( 24%)]  Loss: 0.006535 (0.00671)  Time: 0.699s, 2930.27/s  (0.725s, 2825.93/s)  avg LR: 1.867e-03  iter ratio: 0.0000  Data: 0.025 (0.051)
INFO:Train: 7 [ 200/625 ( 32%)]  Loss: 0.006498 (0.00667)  Time: 0.699s, 2930.41/s  (0.719s, 2847.90/s)  avg LR: 1.867e-03  iter ratio: 0.0000  Data: 0.025 (0.045)
INFO:Train: 7 [ 250/625 ( 40%)]  Loss: 0.006115 (0.00658)  Time: 0.700s, 2924.37/s  (0.716s, 2861.29/s)  avg LR: 1.867e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 7 [ 300/625 ( 48%)]  Loss: 0.006829 (0.00661)  Time: 0.699s, 2931.77/s  (0.714s, 2870.08/s)  avg LR: 1.867e-03  iter ratio: 0.0000  Data: 0.025 (0.040)
INFO:Train: 7 [ 350/625 ( 56%)]  Loss: 0.006797 (0.00664)  Time: 0.699s, 2930.71/s  (0.712s, 2876.61/s)  avg LR: 1.867e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 7 [ 400/625 ( 64%)]  Loss: 0.006117 (0.00658)  Time: 0.699s, 2931.33/s  (0.711s, 2881.51/s)  avg LR: 1.867e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 7 [ 450/625 ( 72%)]  Loss: 0.006421 (0.00656)  Time: 0.699s, 2929.96/s  (0.710s, 2885.30/s)  avg LR: 1.867e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 7 [ 500/625 ( 80%)]  Loss: 0.006762 (0.00658)  Time: 0.703s, 2914.44/s  (0.709s, 2888.38/s)  avg LR: 1.867e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 7 [ 550/625 ( 88%)]  Loss: 0.007069 (0.00662)  Time: 0.700s, 2927.31/s  (0.708s, 2890.89/s)  avg LR: 1.867e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 7 [ 600/625 ( 96%)]  Loss: 0.006188 (0.00659)  Time: 0.699s, 2929.72/s  (0.708s, 2893.06/s)  avg LR: 1.867e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 7 [ 624/625 (100%)]  Loss: 0.006401 (0.00657)  Time: 0.672s, 3047.36/s  (0.708s, 2894.46/s)  avg LR: 1.867e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.355 (4.355)  Loss:  3.5059 (3.5059)  Acc@1: 25.5371 (25.5371)  Acc@5: 51.5625 (51.5625)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  2.7539 (3.9277)  Acc@1: 44.9292 (21.5180)  Acc@5: 66.1557 (44.7660)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-7.pth.tar', 21.517999995117187)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-6.pth.tar', 16.664000030517577)

INFO:7-epoch: remaining time 38.46 h
INFO:Train: 8 [   0/625 (  0%)]  Loss: 0.006651 (0.00665)  Time: 4.451s,  460.14/s  (4.451s,  460.14/s)  avg LR: 2.133e-03  iter ratio: 0.0000  Data: 3.541 (3.541)
INFO:Train: 8 [  50/625 (  8%)]  Loss: 0.006188 (0.00642)  Time: 0.699s, 2930.78/s  (0.776s, 2638.81/s)  avg LR: 2.133e-03  iter ratio: 0.0000  Data: 0.022 (0.097)
INFO:Train: 8 [ 100/625 ( 16%)]  Loss: 0.006242 (0.00636)  Time: 0.698s, 2934.23/s  (0.740s, 2769.06/s)  avg LR: 2.133e-03  iter ratio: 0.0000  Data: 0.023 (0.063)
INFO:Train: 8 [ 150/625 ( 24%)]  Loss: 0.006876 (0.00649)  Time: 0.699s, 2930.74/s  (0.727s, 2815.95/s)  avg LR: 2.133e-03  iter ratio: 0.0000  Data: 0.025 (0.051)
INFO:Train: 8 [ 200/625 ( 32%)]  Loss: 0.006182 (0.00643)  Time: 0.698s, 2935.88/s  (0.721s, 2839.76/s)  avg LR: 2.133e-03  iter ratio: 0.0000  Data: 0.025 (0.045)
INFO:Train: 8 [ 250/625 ( 40%)]  Loss: 0.006063 (0.00637)  Time: 0.699s, 2930.37/s  (0.718s, 2853.87/s)  avg LR: 2.133e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 8 [ 300/625 ( 48%)]  Loss: 0.006050 (0.00632)  Time: 0.699s, 2929.78/s  (0.715s, 2864.09/s)  avg LR: 2.133e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 8 [ 350/625 ( 56%)]  Loss: 0.006675 (0.00637)  Time: 0.699s, 2927.97/s  (0.713s, 2870.89/s)  avg LR: 2.133e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 8 [ 400/625 ( 64%)]  Loss: 0.006321 (0.00636)  Time: 0.699s, 2928.71/s  (0.712s, 2876.57/s)  avg LR: 2.133e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 8 [ 450/625 ( 72%)]  Loss: 0.005677 (0.00629)  Time: 0.699s, 2931.50/s  (0.711s, 2880.84/s)  avg LR: 2.133e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 8 [ 500/625 ( 80%)]  Loss: 0.006292 (0.00629)  Time: 0.699s, 2930.88/s  (0.710s, 2884.31/s)  avg LR: 2.133e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 8 [ 550/625 ( 88%)]  Loss: 0.006148 (0.00628)  Time: 0.700s, 2927.80/s  (0.709s, 2887.12/s)  avg LR: 2.133e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 8 [ 600/625 ( 96%)]  Loss: 0.006011 (0.00626)  Time: 0.701s, 2921.36/s  (0.709s, 2889.31/s)  avg LR: 2.133e-03  iter ratio: 0.0000  Data: 0.022 (0.034)
INFO:Train: 8 [ 624/625 (100%)]  Loss: 0.006329 (0.00626)  Time: 0.672s, 3047.44/s  (0.709s, 2890.36/s)  avg LR: 2.133e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.311 (4.311)  Loss:  3.3828 (3.3828)  Acc@1: 29.3945 (29.3945)  Acc@5: 57.6660 (57.6660)
INFO:Test: [  24/24]  Time: 0.079 (0.493)  Loss:  2.7969 (3.7321)  Acc@1: 45.2830 (24.0680)  Acc@5: 63.4434 (49.1420)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-8.pth.tar', 24.067999954833983)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-7.pth.tar', 21.517999995117187)

INFO:8-epoch: remaining time 38.36 h
INFO:Train: 9 [   0/625 (  0%)]  Loss: 0.005859 (0.00586)  Time: 4.429s,  462.40/s  (4.429s,  462.40/s)  avg LR: 2.400e-03  iter ratio: 0.0000  Data: 3.744 (3.744)
INFO:Train: 9 [  50/625 (  8%)]  Loss: 0.005917 (0.00589)  Time: 0.698s, 2932.22/s  (0.775s, 2644.21/s)  avg LR: 2.400e-03  iter ratio: 0.0000  Data: 0.026 (0.100)
INFO:Train: 9 [ 100/625 ( 16%)]  Loss: 0.006268 (0.00601)  Time: 0.699s, 2927.94/s  (0.738s, 2776.92/s)  avg LR: 2.400e-03  iter ratio: 0.0000  Data: 0.029 (0.064)
INFO:Train: 9 [ 150/625 ( 24%)]  Loss: 0.006284 (0.00608)  Time: 0.697s, 2939.24/s  (0.725s, 2825.18/s)  avg LR: 2.400e-03  iter ratio: 0.0000  Data: 0.026 (0.052)
INFO:Train: 9 [ 200/625 ( 32%)]  Loss: 0.006681 (0.00620)  Time: 0.698s, 2933.75/s  (0.719s, 2849.89/s)  avg LR: 2.400e-03  iter ratio: 0.0000  Data: 0.027 (0.046)
INFO:Train: 9 [ 250/625 ( 40%)]  Loss: 0.005920 (0.00615)  Time: 0.700s, 2926.65/s  (0.715s, 2863.61/s)  avg LR: 2.400e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 9 [ 300/625 ( 48%)]  Loss: 0.005975 (0.00613)  Time: 0.699s, 2929.46/s  (0.713s, 2873.38/s)  avg LR: 2.400e-03  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 9 [ 350/625 ( 56%)]  Loss: 0.006261 (0.00615)  Time: 0.700s, 2926.91/s  (0.711s, 2880.20/s)  avg LR: 2.400e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 9 [ 400/625 ( 64%)]  Loss: 0.006652 (0.00620)  Time: 0.699s, 2930.90/s  (0.710s, 2885.41/s)  avg LR: 2.400e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 9 [ 450/625 ( 72%)]  Loss: 0.006388 (0.00622)  Time: 0.700s, 2925.72/s  (0.709s, 2889.33/s)  avg LR: 2.400e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 9 [ 500/625 ( 80%)]  Loss: 0.005906 (0.00619)  Time: 0.700s, 2927.00/s  (0.708s, 2892.59/s)  avg LR: 2.400e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 9 [ 550/625 ( 88%)]  Loss: 0.005950 (0.00617)  Time: 0.701s, 2921.77/s  (0.707s, 2895.09/s)  avg LR: 2.400e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 9 [ 600/625 ( 96%)]  Loss: 0.005892 (0.00615)  Time: 0.699s, 2929.43/s  (0.707s, 2897.33/s)  avg LR: 2.400e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 9 [ 624/625 (100%)]  Loss: 0.005740 (0.00612)  Time: 0.671s, 3053.49/s  (0.706s, 2898.81/s)  avg LR: 2.400e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.341 (4.341)  Loss:  2.9844 (2.9844)  Acc@1: 35.1562 (35.1562)  Acc@5: 66.0156 (66.0156)
INFO:Test: [  24/24]  Time: 0.080 (0.500)  Loss:  2.4609 (3.4589)  Acc@1: 52.2406 (29.0380)  Acc@5: 69.6934 (55.7400)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-9.pth.tar', 29.038000068359374)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-8.pth.tar', 24.067999954833983)

INFO:9-epoch: remaining time 38.12 h
INFO:Train: 10 [   0/625 (  0%)]  Loss: 0.006111 (0.00611)  Time: 4.500s,  455.10/s  (4.500s,  455.10/s)  avg LR: 2.667e-03  iter ratio: 0.0000  Data: 3.586 (3.586)
INFO:Train: 10 [  50/625 (  8%)]  Loss: 0.006188 (0.00615)  Time: 0.700s, 2925.34/s  (0.778s, 2630.83/s)  avg LR: 2.667e-03  iter ratio: 0.0000  Data: 0.025 (0.098)
INFO:Train: 10 [ 100/625 ( 16%)]  Loss: 0.006180 (0.00616)  Time: 0.700s, 2927.42/s  (0.741s, 2763.34/s)  avg LR: 2.667e-03  iter ratio: 0.0000  Data: 0.025 (0.063)
INFO:Train: 10 [ 150/625 ( 24%)]  Loss: 0.006067 (0.00614)  Time: 0.700s, 2925.42/s  (0.729s, 2811.19/s)  avg LR: 2.667e-03  iter ratio: 0.0000  Data: 0.025 (0.052)
INFO:Train: 10 [ 200/625 ( 32%)]  Loss: 0.005401 (0.00599)  Time: 0.699s, 2928.14/s  (0.722s, 2835.74/s)  avg LR: 2.667e-03  iter ratio: 0.0000  Data: 0.025 (0.046)
INFO:Train: 10 [ 250/625 ( 40%)]  Loss: 0.005681 (0.00594)  Time: 0.701s, 2921.61/s  (0.718s, 2850.70/s)  avg LR: 2.667e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 10 [ 300/625 ( 48%)]  Loss: 0.006108 (0.00596)  Time: 0.701s, 2923.15/s  (0.716s, 2860.62/s)  avg LR: 2.667e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 10 [ 350/625 ( 56%)]  Loss: 0.006249 (0.00600)  Time: 0.701s, 2920.27/s  (0.714s, 2867.75/s)  avg LR: 2.667e-03  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 10 [ 400/625 ( 64%)]  Loss: 0.006624 (0.00607)  Time: 0.700s, 2925.73/s  (0.713s, 2872.98/s)  avg LR: 2.667e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 10 [ 450/625 ( 72%)]  Loss: 0.005673 (0.00603)  Time: 0.700s, 2927.37/s  (0.712s, 2877.08/s)  avg LR: 2.667e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 10 [ 500/625 ( 80%)]  Loss: 0.005862 (0.00601)  Time: 0.702s, 2917.82/s  (0.711s, 2880.07/s)  avg LR: 2.667e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 10 [ 550/625 ( 88%)]  Loss: 0.005503 (0.00597)  Time: 0.701s, 2920.25/s  (0.710s, 2883.01/s)  avg LR: 2.667e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 10 [ 600/625 ( 96%)]  Loss: 0.006211 (0.00599)  Time: 0.701s, 2922.88/s  (0.710s, 2885.41/s)  avg LR: 2.667e-03  iter ratio: 0.0000  Data: 0.023 (0.034)
INFO:Train: 10 [ 624/625 (100%)]  Loss: 0.005331 (0.00594)  Time: 0.672s, 3048.80/s  (0.709s, 2886.84/s)  avg LR: 2.667e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.317 (4.317)  Loss:  2.4766 (2.4766)  Acc@1: 44.9707 (44.9707)  Acc@5: 74.2188 (74.2188)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  1.8750 (3.2976)  Acc@1: 62.3821 (32.3000)  Acc@5: 79.9528 (59.0100)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-10.pth.tar', 32.300000013427734)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-9.pth.tar', 29.038000068359374)

INFO:10-epoch: remaining time 38.18 h
INFO:Train: 11 [   0/625 (  0%)]  Loss: 0.006238 (0.00624)  Time: 4.106s,  498.82/s  (4.106s,  498.82/s)  avg LR: 2.933e-03  iter ratio: 0.0000  Data: 3.418 (3.418)
INFO:Train: 11 [  50/625 (  8%)]  Loss: 0.005701 (0.00597)  Time: 0.700s, 2926.07/s  (0.767s, 2670.29/s)  avg LR: 2.933e-03  iter ratio: 0.0000  Data: 0.027 (0.092)
INFO:Train: 11 [ 100/625 ( 16%)]  Loss: 0.005981 (0.00597)  Time: 0.699s, 2930.51/s  (0.734s, 2789.71/s)  avg LR: 2.933e-03  iter ratio: 0.0000  Data: 0.026 (0.060)
INFO:Train: 11 [ 150/625 ( 24%)]  Loss: 0.006028 (0.00599)  Time: 0.700s, 2926.97/s  (0.723s, 2831.94/s)  avg LR: 2.933e-03  iter ratio: 0.0000  Data: 0.028 (0.049)
INFO:Train: 11 [ 200/625 ( 32%)]  Loss: 0.005715 (0.00593)  Time: 0.701s, 2922.41/s  (0.718s, 2853.58/s)  avg LR: 2.933e-03  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 11 [ 250/625 ( 40%)]  Loss: 0.005490 (0.00586)  Time: 0.701s, 2922.66/s  (0.714s, 2866.95/s)  avg LR: 2.933e-03  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 11 [ 300/625 ( 48%)]  Loss: 0.005776 (0.00585)  Time: 0.700s, 2924.04/s  (0.712s, 2876.19/s)  avg LR: 2.933e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 11 [ 350/625 ( 56%)]  Loss: 0.006277 (0.00590)  Time: 0.699s, 2928.80/s  (0.711s, 2881.16/s)  avg LR: 2.933e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 11 [ 400/625 ( 64%)]  Loss: 0.005466 (0.00585)  Time: 0.700s, 2925.34/s  (0.710s, 2885.54/s)  avg LR: 2.933e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 11 [ 450/625 ( 72%)]  Loss: 0.005292 (0.00580)  Time: 0.699s, 2928.28/s  (0.709s, 2888.94/s)  avg LR: 2.933e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 11 [ 500/625 ( 80%)]  Loss: 0.005515 (0.00577)  Time: 0.699s, 2928.69/s  (0.708s, 2891.65/s)  avg LR: 2.933e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 11 [ 550/625 ( 88%)]  Loss: 0.005852 (0.00578)  Time: 0.700s, 2925.00/s  (0.708s, 2893.87/s)  avg LR: 2.933e-03  iter ratio: 0.0000  Data: 0.029 (0.034)
INFO:Train: 11 [ 600/625 ( 96%)]  Loss: 0.005897 (0.00579)  Time: 0.698s, 2935.72/s  (0.707s, 2895.66/s)  avg LR: 2.933e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 11 [ 624/625 (100%)]  Loss: 0.005543 (0.00577)  Time: 0.671s, 3053.00/s  (0.707s, 2897.09/s)  avg LR: 2.933e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.357 (4.357)  Loss:  2.1543 (2.1543)  Acc@1: 51.0742 (51.0742)  Acc@5: 78.2227 (78.2227)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  2.1973 (2.9828)  Acc@1: 55.7783 (36.2260)  Acc@5: 74.1745 (63.0700)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-11.pth.tar', 36.22600005371094)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-10.pth.tar', 32.300000013427734)

INFO:11-epoch: remaining time 37.88 h
INFO:Train: 12 [   0/625 (  0%)]  Loss: 0.005819 (0.00582)  Time: 4.171s,  490.97/s  (4.171s,  490.97/s)  avg LR: 3.200e-03  iter ratio: 0.0000  Data: 3.261 (3.261)
INFO:Train: 12 [  50/625 (  8%)]  Loss: 0.005454 (0.00564)  Time: 0.697s, 2937.39/s  (0.768s, 2666.12/s)  avg LR: 3.200e-03  iter ratio: 0.0000  Data: 0.024 (0.089)
INFO:Train: 12 [ 100/625 ( 16%)]  Loss: 0.006204 (0.00583)  Time: 0.698s, 2932.14/s  (0.735s, 2786.85/s)  avg LR: 3.200e-03  iter ratio: 0.0000  Data: 0.023 (0.058)
INFO:Train: 12 [ 150/625 ( 24%)]  Loss: 0.005857 (0.00583)  Time: 0.700s, 2927.78/s  (0.724s, 2830.42/s)  avg LR: 3.200e-03  iter ratio: 0.0000  Data: 0.021 (0.047)
INFO:Train: 12 [ 200/625 ( 32%)]  Loss: 0.005189 (0.00570)  Time: 0.698s, 2932.99/s  (0.718s, 2852.92/s)  avg LR: 3.200e-03  iter ratio: 0.0000  Data: 0.024 (0.042)
INFO:Train: 12 [ 250/625 ( 40%)]  Loss: 0.005828 (0.00573)  Time: 0.701s, 2921.55/s  (0.715s, 2865.02/s)  avg LR: 3.200e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 12 [ 300/625 ( 48%)]  Loss: 0.005898 (0.00575)  Time: 0.701s, 2922.48/s  (0.713s, 2873.34/s)  avg LR: 3.200e-03  iter ratio: 0.0000  Data: 0.024 (0.037)
INFO:Train: 12 [ 350/625 ( 56%)]  Loss: 0.005052 (0.00566)  Time: 0.701s, 2920.44/s  (0.711s, 2878.68/s)  avg LR: 3.200e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 12 [ 400/625 ( 64%)]  Loss: 0.005675 (0.00566)  Time: 0.699s, 2929.21/s  (0.710s, 2882.63/s)  avg LR: 3.200e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 12 [ 450/625 ( 72%)]  Loss: 0.005805 (0.00568)  Time: 0.700s, 2924.11/s  (0.710s, 2886.29/s)  avg LR: 3.200e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 12 [ 500/625 ( 80%)]  Loss: 0.005618 (0.00567)  Time: 0.698s, 2932.23/s  (0.709s, 2889.64/s)  avg LR: 3.200e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 12 [ 550/625 ( 88%)]  Loss: 0.005657 (0.00567)  Time: 0.700s, 2926.01/s  (0.708s, 2892.38/s)  avg LR: 3.200e-03  iter ratio: 0.0000  Data: 0.025 (0.032)
INFO:Train: 12 [ 600/625 ( 96%)]  Loss: 0.005315 (0.00564)  Time: 0.699s, 2928.51/s  (0.708s, 2894.54/s)  avg LR: 3.200e-03  iter ratio: 0.0000  Data: 0.024 (0.032)
INFO:Train: 12 [ 624/625 (100%)]  Loss: 0.006167 (0.00568)  Time: 0.672s, 3048.06/s  (0.707s, 2895.82/s)  avg LR: 3.200e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.339 (4.339)  Loss:  2.2812 (2.2812)  Acc@1: 49.6582 (49.6582)  Acc@5: 76.5137 (76.5137)
INFO:Test: [  24/24]  Time: 0.079 (0.495)  Loss:  1.8516 (2.8916)  Acc@1: 61.2028 (38.5240)  Acc@5: 80.6604 (65.3080)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-12.pth.tar', 38.524000018310545)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-11.pth.tar', 36.22600005371094)

INFO:12-epoch: remaining time 37.77 h
INFO:Train: 13 [   0/625 (  0%)]  Loss: 0.005374 (0.00537)  Time: 4.327s,  473.34/s  (4.327s,  473.34/s)  avg LR: 3.467e-03  iter ratio: 0.0000  Data: 3.638 (3.638)
INFO:Train: 13 [  50/625 (  8%)]  Loss: 0.005500 (0.00544)  Time: 0.700s, 2926.46/s  (0.771s, 2656.02/s)  avg LR: 3.467e-03  iter ratio: 0.0000  Data: 0.026 (0.098)
INFO:Train: 13 [ 100/625 ( 16%)]  Loss: 0.005736 (0.00554)  Time: 0.703s, 2913.69/s  (0.736s, 2782.62/s)  avg LR: 3.467e-03  iter ratio: 0.0000  Data: 0.025 (0.062)
INFO:Train: 13 [ 150/625 ( 24%)]  Loss: 0.004909 (0.00538)  Time: 0.701s, 2921.70/s  (0.724s, 2828.19/s)  avg LR: 3.467e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 13 [ 200/625 ( 32%)]  Loss: 0.005836 (0.00547)  Time: 0.698s, 2932.82/s  (0.718s, 2851.54/s)  avg LR: 3.467e-03  iter ratio: 0.0000  Data: 0.025 (0.045)
INFO:Train: 13 [ 250/625 ( 40%)]  Loss: 0.005767 (0.00552)  Time: 0.699s, 2929.73/s  (0.715s, 2866.03/s)  avg LR: 3.467e-03  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 13 [ 300/625 ( 48%)]  Loss: 0.005273 (0.00549)  Time: 0.699s, 2931.48/s  (0.712s, 2875.70/s)  avg LR: 3.467e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 13 [ 350/625 ( 56%)]  Loss: 0.005800 (0.00552)  Time: 0.700s, 2923.92/s  (0.710s, 2882.70/s)  avg LR: 3.467e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 13 [ 400/625 ( 64%)]  Loss: 0.005436 (0.00551)  Time: 0.705s, 2905.41/s  (0.709s, 2887.70/s)  avg LR: 3.467e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 13 [ 450/625 ( 72%)]  Loss: 0.005510 (0.00551)  Time: 0.699s, 2928.85/s  (0.708s, 2891.82/s)  avg LR: 3.467e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 13 [ 500/625 ( 80%)]  Loss: 0.005131 (0.00548)  Time: 0.703s, 2911.74/s  (0.707s, 2895.12/s)  avg LR: 3.467e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 13 [ 550/625 ( 88%)]  Loss: 0.005421 (0.00547)  Time: 0.703s, 2912.59/s  (0.707s, 2897.74/s)  avg LR: 3.467e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 13 [ 600/625 ( 96%)]  Loss: 0.005946 (0.00551)  Time: 0.698s, 2935.65/s  (0.706s, 2899.95/s)  avg LR: 3.467e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 13 [ 624/625 (100%)]  Loss: 0.006015 (0.00555)  Time: 0.672s, 3047.07/s  (0.706s, 2901.35/s)  avg LR: 3.467e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.377 (4.377)  Loss:  2.0352 (2.0352)  Acc@1: 53.6621 (53.6621)  Acc@5: 78.1738 (78.1738)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  1.6348 (2.6682)  Acc@1: 63.3255 (41.0480)  Acc@5: 82.4292 (68.4400)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-13.pth.tar', 41.047999970703124)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-12.pth.tar', 38.524000018310545)

INFO:13-epoch: remaining time 37.58 h
INFO:Train: 14 [   0/625 (  0%)]  Loss: 0.005374 (0.00537)  Time: 4.672s,  438.31/s  (4.672s,  438.31/s)  avg LR: 3.733e-03  iter ratio: 0.0000  Data: 3.756 (3.756)
INFO:Train: 14 [  50/625 (  8%)]  Loss: 0.006075 (0.00572)  Time: 0.696s, 2940.49/s  (0.778s, 2631.08/s)  avg LR: 3.733e-03  iter ratio: 0.0000  Data: 0.024 (0.100)
INFO:Train: 14 [ 100/625 ( 16%)]  Loss: 0.005086 (0.00551)  Time: 0.697s, 2938.18/s  (0.740s, 2769.00/s)  avg LR: 3.733e-03  iter ratio: 0.0000  Data: 0.026 (0.063)
INFO:Train: 14 [ 150/625 ( 24%)]  Loss: 0.005167 (0.00543)  Time: 0.698s, 2933.32/s  (0.727s, 2818.80/s)  avg LR: 3.733e-03  iter ratio: 0.0000  Data: 0.025 (0.051)
INFO:Train: 14 [ 200/625 ( 32%)]  Loss: 0.005342 (0.00541)  Time: 0.697s, 2938.90/s  (0.720s, 2844.74/s)  avg LR: 3.733e-03  iter ratio: 0.0000  Data: 0.024 (0.045)
INFO:Train: 14 [ 250/625 ( 40%)]  Loss: 0.005842 (0.00548)  Time: 0.700s, 2927.79/s  (0.716s, 2860.19/s)  avg LR: 3.733e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 14 [ 300/625 ( 48%)]  Loss: 0.005528 (0.00549)  Time: 0.699s, 2929.13/s  (0.714s, 2870.34/s)  avg LR: 3.733e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 14 [ 350/625 ( 56%)]  Loss: 0.005054 (0.00543)  Time: 0.707s, 2896.18/s  (0.712s, 2877.40/s)  avg LR: 3.733e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 14 [ 400/625 ( 64%)]  Loss: 0.005106 (0.00540)  Time: 0.699s, 2931.63/s  (0.710s, 2882.70/s)  avg LR: 3.733e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 14 [ 450/625 ( 72%)]  Loss: 0.005761 (0.00543)  Time: 0.700s, 2923.71/s  (0.709s, 2887.22/s)  avg LR: 3.733e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 14 [ 500/625 ( 80%)]  Loss: 0.005211 (0.00541)  Time: 0.699s, 2931.19/s  (0.708s, 2891.01/s)  avg LR: 3.733e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 14 [ 550/625 ( 88%)]  Loss: 0.005222 (0.00540)  Time: 0.699s, 2931.94/s  (0.708s, 2893.87/s)  avg LR: 3.733e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 14 [ 600/625 ( 96%)]  Loss: 0.004857 (0.00536)  Time: 0.701s, 2923.15/s  (0.707s, 2896.36/s)  avg LR: 3.733e-03  iter ratio: 0.0000  Data: 0.029 (0.033)
INFO:Train: 14 [ 624/625 (100%)]  Loss: 0.005062 (0.00533)  Time: 0.670s, 3055.96/s  (0.707s, 2897.76/s)  avg LR: 3.733e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.305 (4.305)  Loss:  2.0547 (2.0547)  Acc@1: 54.7852 (54.7852)  Acc@5: 80.8105 (80.8105)
INFO:Test: [  24/24]  Time: 0.079 (0.495)  Loss:  1.8965 (2.6577)  Acc@1: 64.1509 (42.6320)  Acc@5: 78.7736 (70.0740)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-14.pth.tar', 42.63199994140625)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-13.pth.tar', 41.047999970703124)

INFO:14-epoch: remaining time 37.52 h
INFO:Train: 15 [   0/625 (  0%)]  Loss: 0.005867 (0.00587)  Time: 4.313s,  474.88/s  (4.313s,  474.88/s)  avg LR: 4.000e-03  iter ratio: 0.0000  Data: 3.632 (3.632)
INFO:Train: 15 [  50/625 (  8%)]  Loss: 0.005419 (0.00564)  Time: 0.699s, 2928.05/s  (0.771s, 2655.38/s)  avg LR: 4.000e-03  iter ratio: 0.0000  Data: 0.027 (0.097)
INFO:Train: 15 [ 100/625 ( 16%)]  Loss: 0.005729 (0.00567)  Time: 0.700s, 2926.68/s  (0.736s, 2781.58/s)  avg LR: 4.000e-03  iter ratio: 0.0000  Data: 0.028 (0.063)
INFO:Train: 15 [ 150/625 ( 24%)]  Loss: 0.005155 (0.00554)  Time: 0.699s, 2929.22/s  (0.725s, 2824.69/s)  avg LR: 4.000e-03  iter ratio: 0.0000  Data: 0.028 (0.051)
INFO:Train: 15 [ 200/625 ( 32%)]  Loss: 0.005052 (0.00544)  Time: 0.699s, 2930.27/s  (0.719s, 2848.21/s)  avg LR: 4.000e-03  iter ratio: 0.0000  Data: 0.028 (0.045)
INFO:Train: 15 [ 250/625 ( 40%)]  Loss: 0.005410 (0.00544)  Time: 0.699s, 2929.42/s  (0.715s, 2862.52/s)  avg LR: 4.000e-03  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 15 [ 300/625 ( 48%)]  Loss: 0.005419 (0.00544)  Time: 0.701s, 2921.92/s  (0.713s, 2872.68/s)  avg LR: 4.000e-03  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 15 [ 350/625 ( 56%)]  Loss: 0.005317 (0.00542)  Time: 0.700s, 2926.59/s  (0.711s, 2879.80/s)  avg LR: 4.000e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 15 [ 400/625 ( 64%)]  Loss: 0.006189 (0.00551)  Time: 0.700s, 2925.42/s  (0.710s, 2884.89/s)  avg LR: 4.000e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 15 [ 450/625 ( 72%)]  Loss: 0.005046 (0.00546)  Time: 0.701s, 2920.06/s  (0.709s, 2888.73/s)  avg LR: 4.000e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 15 [ 500/625 ( 80%)]  Loss: 0.005727 (0.00548)  Time: 0.700s, 2925.65/s  (0.708s, 2891.85/s)  avg LR: 4.000e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 15 [ 550/625 ( 88%)]  Loss: 0.005607 (0.00549)  Time: 0.700s, 2927.49/s  (0.708s, 2894.37/s)  avg LR: 4.000e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 15 [ 600/625 ( 96%)]  Loss: 0.005847 (0.00552)  Time: 0.700s, 2927.37/s  (0.707s, 2896.51/s)  avg LR: 4.000e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 15 [ 624/625 (100%)]  Loss: 0.005190 (0.00550)  Time: 0.671s, 3049.99/s  (0.707s, 2897.86/s)  avg LR: 4.000e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.387 (4.387)  Loss:  1.9004 (1.9004)  Acc@1: 58.5449 (58.5449)  Acc@5: 81.3477 (81.3477)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.6465 (2.5550)  Acc@1: 66.2736 (44.6500)  Acc@5: 83.1368 (71.1000)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-15.pth.tar', 44.650000087890625)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-14.pth.tar', 42.63199994140625)

INFO:15-epoch: remaining time 37.37 h
INFO:Train: 16 [   0/625 (  0%)]  Loss: 0.005222 (0.00522)  Time: 4.243s,  482.68/s  (4.243s,  482.68/s)  avg LR: 4.267e-03  iter ratio: 0.0000  Data: 3.313 (3.313)
INFO:Train: 16 [  50/625 (  8%)]  Loss: 0.005284 (0.00525)  Time: 0.700s, 2927.50/s  (0.771s, 2656.91/s)  avg LR: 4.267e-03  iter ratio: 0.0000  Data: 0.026 (0.092)
INFO:Train: 16 [ 100/625 ( 16%)]  Loss: 0.006024 (0.00551)  Time: 0.700s, 2927.22/s  (0.736s, 2782.72/s)  avg LR: 4.267e-03  iter ratio: 0.0000  Data: 0.026 (0.060)
INFO:Train: 16 [ 150/625 ( 24%)]  Loss: 0.005117 (0.00541)  Time: 0.699s, 2928.31/s  (0.724s, 2827.75/s)  avg LR: 4.267e-03  iter ratio: 0.0000  Data: 0.027 (0.049)
INFO:Train: 16 [ 200/625 ( 32%)]  Loss: 0.005252 (0.00538)  Time: 0.700s, 2926.61/s  (0.718s, 2850.89/s)  avg LR: 4.267e-03  iter ratio: 0.0000  Data: 0.026 (0.043)
INFO:Train: 16 [ 250/625 ( 40%)]  Loss: 0.005041 (0.00532)  Time: 0.700s, 2925.02/s  (0.715s, 2864.37/s)  avg LR: 4.267e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 16 [ 300/625 ( 48%)]  Loss: 0.005305 (0.00532)  Time: 0.700s, 2926.66/s  (0.713s, 2874.01/s)  avg LR: 4.267e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 16 [ 350/625 ( 56%)]  Loss: 0.005542 (0.00535)  Time: 0.701s, 2920.16/s  (0.711s, 2880.44/s)  avg LR: 4.267e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 16 [ 400/625 ( 64%)]  Loss: 0.005768 (0.00540)  Time: 0.700s, 2924.25/s  (0.710s, 2885.58/s)  avg LR: 4.267e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 16 [ 450/625 ( 72%)]  Loss: 0.005261 (0.00538)  Time: 0.698s, 2933.53/s  (0.709s, 2889.53/s)  avg LR: 4.267e-03  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 16 [ 500/625 ( 80%)]  Loss: 0.005916 (0.00543)  Time: 0.699s, 2930.96/s  (0.708s, 2892.86/s)  avg LR: 4.267e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 16 [ 550/625 ( 88%)]  Loss: 0.005691 (0.00545)  Time: 0.700s, 2924.73/s  (0.707s, 2895.42/s)  avg LR: 4.267e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 16 [ 600/625 ( 96%)]  Loss: 0.005101 (0.00542)  Time: 0.698s, 2933.10/s  (0.707s, 2897.40/s)  avg LR: 4.267e-03  iter ratio: 0.0000  Data: 0.026 (0.032)
INFO:Train: 16 [ 624/625 (100%)]  Loss: 0.005102 (0.00540)  Time: 0.672s, 3047.25/s  (0.707s, 2898.72/s)  avg LR: 4.267e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.284 (4.284)  Loss:  1.8877 (1.8877)  Acc@1: 60.3027 (60.3027)  Acc@5: 82.4707 (82.4707)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.4639 (2.4168)  Acc@1: 71.1085 (47.1380)  Acc@5: 85.2594 (74.2180)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-16.pth.tar', 47.13799999023438)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-15.pth.tar', 44.650000087890625)

INFO:16-epoch: remaining time 37.25 h
INFO:Train: 17 [   0/625 (  0%)]  Loss: 0.005251 (0.00525)  Time: 4.065s,  503.85/s  (4.065s,  503.85/s)  avg LR: 4.533e-03  iter ratio: 0.0000  Data: 3.361 (3.361)
INFO:Train: 17 [  50/625 (  8%)]  Loss: 0.005341 (0.00530)  Time: 0.699s, 2927.84/s  (0.767s, 2669.30/s)  avg LR: 4.533e-03  iter ratio: 0.0000  Data: 0.028 (0.093)
INFO:Train: 17 [ 100/625 ( 16%)]  Loss: 0.004768 (0.00512)  Time: 0.702s, 2915.83/s  (0.735s, 2786.29/s)  avg LR: 4.533e-03  iter ratio: 0.0000  Data: 0.028 (0.061)
INFO:Train: 17 [ 150/625 ( 24%)]  Loss: 0.005331 (0.00517)  Time: 0.700s, 2925.03/s  (0.725s, 2826.51/s)  avg LR: 4.533e-03  iter ratio: 0.0000  Data: 0.027 (0.050)
INFO:Train: 17 [ 200/625 ( 32%)]  Loss: 0.004744 (0.00509)  Time: 0.700s, 2924.71/s  (0.719s, 2849.27/s)  avg LR: 4.533e-03  iter ratio: 0.0000  Data: 0.026 (0.045)
INFO:Train: 17 [ 250/625 ( 40%)]  Loss: 0.005447 (0.00515)  Time: 0.700s, 2926.75/s  (0.715s, 2863.14/s)  avg LR: 4.533e-03  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 17 [ 300/625 ( 48%)]  Loss: 0.004601 (0.00507)  Time: 0.701s, 2923.01/s  (0.713s, 2872.79/s)  avg LR: 4.533e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 17 [ 350/625 ( 56%)]  Loss: 0.005785 (0.00516)  Time: 0.699s, 2929.04/s  (0.711s, 2879.50/s)  avg LR: 4.533e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 17 [ 400/625 ( 64%)]  Loss: 0.005146 (0.00516)  Time: 0.700s, 2926.22/s  (0.710s, 2884.70/s)  avg LR: 4.533e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 17 [ 450/625 ( 72%)]  Loss: 0.005101 (0.00515)  Time: 0.700s, 2927.26/s  (0.709s, 2888.59/s)  avg LR: 4.533e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 17 [ 500/625 ( 80%)]  Loss: 0.005123 (0.00515)  Time: 0.700s, 2926.59/s  (0.708s, 2891.77/s)  avg LR: 4.533e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 17 [ 550/625 ( 88%)]  Loss: 0.004761 (0.00512)  Time: 0.700s, 2925.76/s  (0.708s, 2894.31/s)  avg LR: 4.533e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 17 [ 600/625 ( 96%)]  Loss: 0.005005 (0.00511)  Time: 0.700s, 2924.97/s  (0.707s, 2896.40/s)  avg LR: 4.533e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 17 [ 624/625 (100%)]  Loss: 0.005708 (0.00515)  Time: 0.672s, 3047.13/s  (0.707s, 2897.59/s)  avg LR: 4.533e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.357 (4.357)  Loss:  1.8965 (1.8965)  Acc@1: 58.7402 (58.7402)  Acc@5: 82.8613 (82.8613)
INFO:Test: [  24/24]  Time: 0.080 (0.498)  Loss:  1.3320 (2.4104)  Acc@1: 71.4623 (47.3460)  Acc@5: 87.8538 (73.9820)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-17.pth.tar', 47.34600001464844)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-16.pth.tar', 47.13799999023438)

INFO:17-epoch: remaining time 37.11 h
INFO:Train: 18 [   0/625 (  0%)]  Loss: 0.005288 (0.00529)  Time: 4.358s,  469.92/s  (4.358s,  469.92/s)  avg LR: 4.800e-03  iter ratio: 0.0000  Data: 3.449 (3.449)
INFO:Train: 18 [  50/625 (  8%)]  Loss: 0.005106 (0.00520)  Time: 0.701s, 2921.47/s  (0.775s, 2643.94/s)  avg LR: 4.800e-03  iter ratio: 0.0000  Data: 0.029 (0.097)
INFO:Train: 18 [ 100/625 ( 16%)]  Loss: 0.005304 (0.00523)  Time: 0.703s, 2913.37/s  (0.739s, 2772.27/s)  avg LR: 4.800e-03  iter ratio: 0.0000  Data: 0.030 (0.064)
INFO:Train: 18 [ 150/625 ( 24%)]  Loss: 0.005587 (0.00532)  Time: 0.701s, 2921.53/s  (0.727s, 2817.69/s)  avg LR: 4.800e-03  iter ratio: 0.0000  Data: 0.028 (0.053)
INFO:Train: 18 [ 200/625 ( 32%)]  Loss: 0.005100 (0.00528)  Time: 0.702s, 2916.68/s  (0.721s, 2840.50/s)  avg LR: 4.800e-03  iter ratio: 0.0000  Data: 0.031 (0.047)
INFO:Train: 18 [ 250/625 ( 40%)]  Loss: 0.005776 (0.00536)  Time: 0.701s, 2922.57/s  (0.717s, 2854.53/s)  avg LR: 4.800e-03  iter ratio: 0.0000  Data: 0.029 (0.044)
INFO:Train: 18 [ 300/625 ( 48%)]  Loss: 0.004911 (0.00530)  Time: 0.702s, 2917.34/s  (0.715s, 2864.46/s)  avg LR: 4.800e-03  iter ratio: 0.0000  Data: 0.030 (0.042)
INFO:Train: 18 [ 350/625 ( 56%)]  Loss: 0.005375 (0.00531)  Time: 0.702s, 2916.12/s  (0.713s, 2871.17/s)  avg LR: 4.800e-03  iter ratio: 0.0000  Data: 0.030 (0.040)
INFO:Train: 18 [ 400/625 ( 64%)]  Loss: 0.004726 (0.00524)  Time: 0.703s, 2912.63/s  (0.712s, 2876.17/s)  avg LR: 4.800e-03  iter ratio: 0.0000  Data: 0.030 (0.039)
INFO:Train: 18 [ 450/625 ( 72%)]  Loss: 0.004650 (0.00518)  Time: 0.701s, 2923.34/s  (0.711s, 2880.05/s)  avg LR: 4.800e-03  iter ratio: 0.0000  Data: 0.030 (0.038)
INFO:Train: 18 [ 500/625 ( 80%)]  Loss: 0.004823 (0.00515)  Time: 0.703s, 2915.21/s  (0.710s, 2883.10/s)  avg LR: 4.800e-03  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 18 [ 550/625 ( 88%)]  Loss: 0.005518 (0.00518)  Time: 0.707s, 2898.50/s  (0.710s, 2885.35/s)  avg LR: 4.800e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 18 [ 600/625 ( 96%)]  Loss: 0.004882 (0.00516)  Time: 0.704s, 2908.33/s  (0.709s, 2886.95/s)  avg LR: 4.800e-03  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 18 [ 624/625 (100%)]  Loss: 0.005617 (0.00519)  Time: 0.671s, 3052.77/s  (0.709s, 2888.16/s)  avg LR: 4.800e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.328 (4.328)  Loss:  1.7051 (1.7051)  Acc@1: 63.2812 (63.2812)  Acc@5: 85.4004 (85.4004)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.4658 (2.4030)  Acc@1: 69.1038 (48.2580)  Acc@5: 86.0849 (74.6980)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-18.pth.tar', 48.25800002441406)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-17.pth.tar', 47.34600001464844)

INFO:18-epoch: remaining time 37.13 h
INFO:Train: 19 [   0/625 (  0%)]  Loss: 0.005015 (0.00501)  Time: 4.143s,  494.34/s  (4.143s,  494.34/s)  avg LR: 5.067e-03  iter ratio: 0.0000  Data: 3.454 (3.454)
INFO:Train: 19 [  50/625 (  8%)]  Loss: 0.005509 (0.00526)  Time: 0.700s, 2926.67/s  (0.769s, 2662.08/s)  avg LR: 5.067e-03  iter ratio: 0.0000  Data: 0.027 (0.095)
INFO:Train: 19 [ 100/625 ( 16%)]  Loss: 0.004909 (0.00514)  Time: 0.701s, 2923.09/s  (0.736s, 2782.90/s)  avg LR: 5.067e-03  iter ratio: 0.0000  Data: 0.028 (0.062)
INFO:Train: 19 [ 150/625 ( 24%)]  Loss: 0.005565 (0.00525)  Time: 0.701s, 2923.50/s  (0.725s, 2826.01/s)  avg LR: 5.067e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 19 [ 200/625 ( 32%)]  Loss: 0.005092 (0.00522)  Time: 0.700s, 2925.81/s  (0.719s, 2848.33/s)  avg LR: 5.067e-03  iter ratio: 0.0000  Data: 0.025 (0.045)
INFO:Train: 19 [ 250/625 ( 40%)]  Loss: 0.005765 (0.00531)  Time: 0.706s, 2899.95/s  (0.716s, 2861.24/s)  avg LR: 5.067e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 19 [ 300/625 ( 48%)]  Loss: 0.005194 (0.00529)  Time: 0.702s, 2916.10/s  (0.714s, 2870.12/s)  avg LR: 5.067e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 19 [ 350/625 ( 56%)]  Loss: 0.005253 (0.00529)  Time: 0.704s, 2910.96/s  (0.712s, 2876.54/s)  avg LR: 5.067e-03  iter ratio: 0.0000  Data: 0.030 (0.038)
INFO:Train: 19 [ 400/625 ( 64%)]  Loss: 0.004447 (0.00519)  Time: 0.703s, 2913.55/s  (0.711s, 2881.20/s)  avg LR: 5.067e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 19 [ 450/625 ( 72%)]  Loss: 0.004170 (0.00509)  Time: 0.703s, 2913.73/s  (0.710s, 2884.82/s)  avg LR: 5.067e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 19 [ 500/625 ( 80%)]  Loss: 0.005269 (0.00511)  Time: 0.703s, 2913.60/s  (0.709s, 2887.74/s)  avg LR: 5.067e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 19 [ 550/625 ( 88%)]  Loss: 0.004999 (0.00510)  Time: 0.703s, 2913.63/s  (0.709s, 2890.03/s)  avg LR: 5.067e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 19 [ 600/625 ( 96%)]  Loss: 0.004949 (0.00509)  Time: 0.703s, 2913.31/s  (0.708s, 2892.05/s)  avg LR: 5.067e-03  iter ratio: 0.0000  Data: 0.030 (0.034)
INFO:Train: 19 [ 624/625 (100%)]  Loss: 0.005439 (0.00511)  Time: 0.672s, 3047.95/s  (0.708s, 2893.35/s)  avg LR: 5.067e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.370 (4.370)  Loss:  1.8203 (1.8203)  Acc@1: 59.5703 (59.5703)  Acc@5: 82.4707 (82.4707)
INFO:Test: [  24/24]  Time: 0.080 (0.502)  Loss:  1.7715 (2.3736)  Acc@1: 64.2689 (48.2860)  Acc@5: 80.8962 (74.5040)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-19.pth.tar', 48.285999992675784)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-18.pth.tar', 48.25800002441406)

INFO:19-epoch: remaining time 36.92 h
INFO:Train: 20 [   0/625 (  0%)]  Loss: 0.004596 (0.00460)  Time: 4.677s,  437.86/s  (4.677s,  437.86/s)  avg LR: 5.333e-03  iter ratio: 0.0000  Data: 3.741 (3.741)
INFO:Train: 20 [  50/625 (  8%)]  Loss: 0.005838 (0.00522)  Time: 0.706s, 2900.23/s  (0.783s, 2614.25/s)  avg LR: 5.333e-03  iter ratio: 0.0000  Data: 0.033 (0.103)
INFO:Train: 20 [ 100/625 ( 16%)]  Loss: 0.005415 (0.00528)  Time: 0.706s, 2901.49/s  (0.745s, 2749.29/s)  avg LR: 5.333e-03  iter ratio: 0.0000  Data: 0.033 (0.067)
INFO:Train: 20 [ 150/625 ( 24%)]  Loss: 0.005001 (0.00521)  Time: 0.705s, 2906.07/s  (0.732s, 2798.20/s)  avg LR: 5.333e-03  iter ratio: 0.0000  Data: 0.032 (0.055)
INFO:Train: 20 [ 200/625 ( 32%)]  Loss: 0.004945 (0.00516)  Time: 0.702s, 2916.29/s  (0.725s, 2824.02/s)  avg LR: 5.333e-03  iter ratio: 0.0000  Data: 0.027 (0.049)
INFO:Train: 20 [ 250/625 ( 40%)]  Loss: 0.005175 (0.00516)  Time: 0.704s, 2910.66/s  (0.721s, 2839.44/s)  avg LR: 5.333e-03  iter ratio: 0.0000  Data: 0.026 (0.045)
INFO:Train: 20 [ 300/625 ( 48%)]  Loss: 0.005110 (0.00515)  Time: 0.704s, 2908.69/s  (0.719s, 2850.00/s)  avg LR: 5.333e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 20 [ 350/625 ( 56%)]  Loss: 0.005173 (0.00516)  Time: 0.701s, 2920.67/s  (0.717s, 2857.46/s)  avg LR: 5.333e-03  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 20 [ 400/625 ( 64%)]  Loss: 0.004976 (0.00514)  Time: 0.701s, 2919.80/s  (0.715s, 2862.50/s)  avg LR: 5.333e-03  iter ratio: 0.0000  Data: 0.029 (0.039)
INFO:Train: 20 [ 450/625 ( 72%)]  Loss: 0.004938 (0.00512)  Time: 0.701s, 2920.28/s  (0.714s, 2866.91/s)  avg LR: 5.333e-03  iter ratio: 0.0000  Data: 0.030 (0.038)
INFO:Train: 20 [ 500/625 ( 80%)]  Loss: 0.005768 (0.00518)  Time: 0.703s, 2914.55/s  (0.714s, 2870.19/s)  avg LR: 5.333e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 20 [ 550/625 ( 88%)]  Loss: 0.005009 (0.00516)  Time: 0.702s, 2917.74/s  (0.713s, 2872.80/s)  avg LR: 5.333e-03  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 20 [ 600/625 ( 96%)]  Loss: 0.005092 (0.00516)  Time: 0.704s, 2910.53/s  (0.712s, 2874.99/s)  avg LR: 5.333e-03  iter ratio: 0.0000  Data: 0.029 (0.037)
INFO:Train: 20 [ 624/625 (100%)]  Loss: 0.005024 (0.00515)  Time: 0.671s, 3051.58/s  (0.712s, 2876.41/s)  avg LR: 5.333e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.330 (4.330)  Loss:  1.6113 (1.6113)  Acc@1: 63.2324 (63.2324)  Acc@5: 84.6191 (84.6191)
INFO:Test: [  24/24]  Time: 0.079 (0.500)  Loss:  1.1445 (2.1746)  Acc@1: 74.5283 (51.0840)  Acc@5: 90.3302 (76.8060)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-20.pth.tar', 51.08399992431641)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-19.pth.tar', 48.285999992675784)

INFO:20-epoch: remaining time 37.04 h
INFO:Train: 21 [   0/625 (  0%)]  Loss: 0.004182 (0.00418)  Time: 4.346s,  471.22/s  (4.346s,  471.22/s)  avg LR: 5.600e-03  iter ratio: 0.0000  Data: 3.651 (3.651)
INFO:Train: 21 [  50/625 (  8%)]  Loss: 0.004401 (0.00429)  Time: 0.701s, 2923.15/s  (0.774s, 2646.05/s)  avg LR: 5.600e-03  iter ratio: 0.0000  Data: 0.028 (0.099)
INFO:Train: 21 [ 100/625 ( 16%)]  Loss: 0.004850 (0.00448)  Time: 0.701s, 2922.32/s  (0.738s, 2774.08/s)  avg LR: 5.600e-03  iter ratio: 0.0000  Data: 0.028 (0.064)
INFO:Train: 21 [ 150/625 ( 24%)]  Loss: 0.005062 (0.00462)  Time: 0.703s, 2914.62/s  (0.726s, 2820.00/s)  avg LR: 5.600e-03  iter ratio: 0.0000  Data: 0.030 (0.052)
INFO:Train: 21 [ 200/625 ( 32%)]  Loss: 0.004710 (0.00464)  Time: 0.701s, 2922.62/s  (0.720s, 2843.45/s)  avg LR: 5.600e-03  iter ratio: 0.0000  Data: 0.028 (0.045)
INFO:Train: 21 [ 250/625 ( 40%)]  Loss: 0.005395 (0.00477)  Time: 0.702s, 2918.42/s  (0.717s, 2857.44/s)  avg LR: 5.600e-03  iter ratio: 0.0000  Data: 0.029 (0.042)
INFO:Train: 21 [ 300/625 ( 48%)]  Loss: 0.005027 (0.00480)  Time: 0.700s, 2925.26/s  (0.714s, 2866.71/s)  avg LR: 5.600e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 21 [ 350/625 ( 56%)]  Loss: 0.004712 (0.00479)  Time: 0.699s, 2930.88/s  (0.713s, 2873.67/s)  avg LR: 5.600e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 21 [ 400/625 ( 64%)]  Loss: 0.005499 (0.00487)  Time: 0.702s, 2916.22/s  (0.711s, 2879.03/s)  avg LR: 5.600e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 21 [ 450/625 ( 72%)]  Loss: 0.004939 (0.00488)  Time: 0.700s, 2927.34/s  (0.710s, 2882.99/s)  avg LR: 5.600e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 21 [ 500/625 ( 80%)]  Loss: 0.005381 (0.00492)  Time: 0.699s, 2930.07/s  (0.710s, 2885.94/s)  avg LR: 5.600e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 21 [ 550/625 ( 88%)]  Loss: 0.004845 (0.00492)  Time: 0.700s, 2925.65/s  (0.709s, 2888.64/s)  avg LR: 5.600e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 21 [ 600/625 ( 96%)]  Loss: 0.004969 (0.00492)  Time: 0.702s, 2917.84/s  (0.708s, 2891.15/s)  avg LR: 5.600e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 21 [ 624/625 (100%)]  Loss: 0.004835 (0.00491)  Time: 0.672s, 3048.24/s  (0.708s, 2892.43/s)  avg LR: 5.600e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.401 (4.401)  Loss:  1.7217 (1.7217)  Acc@1: 62.3047 (62.3047)  Acc@5: 83.8867 (83.8867)
INFO:Test: [  24/24]  Time: 0.080 (0.497)  Loss:  1.4189 (2.2593)  Acc@1: 69.1038 (50.9100)  Acc@5: 88.2075 (76.5340)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-20.pth.tar', 51.08399992431641)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-21.pth.tar', 50.91000002441406)

INFO:21-epoch: remaining time 36.70 h
INFO:Train: 22 [   0/625 (  0%)]  Loss: 0.004083 (0.00408)  Time: 4.637s,  441.62/s  (4.637s,  441.62/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 3.705 (3.705)
INFO:Train: 22 [  50/625 (  8%)]  Loss: 0.005891 (0.00499)  Time: 0.700s, 2923.92/s  (0.780s, 2625.62/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.028 (0.102)
INFO:Train: 22 [ 100/625 ( 16%)]  Loss: 0.004460 (0.00481)  Time: 0.703s, 2911.21/s  (0.742s, 2761.11/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.031 (0.066)
INFO:Train: 22 [ 150/625 ( 24%)]  Loss: 0.004778 (0.00480)  Time: 0.700s, 2926.69/s  (0.729s, 2810.68/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.028 (0.054)
INFO:Train: 22 [ 200/625 ( 32%)]  Loss: 0.004999 (0.00484)  Time: 0.701s, 2922.76/s  (0.722s, 2835.56/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.029 (0.048)
INFO:Train: 22 [ 250/625 ( 40%)]  Loss: 0.005300 (0.00492)  Time: 0.701s, 2921.92/s  (0.718s, 2851.44/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.029 (0.045)
INFO:Train: 22 [ 300/625 ( 48%)]  Loss: 0.004537 (0.00486)  Time: 0.704s, 2908.86/s  (0.716s, 2862.25/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.032 (0.042)
INFO:Train: 22 [ 350/625 ( 56%)]  Loss: 0.004701 (0.00484)  Time: 0.704s, 2910.08/s  (0.714s, 2869.87/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.033 (0.040)
INFO:Train: 22 [ 400/625 ( 64%)]  Loss: 0.005101 (0.00487)  Time: 0.702s, 2917.68/s  (0.712s, 2876.03/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.032 (0.039)
INFO:Train: 22 [ 450/625 ( 72%)]  Loss: 0.004915 (0.00488)  Time: 0.702s, 2917.67/s  (0.711s, 2880.78/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.032 (0.038)
INFO:Train: 22 [ 500/625 ( 80%)]  Loss: 0.005170 (0.00490)  Time: 0.703s, 2915.10/s  (0.710s, 2884.63/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.032 (0.037)
INFO:Train: 22 [ 550/625 ( 88%)]  Loss: 0.005044 (0.00491)  Time: 0.703s, 2912.20/s  (0.709s, 2887.67/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.031 (0.037)
INFO:Train: 22 [ 600/625 ( 96%)]  Loss: 0.005705 (0.00498)  Time: 0.700s, 2926.28/s  (0.709s, 2890.31/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 22 [ 624/625 (100%)]  Loss: 0.005023 (0.00498)  Time: 0.670s, 3056.07/s  (0.708s, 2891.71/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.317 (4.317)  Loss:  1.9893 (1.9893)  Acc@1: 58.6426 (58.6426)  Acc@5: 79.8828 (79.8828)
INFO:Test: [  24/24]  Time: 0.080 (0.499)  Loss:  1.4951 (2.3169)  Acc@1: 70.4009 (50.1760)  Acc@5: 86.2028 (75.7920)
INFO:22-epoch: remaining time 36.59 h
INFO:Train: 23 [   0/625 (  0%)]  Loss: 0.004681 (0.00468)  Time: 4.212s,  486.18/s  (4.212s,  486.18/s)  avg LR: 6.133e-03  iter ratio: 0.0000  Data: 3.519 (3.519)
INFO:Train: 23 [  50/625 (  8%)]  Loss: 0.004680 (0.00468)  Time: 0.700s, 2925.44/s  (0.771s, 2657.10/s)  avg LR: 6.133e-03  iter ratio: 0.0000  Data: 0.028 (0.096)
INFO:Train: 23 [ 100/625 ( 16%)]  Loss: 0.005325 (0.00490)  Time: 0.702s, 2918.26/s  (0.737s, 2780.30/s)  avg LR: 6.133e-03  iter ratio: 0.0000  Data: 0.030 (0.062)
INFO:Train: 23 [ 150/625 ( 24%)]  Loss: 0.005261 (0.00499)  Time: 0.702s, 2916.43/s  (0.725s, 2826.00/s)  avg LR: 6.133e-03  iter ratio: 0.0000  Data: 0.029 (0.051)
INFO:Train: 23 [ 200/625 ( 32%)]  Loss: 0.005840 (0.00516)  Time: 0.700s, 2926.60/s  (0.719s, 2849.14/s)  avg LR: 6.133e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 23 [ 250/625 ( 40%)]  Loss: 0.005021 (0.00513)  Time: 0.699s, 2928.56/s  (0.715s, 2863.59/s)  avg LR: 6.133e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 23 [ 300/625 ( 48%)]  Loss: 0.005067 (0.00513)  Time: 0.698s, 2933.40/s  (0.713s, 2873.27/s)  avg LR: 6.133e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 23 [ 350/625 ( 56%)]  Loss: 0.004737 (0.00508)  Time: 0.697s, 2938.86/s  (0.711s, 2880.26/s)  avg LR: 6.133e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 23 [ 400/625 ( 64%)]  Loss: 0.004485 (0.00501)  Time: 0.699s, 2931.99/s  (0.710s, 2885.37/s)  avg LR: 6.133e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 23 [ 450/625 ( 72%)]  Loss: 0.005002 (0.00501)  Time: 0.700s, 2927.78/s  (0.709s, 2889.35/s)  avg LR: 6.133e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 23 [ 500/625 ( 80%)]  Loss: 0.004926 (0.00500)  Time: 0.700s, 2926.68/s  (0.708s, 2892.58/s)  avg LR: 6.133e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 23 [ 550/625 ( 88%)]  Loss: 0.005559 (0.00505)  Time: 0.700s, 2926.47/s  (0.707s, 2895.28/s)  avg LR: 6.133e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 23 [ 600/625 ( 96%)]  Loss: 0.005429 (0.00508)  Time: 0.699s, 2930.21/s  (0.707s, 2897.51/s)  avg LR: 6.133e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 23 [ 624/625 (100%)]  Loss: 0.004607 (0.00504)  Time: 0.671s, 3050.30/s  (0.706s, 2898.83/s)  avg LR: 6.133e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.339 (4.339)  Loss:  1.7627 (1.7627)  Acc@1: 61.0352 (61.0352)  Acc@5: 84.2773 (84.2773)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.5078 (2.2192)  Acc@1: 69.5755 (52.5020)  Acc@5: 86.6745 (77.9080)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-23.pth.tar', 52.501999970703125)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-20.pth.tar', 51.08399992431641)

INFO:23-epoch: remaining time 36.37 h
INFO:Train: 24 [   0/625 (  0%)]  Loss: 0.004428 (0.00443)  Time: 4.648s,  440.63/s  (4.648s,  440.63/s)  avg LR: 6.400e-03  iter ratio: 0.0000  Data: 3.716 (3.716)
INFO:Train: 24 [  50/625 (  8%)]  Loss: 0.005723 (0.00508)  Time: 0.700s, 2926.03/s  (0.780s, 2624.60/s)  avg LR: 6.400e-03  iter ratio: 0.0000  Data: 0.026 (0.102)
INFO:Train: 24 [ 100/625 ( 16%)]  Loss: 0.005130 (0.00509)  Time: 0.703s, 2912.08/s  (0.742s, 2759.49/s)  avg LR: 6.400e-03  iter ratio: 0.0000  Data: 0.027 (0.066)
INFO:Train: 24 [ 150/625 ( 24%)]  Loss: 0.005415 (0.00517)  Time: 0.703s, 2914.21/s  (0.729s, 2808.75/s)  avg LR: 6.400e-03  iter ratio: 0.0000  Data: 0.027 (0.054)
INFO:Train: 24 [ 200/625 ( 32%)]  Loss: 0.004308 (0.00500)  Time: 0.703s, 2912.51/s  (0.722s, 2834.76/s)  avg LR: 6.400e-03  iter ratio: 0.0000  Data: 0.027 (0.048)
INFO:Train: 24 [ 250/625 ( 40%)]  Loss: 0.004620 (0.00494)  Time: 0.701s, 2920.51/s  (0.718s, 2850.44/s)  avg LR: 6.400e-03  iter ratio: 0.0000  Data: 0.026 (0.044)
INFO:Train: 24 [ 300/625 ( 48%)]  Loss: 0.004927 (0.00494)  Time: 0.702s, 2919.29/s  (0.716s, 2860.75/s)  avg LR: 6.400e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 24 [ 350/625 ( 56%)]  Loss: 0.005224 (0.00497)  Time: 0.701s, 2921.51/s  (0.714s, 2868.01/s)  avg LR: 6.400e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 24 [ 400/625 ( 64%)]  Loss: 0.005003 (0.00498)  Time: 0.700s, 2924.00/s  (0.713s, 2873.53/s)  avg LR: 6.400e-03  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 24 [ 450/625 ( 72%)]  Loss: 0.005465 (0.00502)  Time: 0.702s, 2915.58/s  (0.712s, 2877.77/s)  avg LR: 6.400e-03  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 24 [ 500/625 ( 80%)]  Loss: 0.004695 (0.00499)  Time: 0.704s, 2909.57/s  (0.711s, 2881.04/s)  avg LR: 6.400e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 24 [ 550/625 ( 88%)]  Loss: 0.004864 (0.00498)  Time: 0.703s, 2912.52/s  (0.710s, 2883.88/s)  avg LR: 6.400e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 24 [ 600/625 ( 96%)]  Loss: 0.005160 (0.00500)  Time: 0.701s, 2919.93/s  (0.710s, 2886.22/s)  avg LR: 6.400e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 24 [ 624/625 (100%)]  Loss: 0.005229 (0.00501)  Time: 0.671s, 3050.97/s  (0.709s, 2887.69/s)  avg LR: 6.400e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.288 (4.288)  Loss:  1.7139 (1.7139)  Acc@1: 60.9863 (60.9863)  Acc@5: 84.1797 (84.1797)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.2061 (2.1925)  Acc@1: 74.2924 (52.4260)  Acc@5: 90.0943 (77.6520)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-23.pth.tar', 52.501999970703125)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-24.pth.tar', 52.425999951171875)

INFO:24-epoch: remaining time 36.36 h
INFO:Train: 25 [   0/625 (  0%)]  Loss: 0.005385 (0.00539)  Time: 4.148s,  493.72/s  (4.148s,  493.72/s)  avg LR: 6.667e-03  iter ratio: 0.0000  Data: 3.466 (3.466)
INFO:Train: 25 [  50/625 (  8%)]  Loss: 0.005569 (0.00548)  Time: 0.698s, 2932.76/s  (0.770s, 2661.09/s)  avg LR: 6.667e-03  iter ratio: 0.0000  Data: 0.027 (0.095)
INFO:Train: 25 [ 100/625 ( 16%)]  Loss: 0.004490 (0.00515)  Time: 0.700s, 2927.22/s  (0.736s, 2783.62/s)  avg LR: 6.667e-03  iter ratio: 0.0000  Data: 0.027 (0.062)
INFO:Train: 25 [ 150/625 ( 24%)]  Loss: 0.004558 (0.00500)  Time: 0.702s, 2915.57/s  (0.724s, 2827.50/s)  avg LR: 6.667e-03  iter ratio: 0.0000  Data: 0.030 (0.051)
INFO:Train: 25 [ 200/625 ( 32%)]  Loss: 0.005437 (0.00509)  Time: 0.699s, 2929.59/s  (0.719s, 2850.15/s)  avg LR: 6.667e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 25 [ 250/625 ( 40%)]  Loss: 0.004587 (0.00500)  Time: 0.699s, 2929.71/s  (0.715s, 2864.06/s)  avg LR: 6.667e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 25 [ 300/625 ( 48%)]  Loss: 0.005488 (0.00507)  Time: 0.700s, 2925.44/s  (0.713s, 2873.45/s)  avg LR: 6.667e-03  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 25 [ 350/625 ( 56%)]  Loss: 0.004758 (0.00503)  Time: 0.702s, 2916.97/s  (0.711s, 2880.15/s)  avg LR: 6.667e-03  iter ratio: 0.0000  Data: 0.030 (0.038)
INFO:Train: 25 [ 400/625 ( 64%)]  Loss: 0.005131 (0.00504)  Time: 0.700s, 2926.21/s  (0.710s, 2885.19/s)  avg LR: 6.667e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 25 [ 450/625 ( 72%)]  Loss: 0.005418 (0.00508)  Time: 0.701s, 2919.74/s  (0.709s, 2889.11/s)  avg LR: 6.667e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 25 [ 500/625 ( 80%)]  Loss: 0.005448 (0.00512)  Time: 0.699s, 2931.80/s  (0.708s, 2892.14/s)  avg LR: 6.667e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 25 [ 550/625 ( 88%)]  Loss: 0.004606 (0.00507)  Time: 0.699s, 2929.33/s  (0.708s, 2894.52/s)  avg LR: 6.667e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 25 [ 600/625 ( 96%)]  Loss: 0.004814 (0.00505)  Time: 0.700s, 2924.61/s  (0.707s, 2896.60/s)  avg LR: 6.667e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 25 [ 624/625 (100%)]  Loss: 0.004674 (0.00503)  Time: 0.671s, 3053.09/s  (0.707s, 2897.89/s)  avg LR: 6.667e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.381 (4.381)  Loss:  1.4365 (1.4365)  Acc@1: 67.5781 (67.5781)  Acc@5: 86.8652 (86.8652)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  1.4443 (2.1853)  Acc@1: 69.2217 (52.0300)  Acc@5: 87.6179 (77.2180)
INFO:25-epoch: remaining time 36.16 h
INFO:Train: 26 [   0/625 (  0%)]  Loss: 0.004210 (0.00421)  Time: 4.382s,  467.37/s  (4.382s,  467.37/s)  avg LR: 6.933e-03  iter ratio: 0.0000  Data: 3.461 (3.461)
INFO:Train: 26 [  50/625 (  8%)]  Loss: 0.005244 (0.00473)  Time: 0.702s, 2918.11/s  (0.778s, 2633.56/s)  avg LR: 6.933e-03  iter ratio: 0.0000  Data: 0.028 (0.099)
INFO:Train: 26 [ 100/625 ( 16%)]  Loss: 0.005002 (0.00482)  Time: 0.703s, 2912.29/s  (0.741s, 2763.06/s)  avg LR: 6.933e-03  iter ratio: 0.0000  Data: 0.027 (0.065)
INFO:Train: 26 [ 150/625 ( 24%)]  Loss: 0.004576 (0.00476)  Time: 0.704s, 2909.74/s  (0.729s, 2810.00/s)  avg LR: 6.933e-03  iter ratio: 0.0000  Data: 0.026 (0.053)
INFO:Train: 26 [ 200/625 ( 32%)]  Loss: 0.005595 (0.00493)  Time: 0.703s, 2912.38/s  (0.723s, 2834.00/s)  avg LR: 6.933e-03  iter ratio: 0.0000  Data: 0.026 (0.048)
INFO:Train: 26 [ 250/625 ( 40%)]  Loss: 0.004482 (0.00485)  Time: 0.703s, 2915.03/s  (0.719s, 2848.77/s)  avg LR: 6.933e-03  iter ratio: 0.0000  Data: 0.027 (0.044)
INFO:Train: 26 [ 300/625 ( 48%)]  Loss: 0.005101 (0.00489)  Time: 0.706s, 2898.93/s  (0.716s, 2858.83/s)  avg LR: 6.933e-03  iter ratio: 0.0000  Data: 0.029 (0.042)
INFO:Train: 26 [ 350/625 ( 56%)]  Loss: 0.004570 (0.00485)  Time: 0.705s, 2906.70/s  (0.715s, 2865.83/s)  avg LR: 6.933e-03  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 26 [ 400/625 ( 64%)]  Loss: 0.004877 (0.00485)  Time: 0.702s, 2917.91/s  (0.713s, 2871.09/s)  avg LR: 6.933e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 26 [ 450/625 ( 72%)]  Loss: 0.004247 (0.00479)  Time: 0.705s, 2904.79/s  (0.712s, 2875.12/s)  avg LR: 6.933e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 26 [ 500/625 ( 80%)]  Loss: 0.004540 (0.00477)  Time: 0.702s, 2918.70/s  (0.712s, 2878.38/s)  avg LR: 6.933e-03  iter ratio: 0.0000  Data: 0.029 (0.037)
INFO:Train: 26 [ 550/625 ( 88%)]  Loss: 0.005975 (0.00487)  Time: 0.700s, 2924.28/s  (0.711s, 2881.13/s)  avg LR: 6.933e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 26 [ 600/625 ( 96%)]  Loss: 0.004557 (0.00484)  Time: 0.702s, 2918.73/s  (0.710s, 2883.32/s)  avg LR: 6.933e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 26 [ 624/625 (100%)]  Loss: 0.005433 (0.00489)  Time: 0.671s, 3052.96/s  (0.710s, 2884.79/s)  avg LR: 6.933e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.291 (4.291)  Loss:  1.7373 (1.7373)  Acc@1: 60.4980 (60.4980)  Acc@5: 83.8379 (83.8379)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  1.5039 (2.2413)  Acc@1: 68.2783 (50.8860)  Acc@5: 85.0236 (76.5440)
INFO:26-epoch: remaining time 36.15 h
INFO:Train: 27 [   0/625 (  0%)]  Loss: 0.005438 (0.00544)  Time: 3.918s,  522.76/s  (3.918s,  522.76/s)  avg LR: 7.200e-03  iter ratio: 0.0000  Data: 3.227 (3.227)
INFO:Train: 27 [  50/625 (  8%)]  Loss: 0.005072 (0.00525)  Time: 0.701s, 2922.18/s  (0.765s, 2678.03/s)  avg LR: 7.200e-03  iter ratio: 0.0000  Data: 0.028 (0.091)
INFO:Train: 27 [ 100/625 ( 16%)]  Loss: 0.004590 (0.00503)  Time: 0.700s, 2927.35/s  (0.733s, 2792.23/s)  avg LR: 7.200e-03  iter ratio: 0.0000  Data: 0.026 (0.060)
INFO:Train: 27 [ 150/625 ( 24%)]  Loss: 0.004882 (0.00500)  Time: 0.701s, 2921.32/s  (0.723s, 2832.99/s)  avg LR: 7.200e-03  iter ratio: 0.0000  Data: 0.029 (0.049)
INFO:Train: 27 [ 200/625 ( 32%)]  Loss: 0.004910 (0.00498)  Time: 0.701s, 2921.30/s  (0.718s, 2854.03/s)  avg LR: 7.200e-03  iter ratio: 0.0000  Data: 0.028 (0.044)
INFO:Train: 27 [ 250/625 ( 40%)]  Loss: 0.005198 (0.00502)  Time: 0.700s, 2927.17/s  (0.714s, 2866.75/s)  avg LR: 7.200e-03  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 27 [ 300/625 ( 48%)]  Loss: 0.005371 (0.00507)  Time: 0.700s, 2925.96/s  (0.712s, 2875.36/s)  avg LR: 7.200e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 27 [ 350/625 ( 56%)]  Loss: 0.004992 (0.00506)  Time: 0.701s, 2919.97/s  (0.711s, 2881.60/s)  avg LR: 7.200e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 27 [ 400/625 ( 64%)]  Loss: 0.004784 (0.00503)  Time: 0.699s, 2930.52/s  (0.710s, 2886.30/s)  avg LR: 7.200e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 27 [ 450/625 ( 72%)]  Loss: 0.005924 (0.00512)  Time: 0.701s, 2919.53/s  (0.709s, 2889.94/s)  avg LR: 7.200e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 27 [ 500/625 ( 80%)]  Loss: 0.004627 (0.00507)  Time: 0.699s, 2929.68/s  (0.708s, 2892.87/s)  avg LR: 7.200e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 27 [ 550/625 ( 88%)]  Loss: 0.004907 (0.00506)  Time: 0.702s, 2917.14/s  (0.707s, 2895.24/s)  avg LR: 7.200e-03  iter ratio: 0.0000  Data: 0.029 (0.034)
INFO:Train: 27 [ 600/625 ( 96%)]  Loss: 0.004657 (0.00503)  Time: 0.709s, 2887.96/s  (0.707s, 2897.16/s)  avg LR: 7.200e-03  iter ratio: 0.0000  Data: 0.031 (0.033)
INFO:Train: 27 [ 624/625 (100%)]  Loss: 0.004600 (0.00500)  Time: 0.673s, 3045.18/s  (0.707s, 2898.25/s)  avg LR: 7.200e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.385 (4.385)  Loss:  1.6797 (1.6797)  Acc@1: 61.0840 (61.0840)  Acc@5: 84.4727 (84.4727)
INFO:Test: [  24/24]  Time: 0.080 (0.498)  Loss:  1.5020 (2.1826)  Acc@1: 66.6274 (51.7820)  Acc@5: 86.0849 (77.0620)
INFO:27-epoch: remaining time 35.86 h
INFO:Train: 28 [   0/625 (  0%)]  Loss: 0.004893 (0.00489)  Time: 4.602s,  444.98/s  (4.602s,  444.98/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 3.706 (3.706)
INFO:Train: 28 [  50/625 (  8%)]  Loss: 0.004775 (0.00483)  Time: 0.700s, 2924.99/s  (0.778s, 2631.58/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.028 (0.101)
INFO:Train: 28 [ 100/625 ( 16%)]  Loss: 0.004855 (0.00484)  Time: 0.700s, 2924.20/s  (0.741s, 2764.82/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.028 (0.066)
INFO:Train: 28 [ 150/625 ( 24%)]  Loss: 0.004973 (0.00487)  Time: 0.699s, 2928.43/s  (0.728s, 2813.19/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.027 (0.054)
INFO:Train: 28 [ 200/625 ( 32%)]  Loss: 0.004963 (0.00489)  Time: 0.700s, 2925.03/s  (0.722s, 2838.42/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.028 (0.048)
INFO:Train: 28 [ 250/625 ( 40%)]  Loss: 0.004890 (0.00489)  Time: 0.699s, 2931.12/s  (0.718s, 2853.69/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.027 (0.044)
INFO:Train: 28 [ 300/625 ( 48%)]  Loss: 0.005411 (0.00497)  Time: 0.700s, 2926.08/s  (0.715s, 2863.99/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 28 [ 350/625 ( 56%)]  Loss: 0.004884 (0.00496)  Time: 0.698s, 2935.80/s  (0.713s, 2871.52/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 28 [ 400/625 ( 64%)]  Loss: 0.004971 (0.00496)  Time: 0.701s, 2923.27/s  (0.712s, 2877.19/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 28 [ 450/625 ( 72%)]  Loss: 0.005511 (0.00501)  Time: 0.700s, 2927.25/s  (0.711s, 2881.56/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 28 [ 500/625 ( 80%)]  Loss: 0.005077 (0.00502)  Time: 0.700s, 2927.59/s  (0.710s, 2885.04/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 28 [ 550/625 ( 88%)]  Loss: 0.004786 (0.00500)  Time: 0.699s, 2928.60/s  (0.709s, 2887.86/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 28 [ 600/625 ( 96%)]  Loss: 0.005585 (0.00504)  Time: 0.703s, 2914.73/s  (0.709s, 2890.15/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 28 [ 624/625 (100%)]  Loss: 0.004419 (0.00500)  Time: 0.671s, 3052.86/s  (0.708s, 2891.68/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.298 (4.298)  Loss:  1.6670 (1.6670)  Acc@1: 62.1582 (62.1582)  Acc@5: 85.3027 (85.3027)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  1.3535 (2.1695)  Acc@1: 70.4009 (52.4340)  Acc@5: 88.6792 (77.7260)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-23.pth.tar', 52.501999970703125)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-28.pth.tar', 52.43400007080078)

INFO:28-epoch: remaining time 35.81 h
INFO:Train: 29 [   0/625 (  0%)]  Loss: 0.004824 (0.00482)  Time: 4.342s,  471.64/s  (4.342s,  471.64/s)  avg LR: 7.733e-03  iter ratio: 0.0000  Data: 3.652 (3.652)
INFO:Train: 29 [  50/625 (  8%)]  Loss: 0.005105 (0.00496)  Time: 0.700s, 2927.59/s  (0.773s, 2648.51/s)  avg LR: 7.733e-03  iter ratio: 0.0000  Data: 0.027 (0.100)
INFO:Train: 29 [ 100/625 ( 16%)]  Loss: 0.004602 (0.00484)  Time: 0.699s, 2929.17/s  (0.738s, 2775.38/s)  avg LR: 7.733e-03  iter ratio: 0.0000  Data: 0.026 (0.065)
INFO:Train: 29 [ 150/625 ( 24%)]  Loss: 0.005159 (0.00492)  Time: 0.697s, 2937.26/s  (0.726s, 2821.17/s)  avg LR: 7.733e-03  iter ratio: 0.0000  Data: 0.024 (0.053)
INFO:Train: 29 [ 200/625 ( 32%)]  Loss: 0.004896 (0.00492)  Time: 0.699s, 2928.69/s  (0.720s, 2844.64/s)  avg LR: 7.733e-03  iter ratio: 0.0000  Data: 0.027 (0.047)
INFO:Train: 29 [ 250/625 ( 40%)]  Loss: 0.006101 (0.00511)  Time: 0.699s, 2931.08/s  (0.716s, 2858.80/s)  avg LR: 7.733e-03  iter ratio: 0.0000  Data: 0.026 (0.043)
INFO:Train: 29 [ 300/625 ( 48%)]  Loss: 0.004523 (0.00503)  Time: 0.698s, 2935.36/s  (0.714s, 2868.77/s)  avg LR: 7.733e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 29 [ 350/625 ( 56%)]  Loss: 0.005170 (0.00505)  Time: 0.697s, 2936.48/s  (0.712s, 2876.02/s)  avg LR: 7.733e-03  iter ratio: 0.0000  Data: 0.024 (0.039)
INFO:Train: 29 [ 400/625 ( 64%)]  Loss: 0.004531 (0.00499)  Time: 0.698s, 2933.16/s  (0.711s, 2881.38/s)  avg LR: 7.733e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 29 [ 450/625 ( 72%)]  Loss: 0.004680 (0.00496)  Time: 0.697s, 2937.28/s  (0.710s, 2885.55/s)  avg LR: 7.733e-03  iter ratio: 0.0000  Data: 0.024 (0.037)
INFO:Train: 29 [ 500/625 ( 80%)]  Loss: 0.005195 (0.00498)  Time: 0.697s, 2936.85/s  (0.709s, 2888.83/s)  avg LR: 7.733e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 29 [ 550/625 ( 88%)]  Loss: 0.005438 (0.00502)  Time: 0.699s, 2930.57/s  (0.708s, 2891.64/s)  avg LR: 7.733e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 29 [ 600/625 ( 96%)]  Loss: 0.004430 (0.00497)  Time: 0.699s, 2928.22/s  (0.708s, 2893.94/s)  avg LR: 7.733e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 29 [ 624/625 (100%)]  Loss: 0.005144 (0.00499)  Time: 0.671s, 3049.94/s  (0.707s, 2895.26/s)  avg LR: 7.733e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.343 (4.343)  Loss:  1.6611 (1.6611)  Acc@1: 63.0859 (63.0859)  Acc@5: 86.2793 (86.2793)
INFO:Test: [  24/24]  Time: 0.080 (0.494)  Loss:  1.3994 (2.4141)  Acc@1: 72.2877 (48.6860)  Acc@5: 88.2076 (74.2220)
INFO:29-epoch: remaining time 35.65 h
INFO:Train: 30 [   0/625 (  0%)]  Loss: 0.005234 (0.00523)  Time: 4.556s,  449.55/s  (4.556s,  449.55/s)  avg LR: 7.805e-03  iter ratio: 0.0000  Data: 3.605 (3.605)
INFO:Train: 30 [  50/625 (  8%)]  Loss: 0.004575 (0.00490)  Time: 0.698s, 2933.63/s  (0.778s, 2632.23/s)  avg LR: 7.805e-03  iter ratio: 0.0000  Data: 0.024 (0.099)
INFO:Train: 30 [ 100/625 ( 16%)]  Loss: 0.005293 (0.00503)  Time: 0.698s, 2936.10/s  (0.740s, 2767.01/s)  avg LR: 7.805e-03  iter ratio: 0.0000  Data: 0.024 (0.064)
INFO:Train: 30 [ 150/625 ( 24%)]  Loss: 0.004480 (0.00490)  Time: 0.698s, 2935.78/s  (0.727s, 2815.37/s)  avg LR: 7.805e-03  iter ratio: 0.0000  Data: 0.024 (0.052)
INFO:Train: 30 [ 200/625 ( 32%)]  Loss: 0.005268 (0.00497)  Time: 0.699s, 2930.02/s  (0.721s, 2840.61/s)  avg LR: 7.805e-03  iter ratio: 0.0000  Data: 0.023 (0.046)
INFO:Train: 30 [ 250/625 ( 40%)]  Loss: 0.005224 (0.00501)  Time: 0.699s, 2931.62/s  (0.717s, 2855.97/s)  avg LR: 7.805e-03  iter ratio: 0.0000  Data: 0.025 (0.042)
INFO:Train: 30 [ 300/625 ( 48%)]  Loss: 0.005109 (0.00503)  Time: 0.698s, 2934.07/s  (0.715s, 2866.30/s)  avg LR: 7.805e-03  iter ratio: 0.0000  Data: 0.024 (0.040)
INFO:Train: 30 [ 350/625 ( 56%)]  Loss: 0.004913 (0.00501)  Time: 0.698s, 2932.29/s  (0.713s, 2873.59/s)  avg LR: 7.805e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 30 [ 400/625 ( 64%)]  Loss: 0.004899 (0.00500)  Time: 0.698s, 2935.59/s  (0.711s, 2879.12/s)  avg LR: 7.805e-03  iter ratio: 0.0000  Data: 0.024 (0.037)
INFO:Train: 30 [ 450/625 ( 72%)]  Loss: 0.004853 (0.00498)  Time: 0.698s, 2932.42/s  (0.710s, 2883.43/s)  avg LR: 7.805e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 30 [ 500/625 ( 80%)]  Loss: 0.004600 (0.00495)  Time: 0.697s, 2937.29/s  (0.709s, 2886.93/s)  avg LR: 7.805e-03  iter ratio: 0.0000  Data: 0.023 (0.035)
INFO:Train: 30 [ 550/625 ( 88%)]  Loss: 0.004641 (0.00492)  Time: 0.698s, 2935.45/s  (0.709s, 2889.63/s)  avg LR: 7.805e-03  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 30 [ 600/625 ( 96%)]  Loss: 0.005760 (0.00499)  Time: 0.697s, 2939.43/s  (0.708s, 2891.74/s)  avg LR: 7.805e-03  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 30 [ 624/625 (100%)]  Loss: 0.005429 (0.00502)  Time: 0.671s, 3053.31/s  (0.708s, 2893.14/s)  avg LR: 7.805e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.287 (4.287)  Loss:  1.6943 (1.6943)  Acc@1: 64.0625 (64.0625)  Acc@5: 85.1562 (85.1562)
INFO:Test: [  24/24]  Time: 0.079 (0.497)  Loss:  1.4502 (2.2683)  Acc@1: 72.0519 (51.5820)  Acc@5: 85.3774 (76.7840)
INFO:30-epoch: remaining time 35.54 h
INFO:Train: 31 [   0/625 (  0%)]  Loss: 0.004821 (0.00482)  Time: 4.339s,  472.00/s  (4.339s,  472.00/s)  avg LR: 7.792e-03  iter ratio: 0.0000  Data: 3.651 (3.651)
INFO:Train: 31 [  50/625 (  8%)]  Loss: 0.004816 (0.00482)  Time: 0.698s, 2934.55/s  (0.773s, 2650.28/s)  avg LR: 7.792e-03  iter ratio: 0.0000  Data: 0.025 (0.099)
INFO:Train: 31 [ 100/625 ( 16%)]  Loss: 0.004478 (0.00470)  Time: 0.699s, 2930.69/s  (0.737s, 2778.25/s)  avg LR: 7.792e-03  iter ratio: 0.0000  Data: 0.025 (0.064)
INFO:Train: 31 [ 150/625 ( 24%)]  Loss: 0.004718 (0.00471)  Time: 0.699s, 2931.20/s  (0.725s, 2824.16/s)  avg LR: 7.792e-03  iter ratio: 0.0000  Data: 0.026 (0.052)
INFO:Train: 31 [ 200/625 ( 32%)]  Loss: 0.004088 (0.00458)  Time: 0.698s, 2934.04/s  (0.719s, 2847.65/s)  avg LR: 7.792e-03  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 31 [ 250/625 ( 40%)]  Loss: 0.005004 (0.00465)  Time: 0.698s, 2933.46/s  (0.716s, 2862.10/s)  avg LR: 7.792e-03  iter ratio: 0.0000  Data: 0.025 (0.042)
INFO:Train: 31 [ 300/625 ( 48%)]  Loss: 0.004373 (0.00461)  Time: 0.698s, 2933.13/s  (0.713s, 2871.82/s)  avg LR: 7.792e-03  iter ratio: 0.0000  Data: 0.025 (0.040)
INFO:Train: 31 [ 350/625 ( 56%)]  Loss: 0.004369 (0.00458)  Time: 0.698s, 2933.59/s  (0.711s, 2878.89/s)  avg LR: 7.792e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 31 [ 400/625 ( 64%)]  Loss: 0.004763 (0.00460)  Time: 0.701s, 2921.60/s  (0.710s, 2884.07/s)  avg LR: 7.792e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 31 [ 450/625 ( 72%)]  Loss: 0.005443 (0.00469)  Time: 0.698s, 2936.11/s  (0.709s, 2888.24/s)  avg LR: 7.792e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 31 [ 500/625 ( 80%)]  Loss: 0.004709 (0.00469)  Time: 0.698s, 2933.19/s  (0.708s, 2891.54/s)  avg LR: 7.792e-03  iter ratio: 0.0000  Data: 0.022 (0.035)
INFO:Train: 31 [ 550/625 ( 88%)]  Loss: 0.005373 (0.00475)  Time: 0.698s, 2933.44/s  (0.708s, 2894.30/s)  avg LR: 7.792e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 31 [ 600/625 ( 96%)]  Loss: 0.004284 (0.00471)  Time: 0.697s, 2938.23/s  (0.707s, 2896.60/s)  avg LR: 7.792e-03  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 31 [ 624/625 (100%)]  Loss: 0.004816 (0.00472)  Time: 0.672s, 3047.88/s  (0.707s, 2897.83/s)  avg LR: 7.792e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.333 (4.333)  Loss:  1.5332 (1.5332)  Acc@1: 65.7227 (65.7227)  Acc@5: 86.9629 (86.9629)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.4121 (2.2367)  Acc@1: 72.7594 (52.2000)  Acc@5: 86.0849 (77.1460)
INFO:31-epoch: remaining time 35.36 h
INFO:Train: 32 [   0/625 (  0%)]  Loss: 0.004837 (0.00484)  Time: 4.299s,  476.36/s  (4.299s,  476.36/s)  avg LR: 7.779e-03  iter ratio: 0.0000  Data: 3.390 (3.390)
INFO:Train: 32 [  50/625 (  8%)]  Loss: 0.004522 (0.00468)  Time: 0.699s, 2931.60/s  (0.773s, 2650.39/s)  avg LR: 7.779e-03  iter ratio: 0.0000  Data: 0.025 (0.094)
INFO:Train: 32 [ 100/625 ( 16%)]  Loss: 0.004486 (0.00461)  Time: 0.697s, 2937.11/s  (0.737s, 2776.98/s)  avg LR: 7.779e-03  iter ratio: 0.0000  Data: 0.024 (0.061)
INFO:Train: 32 [ 150/625 ( 24%)]  Loss: 0.005378 (0.00481)  Time: 0.697s, 2938.18/s  (0.726s, 2822.14/s)  avg LR: 7.779e-03  iter ratio: 0.0000  Data: 0.023 (0.050)
INFO:Train: 32 [ 200/625 ( 32%)]  Loss: 0.004282 (0.00470)  Time: 0.699s, 2929.56/s  (0.720s, 2845.16/s)  avg LR: 7.779e-03  iter ratio: 0.0000  Data: 0.024 (0.045)
INFO:Train: 32 [ 250/625 ( 40%)]  Loss: 0.004844 (0.00472)  Time: 0.697s, 2936.75/s  (0.716s, 2859.34/s)  avg LR: 7.779e-03  iter ratio: 0.0000  Data: 0.023 (0.041)
INFO:Train: 32 [ 300/625 ( 48%)]  Loss: 0.005194 (0.00479)  Time: 0.700s, 2926.91/s  (0.714s, 2868.62/s)  avg LR: 7.779e-03  iter ratio: 0.0000  Data: 0.024 (0.039)
INFO:Train: 32 [ 350/625 ( 56%)]  Loss: 0.004947 (0.00481)  Time: 0.699s, 2929.13/s  (0.712s, 2875.24/s)  avg LR: 7.779e-03  iter ratio: 0.0000  Data: 0.024 (0.038)
INFO:Train: 32 [ 400/625 ( 64%)]  Loss: 0.004797 (0.00481)  Time: 0.699s, 2930.26/s  (0.711s, 2880.34/s)  avg LR: 7.779e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 32 [ 450/625 ( 72%)]  Loss: 0.004878 (0.00482)  Time: 0.697s, 2936.24/s  (0.710s, 2884.28/s)  avg LR: 7.779e-03  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 32 [ 500/625 ( 80%)]  Loss: 0.005411 (0.00487)  Time: 0.699s, 2930.24/s  (0.709s, 2887.45/s)  avg LR: 7.779e-03  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 32 [ 550/625 ( 88%)]  Loss: 0.004986 (0.00488)  Time: 0.699s, 2931.12/s  (0.709s, 2890.06/s)  avg LR: 7.779e-03  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 32 [ 600/625 ( 96%)]  Loss: 0.004590 (0.00486)  Time: 0.700s, 2924.84/s  (0.708s, 2892.26/s)  avg LR: 7.779e-03  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 32 [ 624/625 (100%)]  Loss: 0.005226 (0.00488)  Time: 0.672s, 3049.34/s  (0.708s, 2893.71/s)  avg LR: 7.779e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.293 (4.293)  Loss:  1.5332 (1.5332)  Acc@1: 68.6035 (68.6035)  Acc@5: 88.2812 (88.2812)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.4424 (2.2672)  Acc@1: 71.9340 (53.5220)  Acc@5: 87.8538 (78.3160)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-32.pth.tar', 53.5219999609375)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-23.pth.tar', 52.501999970703125)

INFO:32-epoch: remaining time 35.28 h
INFO:Train: 33 [   0/625 (  0%)]  Loss: 0.005109 (0.00511)  Time: 4.026s,  508.71/s  (4.026s,  508.71/s)  avg LR: 7.765e-03  iter ratio: 0.0000  Data: 3.337 (3.337)
INFO:Train: 33 [  50/625 (  8%)]  Loss: 0.004492 (0.00480)  Time: 0.697s, 2939.59/s  (0.766s, 2674.30/s)  avg LR: 7.765e-03  iter ratio: 0.0000  Data: 0.026 (0.094)
INFO:Train: 33 [ 100/625 ( 16%)]  Loss: 0.005475 (0.00503)  Time: 0.698s, 2934.86/s  (0.733s, 2792.37/s)  avg LR: 7.765e-03  iter ratio: 0.0000  Data: 0.026 (0.061)
INFO:Train: 33 [ 150/625 ( 24%)]  Loss: 0.004791 (0.00497)  Time: 0.699s, 2931.80/s  (0.723s, 2834.55/s)  avg LR: 7.765e-03  iter ratio: 0.0000  Data: 0.025 (0.050)
INFO:Train: 33 [ 200/625 ( 32%)]  Loss: 0.004779 (0.00493)  Time: 0.702s, 2919.35/s  (0.717s, 2855.57/s)  avg LR: 7.765e-03  iter ratio: 0.0000  Data: 0.026 (0.045)
INFO:Train: 33 [ 250/625 ( 40%)]  Loss: 0.004194 (0.00481)  Time: 0.699s, 2928.33/s  (0.714s, 2868.15/s)  avg LR: 7.765e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 33 [ 300/625 ( 48%)]  Loss: 0.004682 (0.00479)  Time: 0.699s, 2930.84/s  (0.712s, 2876.85/s)  avg LR: 7.765e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 33 [ 350/625 ( 56%)]  Loss: 0.004494 (0.00475)  Time: 0.699s, 2930.85/s  (0.710s, 2883.02/s)  avg LR: 7.765e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 33 [ 400/625 ( 64%)]  Loss: 0.004535 (0.00473)  Time: 0.699s, 2928.77/s  (0.709s, 2887.50/s)  avg LR: 7.765e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 33 [ 450/625 ( 72%)]  Loss: 0.005062 (0.00476)  Time: 0.700s, 2925.91/s  (0.708s, 2890.90/s)  avg LR: 7.765e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 33 [ 500/625 ( 80%)]  Loss: 0.005356 (0.00482)  Time: 0.699s, 2929.50/s  (0.708s, 2893.65/s)  avg LR: 7.765e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 33 [ 550/625 ( 88%)]  Loss: 0.004354 (0.00478)  Time: 0.700s, 2927.02/s  (0.707s, 2895.96/s)  avg LR: 7.765e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 33 [ 600/625 ( 96%)]  Loss: 0.004324 (0.00474)  Time: 0.699s, 2928.21/s  (0.707s, 2897.87/s)  avg LR: 7.765e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 33 [ 624/625 (100%)]  Loss: 0.005473 (0.00479)  Time: 0.670s, 3054.87/s  (0.706s, 2899.07/s)  avg LR: 7.765e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.331 (4.331)  Loss:  1.5508 (1.5508)  Acc@1: 67.2852 (67.2852)  Acc@5: 86.6699 (86.6699)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.2178 (2.2248)  Acc@1: 74.6462 (52.0800)  Acc@5: 90.5660 (77.0860)
INFO:33-epoch: remaining time 35.09 h
INFO:Train: 34 [   0/625 (  0%)]  Loss: 0.005254 (0.00525)  Time: 4.383s,  467.26/s  (4.383s,  467.26/s)  avg LR: 7.751e-03  iter ratio: 0.0000  Data: 3.474 (3.474)
INFO:Train: 34 [  50/625 (  8%)]  Loss: 0.004597 (0.00493)  Time: 0.700s, 2925.88/s  (0.775s, 2642.70/s)  avg LR: 7.751e-03  iter ratio: 0.0000  Data: 0.025 (0.096)
INFO:Train: 34 [ 100/625 ( 16%)]  Loss: 0.004555 (0.00480)  Time: 0.700s, 2923.66/s  (0.739s, 2771.46/s)  avg LR: 7.751e-03  iter ratio: 0.0000  Data: 0.025 (0.063)
INFO:Train: 34 [ 150/625 ( 24%)]  Loss: 0.004896 (0.00483)  Time: 0.700s, 2924.62/s  (0.727s, 2817.68/s)  avg LR: 7.751e-03  iter ratio: 0.0000  Data: 0.025 (0.051)
INFO:Train: 34 [ 200/625 ( 32%)]  Loss: 0.004970 (0.00485)  Time: 0.699s, 2928.56/s  (0.721s, 2841.21/s)  avg LR: 7.751e-03  iter ratio: 0.0000  Data: 0.025 (0.046)
INFO:Train: 34 [ 250/625 ( 40%)]  Loss: 0.004531 (0.00480)  Time: 0.701s, 2920.43/s  (0.717s, 2855.61/s)  avg LR: 7.751e-03  iter ratio: 0.0000  Data: 0.025 (0.042)
INFO:Train: 34 [ 300/625 ( 48%)]  Loss: 0.004081 (0.00470)  Time: 0.701s, 2922.24/s  (0.715s, 2865.35/s)  avg LR: 7.751e-03  iter ratio: 0.0000  Data: 0.025 (0.040)
INFO:Train: 34 [ 350/625 ( 56%)]  Loss: 0.004911 (0.00472)  Time: 0.701s, 2923.08/s  (0.713s, 2872.28/s)  avg LR: 7.751e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 34 [ 400/625 ( 64%)]  Loss: 0.004583 (0.00471)  Time: 0.702s, 2916.89/s  (0.712s, 2877.45/s)  avg LR: 7.751e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 34 [ 450/625 ( 72%)]  Loss: 0.005569 (0.00479)  Time: 0.699s, 2929.04/s  (0.711s, 2881.56/s)  avg LR: 7.751e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 34 [ 500/625 ( 80%)]  Loss: 0.005471 (0.00486)  Time: 0.701s, 2919.65/s  (0.710s, 2884.77/s)  avg LR: 7.751e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 34 [ 550/625 ( 88%)]  Loss: 0.004915 (0.00486)  Time: 0.701s, 2919.65/s  (0.709s, 2887.33/s)  avg LR: 7.751e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 34 [ 600/625 ( 96%)]  Loss: 0.005327 (0.00490)  Time: 0.701s, 2921.43/s  (0.709s, 2889.52/s)  avg LR: 7.751e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 34 [ 624/625 (100%)]  Loss: 0.004390 (0.00486)  Time: 0.671s, 3052.31/s  (0.708s, 2891.08/s)  avg LR: 7.751e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.313 (4.313)  Loss:  1.8857 (1.8857)  Acc@1: 60.2051 (60.2051)  Acc@5: 82.2754 (82.2754)
INFO:Test: [  24/24]  Time: 0.079 (0.495)  Loss:  1.6348 (2.3266)  Acc@1: 68.9859 (51.1280)  Acc@5: 86.0849 (76.2440)
INFO:34-epoch: remaining time 35.05 h
INFO:Train: 35 [   0/625 (  0%)]  Loss: 0.005018 (0.00502)  Time: 4.119s,  497.26/s  (4.119s,  497.26/s)  avg LR: 7.736e-03  iter ratio: 0.0000  Data: 3.427 (3.427)
INFO:Train: 35 [  50/625 (  8%)]  Loss: 0.004954 (0.00499)  Time: 0.699s, 2929.16/s  (0.769s, 2663.91/s)  avg LR: 7.736e-03  iter ratio: 0.0000  Data: 0.026 (0.093)
INFO:Train: 35 [ 100/625 ( 16%)]  Loss: 0.005689 (0.00522)  Time: 0.699s, 2929.93/s  (0.735s, 2785.16/s)  avg LR: 7.736e-03  iter ratio: 0.0000  Data: 0.026 (0.060)
INFO:Train: 35 [ 150/625 ( 24%)]  Loss: 0.004834 (0.00512)  Time: 0.697s, 2937.78/s  (0.724s, 2828.75/s)  avg LR: 7.736e-03  iter ratio: 0.0000  Data: 0.026 (0.049)
INFO:Train: 35 [ 200/625 ( 32%)]  Loss: 0.004980 (0.00510)  Time: 0.700s, 2923.65/s  (0.718s, 2851.08/s)  avg LR: 7.736e-03  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 35 [ 250/625 ( 40%)]  Loss: 0.004558 (0.00501)  Time: 0.699s, 2928.37/s  (0.715s, 2864.51/s)  avg LR: 7.736e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 35 [ 300/625 ( 48%)]  Loss: 0.005384 (0.00506)  Time: 0.698s, 2935.65/s  (0.713s, 2873.77/s)  avg LR: 7.736e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 35 [ 350/625 ( 56%)]  Loss: 0.004455 (0.00498)  Time: 0.702s, 2918.33/s  (0.711s, 2880.08/s)  avg LR: 7.736e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 35 [ 400/625 ( 64%)]  Loss: 0.004488 (0.00493)  Time: 0.701s, 2920.64/s  (0.710s, 2884.90/s)  avg LR: 7.736e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 35 [ 450/625 ( 72%)]  Loss: 0.004680 (0.00490)  Time: 0.700s, 2925.71/s  (0.709s, 2888.51/s)  avg LR: 7.736e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 35 [ 500/625 ( 80%)]  Loss: 0.004695 (0.00488)  Time: 0.701s, 2922.99/s  (0.708s, 2891.37/s)  avg LR: 7.736e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 35 [ 550/625 ( 88%)]  Loss: 0.004879 (0.00488)  Time: 0.700s, 2926.90/s  (0.708s, 2893.64/s)  avg LR: 7.736e-03  iter ratio: 0.0000  Data: 0.028 (0.032)
INFO:Train: 35 [ 600/625 ( 96%)]  Loss: 0.004444 (0.00485)  Time: 0.700s, 2924.73/s  (0.707s, 2895.68/s)  avg LR: 7.736e-03  iter ratio: 0.0000  Data: 0.027 (0.032)
INFO:Train: 35 [ 624/625 (100%)]  Loss: 0.004674 (0.00484)  Time: 0.672s, 3046.08/s  (0.707s, 2896.95/s)  avg LR: 7.736e-03  iter ratio: 0.0000  Data: 0.000 (0.031)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.354 (4.354)  Loss:  1.6494 (1.6494)  Acc@1: 64.5996 (64.5996)  Acc@5: 84.6680 (84.6680)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.3652 (2.1900)  Acc@1: 71.2264 (53.2020)  Acc@5: 88.2076 (77.7580)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-32.pth.tar', 53.5219999609375)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-35.pth.tar', 53.20199991210937)

INFO:35-epoch: remaining time 34.87 h
INFO:Train: 36 [   0/625 (  0%)]  Loss: 0.005226 (0.00523)  Time: 4.524s,  452.73/s  (4.524s,  452.73/s)  avg LR: 7.721e-03  iter ratio: 0.0000  Data: 3.610 (3.610)
INFO:Train: 36 [  50/625 (  8%)]  Loss: 0.004736 (0.00498)  Time: 0.697s, 2938.61/s  (0.777s, 2635.71/s)  avg LR: 7.721e-03  iter ratio: 0.0000  Data: 0.024 (0.099)
INFO:Train: 36 [ 100/625 ( 16%)]  Loss: 0.005110 (0.00502)  Time: 0.698s, 2933.02/s  (0.740s, 2768.64/s)  avg LR: 7.721e-03  iter ratio: 0.0000  Data: 0.025 (0.064)
INFO:Train: 36 [ 150/625 ( 24%)]  Loss: 0.003946 (0.00475)  Time: 0.698s, 2936.10/s  (0.727s, 2816.38/s)  avg LR: 7.721e-03  iter ratio: 0.0000  Data: 0.024 (0.052)
INFO:Train: 36 [ 200/625 ( 32%)]  Loss: 0.005407 (0.00488)  Time: 0.699s, 2930.00/s  (0.721s, 2840.75/s)  avg LR: 7.721e-03  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 36 [ 250/625 ( 40%)]  Loss: 0.004512 (0.00482)  Time: 0.698s, 2935.63/s  (0.717s, 2855.77/s)  avg LR: 7.721e-03  iter ratio: 0.0000  Data: 0.024 (0.043)
INFO:Train: 36 [ 300/625 ( 48%)]  Loss: 0.004543 (0.00478)  Time: 0.698s, 2932.94/s  (0.715s, 2866.03/s)  avg LR: 7.721e-03  iter ratio: 0.0000  Data: 0.024 (0.040)
INFO:Train: 36 [ 350/625 ( 56%)]  Loss: 0.004980 (0.00481)  Time: 0.698s, 2932.55/s  (0.713s, 2873.37/s)  avg LR: 7.721e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 36 [ 400/625 ( 64%)]  Loss: 0.005157 (0.00485)  Time: 0.699s, 2931.53/s  (0.711s, 2878.87/s)  avg LR: 7.721e-03  iter ratio: 0.0000  Data: 0.024 (0.037)
INFO:Train: 36 [ 450/625 ( 72%)]  Loss: 0.004250 (0.00479)  Time: 0.698s, 2935.01/s  (0.710s, 2883.24/s)  avg LR: 7.721e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 36 [ 500/625 ( 80%)]  Loss: 0.004967 (0.00480)  Time: 0.699s, 2931.15/s  (0.709s, 2886.76/s)  avg LR: 7.721e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 36 [ 550/625 ( 88%)]  Loss: 0.005612 (0.00487)  Time: 0.698s, 2935.36/s  (0.709s, 2889.62/s)  avg LR: 7.721e-03  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 36 [ 600/625 ( 96%)]  Loss: 0.005183 (0.00489)  Time: 0.698s, 2935.00/s  (0.708s, 2892.00/s)  avg LR: 7.721e-03  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 36 [ 624/625 (100%)]  Loss: 0.004252 (0.00485)  Time: 0.671s, 3051.56/s  (0.708s, 2893.40/s)  avg LR: 7.721e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.309 (4.309)  Loss:  1.6387 (1.6387)  Acc@1: 65.8691 (65.8691)  Acc@5: 85.1074 (85.1074)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  1.2402 (2.1666)  Acc@1: 75.0000 (53.7760)  Acc@5: 90.8019 (78.6160)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-36.pth.tar', 53.776)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-32.pth.tar', 53.5219999609375)

INFO:36-epoch: remaining time 34.76 h
INFO:Train: 37 [   0/625 (  0%)]  Loss: 0.005075 (0.00508)  Time: 4.034s,  507.70/s  (4.034s,  507.70/s)  avg LR: 7.705e-03  iter ratio: 0.0000  Data: 3.354 (3.354)
INFO:Train: 37 [  50/625 (  8%)]  Loss: 0.004605 (0.00484)  Time: 0.701s, 2920.81/s  (0.767s, 2671.63/s)  avg LR: 7.705e-03  iter ratio: 0.0000  Data: 0.025 (0.094)
INFO:Train: 37 [ 100/625 ( 16%)]  Loss: 0.004737 (0.00481)  Time: 0.699s, 2928.69/s  (0.734s, 2788.95/s)  avg LR: 7.705e-03  iter ratio: 0.0000  Data: 0.026 (0.062)
INFO:Train: 37 [ 150/625 ( 24%)]  Loss: 0.004965 (0.00485)  Time: 0.700s, 2923.82/s  (0.723s, 2831.08/s)  avg LR: 7.705e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 37 [ 200/625 ( 32%)]  Loss: 0.004494 (0.00478)  Time: 0.701s, 2921.58/s  (0.718s, 2852.40/s)  avg LR: 7.705e-03  iter ratio: 0.0000  Data: 0.026 (0.045)
INFO:Train: 37 [ 250/625 ( 40%)]  Loss: 0.004644 (0.00475)  Time: 0.701s, 2922.85/s  (0.715s, 2865.49/s)  avg LR: 7.705e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 37 [ 300/625 ( 48%)]  Loss: 0.004915 (0.00478)  Time: 0.697s, 2938.36/s  (0.713s, 2874.24/s)  avg LR: 7.705e-03  iter ratio: 0.0000  Data: 0.023 (0.040)
INFO:Train: 37 [ 350/625 ( 56%)]  Loss: 0.005023 (0.00481)  Time: 0.700s, 2927.13/s  (0.711s, 2880.54/s)  avg LR: 7.705e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 37 [ 400/625 ( 64%)]  Loss: 0.004393 (0.00476)  Time: 0.700s, 2925.38/s  (0.710s, 2885.26/s)  avg LR: 7.705e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 37 [ 450/625 ( 72%)]  Loss: 0.004534 (0.00474)  Time: 0.702s, 2918.72/s  (0.709s, 2888.99/s)  avg LR: 7.705e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 37 [ 500/625 ( 80%)]  Loss: 0.004127 (0.00468)  Time: 0.702s, 2915.51/s  (0.708s, 2891.98/s)  avg LR: 7.705e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 37 [ 550/625 ( 88%)]  Loss: 0.004790 (0.00469)  Time: 0.700s, 2927.43/s  (0.708s, 2894.40/s)  avg LR: 7.705e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 37 [ 600/625 ( 96%)]  Loss: 0.004970 (0.00471)  Time: 0.701s, 2922.54/s  (0.707s, 2896.50/s)  avg LR: 7.705e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 37 [ 624/625 (100%)]  Loss: 0.004978 (0.00473)  Time: 0.671s, 3051.01/s  (0.707s, 2897.77/s)  avg LR: 7.705e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.370 (4.370)  Loss:  1.5352 (1.5352)  Acc@1: 65.4785 (65.4785)  Acc@5: 86.6211 (86.6211)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.3652 (2.1546)  Acc@1: 69.3396 (53.1020)  Acc@5: 87.0283 (78.2260)
INFO:37-epoch: remaining time 34.58 h
INFO:Train: 38 [   0/625 (  0%)]  Loss: 0.004760 (0.00476)  Time: 4.224s,  484.87/s  (4.224s,  484.87/s)  avg LR: 7.689e-03  iter ratio: 0.0000  Data: 3.296 (3.296)
INFO:Train: 38 [  50/625 (  8%)]  Loss: 0.004879 (0.00482)  Time: 0.702s, 2917.75/s  (0.771s, 2657.18/s)  avg LR: 7.689e-03  iter ratio: 0.0000  Data: 0.026 (0.092)
INFO:Train: 38 [ 100/625 ( 16%)]  Loss: 0.004936 (0.00486)  Time: 0.702s, 2918.40/s  (0.736s, 2781.53/s)  avg LR: 7.689e-03  iter ratio: 0.0000  Data: 0.026 (0.060)
INFO:Train: 38 [ 150/625 ( 24%)]  Loss: 0.004895 (0.00487)  Time: 0.704s, 2910.04/s  (0.725s, 2826.03/s)  avg LR: 7.689e-03  iter ratio: 0.0000  Data: 0.027 (0.049)
INFO:Train: 38 [ 200/625 ( 32%)]  Loss: 0.004309 (0.00476)  Time: 0.702s, 2916.62/s  (0.719s, 2849.06/s)  avg LR: 7.689e-03  iter ratio: 0.0000  Data: 0.025 (0.044)
INFO:Train: 38 [ 250/625 ( 40%)]  Loss: 0.004699 (0.00475)  Time: 0.702s, 2917.16/s  (0.715s, 2863.08/s)  avg LR: 7.689e-03  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 38 [ 300/625 ( 48%)]  Loss: 0.004405 (0.00470)  Time: 0.700s, 2924.52/s  (0.713s, 2872.32/s)  avg LR: 7.689e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 38 [ 350/625 ( 56%)]  Loss: 0.004515 (0.00467)  Time: 0.701s, 2921.11/s  (0.711s, 2879.07/s)  avg LR: 7.689e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 38 [ 400/625 ( 64%)]  Loss: 0.004798 (0.00469)  Time: 0.702s, 2917.06/s  (0.710s, 2884.01/s)  avg LR: 7.689e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 38 [ 450/625 ( 72%)]  Loss: 0.004479 (0.00467)  Time: 0.702s, 2918.96/s  (0.709s, 2887.94/s)  avg LR: 7.689e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 38 [ 500/625 ( 80%)]  Loss: 0.004025 (0.00461)  Time: 0.702s, 2918.20/s  (0.708s, 2891.08/s)  avg LR: 7.689e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 38 [ 550/625 ( 88%)]  Loss: 0.005142 (0.00465)  Time: 0.701s, 2922.77/s  (0.708s, 2893.71/s)  avg LR: 7.689e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 38 [ 600/625 ( 96%)]  Loss: 0.004470 (0.00464)  Time: 0.704s, 2910.15/s  (0.707s, 2895.92/s)  avg LR: 7.689e-03  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 38 [ 624/625 (100%)]  Loss: 0.005102 (0.00467)  Time: 0.670s, 3056.10/s  (0.707s, 2897.48/s)  avg LR: 7.689e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.300 (4.300)  Loss:  1.6738 (1.6738)  Acc@1: 63.2812 (63.2812)  Acc@5: 85.4980 (85.4980)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  1.2754 (2.1950)  Acc@1: 73.2311 (52.9800)  Acc@5: 89.0330 (77.7340)
INFO:38-epoch: remaining time 34.49 h
INFO:Train: 39 [   0/625 (  0%)]  Loss: 0.004718 (0.00472)  Time: 4.391s,  466.44/s  (4.391s,  466.44/s)  avg LR: 7.673e-03  iter ratio: 0.0000  Data: 3.691 (3.691)
INFO:Train: 39 [  50/625 (  8%)]  Loss: 0.005093 (0.00491)  Time: 0.702s, 2915.96/s  (0.773s, 2649.37/s)  avg LR: 7.673e-03  iter ratio: 0.0000  Data: 0.027 (0.099)
INFO:Train: 39 [ 100/625 ( 16%)]  Loss: 0.005071 (0.00496)  Time: 0.700s, 2925.29/s  (0.737s, 2779.71/s)  avg LR: 7.673e-03  iter ratio: 0.0000  Data: 0.026 (0.063)
INFO:Train: 39 [ 150/625 ( 24%)]  Loss: 0.005060 (0.00499)  Time: 0.699s, 2931.69/s  (0.725s, 2826.29/s)  avg LR: 7.673e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 39 [ 200/625 ( 32%)]  Loss: 0.004807 (0.00495)  Time: 0.700s, 2924.07/s  (0.719s, 2850.38/s)  avg LR: 7.673e-03  iter ratio: 0.0000  Data: 0.025 (0.045)
INFO:Train: 39 [ 250/625 ( 40%)]  Loss: 0.005705 (0.00508)  Time: 0.700s, 2926.85/s  (0.715s, 2865.02/s)  avg LR: 7.673e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 39 [ 300/625 ( 48%)]  Loss: 0.004936 (0.00506)  Time: 0.700s, 2926.81/s  (0.712s, 2874.91/s)  avg LR: 7.673e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 39 [ 350/625 ( 56%)]  Loss: 0.005170 (0.00507)  Time: 0.700s, 2925.19/s  (0.711s, 2882.22/s)  avg LR: 7.673e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 39 [ 400/625 ( 64%)]  Loss: 0.005558 (0.00512)  Time: 0.698s, 2933.92/s  (0.709s, 2887.63/s)  avg LR: 7.673e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 39 [ 450/625 ( 72%)]  Loss: 0.005461 (0.00516)  Time: 0.701s, 2922.38/s  (0.708s, 2891.69/s)  avg LR: 7.673e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 39 [ 500/625 ( 80%)]  Loss: 0.005604 (0.00520)  Time: 0.699s, 2931.91/s  (0.707s, 2895.18/s)  avg LR: 7.673e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 39 [ 550/625 ( 88%)]  Loss: 0.004416 (0.00513)  Time: 0.699s, 2931.64/s  (0.707s, 2898.07/s)  avg LR: 7.673e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 39 [ 600/625 ( 96%)]  Loss: 0.004636 (0.00510)  Time: 0.699s, 2931.94/s  (0.706s, 2900.41/s)  avg LR: 7.673e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 39 [ 624/625 (100%)]  Loss: 0.005182 (0.00510)  Time: 0.672s, 3047.21/s  (0.706s, 2901.83/s)  avg LR: 7.673e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.375 (4.375)  Loss:  1.5957 (1.5957)  Acc@1: 64.6973 (64.6973)  Acc@5: 85.8887 (85.8887)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  1.9502 (2.2782)  Acc@1: 61.4387 (51.0420)  Acc@5: 78.8915 (75.9220)
INFO:39-epoch: remaining time 34.27 h
INFO:Train: 40 [   0/625 (  0%)]  Loss: 0.004266 (0.00427)  Time: 4.292s,  477.21/s  (4.292s,  477.21/s)  avg LR: 7.656e-03  iter ratio: 0.0000  Data: 3.367 (3.367)
INFO:Train: 40 [  50/625 (  8%)]  Loss: 0.004852 (0.00456)  Time: 0.700s, 2926.68/s  (0.772s, 2652.24/s)  avg LR: 7.656e-03  iter ratio: 0.0000  Data: 0.026 (0.094)
INFO:Train: 40 [ 100/625 ( 16%)]  Loss: 0.004233 (0.00445)  Time: 0.701s, 2921.43/s  (0.737s, 2778.95/s)  avg LR: 7.656e-03  iter ratio: 0.0000  Data: 0.025 (0.061)
INFO:Train: 40 [ 150/625 ( 24%)]  Loss: 0.004982 (0.00458)  Time: 0.701s, 2920.12/s  (0.725s, 2824.42/s)  avg LR: 7.656e-03  iter ratio: 0.0000  Data: 0.026 (0.050)
INFO:Train: 40 [ 200/625 ( 32%)]  Loss: 0.004546 (0.00458)  Time: 0.702s, 2919.34/s  (0.719s, 2847.71/s)  avg LR: 7.656e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 40 [ 250/625 ( 40%)]  Loss: 0.005048 (0.00465)  Time: 0.701s, 2921.20/s  (0.716s, 2861.91/s)  avg LR: 7.656e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 40 [ 300/625 ( 48%)]  Loss: 0.004842 (0.00468)  Time: 0.702s, 2919.08/s  (0.713s, 2871.54/s)  avg LR: 7.656e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 40 [ 350/625 ( 56%)]  Loss: 0.005097 (0.00473)  Time: 0.702s, 2918.25/s  (0.711s, 2878.45/s)  avg LR: 7.656e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 40 [ 400/625 ( 64%)]  Loss: 0.004591 (0.00472)  Time: 0.703s, 2914.48/s  (0.710s, 2883.65/s)  avg LR: 7.656e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 40 [ 450/625 ( 72%)]  Loss: 0.004802 (0.00473)  Time: 0.703s, 2914.61/s  (0.709s, 2887.66/s)  avg LR: 7.656e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 40 [ 500/625 ( 80%)]  Loss: 0.005050 (0.00476)  Time: 0.702s, 2916.16/s  (0.708s, 2890.90/s)  avg LR: 7.656e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 40 [ 550/625 ( 88%)]  Loss: 0.004675 (0.00475)  Time: 0.701s, 2921.22/s  (0.708s, 2893.48/s)  avg LR: 7.656e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 40 [ 600/625 ( 96%)]  Loss: 0.004861 (0.00476)  Time: 0.703s, 2913.23/s  (0.707s, 2895.62/s)  avg LR: 7.656e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 40 [ 624/625 (100%)]  Loss: 0.004808 (0.00476)  Time: 0.671s, 3052.74/s  (0.707s, 2897.07/s)  avg LR: 7.656e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.301 (4.301)  Loss:  1.5977 (1.5977)  Acc@1: 63.1348 (63.1348)  Acc@5: 84.6680 (84.6680)
INFO:Test: [  24/24]  Time: 0.079 (0.493)  Loss:  1.2773 (2.0918)  Acc@1: 72.5236 (53.9600)  Acc@5: 89.7406 (78.9760)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-40.pth.tar', 53.96000008789063)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-36.pth.tar', 53.776)

INFO:40-epoch: remaining time 34.23 h
INFO:Train: 41 [   0/625 (  0%)]  Loss: 0.004752 (0.00475)  Time: 4.388s,  466.77/s  (4.388s,  466.77/s)  avg LR: 7.639e-03  iter ratio: 0.0000  Data: 3.692 (3.692)
INFO:Train: 41 [  50/625 (  8%)]  Loss: 0.004537 (0.00464)  Time: 0.702s, 2916.35/s  (0.776s, 2638.58/s)  avg LR: 7.639e-03  iter ratio: 0.0000  Data: 0.024 (0.098)
INFO:Train: 41 [ 100/625 ( 16%)]  Loss: 0.004661 (0.00465)  Time: 0.706s, 2901.60/s  (0.740s, 2765.96/s)  avg LR: 7.639e-03  iter ratio: 0.0000  Data: 0.024 (0.063)
INFO:Train: 41 [ 150/625 ( 24%)]  Loss: 0.005679 (0.00491)  Time: 0.704s, 2909.54/s  (0.728s, 2812.52/s)  avg LR: 7.639e-03  iter ratio: 0.0000  Data: 0.023 (0.051)
INFO:Train: 41 [ 200/625 ( 32%)]  Loss: 0.005049 (0.00494)  Time: 0.700s, 2926.74/s  (0.722s, 2836.22/s)  avg LR: 7.639e-03  iter ratio: 0.0000  Data: 0.025 (0.045)
INFO:Train: 41 [ 250/625 ( 40%)]  Loss: 0.004224 (0.00482)  Time: 0.700s, 2925.58/s  (0.718s, 2850.78/s)  avg LR: 7.639e-03  iter ratio: 0.0000  Data: 0.023 (0.041)
INFO:Train: 41 [ 300/625 ( 48%)]  Loss: 0.004818 (0.00482)  Time: 0.700s, 2926.33/s  (0.716s, 2860.55/s)  avg LR: 7.639e-03  iter ratio: 0.0000  Data: 0.024 (0.039)
INFO:Train: 41 [ 350/625 ( 56%)]  Loss: 0.004596 (0.00479)  Time: 0.700s, 2927.28/s  (0.714s, 2867.71/s)  avg LR: 7.639e-03  iter ratio: 0.0000  Data: 0.022 (0.037)
INFO:Train: 41 [ 400/625 ( 64%)]  Loss: 0.004496 (0.00476)  Time: 0.700s, 2925.62/s  (0.713s, 2873.09/s)  avg LR: 7.639e-03  iter ratio: 0.0000  Data: 0.022 (0.036)
INFO:Train: 41 [ 450/625 ( 72%)]  Loss: 0.004922 (0.00477)  Time: 0.699s, 2929.98/s  (0.712s, 2877.18/s)  avg LR: 7.639e-03  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 41 [ 500/625 ( 80%)]  Loss: 0.005069 (0.00480)  Time: 0.702s, 2919.09/s  (0.711s, 2880.58/s)  avg LR: 7.639e-03  iter ratio: 0.0000  Data: 0.023 (0.034)
INFO:Train: 41 [ 550/625 ( 88%)]  Loss: 0.004599 (0.00478)  Time: 0.699s, 2929.48/s  (0.710s, 2883.34/s)  avg LR: 7.639e-03  iter ratio: 0.0000  Data: 0.024 (0.033)
INFO:Train: 41 [ 600/625 ( 96%)]  Loss: 0.005249 (0.00482)  Time: 0.700s, 2926.25/s  (0.710s, 2885.75/s)  avg LR: 7.639e-03  iter ratio: 0.0000  Data: 0.023 (0.032)
INFO:Train: 41 [ 624/625 (100%)]  Loss: 0.005182 (0.00485)  Time: 0.672s, 3046.18/s  (0.709s, 2887.12/s)  avg LR: 7.639e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.351 (4.351)  Loss:  1.4365 (1.4365)  Acc@1: 66.8457 (66.8457)  Acc@5: 87.5977 (87.5977)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.1641 (1.9809)  Acc@1: 75.7076 (55.8100)  Acc@5: 89.3868 (80.3160)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-41.pth.tar', 55.81000004882812)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-40.pth.tar', 53.96000008789063)

INFO:41-epoch: remaining time 34.20 h
INFO:Train: 42 [   0/625 (  0%)]  Loss: 0.005496 (0.00550)  Time: 4.459s,  459.34/s  (4.459s,  459.34/s)  avg LR: 7.622e-03  iter ratio: 0.0000  Data: 3.550 (3.550)
INFO:Train: 42 [  50/625 (  8%)]  Loss: 0.004518 (0.00501)  Time: 0.698s, 2932.90/s  (0.774s, 2644.47/s)  avg LR: 7.622e-03  iter ratio: 0.0000  Data: 0.025 (0.096)
INFO:Train: 42 [ 100/625 ( 16%)]  Loss: 0.004559 (0.00486)  Time: 0.698s, 2932.51/s  (0.738s, 2776.71/s)  avg LR: 7.622e-03  iter ratio: 0.0000  Data: 0.025 (0.061)
INFO:Train: 42 [ 150/625 ( 24%)]  Loss: 0.004663 (0.00481)  Time: 0.698s, 2935.17/s  (0.725s, 2824.39/s)  avg LR: 7.622e-03  iter ratio: 0.0000  Data: 0.025 (0.049)
INFO:Train: 42 [ 200/625 ( 32%)]  Loss: 0.005627 (0.00497)  Time: 0.698s, 2933.93/s  (0.719s, 2849.01/s)  avg LR: 7.622e-03  iter ratio: 0.0000  Data: 0.024 (0.044)
INFO:Train: 42 [ 250/625 ( 40%)]  Loss: 0.004563 (0.00490)  Time: 0.699s, 2929.08/s  (0.715s, 2863.98/s)  avg LR: 7.622e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 42 [ 300/625 ( 48%)]  Loss: 0.004789 (0.00489)  Time: 0.697s, 2938.00/s  (0.713s, 2874.13/s)  avg LR: 7.622e-03  iter ratio: 0.0000  Data: 0.024 (0.038)
INFO:Train: 42 [ 350/625 ( 56%)]  Loss: 0.004673 (0.00486)  Time: 0.701s, 2923.39/s  (0.711s, 2881.45/s)  avg LR: 7.622e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 42 [ 400/625 ( 64%)]  Loss: 0.004401 (0.00481)  Time: 0.698s, 2933.72/s  (0.709s, 2887.00/s)  avg LR: 7.622e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 42 [ 450/625 ( 72%)]  Loss: 0.004016 (0.00473)  Time: 0.699s, 2931.89/s  (0.708s, 2891.22/s)  avg LR: 7.622e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 42 [ 500/625 ( 80%)]  Loss: 0.005120 (0.00477)  Time: 0.700s, 2925.99/s  (0.708s, 2894.64/s)  avg LR: 7.622e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 42 [ 550/625 ( 88%)]  Loss: 0.004259 (0.00472)  Time: 0.699s, 2930.29/s  (0.707s, 2897.52/s)  avg LR: 7.622e-03  iter ratio: 0.0000  Data: 0.024 (0.033)
INFO:Train: 42 [ 600/625 ( 96%)]  Loss: 0.004457 (0.00470)  Time: 0.698s, 2934.35/s  (0.706s, 2899.91/s)  avg LR: 7.622e-03  iter ratio: 0.0000  Data: 0.025 (0.032)
INFO:Train: 42 [ 624/625 (100%)]  Loss: 0.005043 (0.00473)  Time: 0.671s, 3052.30/s  (0.706s, 2901.33/s)  avg LR: 7.622e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.311 (4.311)  Loss:  1.4561 (1.4561)  Acc@1: 67.0898 (67.0898)  Acc@5: 87.9395 (87.9395)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  1.2988 (2.1238)  Acc@1: 72.2877 (54.3800)  Acc@5: 88.9151 (78.7620)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-41.pth.tar', 55.81000004882812)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-42.pth.tar', 54.37999998535156)

INFO:42-epoch: remaining time 33.91 h
INFO:Train: 43 [   0/625 (  0%)]  Loss: 0.005116 (0.00512)  Time: 4.409s,  464.47/s  (4.409s,  464.47/s)  avg LR: 7.604e-03  iter ratio: 0.0000  Data: 3.710 (3.710)
INFO:Train: 43 [  50/625 (  8%)]  Loss: 0.004910 (0.00501)  Time: 0.700s, 2924.95/s  (0.773s, 2648.24/s)  avg LR: 7.604e-03  iter ratio: 0.0000  Data: 0.026 (0.100)
INFO:Train: 43 [ 100/625 ( 16%)]  Loss: 0.004875 (0.00497)  Time: 0.701s, 2921.13/s  (0.737s, 2777.70/s)  avg LR: 7.604e-03  iter ratio: 0.0000  Data: 0.029 (0.064)
INFO:Train: 43 [ 150/625 ( 24%)]  Loss: 0.004533 (0.00486)  Time: 0.702s, 2919.15/s  (0.725s, 2824.32/s)  avg LR: 7.604e-03  iter ratio: 0.0000  Data: 0.027 (0.052)
INFO:Train: 43 [ 200/625 ( 32%)]  Loss: 0.004841 (0.00485)  Time: 0.701s, 2920.79/s  (0.719s, 2848.43/s)  avg LR: 7.604e-03  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 43 [ 250/625 ( 40%)]  Loss: 0.004624 (0.00482)  Time: 0.702s, 2916.30/s  (0.715s, 2863.05/s)  avg LR: 7.604e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 43 [ 300/625 ( 48%)]  Loss: 0.004620 (0.00479)  Time: 0.700s, 2923.72/s  (0.713s, 2872.97/s)  avg LR: 7.604e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 43 [ 350/625 ( 56%)]  Loss: 0.004622 (0.00477)  Time: 0.702s, 2919.26/s  (0.711s, 2880.06/s)  avg LR: 7.604e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 43 [ 400/625 ( 64%)]  Loss: 0.005168 (0.00481)  Time: 0.700s, 2927.48/s  (0.710s, 2885.29/s)  avg LR: 7.604e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 43 [ 450/625 ( 72%)]  Loss: 0.004423 (0.00477)  Time: 0.701s, 2923.44/s  (0.709s, 2889.44/s)  avg LR: 7.604e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 43 [ 500/625 ( 80%)]  Loss: 0.005454 (0.00484)  Time: 0.701s, 2919.82/s  (0.708s, 2892.74/s)  avg LR: 7.604e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 43 [ 550/625 ( 88%)]  Loss: 0.004588 (0.00481)  Time: 0.703s, 2914.78/s  (0.707s, 2895.39/s)  avg LR: 7.604e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 43 [ 600/625 ( 96%)]  Loss: 0.005016 (0.00483)  Time: 0.701s, 2922.46/s  (0.707s, 2897.65/s)  avg LR: 7.604e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 43 [ 624/625 (100%)]  Loss: 0.005553 (0.00488)  Time: 0.672s, 3046.15/s  (0.706s, 2899.08/s)  avg LR: 7.604e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.390 (4.390)  Loss:  1.4443 (1.4443)  Acc@1: 68.9453 (68.9453)  Acc@5: 88.6719 (88.6719)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.3037 (2.0780)  Acc@1: 73.3491 (55.5480)  Acc@5: 87.5000 (79.6000)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-41.pth.tar', 55.81000004882812)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-43.pth.tar', 55.54800005859375)

INFO:43-epoch: remaining time 33.81 h
INFO:Train: 44 [   0/625 (  0%)]  Loss: 0.005072 (0.00507)  Time: 4.353s,  470.43/s  (4.353s,  470.43/s)  avg LR: 7.585e-03  iter ratio: 0.0000  Data: 3.416 (3.416)
INFO:Train: 44 [  50/625 (  8%)]  Loss: 0.004805 (0.00494)  Time: 0.698s, 2935.21/s  (0.773s, 2648.16/s)  avg LR: 7.585e-03  iter ratio: 0.0000  Data: 0.025 (0.094)
INFO:Train: 44 [ 100/625 ( 16%)]  Loss: 0.004776 (0.00488)  Time: 0.698s, 2934.81/s  (0.737s, 2777.54/s)  avg LR: 7.585e-03  iter ratio: 0.0000  Data: 0.024 (0.061)
INFO:Train: 44 [ 150/625 ( 24%)]  Loss: 0.004758 (0.00485)  Time: 0.698s, 2932.03/s  (0.725s, 2824.79/s)  avg LR: 7.585e-03  iter ratio: 0.0000  Data: 0.025 (0.049)
INFO:Train: 44 [ 200/625 ( 32%)]  Loss: 0.004813 (0.00484)  Time: 0.699s, 2930.46/s  (0.719s, 2848.84/s)  avg LR: 7.585e-03  iter ratio: 0.0000  Data: 0.026 (0.044)
INFO:Train: 44 [ 250/625 ( 40%)]  Loss: 0.004718 (0.00482)  Time: 0.698s, 2932.95/s  (0.715s, 2863.81/s)  avg LR: 7.585e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 44 [ 300/625 ( 48%)]  Loss: 0.005201 (0.00488)  Time: 0.698s, 2932.87/s  (0.713s, 2873.72/s)  avg LR: 7.585e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 44 [ 350/625 ( 56%)]  Loss: 0.004842 (0.00487)  Time: 0.698s, 2932.90/s  (0.711s, 2880.83/s)  avg LR: 7.585e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 44 [ 400/625 ( 64%)]  Loss: 0.005189 (0.00491)  Time: 0.698s, 2934.12/s  (0.710s, 2886.36/s)  avg LR: 7.585e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 44 [ 450/625 ( 72%)]  Loss: 0.004861 (0.00490)  Time: 0.698s, 2935.36/s  (0.709s, 2890.58/s)  avg LR: 7.585e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 44 [ 500/625 ( 80%)]  Loss: 0.005240 (0.00493)  Time: 0.700s, 2924.87/s  (0.708s, 2894.03/s)  avg LR: 7.585e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 44 [ 550/625 ( 88%)]  Loss: 0.005047 (0.00494)  Time: 0.698s, 2934.45/s  (0.707s, 2896.85/s)  avg LR: 7.585e-03  iter ratio: 0.0000  Data: 0.024 (0.033)
INFO:Train: 44 [ 600/625 ( 96%)]  Loss: 0.004293 (0.00489)  Time: 0.698s, 2932.52/s  (0.706s, 2899.16/s)  avg LR: 7.585e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 44 [ 624/625 (100%)]  Loss: 0.004607 (0.00487)  Time: 0.671s, 3051.93/s  (0.706s, 2900.56/s)  avg LR: 7.585e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.289 (4.289)  Loss:  1.5049 (1.5049)  Acc@1: 67.9199 (67.9199)  Acc@5: 86.2793 (86.2793)
INFO:Test: [  24/24]  Time: 0.079 (0.495)  Loss:  1.1934 (2.0507)  Acc@1: 72.4057 (55.0180)  Acc@5: 90.6840 (79.3960)
INFO:44-epoch: remaining time 33.66 h
INFO:Train: 45 [   0/625 (  0%)]  Loss: 0.005053 (0.00505)  Time: 4.189s,  488.91/s  (4.189s,  488.91/s)  avg LR: 7.567e-03  iter ratio: 0.0000  Data: 3.487 (3.487)
INFO:Train: 45 [  50/625 (  8%)]  Loss: 0.005131 (0.00509)  Time: 0.699s, 2930.18/s  (0.771s, 2654.71/s)  avg LR: 7.567e-03  iter ratio: 0.0000  Data: 0.025 (0.093)
INFO:Train: 45 [ 100/625 ( 16%)]  Loss: 0.004782 (0.00499)  Time: 0.702s, 2916.77/s  (0.738s, 2776.57/s)  avg LR: 7.567e-03  iter ratio: 0.0000  Data: 0.025 (0.059)
INFO:Train: 45 [ 150/625 ( 24%)]  Loss: 0.004606 (0.00489)  Time: 0.702s, 2915.54/s  (0.726s, 2820.03/s)  avg LR: 7.567e-03  iter ratio: 0.0000  Data: 0.025 (0.047)
INFO:Train: 45 [ 200/625 ( 32%)]  Loss: 0.004483 (0.00481)  Time: 0.705s, 2904.27/s  (0.721s, 2842.00/s)  avg LR: 7.567e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 45 [ 250/625 ( 40%)]  Loss: 0.005006 (0.00484)  Time: 0.703s, 2912.59/s  (0.717s, 2855.50/s)  avg LR: 7.567e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 45 [ 300/625 ( 48%)]  Loss: 0.004461 (0.00479)  Time: 0.700s, 2926.37/s  (0.715s, 2864.66/s)  avg LR: 7.567e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 45 [ 350/625 ( 56%)]  Loss: 0.004944 (0.00481)  Time: 0.703s, 2912.01/s  (0.713s, 2871.05/s)  avg LR: 7.567e-03  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 45 [ 400/625 ( 64%)]  Loss: 0.004622 (0.00479)  Time: 0.704s, 2908.46/s  (0.712s, 2875.79/s)  avg LR: 7.567e-03  iter ratio: 0.0000  Data: 0.024 (0.033)
INFO:Train: 45 [ 450/625 ( 72%)]  Loss: 0.004552 (0.00476)  Time: 0.704s, 2909.26/s  (0.711s, 2879.49/s)  avg LR: 7.567e-03  iter ratio: 0.0000  Data: 0.024 (0.032)
INFO:Train: 45 [ 500/625 ( 80%)]  Loss: 0.005501 (0.00483)  Time: 0.705s, 2906.93/s  (0.711s, 2882.35/s)  avg LR: 7.567e-03  iter ratio: 0.0000  Data: 0.024 (0.031)
INFO:Train: 45 [ 550/625 ( 88%)]  Loss: 0.004641 (0.00482)  Time: 0.704s, 2909.01/s  (0.710s, 2884.72/s)  avg LR: 7.567e-03  iter ratio: 0.0000  Data: 0.022 (0.030)
INFO:Train: 45 [ 600/625 ( 96%)]  Loss: 0.005061 (0.00483)  Time: 0.702s, 2917.95/s  (0.709s, 2886.85/s)  avg LR: 7.567e-03  iter ratio: 0.0000  Data: 0.023 (0.030)
INFO:Train: 45 [ 624/625 (100%)]  Loss: 0.005009 (0.00485)  Time: 0.672s, 3046.08/s  (0.709s, 2888.23/s)  avg LR: 7.567e-03  iter ratio: 0.0000  Data: 0.000 (0.029)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.389 (4.389)  Loss:  1.8232 (1.8232)  Acc@1: 63.2324 (63.2324)  Acc@5: 81.6895 (81.6895)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.4863 (2.0972)  Acc@1: 68.8679 (54.1160)  Acc@5: 83.8443 (78.7720)
INFO:45-epoch: remaining time 33.68 h
INFO:Train: 46 [   0/625 (  0%)]  Loss: 0.005071 (0.00507)  Time: 4.418s,  463.59/s  (4.418s,  463.59/s)  avg LR: 7.548e-03  iter ratio: 0.0000  Data: 3.498 (3.498)
INFO:Train: 46 [  50/625 (  8%)]  Loss: 0.004253 (0.00466)  Time: 0.698s, 2934.65/s  (0.775s, 2642.22/s)  avg LR: 7.548e-03  iter ratio: 0.0000  Data: 0.026 (0.095)
INFO:Train: 46 [ 100/625 ( 16%)]  Loss: 0.004933 (0.00475)  Time: 0.699s, 2928.75/s  (0.739s, 2772.41/s)  avg LR: 7.548e-03  iter ratio: 0.0000  Data: 0.027 (0.061)
INFO:Train: 46 [ 150/625 ( 24%)]  Loss: 0.005496 (0.00494)  Time: 0.699s, 2929.13/s  (0.726s, 2819.25/s)  avg LR: 7.548e-03  iter ratio: 0.0000  Data: 0.026 (0.049)
INFO:Train: 46 [ 200/625 ( 32%)]  Loss: 0.005148 (0.00498)  Time: 0.700s, 2926.23/s  (0.720s, 2843.67/s)  avg LR: 7.548e-03  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 46 [ 250/625 ( 40%)]  Loss: 0.004806 (0.00495)  Time: 0.700s, 2927.49/s  (0.716s, 2858.44/s)  avg LR: 7.548e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 46 [ 300/625 ( 48%)]  Loss: 0.004179 (0.00484)  Time: 0.699s, 2929.49/s  (0.714s, 2868.62/s)  avg LR: 7.548e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 46 [ 350/625 ( 56%)]  Loss: 0.004824 (0.00484)  Time: 0.699s, 2929.44/s  (0.712s, 2875.84/s)  avg LR: 7.548e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 46 [ 400/625 ( 64%)]  Loss: 0.004946 (0.00485)  Time: 0.699s, 2929.17/s  (0.711s, 2881.27/s)  avg LR: 7.548e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 46 [ 450/625 ( 72%)]  Loss: 0.004858 (0.00485)  Time: 0.699s, 2927.97/s  (0.710s, 2885.61/s)  avg LR: 7.548e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 46 [ 500/625 ( 80%)]  Loss: 0.004662 (0.00483)  Time: 0.700s, 2927.49/s  (0.709s, 2888.95/s)  avg LR: 7.548e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 46 [ 550/625 ( 88%)]  Loss: 0.004485 (0.00481)  Time: 0.700s, 2926.63/s  (0.708s, 2891.77/s)  avg LR: 7.548e-03  iter ratio: 0.0000  Data: 0.027 (0.032)
INFO:Train: 46 [ 600/625 ( 96%)]  Loss: 0.005173 (0.00483)  Time: 0.699s, 2929.41/s  (0.708s, 2894.03/s)  avg LR: 7.548e-03  iter ratio: 0.0000  Data: 0.026 (0.032)
INFO:Train: 46 [ 624/625 (100%)]  Loss: 0.004453 (0.00481)  Time: 0.671s, 3051.46/s  (0.707s, 2895.52/s)  avg LR: 7.548e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.302 (4.302)  Loss:  1.4990 (1.4990)  Acc@1: 67.3340 (67.3340)  Acc@5: 87.0605 (87.0605)
INFO:Test: [  24/24]  Time: 0.079 (0.495)  Loss:  1.3564 (2.1652)  Acc@1: 70.9906 (53.1620)  Acc@5: 88.9151 (78.2660)
INFO:46-epoch: remaining time 33.47 h
INFO:Train: 47 [   0/625 (  0%)]  Loss: 0.004153 (0.00415)  Time: 4.134s,  495.44/s  (4.134s,  495.44/s)  avg LR: 7.528e-03  iter ratio: 0.0000  Data: 3.441 (3.441)
INFO:Train: 47 [  50/625 (  8%)]  Loss: 0.004998 (0.00458)  Time: 0.702s, 2915.89/s  (0.768s, 2667.94/s)  avg LR: 7.528e-03  iter ratio: 0.0000  Data: 0.027 (0.094)
INFO:Train: 47 [ 100/625 ( 16%)]  Loss: 0.004443 (0.00453)  Time: 0.701s, 2920.38/s  (0.734s, 2789.98/s)  avg LR: 7.528e-03  iter ratio: 0.0000  Data: 0.028 (0.060)
INFO:Train: 47 [ 150/625 ( 24%)]  Loss: 0.004561 (0.00454)  Time: 0.700s, 2924.35/s  (0.723s, 2833.61/s)  avg LR: 7.528e-03  iter ratio: 0.0000  Data: 0.027 (0.049)
INFO:Train: 47 [ 200/625 ( 32%)]  Loss: 0.005357 (0.00470)  Time: 0.700s, 2924.62/s  (0.717s, 2856.04/s)  avg LR: 7.528e-03  iter ratio: 0.0000  Data: 0.027 (0.044)
INFO:Train: 47 [ 250/625 ( 40%)]  Loss: 0.005518 (0.00484)  Time: 0.699s, 2929.40/s  (0.714s, 2869.81/s)  avg LR: 7.528e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 47 [ 300/625 ( 48%)]  Loss: 0.004711 (0.00482)  Time: 0.699s, 2929.61/s  (0.711s, 2879.04/s)  avg LR: 7.528e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 47 [ 350/625 ( 56%)]  Loss: 0.005209 (0.00487)  Time: 0.700s, 2926.52/s  (0.710s, 2885.74/s)  avg LR: 7.528e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 47 [ 400/625 ( 64%)]  Loss: 0.005078 (0.00489)  Time: 0.699s, 2929.69/s  (0.708s, 2890.73/s)  avg LR: 7.528e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 47 [ 450/625 ( 72%)]  Loss: 0.005471 (0.00495)  Time: 0.699s, 2928.01/s  (0.707s, 2894.76/s)  avg LR: 7.528e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 47 [ 500/625 ( 80%)]  Loss: 0.004498 (0.00491)  Time: 0.700s, 2926.98/s  (0.707s, 2898.28/s)  avg LR: 7.528e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 47 [ 550/625 ( 88%)]  Loss: 0.004831 (0.00490)  Time: 0.702s, 2919.22/s  (0.706s, 2900.72/s)  avg LR: 7.528e-03  iter ratio: 0.0000  Data: 0.029 (0.033)
INFO:Train: 47 [ 600/625 ( 96%)]  Loss: 0.004558 (0.00488)  Time: 0.700s, 2926.82/s  (0.706s, 2902.83/s)  avg LR: 7.528e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 47 [ 624/625 (100%)]  Loss: 0.005037 (0.00489)  Time: 0.670s, 3055.27/s  (0.705s, 2904.12/s)  avg LR: 7.528e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.388 (4.388)  Loss:  1.5840 (1.5840)  Acc@1: 66.3086 (66.3086)  Acc@5: 86.2305 (86.2305)
INFO:Test: [  24/24]  Time: 0.080 (0.497)  Loss:  1.4629 (2.0982)  Acc@1: 70.8726 (55.2740)  Acc@5: 86.0849 (79.2220)
INFO:47-epoch: remaining time 33.26 h
INFO:Train: 48 [   0/625 (  0%)]  Loss: 0.004402 (0.00440)  Time: 4.642s,  441.16/s  (4.642s,  441.16/s)  avg LR: 7.508e-03  iter ratio: 0.0000  Data: 3.738 (3.738)
INFO:Train: 48 [  50/625 (  8%)]  Loss: 0.004881 (0.00464)  Time: 0.699s, 2929.45/s  (0.779s, 2630.32/s)  avg LR: 7.508e-03  iter ratio: 0.0000  Data: 0.025 (0.101)
INFO:Train: 48 [ 100/625 ( 16%)]  Loss: 0.004876 (0.00472)  Time: 0.700s, 2927.47/s  (0.740s, 2766.80/s)  avg LR: 7.508e-03  iter ratio: 0.0000  Data: 0.026 (0.065)
INFO:Train: 48 [ 150/625 ( 24%)]  Loss: 0.004423 (0.00465)  Time: 0.700s, 2924.03/s  (0.727s, 2816.14/s)  avg LR: 7.508e-03  iter ratio: 0.0000  Data: 0.027 (0.052)
INFO:Train: 48 [ 200/625 ( 32%)]  Loss: 0.004693 (0.00466)  Time: 0.702s, 2917.65/s  (0.721s, 2841.78/s)  avg LR: 7.508e-03  iter ratio: 0.0000  Data: 0.028 (0.046)
INFO:Train: 48 [ 250/625 ( 40%)]  Loss: 0.005255 (0.00476)  Time: 0.700s, 2926.84/s  (0.717s, 2857.41/s)  avg LR: 7.508e-03  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 48 [ 300/625 ( 48%)]  Loss: 0.005067 (0.00480)  Time: 0.701s, 2921.77/s  (0.714s, 2867.92/s)  avg LR: 7.508e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 48 [ 350/625 ( 56%)]  Loss: 0.004773 (0.00480)  Time: 0.700s, 2924.79/s  (0.712s, 2875.53/s)  avg LR: 7.508e-03  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 48 [ 400/625 ( 64%)]  Loss: 0.004147 (0.00472)  Time: 0.701s, 2923.52/s  (0.711s, 2881.31/s)  avg LR: 7.508e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 48 [ 450/625 ( 72%)]  Loss: 0.005243 (0.00478)  Time: 0.700s, 2925.41/s  (0.710s, 2885.83/s)  avg LR: 7.508e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 48 [ 500/625 ( 80%)]  Loss: 0.004743 (0.00477)  Time: 0.700s, 2925.19/s  (0.709s, 2889.32/s)  avg LR: 7.508e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 48 [ 550/625 ( 88%)]  Loss: 0.004977 (0.00479)  Time: 0.700s, 2924.45/s  (0.708s, 2892.29/s)  avg LR: 7.508e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 48 [ 600/625 ( 96%)]  Loss: 0.004815 (0.00479)  Time: 0.701s, 2920.56/s  (0.707s, 2894.80/s)  avg LR: 7.508e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 48 [ 624/625 (100%)]  Loss: 0.005563 (0.00485)  Time: 0.670s, 3055.45/s  (0.707s, 2896.39/s)  avg LR: 7.508e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.308 (4.308)  Loss:  1.7559 (1.7559)  Acc@1: 64.5996 (64.5996)  Acc@5: 83.3496 (83.3496)
INFO:Test: [  24/24]  Time: 0.079 (0.495)  Loss:  1.5684 (2.2390)  Acc@1: 67.9245 (53.3520)  Acc@5: 86.3208 (77.4160)
INFO:48-epoch: remaining time 33.22 h
INFO:Train: 49 [   0/625 (  0%)]  Loss: 0.005151 (0.00515)  Time: 4.452s,  459.99/s  (4.452s,  459.99/s)  avg LR: 7.488e-03  iter ratio: 0.0000  Data: 3.752 (3.752)
INFO:Train: 49 [  50/625 (  8%)]  Loss: 0.004865 (0.00501)  Time: 0.704s, 2909.22/s  (0.778s, 2631.98/s)  avg LR: 7.488e-03  iter ratio: 0.0000  Data: 0.022 (0.096)
INFO:Train: 49 [ 100/625 ( 16%)]  Loss: 0.004721 (0.00491)  Time: 0.702s, 2915.51/s  (0.741s, 2762.00/s)  avg LR: 7.488e-03  iter ratio: 0.0000  Data: 0.023 (0.060)
INFO:Train: 49 [ 150/625 ( 24%)]  Loss: 0.005101 (0.00496)  Time: 0.703s, 2914.20/s  (0.729s, 2808.50/s)  avg LR: 7.488e-03  iter ratio: 0.0000  Data: 0.025 (0.048)
INFO:Train: 49 [ 200/625 ( 32%)]  Loss: 0.004776 (0.00492)  Time: 0.702s, 2915.77/s  (0.723s, 2832.36/s)  avg LR: 7.488e-03  iter ratio: 0.0000  Data: 0.023 (0.042)
INFO:Train: 49 [ 250/625 ( 40%)]  Loss: 0.004319 (0.00482)  Time: 0.704s, 2910.70/s  (0.719s, 2846.85/s)  avg LR: 7.488e-03  iter ratio: 0.0000  Data: 0.023 (0.038)
INFO:Train: 49 [ 300/625 ( 48%)]  Loss: 0.005029 (0.00485)  Time: 0.701s, 2919.63/s  (0.717s, 2856.71/s)  avg LR: 7.488e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 49 [ 350/625 ( 56%)]  Loss: 0.005535 (0.00494)  Time: 0.703s, 2912.49/s  (0.715s, 2864.31/s)  avg LR: 7.488e-03  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 49 [ 400/625 ( 64%)]  Loss: 0.004117 (0.00485)  Time: 0.703s, 2912.14/s  (0.714s, 2870.10/s)  avg LR: 7.488e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 49 [ 450/625 ( 72%)]  Loss: 0.005402 (0.00490)  Time: 0.706s, 2899.07/s  (0.712s, 2874.65/s)  avg LR: 7.488e-03  iter ratio: 0.0000  Data: 0.025 (0.032)
INFO:Train: 49 [ 500/625 ( 80%)]  Loss: 0.004665 (0.00488)  Time: 0.706s, 2899.97/s  (0.712s, 2878.39/s)  avg LR: 7.488e-03  iter ratio: 0.0000  Data: 0.023 (0.031)
INFO:Train: 49 [ 550/625 ( 88%)]  Loss: 0.005015 (0.00489)  Time: 0.705s, 2906.15/s  (0.711s, 2881.12/s)  avg LR: 7.488e-03  iter ratio: 0.0000  Data: 0.025 (0.031)
INFO:Train: 49 [ 600/625 ( 96%)]  Loss: 0.004958 (0.00490)  Time: 0.704s, 2908.51/s  (0.710s, 2883.66/s)  avg LR: 7.488e-03  iter ratio: 0.0000  Data: 0.025 (0.030)
INFO:Train: 49 [ 624/625 (100%)]  Loss: 0.004939 (0.00490)  Time: 0.672s, 3045.70/s  (0.710s, 2885.24/s)  avg LR: 7.488e-03  iter ratio: 0.0000  Data: 0.000 (0.030)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.371 (4.371)  Loss:  1.5801 (1.5801)  Acc@1: 66.6504 (66.6504)  Acc@5: 85.4492 (85.4492)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  1.2979 (1.9862)  Acc@1: 71.3443 (56.5740)  Acc@5: 89.0330 (80.6900)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-49.pth.tar', 56.57400009277344)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-41.pth.tar', 55.81000004882812)

INFO:49-epoch: remaining time 33.24 h
INFO:Train: 50 [   0/625 (  0%)]  Loss: 0.005288 (0.00529)  Time: 4.595s,  445.74/s  (4.595s,  445.74/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 3.690 (3.690)
INFO:Train: 50 [  50/625 (  8%)]  Loss: 0.004524 (0.00491)  Time: 0.699s, 2928.48/s  (0.778s, 2633.07/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.025 (0.100)
INFO:Train: 50 [ 100/625 ( 16%)]  Loss: 0.004275 (0.00470)  Time: 0.699s, 2930.97/s  (0.740s, 2768.64/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.025 (0.064)
INFO:Train: 50 [ 150/625 ( 24%)]  Loss: 0.004318 (0.00460)  Time: 0.700s, 2924.25/s  (0.727s, 2817.66/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.026 (0.052)
INFO:Train: 50 [ 200/625 ( 32%)]  Loss: 0.005165 (0.00471)  Time: 0.699s, 2927.90/s  (0.720s, 2842.85/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 50 [ 250/625 ( 40%)]  Loss: 0.005326 (0.00482)  Time: 0.700s, 2925.49/s  (0.716s, 2858.52/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.025 (0.042)
INFO:Train: 50 [ 300/625 ( 48%)]  Loss: 0.005210 (0.00487)  Time: 0.699s, 2931.72/s  (0.714s, 2869.42/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 50 [ 350/625 ( 56%)]  Loss: 0.004741 (0.00486)  Time: 0.701s, 2920.32/s  (0.712s, 2876.95/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 50 [ 400/625 ( 64%)]  Loss: 0.004559 (0.00482)  Time: 0.700s, 2925.00/s  (0.710s, 2882.87/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 50 [ 450/625 ( 72%)]  Loss: 0.005019 (0.00484)  Time: 0.700s, 2924.94/s  (0.709s, 2887.41/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 50 [ 500/625 ( 80%)]  Loss: 0.004911 (0.00485)  Time: 0.700s, 2924.65/s  (0.708s, 2891.10/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 50 [ 550/625 ( 88%)]  Loss: 0.004671 (0.00483)  Time: 0.701s, 2922.52/s  (0.708s, 2894.08/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 50 [ 600/625 ( 96%)]  Loss: 0.004491 (0.00481)  Time: 0.699s, 2930.40/s  (0.707s, 2896.65/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 50 [ 624/625 (100%)]  Loss: 0.005039 (0.00482)  Time: 0.670s, 3055.21/s  (0.707s, 2898.25/s)  avg LR: 7.467e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.281 (4.281)  Loss:  1.6064 (1.6064)  Acc@1: 65.9668 (65.9668)  Acc@5: 86.3770 (86.3770)
INFO:Test: [  24/24]  Time: 0.079 (0.495)  Loss:  1.1465 (2.0902)  Acc@1: 75.2358 (55.4040)  Acc@5: 90.5660 (79.9140)
INFO:50-epoch: remaining time 32.92 h
INFO:Train: 51 [   0/625 (  0%)]  Loss: 0.004959 (0.00496)  Time: 4.351s,  470.75/s  (4.351s,  470.75/s)  avg LR: 7.446e-03  iter ratio: 0.0000  Data: 3.665 (3.665)
INFO:Train: 51 [  50/625 (  8%)]  Loss: 0.003847 (0.00440)  Time: 0.706s, 2898.91/s  (0.775s, 2642.37/s)  avg LR: 7.446e-03  iter ratio: 0.0000  Data: 0.027 (0.099)
INFO:Train: 51 [ 100/625 ( 16%)]  Loss: 0.004652 (0.00449)  Time: 0.706s, 2899.38/s  (0.739s, 2770.43/s)  avg LR: 7.446e-03  iter ratio: 0.0000  Data: 0.026 (0.063)
INFO:Train: 51 [ 150/625 ( 24%)]  Loss: 0.004702 (0.00454)  Time: 0.708s, 2892.81/s  (0.727s, 2816.42/s)  avg LR: 7.446e-03  iter ratio: 0.0000  Data: 0.026 (0.051)
INFO:Train: 51 [ 200/625 ( 32%)]  Loss: 0.004480 (0.00453)  Time: 0.707s, 2897.62/s  (0.721s, 2840.14/s)  avg LR: 7.446e-03  iter ratio: 0.0000  Data: 0.026 (0.045)
INFO:Train: 51 [ 250/625 ( 40%)]  Loss: 0.004645 (0.00455)  Time: 0.707s, 2895.78/s  (0.717s, 2854.44/s)  avg LR: 7.446e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 51 [ 300/625 ( 48%)]  Loss: 0.005255 (0.00465)  Time: 0.707s, 2898.78/s  (0.715s, 2864.23/s)  avg LR: 7.446e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 51 [ 350/625 ( 56%)]  Loss: 0.005106 (0.00471)  Time: 0.707s, 2897.89/s  (0.713s, 2871.15/s)  avg LR: 7.446e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 51 [ 400/625 ( 64%)]  Loss: 0.004684 (0.00470)  Time: 0.706s, 2900.04/s  (0.712s, 2876.27/s)  avg LR: 7.446e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 51 [ 450/625 ( 72%)]  Loss: 0.004313 (0.00466)  Time: 0.706s, 2900.58/s  (0.711s, 2880.79/s)  avg LR: 7.446e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 51 [ 500/625 ( 80%)]  Loss: 0.004957 (0.00469)  Time: 0.704s, 2909.18/s  (0.710s, 2884.17/s)  avg LR: 7.446e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 51 [ 550/625 ( 88%)]  Loss: 0.004573 (0.00468)  Time: 0.704s, 2908.22/s  (0.709s, 2886.75/s)  avg LR: 7.446e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 51 [ 600/625 ( 96%)]  Loss: 0.004740 (0.00469)  Time: 0.707s, 2894.89/s  (0.709s, 2888.95/s)  avg LR: 7.446e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 51 [ 624/625 (100%)]  Loss: 0.004296 (0.00466)  Time: 0.671s, 3051.68/s  (0.709s, 2890.44/s)  avg LR: 7.446e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.356 (4.356)  Loss:  1.6074 (1.6074)  Acc@1: 65.2344 (65.2344)  Acc@5: 86.7188 (86.7188)
INFO:Test: [  24/24]  Time: 0.080 (0.494)  Loss:  1.2070 (2.0652)  Acc@1: 75.7076 (55.8340)  Acc@5: 89.3868 (80.0340)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-49.pth.tar', 56.57400009277344)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-51.pth.tar', 55.83400004882812)

INFO:51-epoch: remaining time 32.89 h
INFO:Train: 52 [   0/625 (  0%)]  Loss: 0.004795 (0.00479)  Time: 4.530s,  452.12/s  (4.530s,  452.12/s)  avg LR: 7.425e-03  iter ratio: 0.0000  Data: 3.623 (3.623)
INFO:Train: 52 [  50/625 (  8%)]  Loss: 0.004645 (0.00472)  Time: 0.701s, 2922.25/s  (0.776s, 2639.48/s)  avg LR: 7.425e-03  iter ratio: 0.0000  Data: 0.026 (0.098)
INFO:Train: 52 [ 100/625 ( 16%)]  Loss: 0.004628 (0.00469)  Time: 0.700s, 2925.15/s  (0.739s, 2773.12/s)  avg LR: 7.425e-03  iter ratio: 0.0000  Data: 0.026 (0.063)
INFO:Train: 52 [ 150/625 ( 24%)]  Loss: 0.004371 (0.00461)  Time: 0.701s, 2923.44/s  (0.726s, 2821.56/s)  avg LR: 7.425e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 52 [ 200/625 ( 32%)]  Loss: 0.004492 (0.00459)  Time: 0.701s, 2923.00/s  (0.719s, 2846.44/s)  avg LR: 7.425e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 52 [ 250/625 ( 40%)]  Loss: 0.004291 (0.00454)  Time: 0.700s, 2924.99/s  (0.716s, 2861.66/s)  avg LR: 7.425e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 52 [ 300/625 ( 48%)]  Loss: 0.004717 (0.00456)  Time: 0.700s, 2927.07/s  (0.713s, 2872.06/s)  avg LR: 7.425e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 52 [ 350/625 ( 56%)]  Loss: 0.005520 (0.00468)  Time: 0.701s, 2922.23/s  (0.711s, 2879.43/s)  avg LR: 7.425e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 52 [ 400/625 ( 64%)]  Loss: 0.004465 (0.00466)  Time: 0.700s, 2926.07/s  (0.710s, 2885.01/s)  avg LR: 7.425e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 52 [ 450/625 ( 72%)]  Loss: 0.004052 (0.00460)  Time: 0.701s, 2923.28/s  (0.709s, 2889.38/s)  avg LR: 7.425e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 52 [ 500/625 ( 80%)]  Loss: 0.005248 (0.00466)  Time: 0.701s, 2923.26/s  (0.708s, 2892.87/s)  avg LR: 7.425e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 52 [ 550/625 ( 88%)]  Loss: 0.004794 (0.00467)  Time: 0.704s, 2909.35/s  (0.707s, 2895.71/s)  avg LR: 7.425e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 52 [ 600/625 ( 96%)]  Loss: 0.004555 (0.00466)  Time: 0.698s, 2932.00/s  (0.707s, 2898.13/s)  avg LR: 7.425e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 52 [ 624/625 (100%)]  Loss: 0.004545 (0.00465)  Time: 0.671s, 3053.77/s  (0.706s, 2899.63/s)  avg LR: 7.425e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.299 (4.299)  Loss:  1.7471 (1.7471)  Acc@1: 64.7949 (64.7949)  Acc@5: 83.7402 (83.7402)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  1.4893 (2.1619)  Acc@1: 70.8726 (54.3660)  Acc@5: 85.2594 (78.7420)
INFO:52-epoch: remaining time 32.65 h
INFO:Train: 53 [   0/625 (  0%)]  Loss: 0.004391 (0.00439)  Time: 4.540s,  451.10/s  (4.540s,  451.10/s)  avg LR: 7.403e-03  iter ratio: 0.0000  Data: 3.848 (3.848)
INFO:Train: 53 [  50/625 (  8%)]  Loss: 0.004836 (0.00461)  Time: 0.701s, 2921.86/s  (0.775s, 2642.92/s)  avg LR: 7.403e-03  iter ratio: 0.0000  Data: 0.025 (0.101)
INFO:Train: 53 [ 100/625 ( 16%)]  Loss: 0.004895 (0.00471)  Time: 0.700s, 2925.96/s  (0.738s, 2776.27/s)  avg LR: 7.403e-03  iter ratio: 0.0000  Data: 0.025 (0.064)
INFO:Train: 53 [ 150/625 ( 24%)]  Loss: 0.004176 (0.00457)  Time: 0.703s, 2914.77/s  (0.725s, 2824.20/s)  avg LR: 7.403e-03  iter ratio: 0.0000  Data: 0.028 (0.052)
INFO:Train: 53 [ 200/625 ( 32%)]  Loss: 0.003937 (0.00445)  Time: 0.699s, 2929.72/s  (0.719s, 2849.12/s)  avg LR: 7.403e-03  iter ratio: 0.0000  Data: 0.025 (0.045)
INFO:Train: 53 [ 250/625 ( 40%)]  Loss: 0.004910 (0.00452)  Time: 0.701s, 2923.53/s  (0.715s, 2864.22/s)  avg LR: 7.403e-03  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 53 [ 300/625 ( 48%)]  Loss: 0.004439 (0.00451)  Time: 0.698s, 2932.13/s  (0.712s, 2874.40/s)  avg LR: 7.403e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 53 [ 350/625 ( 56%)]  Loss: 0.004782 (0.00455)  Time: 0.700s, 2926.11/s  (0.711s, 2881.65/s)  avg LR: 7.403e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 53 [ 400/625 ( 64%)]  Loss: 0.004818 (0.00458)  Time: 0.699s, 2928.39/s  (0.709s, 2887.08/s)  avg LR: 7.403e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 53 [ 450/625 ( 72%)]  Loss: 0.005488 (0.00467)  Time: 0.701s, 2923.21/s  (0.708s, 2890.85/s)  avg LR: 7.403e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 53 [ 500/625 ( 80%)]  Loss: 0.004897 (0.00469)  Time: 0.700s, 2925.80/s  (0.708s, 2893.92/s)  avg LR: 7.403e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 53 [ 550/625 ( 88%)]  Loss: 0.004790 (0.00470)  Time: 0.701s, 2920.79/s  (0.707s, 2896.35/s)  avg LR: 7.403e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 53 [ 600/625 ( 96%)]  Loss: 0.004609 (0.00469)  Time: 0.701s, 2921.43/s  (0.707s, 2898.27/s)  avg LR: 7.403e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 53 [ 624/625 (100%)]  Loss: 0.005030 (0.00471)  Time: 0.671s, 3051.74/s  (0.706s, 2899.69/s)  avg LR: 7.403e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.362 (4.362)  Loss:  1.6465 (1.6465)  Acc@1: 64.0137 (64.0137)  Acc@5: 85.1562 (85.1562)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  1.1914 (2.0015)  Acc@1: 74.8821 (56.7620)  Acc@5: 89.2689 (80.5120)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-53.pth.tar', 56.76199994873047)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-49.pth.tar', 56.57400009277344)

INFO:53-epoch: remaining time 32.56 h
INFO:Train: 54 [   0/625 (  0%)]  Loss: 0.004990 (0.00499)  Time: 4.345s,  471.36/s  (4.345s,  471.36/s)  avg LR: 7.381e-03  iter ratio: 0.0000  Data: 3.418 (3.418)
INFO:Train: 54 [  50/625 (  8%)]  Loss: 0.004521 (0.00476)  Time: 0.699s, 2928.15/s  (0.773s, 2650.96/s)  avg LR: 7.381e-03  iter ratio: 0.0000  Data: 0.023 (0.094)
INFO:Train: 54 [ 100/625 ( 16%)]  Loss: 0.004962 (0.00482)  Time: 0.701s, 2923.32/s  (0.737s, 2779.63/s)  avg LR: 7.381e-03  iter ratio: 0.0000  Data: 0.025 (0.061)
INFO:Train: 54 [ 150/625 ( 24%)]  Loss: 0.004236 (0.00468)  Time: 0.700s, 2924.82/s  (0.725s, 2826.09/s)  avg LR: 7.381e-03  iter ratio: 0.0000  Data: 0.025 (0.049)
INFO:Train: 54 [ 200/625 ( 32%)]  Loss: 0.004888 (0.00472)  Time: 0.702s, 2918.80/s  (0.719s, 2850.02/s)  avg LR: 7.381e-03  iter ratio: 0.0000  Data: 0.025 (0.044)
INFO:Train: 54 [ 250/625 ( 40%)]  Loss: 0.005292 (0.00481)  Time: 0.700s, 2924.27/s  (0.715s, 2864.42/s)  avg LR: 7.381e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 54 [ 300/625 ( 48%)]  Loss: 0.004733 (0.00480)  Time: 0.700s, 2927.69/s  (0.712s, 2874.78/s)  avg LR: 7.381e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 54 [ 350/625 ( 56%)]  Loss: 0.005133 (0.00484)  Time: 0.702s, 2919.32/s  (0.711s, 2881.55/s)  avg LR: 7.381e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 54 [ 400/625 ( 64%)]  Loss: 0.004739 (0.00483)  Time: 0.700s, 2923.96/s  (0.709s, 2887.06/s)  avg LR: 7.381e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 54 [ 450/625 ( 72%)]  Loss: 0.004575 (0.00481)  Time: 0.700s, 2924.50/s  (0.708s, 2891.15/s)  avg LR: 7.381e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 54 [ 500/625 ( 80%)]  Loss: 0.005221 (0.00484)  Time: 0.699s, 2930.03/s  (0.708s, 2894.52/s)  avg LR: 7.381e-03  iter ratio: 0.0000  Data: 0.023 (0.034)
INFO:Train: 54 [ 550/625 ( 88%)]  Loss: 0.005035 (0.00486)  Time: 0.702s, 2917.15/s  (0.707s, 2897.25/s)  avg LR: 7.381e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 54 [ 600/625 ( 96%)]  Loss: 0.004331 (0.00482)  Time: 0.702s, 2919.44/s  (0.706s, 2899.56/s)  avg LR: 7.381e-03  iter ratio: 0.0000  Data: 0.025 (0.032)
INFO:Train: 54 [ 624/625 (100%)]  Loss: 0.005119 (0.00484)  Time: 0.671s, 3050.19/s  (0.706s, 2901.00/s)  avg LR: 7.381e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.335 (4.335)  Loss:  1.7246 (1.7246)  Acc@1: 62.5488 (62.5488)  Acc@5: 83.4961 (83.4961)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  1.3496 (2.1466)  Acc@1: 71.9340 (53.4920)  Acc@5: 88.2075 (78.1900)
INFO:54-epoch: remaining time 32.37 h
INFO:Train: 55 [   0/625 (  0%)]  Loss: 0.004285 (0.00429)  Time: 4.325s,  473.51/s  (4.325s,  473.51/s)  avg LR: 7.359e-03  iter ratio: 0.0000  Data: 3.641 (3.641)
INFO:Train: 55 [  50/625 (  8%)]  Loss: 0.003991 (0.00414)  Time: 0.703s, 2911.71/s  (0.775s, 2641.30/s)  avg LR: 7.359e-03  iter ratio: 0.0000  Data: 0.028 (0.099)
INFO:Train: 55 [ 100/625 ( 16%)]  Loss: 0.004107 (0.00413)  Time: 0.706s, 2898.95/s  (0.740s, 2766.86/s)  avg LR: 7.359e-03  iter ratio: 0.0000  Data: 0.028 (0.064)
INFO:Train: 55 [ 150/625 ( 24%)]  Loss: 0.004679 (0.00427)  Time: 0.703s, 2915.12/s  (0.728s, 2812.05/s)  avg LR: 7.359e-03  iter ratio: 0.0000  Data: 0.026 (0.052)
INFO:Train: 55 [ 200/625 ( 32%)]  Loss: 0.005058 (0.00442)  Time: 0.706s, 2901.34/s  (0.722s, 2835.05/s)  avg LR: 7.359e-03  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 55 [ 250/625 ( 40%)]  Loss: 0.005397 (0.00459)  Time: 0.706s, 2901.31/s  (0.719s, 2849.46/s)  avg LR: 7.359e-03  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 55 [ 300/625 ( 48%)]  Loss: 0.005246 (0.00468)  Time: 0.705s, 2905.63/s  (0.716s, 2858.99/s)  avg LR: 7.359e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 55 [ 350/625 ( 56%)]  Loss: 0.004505 (0.00466)  Time: 0.707s, 2895.17/s  (0.715s, 2865.65/s)  avg LR: 7.359e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 55 [ 400/625 ( 64%)]  Loss: 0.004750 (0.00467)  Time: 0.706s, 2902.90/s  (0.713s, 2870.78/s)  avg LR: 7.359e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 55 [ 450/625 ( 72%)]  Loss: 0.004719 (0.00467)  Time: 0.704s, 2907.04/s  (0.712s, 2874.89/s)  avg LR: 7.359e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 55 [ 500/625 ( 80%)]  Loss: 0.004868 (0.00469)  Time: 0.704s, 2907.31/s  (0.712s, 2878.20/s)  avg LR: 7.359e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 55 [ 550/625 ( 88%)]  Loss: 0.004515 (0.00468)  Time: 0.705s, 2904.45/s  (0.711s, 2880.84/s)  avg LR: 7.359e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 55 [ 600/625 ( 96%)]  Loss: 0.004250 (0.00464)  Time: 0.705s, 2906.62/s  (0.710s, 2883.07/s)  avg LR: 7.359e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 55 [ 624/625 (100%)]  Loss: 0.004895 (0.00466)  Time: 0.672s, 3048.40/s  (0.710s, 2884.59/s)  avg LR: 7.359e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.362 (4.362)  Loss:  1.4639 (1.4639)  Acc@1: 67.8223 (67.8223)  Acc@5: 86.2793 (86.2793)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.2754 (2.0764)  Acc@1: 72.7594 (55.5500)  Acc@5: 88.4434 (79.4040)
INFO:55-epoch: remaining time 32.46 h
INFO:Train: 56 [   0/625 (  0%)]  Loss: 0.004239 (0.00424)  Time: 4.360s,  469.77/s  (4.360s,  469.77/s)  avg LR: 7.336e-03  iter ratio: 0.0000  Data: 3.450 (3.450)
INFO:Train: 56 [  50/625 (  8%)]  Loss: 0.005320 (0.00478)  Time: 0.700s, 2923.85/s  (0.775s, 2643.52/s)  avg LR: 7.336e-03  iter ratio: 0.0000  Data: 0.026 (0.094)
INFO:Train: 56 [ 100/625 ( 16%)]  Loss: 0.004664 (0.00474)  Time: 0.699s, 2928.02/s  (0.739s, 2772.77/s)  avg LR: 7.336e-03  iter ratio: 0.0000  Data: 0.026 (0.060)
INFO:Train: 56 [ 150/625 ( 24%)]  Loss: 0.004270 (0.00462)  Time: 0.700s, 2926.37/s  (0.726s, 2819.73/s)  avg LR: 7.336e-03  iter ratio: 0.0000  Data: 0.025 (0.049)
INFO:Train: 56 [ 200/625 ( 32%)]  Loss: 0.005554 (0.00481)  Time: 0.700s, 2926.57/s  (0.720s, 2844.06/s)  avg LR: 7.336e-03  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 56 [ 250/625 ( 40%)]  Loss: 0.004807 (0.00481)  Time: 0.703s, 2913.61/s  (0.716s, 2858.62/s)  avg LR: 7.336e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 56 [ 300/625 ( 48%)]  Loss: 0.005108 (0.00485)  Time: 0.700s, 2925.96/s  (0.714s, 2868.47/s)  avg LR: 7.336e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 56 [ 350/625 ( 56%)]  Loss: 0.004660 (0.00483)  Time: 0.699s, 2928.54/s  (0.712s, 2875.60/s)  avg LR: 7.336e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 56 [ 400/625 ( 64%)]  Loss: 0.004134 (0.00475)  Time: 0.699s, 2930.77/s  (0.711s, 2880.95/s)  avg LR: 7.336e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 56 [ 450/625 ( 72%)]  Loss: 0.005378 (0.00481)  Time: 0.700s, 2927.15/s  (0.710s, 2885.29/s)  avg LR: 7.336e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 56 [ 500/625 ( 80%)]  Loss: 0.004284 (0.00477)  Time: 0.700s, 2926.72/s  (0.709s, 2888.69/s)  avg LR: 7.336e-03  iter ratio: 0.0000  Data: 0.026 (0.032)
INFO:Train: 56 [ 550/625 ( 88%)]  Loss: 0.005001 (0.00478)  Time: 0.702s, 2916.33/s  (0.708s, 2891.28/s)  avg LR: 7.336e-03  iter ratio: 0.0000  Data: 0.026 (0.032)
INFO:Train: 56 [ 600/625 ( 96%)]  Loss: 0.004597 (0.00477)  Time: 0.700s, 2924.46/s  (0.708s, 2893.52/s)  avg LR: 7.336e-03  iter ratio: 0.0000  Data: 0.025 (0.031)
INFO:Train: 56 [ 624/625 (100%)]  Loss: 0.003842 (0.00470)  Time: 0.672s, 3049.86/s  (0.707s, 2894.94/s)  avg LR: 7.336e-03  iter ratio: 0.0000  Data: 0.000 (0.031)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.299 (4.299)  Loss:  1.6953 (1.6953)  Acc@1: 63.9648 (63.9648)  Acc@5: 83.9844 (83.9844)
INFO:Test: [  24/24]  Time: 0.079 (0.493)  Loss:  1.3789 (2.1437)  Acc@1: 71.8160 (54.7060)  Acc@5: 86.7924 (79.0620)
INFO:56-epoch: remaining time 32.21 h
INFO:Train: 57 [   0/625 (  0%)]  Loss: 0.004478 (0.00448)  Time: 4.201s,  487.49/s  (4.201s,  487.49/s)  avg LR: 7.313e-03  iter ratio: 0.0000  Data: 3.510 (3.510)
INFO:Train: 57 [  50/625 (  8%)]  Loss: 0.005589 (0.00503)  Time: 0.701s, 2922.18/s  (0.770s, 2660.10/s)  avg LR: 7.313e-03  iter ratio: 0.0000  Data: 0.025 (0.096)
INFO:Train: 57 [ 100/625 ( 16%)]  Loss: 0.005130 (0.00507)  Time: 0.704s, 2910.09/s  (0.736s, 2784.02/s)  avg LR: 7.313e-03  iter ratio: 0.0000  Data: 0.026 (0.062)
INFO:Train: 57 [ 150/625 ( 24%)]  Loss: 0.004556 (0.00494)  Time: 0.702s, 2916.37/s  (0.724s, 2828.57/s)  avg LR: 7.313e-03  iter ratio: 0.0000  Data: 0.028 (0.050)
INFO:Train: 57 [ 200/625 ( 32%)]  Loss: 0.005396 (0.00503)  Time: 0.700s, 2926.22/s  (0.718s, 2851.97/s)  avg LR: 7.313e-03  iter ratio: 0.0000  Data: 0.025 (0.044)
INFO:Train: 57 [ 250/625 ( 40%)]  Loss: 0.004761 (0.00498)  Time: 0.703s, 2913.72/s  (0.715s, 2865.99/s)  avg LR: 7.313e-03  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 57 [ 300/625 ( 48%)]  Loss: 0.004426 (0.00491)  Time: 0.701s, 2921.76/s  (0.712s, 2875.47/s)  avg LR: 7.313e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 57 [ 350/625 ( 56%)]  Loss: 0.004173 (0.00481)  Time: 0.702s, 2915.57/s  (0.711s, 2882.19/s)  avg LR: 7.313e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 57 [ 400/625 ( 64%)]  Loss: 0.004674 (0.00480)  Time: 0.702s, 2917.51/s  (0.709s, 2887.26/s)  avg LR: 7.313e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 57 [ 450/625 ( 72%)]  Loss: 0.004397 (0.00476)  Time: 0.708s, 2893.20/s  (0.708s, 2891.16/s)  avg LR: 7.313e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 57 [ 500/625 ( 80%)]  Loss: 0.005440 (0.00482)  Time: 0.700s, 2924.80/s  (0.708s, 2894.20/s)  avg LR: 7.313e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 57 [ 550/625 ( 88%)]  Loss: 0.004972 (0.00483)  Time: 0.702s, 2919.20/s  (0.707s, 2896.74/s)  avg LR: 7.313e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 57 [ 600/625 ( 96%)]  Loss: 0.004185 (0.00478)  Time: 0.701s, 2923.26/s  (0.706s, 2898.91/s)  avg LR: 7.313e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 57 [ 624/625 (100%)]  Loss: 0.004445 (0.00476)  Time: 0.672s, 3049.27/s  (0.706s, 2900.30/s)  avg LR: 7.313e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.354 (4.354)  Loss:  1.5322 (1.5322)  Acc@1: 66.5527 (66.5527)  Acc@5: 86.0352 (86.0352)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.4502 (1.9828)  Acc@1: 70.5189 (56.2860)  Acc@5: 87.3821 (80.6480)
INFO:57-epoch: remaining time 32.05 h
INFO:Train: 58 [   0/625 (  0%)]  Loss: 0.004104 (0.00410)  Time: 4.490s,  456.11/s  (4.490s,  456.11/s)  avg LR: 7.289e-03  iter ratio: 0.0000  Data: 3.580 (3.580)
INFO:Train: 58 [  50/625 (  8%)]  Loss: 0.004257 (0.00418)  Time: 0.699s, 2927.99/s  (0.776s, 2640.76/s)  avg LR: 7.289e-03  iter ratio: 0.0000  Data: 0.025 (0.097)
INFO:Train: 58 [ 100/625 ( 16%)]  Loss: 0.004675 (0.00435)  Time: 0.699s, 2930.98/s  (0.738s, 2773.89/s)  avg LR: 7.289e-03  iter ratio: 0.0000  Data: 0.024 (0.062)
INFO:Train: 58 [ 150/625 ( 24%)]  Loss: 0.005043 (0.00452)  Time: 0.700s, 2926.86/s  (0.726s, 2821.43/s)  avg LR: 7.289e-03  iter ratio: 0.0000  Data: 0.026 (0.050)
INFO:Train: 58 [ 200/625 ( 32%)]  Loss: 0.005542 (0.00472)  Time: 0.700s, 2925.46/s  (0.720s, 2846.24/s)  avg LR: 7.289e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 58 [ 250/625 ( 40%)]  Loss: 0.005174 (0.00480)  Time: 0.701s, 2921.64/s  (0.716s, 2861.51/s)  avg LR: 7.289e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 58 [ 300/625 ( 48%)]  Loss: 0.004680 (0.00478)  Time: 0.701s, 2922.31/s  (0.713s, 2871.65/s)  avg LR: 7.289e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 58 [ 350/625 ( 56%)]  Loss: 0.004466 (0.00474)  Time: 0.699s, 2928.55/s  (0.711s, 2878.97/s)  avg LR: 7.289e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 58 [ 400/625 ( 64%)]  Loss: 0.005309 (0.00481)  Time: 0.698s, 2933.70/s  (0.710s, 2884.52/s)  avg LR: 7.289e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 58 [ 450/625 ( 72%)]  Loss: 0.004681 (0.00479)  Time: 0.701s, 2919.98/s  (0.709s, 2888.72/s)  avg LR: 7.289e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 58 [ 500/625 ( 80%)]  Loss: 0.005233 (0.00483)  Time: 0.699s, 2929.43/s  (0.708s, 2892.11/s)  avg LR: 7.289e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 58 [ 550/625 ( 88%)]  Loss: 0.004731 (0.00482)  Time: 0.702s, 2917.66/s  (0.707s, 2894.97/s)  avg LR: 7.289e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 58 [ 600/625 ( 96%)]  Loss: 0.005040 (0.00484)  Time: 0.699s, 2928.52/s  (0.707s, 2897.29/s)  avg LR: 7.289e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 58 [ 624/625 (100%)]  Loss: 0.004695 (0.00483)  Time: 0.671s, 3052.10/s  (0.706s, 2898.86/s)  avg LR: 7.289e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.291 (4.291)  Loss:  1.6650 (1.6650)  Acc@1: 64.5020 (64.5020)  Acc@5: 86.4258 (86.4258)
INFO:Test: [  24/24]  Time: 0.080 (0.493)  Loss:  1.3535 (2.0614)  Acc@1: 73.8208 (56.0760)  Acc@5: 88.3255 (80.0640)
INFO:58-epoch: remaining time 31.91 h
INFO:Train: 59 [   0/625 (  0%)]  Loss: 0.005061 (0.00506)  Time: 4.384s,  467.17/s  (4.384s,  467.17/s)  avg LR: 7.265e-03  iter ratio: 0.0000  Data: 3.694 (3.694)
INFO:Train: 59 [  50/625 (  8%)]  Loss: 0.004801 (0.00493)  Time: 0.701s, 2923.18/s  (0.773s, 2648.26/s)  avg LR: 7.265e-03  iter ratio: 0.0000  Data: 0.026 (0.099)
INFO:Train: 59 [ 100/625 ( 16%)]  Loss: 0.004923 (0.00493)  Time: 0.701s, 2923.60/s  (0.738s, 2776.43/s)  avg LR: 7.265e-03  iter ratio: 0.0000  Data: 0.027 (0.063)
INFO:Train: 59 [ 150/625 ( 24%)]  Loss: 0.004211 (0.00475)  Time: 0.701s, 2920.54/s  (0.726s, 2822.79/s)  avg LR: 7.265e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 59 [ 200/625 ( 32%)]  Loss: 0.004632 (0.00473)  Time: 0.701s, 2922.91/s  (0.719s, 2846.45/s)  avg LR: 7.265e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 59 [ 250/625 ( 40%)]  Loss: 0.004649 (0.00471)  Time: 0.700s, 2926.90/s  (0.716s, 2861.04/s)  avg LR: 7.265e-03  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 59 [ 300/625 ( 48%)]  Loss: 0.004689 (0.00471)  Time: 0.702s, 2916.28/s  (0.713s, 2870.86/s)  avg LR: 7.265e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 59 [ 350/625 ( 56%)]  Loss: 0.004292 (0.00466)  Time: 0.700s, 2924.36/s  (0.712s, 2877.95/s)  avg LR: 7.265e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 59 [ 400/625 ( 64%)]  Loss: 0.004620 (0.00465)  Time: 0.699s, 2928.06/s  (0.710s, 2883.25/s)  avg LR: 7.265e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 59 [ 450/625 ( 72%)]  Loss: 0.004173 (0.00461)  Time: 0.700s, 2924.76/s  (0.709s, 2887.28/s)  avg LR: 7.265e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 59 [ 500/625 ( 80%)]  Loss: 0.004783 (0.00462)  Time: 0.699s, 2930.82/s  (0.708s, 2890.73/s)  avg LR: 7.265e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 59 [ 550/625 ( 88%)]  Loss: 0.004863 (0.00464)  Time: 0.702s, 2919.37/s  (0.708s, 2893.50/s)  avg LR: 7.265e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 59 [ 600/625 ( 96%)]  Loss: 0.005427 (0.00470)  Time: 0.700s, 2926.54/s  (0.707s, 2895.78/s)  avg LR: 7.265e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 59 [ 624/625 (100%)]  Loss: 0.004874 (0.00471)  Time: 0.671s, 3051.72/s  (0.707s, 2897.21/s)  avg LR: 7.265e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.335 (4.335)  Loss:  1.6045 (1.6045)  Acc@1: 66.0156 (66.0156)  Acc@5: 85.6934 (85.6934)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  1.3818 (1.9797)  Acc@1: 73.7028 (57.7880)  Acc@5: 87.2641 (81.4600)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-59.pth.tar', 57.788000083007816)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-53.pth.tar', 56.76199994873047)

INFO:59-epoch: remaining time 31.82 h
INFO:Train: 60 [   0/625 (  0%)]  Loss: 0.004642 (0.00464)  Time: 4.492s,  455.93/s  (4.492s,  455.93/s)  avg LR: 7.241e-03  iter ratio: 0.0000  Data: 3.573 (3.573)
INFO:Train: 60 [  50/625 (  8%)]  Loss: 0.004105 (0.00437)  Time: 0.699s, 2931.29/s  (0.776s, 2638.32/s)  avg LR: 7.241e-03  iter ratio: 0.0000  Data: 0.025 (0.097)
INFO:Train: 60 [ 100/625 ( 16%)]  Loss: 0.004358 (0.00437)  Time: 0.702s, 2917.77/s  (0.739s, 2771.02/s)  avg LR: 7.241e-03  iter ratio: 0.0000  Data: 0.027 (0.062)
INFO:Train: 60 [ 150/625 ( 24%)]  Loss: 0.005018 (0.00453)  Time: 0.700s, 2925.06/s  (0.727s, 2818.89/s)  avg LR: 7.241e-03  iter ratio: 0.0000  Data: 0.026 (0.050)
INFO:Train: 60 [ 200/625 ( 32%)]  Loss: 0.004576 (0.00454)  Time: 0.700s, 2926.93/s  (0.720s, 2843.64/s)  avg LR: 7.241e-03  iter ratio: 0.0000  Data: 0.026 (0.044)
INFO:Train: 60 [ 250/625 ( 40%)]  Loss: 0.005114 (0.00464)  Time: 0.700s, 2926.60/s  (0.716s, 2858.43/s)  avg LR: 7.241e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 60 [ 300/625 ( 48%)]  Loss: 0.005062 (0.00470)  Time: 0.700s, 2927.28/s  (0.714s, 2868.47/s)  avg LR: 7.241e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 60 [ 350/625 ( 56%)]  Loss: 0.005135 (0.00475)  Time: 0.700s, 2923.63/s  (0.712s, 2875.51/s)  avg LR: 7.241e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 60 [ 400/625 ( 64%)]  Loss: 0.004685 (0.00474)  Time: 0.703s, 2913.15/s  (0.711s, 2880.84/s)  avg LR: 7.241e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 60 [ 450/625 ( 72%)]  Loss: 0.005058 (0.00478)  Time: 0.700s, 2925.46/s  (0.710s, 2885.04/s)  avg LR: 7.241e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 60 [ 500/625 ( 80%)]  Loss: 0.004509 (0.00475)  Time: 0.699s, 2928.60/s  (0.709s, 2888.43/s)  avg LR: 7.241e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 60 [ 550/625 ( 88%)]  Loss: 0.004712 (0.00475)  Time: 0.699s, 2929.54/s  (0.708s, 2891.12/s)  avg LR: 7.241e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 60 [ 600/625 ( 96%)]  Loss: 0.004092 (0.00470)  Time: 0.701s, 2921.00/s  (0.708s, 2893.44/s)  avg LR: 7.241e-03  iter ratio: 0.0000  Data: 0.027 (0.032)
INFO:Train: 60 [ 624/625 (100%)]  Loss: 0.004619 (0.00469)  Time: 0.672s, 3045.95/s  (0.707s, 2894.83/s)  avg LR: 7.241e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.297 (4.297)  Loss:  1.5000 (1.5000)  Acc@1: 67.9688 (67.9688)  Acc@5: 85.7910 (85.7910)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  1.3740 (1.9998)  Acc@1: 69.5755 (55.7520)  Acc@5: 88.9151 (79.9960)
INFO:60-epoch: remaining time 31.68 h
INFO:Train: 61 [   0/625 (  0%)]  Loss: 0.004248 (0.00425)  Time: 4.187s,  489.18/s  (4.187s,  489.18/s)  avg LR: 7.216e-03  iter ratio: 0.0000  Data: 3.483 (3.483)
INFO:Train: 61 [  50/625 (  8%)]  Loss: 0.004028 (0.00414)  Time: 0.702s, 2916.32/s  (0.772s, 2654.01/s)  avg LR: 7.216e-03  iter ratio: 0.0000  Data: 0.027 (0.096)
INFO:Train: 61 [ 100/625 ( 16%)]  Loss: 0.004550 (0.00428)  Time: 0.701s, 2919.76/s  (0.737s, 2777.73/s)  avg LR: 7.216e-03  iter ratio: 0.0000  Data: 0.027 (0.062)
INFO:Train: 61 [ 150/625 ( 24%)]  Loss: 0.004515 (0.00434)  Time: 0.703s, 2914.55/s  (0.726s, 2820.82/s)  avg LR: 7.216e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 61 [ 200/625 ( 32%)]  Loss: 0.004232 (0.00431)  Time: 0.703s, 2914.35/s  (0.720s, 2842.95/s)  avg LR: 7.216e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 61 [ 250/625 ( 40%)]  Loss: 0.004609 (0.00436)  Time: 0.703s, 2914.94/s  (0.717s, 2856.43/s)  avg LR: 7.216e-03  iter ratio: 0.0000  Data: 0.029 (0.042)
INFO:Train: 61 [ 300/625 ( 48%)]  Loss: 0.005217 (0.00449)  Time: 0.701s, 2921.54/s  (0.715s, 2865.39/s)  avg LR: 7.216e-03  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 61 [ 350/625 ( 56%)]  Loss: 0.004581 (0.00450)  Time: 0.701s, 2919.59/s  (0.713s, 2871.92/s)  avg LR: 7.216e-03  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 61 [ 400/625 ( 64%)]  Loss: 0.004508 (0.00450)  Time: 0.706s, 2898.93/s  (0.712s, 2876.62/s)  avg LR: 7.216e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 61 [ 450/625 ( 72%)]  Loss: 0.004870 (0.00454)  Time: 0.706s, 2901.32/s  (0.711s, 2880.68/s)  avg LR: 7.216e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 61 [ 500/625 ( 80%)]  Loss: 0.004166 (0.00450)  Time: 0.706s, 2900.35/s  (0.710s, 2883.94/s)  avg LR: 7.216e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 61 [ 550/625 ( 88%)]  Loss: 0.004917 (0.00454)  Time: 0.705s, 2904.05/s  (0.709s, 2886.69/s)  avg LR: 7.216e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 61 [ 600/625 ( 96%)]  Loss: 0.004949 (0.00457)  Time: 0.706s, 2901.39/s  (0.709s, 2888.92/s)  avg LR: 7.216e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 61 [ 624/625 (100%)]  Loss: 0.004529 (0.00457)  Time: 0.672s, 3048.43/s  (0.709s, 2890.37/s)  avg LR: 7.216e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.335 (4.335)  Loss:  1.5273 (1.5273)  Acc@1: 64.7949 (64.7949)  Acc@5: 86.8652 (86.8652)
INFO:Test: [  24/24]  Time: 0.080 (0.494)  Loss:  1.3574 (2.1235)  Acc@1: 72.8774 (53.9500)  Acc@5: 86.6745 (78.8260)
INFO:61-epoch: remaining time 31.64 h
INFO:Train: 62 [   0/625 (  0%)]  Loss: 0.004786 (0.00479)  Time: 4.395s,  465.99/s  (4.395s,  465.99/s)  avg LR: 7.191e-03  iter ratio: 0.0000  Data: 3.473 (3.473)
INFO:Train: 62 [  50/625 (  8%)]  Loss: 0.004255 (0.00452)  Time: 0.702s, 2918.96/s  (0.774s, 2646.23/s)  avg LR: 7.191e-03  iter ratio: 0.0000  Data: 0.027 (0.096)
INFO:Train: 62 [ 100/625 ( 16%)]  Loss: 0.005009 (0.00468)  Time: 0.701s, 2921.85/s  (0.738s, 2776.46/s)  avg LR: 7.191e-03  iter ratio: 0.0000  Data: 0.026 (0.062)
INFO:Train: 62 [ 150/625 ( 24%)]  Loss: 0.004502 (0.00464)  Time: 0.701s, 2921.81/s  (0.725s, 2823.34/s)  avg LR: 7.191e-03  iter ratio: 0.0000  Data: 0.027 (0.050)
INFO:Train: 62 [ 200/625 ( 32%)]  Loss: 0.004600 (0.00463)  Time: 0.704s, 2910.96/s  (0.719s, 2847.64/s)  avg LR: 7.191e-03  iter ratio: 0.0000  Data: 0.028 (0.045)
INFO:Train: 62 [ 250/625 ( 40%)]  Loss: 0.005629 (0.00480)  Time: 0.703s, 2914.65/s  (0.716s, 2862.09/s)  avg LR: 7.191e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 62 [ 300/625 ( 48%)]  Loss: 0.004777 (0.00479)  Time: 0.702s, 2917.26/s  (0.713s, 2871.71/s)  avg LR: 7.191e-03  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 62 [ 350/625 ( 56%)]  Loss: 0.004236 (0.00472)  Time: 0.703s, 2914.71/s  (0.711s, 2878.95/s)  avg LR: 7.191e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 62 [ 400/625 ( 64%)]  Loss: 0.004933 (0.00475)  Time: 0.703s, 2911.68/s  (0.710s, 2884.29/s)  avg LR: 7.191e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 62 [ 450/625 ( 72%)]  Loss: 0.004139 (0.00469)  Time: 0.702s, 2917.36/s  (0.709s, 2888.32/s)  avg LR: 7.191e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 62 [ 500/625 ( 80%)]  Loss: 0.005008 (0.00472)  Time: 0.704s, 2910.79/s  (0.708s, 2891.61/s)  avg LR: 7.191e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 62 [ 550/625 ( 88%)]  Loss: 0.005291 (0.00476)  Time: 0.703s, 2911.73/s  (0.708s, 2894.39/s)  avg LR: 7.191e-03  iter ratio: 0.0000  Data: 0.029 (0.034)
INFO:Train: 62 [ 600/625 ( 96%)]  Loss: 0.004294 (0.00473)  Time: 0.703s, 2915.27/s  (0.707s, 2896.76/s)  avg LR: 7.191e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 62 [ 624/625 (100%)]  Loss: 0.005012 (0.00475)  Time: 0.671s, 3050.70/s  (0.707s, 2898.29/s)  avg LR: 7.191e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.302 (4.302)  Loss:  1.3174 (1.3174)  Acc@1: 71.1426 (71.1426)  Acc@5: 88.7695 (88.7695)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  1.3477 (2.0026)  Acc@1: 71.8160 (56.1700)  Acc@5: 87.3821 (80.1380)
INFO:62-epoch: remaining time 31.47 h
INFO:Train: 63 [   0/625 (  0%)]  Loss: 0.004854 (0.00485)  Time: 4.171s,  491.06/s  (4.171s,  491.06/s)  avg LR: 7.166e-03  iter ratio: 0.0000  Data: 3.487 (3.487)
INFO:Train: 63 [  50/625 (  8%)]  Loss: 0.004838 (0.00485)  Time: 0.706s, 2899.36/s  (0.772s, 2653.41/s)  avg LR: 7.166e-03  iter ratio: 0.0000  Data: 0.027 (0.097)
INFO:Train: 63 [ 100/625 ( 16%)]  Loss: 0.004945 (0.00488)  Time: 0.710s, 2885.20/s  (0.738s, 2774.54/s)  avg LR: 7.166e-03  iter ratio: 0.0000  Data: 0.029 (0.063)
INFO:Train: 63 [ 150/625 ( 24%)]  Loss: 0.004039 (0.00467)  Time: 0.707s, 2897.31/s  (0.727s, 2818.65/s)  avg LR: 7.166e-03  iter ratio: 0.0000  Data: 0.027 (0.052)
INFO:Train: 63 [ 200/625 ( 32%)]  Loss: 0.003856 (0.00451)  Time: 0.708s, 2890.62/s  (0.721s, 2841.16/s)  avg LR: 7.166e-03  iter ratio: 0.0000  Data: 0.029 (0.046)
INFO:Train: 63 [ 250/625 ( 40%)]  Loss: 0.004665 (0.00453)  Time: 0.707s, 2897.93/s  (0.717s, 2854.95/s)  avg LR: 7.166e-03  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 63 [ 300/625 ( 48%)]  Loss: 0.004682 (0.00455)  Time: 0.707s, 2897.39/s  (0.715s, 2864.38/s)  avg LR: 7.166e-03  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 63 [ 350/625 ( 56%)]  Loss: 0.004282 (0.00452)  Time: 0.708s, 2892.73/s  (0.713s, 2870.96/s)  avg LR: 7.166e-03  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 63 [ 400/625 ( 64%)]  Loss: 0.004089 (0.00447)  Time: 0.707s, 2897.36/s  (0.712s, 2875.72/s)  avg LR: 7.166e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 63 [ 450/625 ( 72%)]  Loss: 0.004831 (0.00451)  Time: 0.705s, 2903.26/s  (0.711s, 2879.68/s)  avg LR: 7.166e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 63 [ 500/625 ( 80%)]  Loss: 0.004784 (0.00453)  Time: 0.710s, 2885.02/s  (0.710s, 2882.81/s)  avg LR: 7.166e-03  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 63 [ 550/625 ( 88%)]  Loss: 0.005194 (0.00459)  Time: 0.706s, 2900.62/s  (0.710s, 2885.80/s)  avg LR: 7.166e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 63 [ 600/625 ( 96%)]  Loss: 0.004825 (0.00461)  Time: 0.706s, 2901.00/s  (0.709s, 2887.93/s)  avg LR: 7.166e-03  iter ratio: 0.0000  Data: 0.029 (0.034)
INFO:Train: 63 [ 624/625 (100%)]  Loss: 0.004530 (0.00460)  Time: 0.671s, 3051.14/s  (0.709s, 2889.32/s)  avg LR: 7.166e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.395 (4.395)  Loss:  1.3555 (1.3555)  Acc@1: 70.1172 (70.1172)  Acc@5: 87.9883 (87.9883)
INFO:Test: [  24/24]  Time: 0.080 (0.498)  Loss:  1.1230 (1.9537)  Acc@1: 77.4764 (56.9040)  Acc@5: 90.6840 (80.6520)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-59.pth.tar', 57.788000083007816)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-63.pth.tar', 56.904000041503906)

INFO:63-epoch: remaining time 31.41 h
INFO:Train: 64 [   0/625 (  0%)]  Loss: 0.004658 (0.00466)  Time: 4.440s,  461.25/s  (4.440s,  461.25/s)  avg LR: 7.140e-03  iter ratio: 0.0000  Data: 3.521 (3.521)
INFO:Train: 64 [  50/625 (  8%)]  Loss: 0.004874 (0.00477)  Time: 0.701s, 2922.52/s  (0.776s, 2638.46/s)  avg LR: 7.140e-03  iter ratio: 0.0000  Data: 0.027 (0.096)
INFO:Train: 64 [ 100/625 ( 16%)]  Loss: 0.004865 (0.00480)  Time: 0.701s, 2920.77/s  (0.739s, 2770.49/s)  avg LR: 7.140e-03  iter ratio: 0.0000  Data: 0.027 (0.062)
INFO:Train: 64 [ 150/625 ( 24%)]  Loss: 0.004074 (0.00462)  Time: 0.704s, 2908.47/s  (0.727s, 2818.51/s)  avg LR: 7.140e-03  iter ratio: 0.0000  Data: 0.030 (0.050)
INFO:Train: 64 [ 200/625 ( 32%)]  Loss: 0.004174 (0.00453)  Time: 0.704s, 2910.60/s  (0.720s, 2843.33/s)  avg LR: 7.140e-03  iter ratio: 0.0000  Data: 0.030 (0.045)
INFO:Train: 64 [ 250/625 ( 40%)]  Loss: 0.005128 (0.00463)  Time: 0.700s, 2924.11/s  (0.716s, 2858.58/s)  avg LR: 7.140e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 64 [ 300/625 ( 48%)]  Loss: 0.005237 (0.00472)  Time: 0.702s, 2915.79/s  (0.714s, 2868.96/s)  avg LR: 7.140e-03  iter ratio: 0.0000  Data: 0.029 (0.039)
INFO:Train: 64 [ 350/625 ( 56%)]  Loss: 0.004960 (0.00475)  Time: 0.701s, 2923.45/s  (0.712s, 2876.52/s)  avg LR: 7.140e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 64 [ 400/625 ( 64%)]  Loss: 0.004867 (0.00476)  Time: 0.701s, 2921.14/s  (0.711s, 2882.17/s)  avg LR: 7.140e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 64 [ 450/625 ( 72%)]  Loss: 0.003962 (0.00468)  Time: 0.701s, 2921.91/s  (0.710s, 2886.50/s)  avg LR: 7.140e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 64 [ 500/625 ( 80%)]  Loss: 0.004330 (0.00465)  Time: 0.701s, 2920.64/s  (0.709s, 2889.90/s)  avg LR: 7.140e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 64 [ 550/625 ( 88%)]  Loss: 0.004197 (0.00461)  Time: 0.701s, 2920.85/s  (0.708s, 2892.57/s)  avg LR: 7.140e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 64 [ 600/625 ( 96%)]  Loss: 0.004540 (0.00461)  Time: 0.701s, 2921.37/s  (0.707s, 2894.95/s)  avg LR: 7.140e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 64 [ 624/625 (100%)]  Loss: 0.003928 (0.00456)  Time: 0.671s, 3054.13/s  (0.707s, 2896.48/s)  avg LR: 7.140e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.309 (4.309)  Loss:  1.2695 (1.2695)  Acc@1: 70.1172 (70.1172)  Acc@5: 88.9160 (88.9160)
INFO:Test: [  24/24]  Time: 0.080 (0.494)  Loss:  1.1621 (1.8586)  Acc@1: 73.1132 (58.4100)  Acc@5: 90.0943 (82.2700)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-64.pth.tar', 58.40999995605469)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-59.pth.tar', 57.788000083007816)

INFO:64-epoch: remaining time 31.17 h
INFO:Train: 65 [   0/625 (  0%)]  Loss: 0.004686 (0.00469)  Time: 4.129s,  496.01/s  (4.129s,  496.01/s)  avg LR: 7.114e-03  iter ratio: 0.0000  Data: 3.436 (3.436)
INFO:Train: 65 [  50/625 (  8%)]  Loss: 0.005484 (0.00508)  Time: 0.704s, 2910.38/s  (0.772s, 2651.78/s)  avg LR: 7.114e-03  iter ratio: 0.0000  Data: 0.024 (0.093)
INFO:Train: 65 [ 100/625 ( 16%)]  Loss: 0.004634 (0.00493)  Time: 0.703s, 2911.88/s  (0.739s, 2772.19/s)  avg LR: 7.114e-03  iter ratio: 0.0000  Data: 0.025 (0.059)
INFO:Train: 65 [ 150/625 ( 24%)]  Loss: 0.003778 (0.00465)  Time: 0.703s, 2911.70/s  (0.727s, 2815.46/s)  avg LR: 7.114e-03  iter ratio: 0.0000  Data: 0.025 (0.048)
INFO:Train: 65 [ 200/625 ( 32%)]  Loss: 0.003740 (0.00446)  Time: 0.704s, 2909.37/s  (0.722s, 2837.47/s)  avg LR: 7.114e-03  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 65 [ 250/625 ( 40%)]  Loss: 0.003726 (0.00434)  Time: 0.707s, 2895.94/s  (0.718s, 2851.00/s)  avg LR: 7.114e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 65 [ 300/625 ( 48%)]  Loss: 0.004661 (0.00439)  Time: 0.702s, 2917.69/s  (0.716s, 2860.10/s)  avg LR: 7.114e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 65 [ 350/625 ( 56%)]  Loss: 0.004406 (0.00439)  Time: 0.702s, 2916.78/s  (0.714s, 2866.76/s)  avg LR: 7.114e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 65 [ 400/625 ( 64%)]  Loss: 0.005151 (0.00447)  Time: 0.704s, 2910.13/s  (0.713s, 2871.71/s)  avg LR: 7.114e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 65 [ 450/625 ( 72%)]  Loss: 0.004392 (0.00447)  Time: 0.702s, 2917.96/s  (0.712s, 2875.52/s)  avg LR: 7.114e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 65 [ 500/625 ( 80%)]  Loss: 0.004436 (0.00446)  Time: 0.704s, 2909.00/s  (0.711s, 2878.69/s)  avg LR: 7.114e-03  iter ratio: 0.0000  Data: 0.024 (0.033)
INFO:Train: 65 [ 550/625 ( 88%)]  Loss: 0.004336 (0.00445)  Time: 0.703s, 2913.28/s  (0.711s, 2881.07/s)  avg LR: 7.114e-03  iter ratio: 0.0000  Data: 0.025 (0.032)
INFO:Train: 65 [ 600/625 ( 96%)]  Loss: 0.004844 (0.00448)  Time: 0.703s, 2912.53/s  (0.710s, 2883.18/s)  avg LR: 7.114e-03  iter ratio: 0.0000  Data: 0.026 (0.031)
INFO:Train: 65 [ 624/625 (100%)]  Loss: 0.005112 (0.00453)  Time: 0.672s, 3045.97/s  (0.710s, 2884.58/s)  avg LR: 7.114e-03  iter ratio: 0.0000  Data: 0.000 (0.031)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.399 (4.399)  Loss:  1.4365 (1.4365)  Acc@1: 69.2383 (69.2383)  Acc@5: 87.4023 (87.4023)
INFO:Test: [  24/24]  Time: 0.080 (0.497)  Loss:  1.1562 (1.9431)  Acc@1: 75.1179 (57.9580)  Acc@5: 90.5660 (81.8360)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-64.pth.tar', 58.40999995605469)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-65.pth.tar', 57.95800005126953)

INFO:65-epoch: remaining time 31.19 h
INFO:Train: 66 [   0/625 (  0%)]  Loss: 0.003842 (0.00384)  Time: 4.374s,  468.27/s  (4.374s,  468.27/s)  avg LR: 7.088e-03  iter ratio: 0.0000  Data: 3.435 (3.435)
INFO:Train: 66 [  50/625 (  8%)]  Loss: 0.004640 (0.00424)  Time: 0.703s, 2913.75/s  (0.775s, 2641.81/s)  avg LR: 7.088e-03  iter ratio: 0.0000  Data: 0.028 (0.095)
INFO:Train: 66 [ 100/625 ( 16%)]  Loss: 0.004707 (0.00440)  Time: 0.701s, 2921.52/s  (0.740s, 2768.08/s)  avg LR: 7.088e-03  iter ratio: 0.0000  Data: 0.027 (0.061)
INFO:Train: 66 [ 150/625 ( 24%)]  Loss: 0.004066 (0.00431)  Time: 0.702s, 2917.33/s  (0.728s, 2812.99/s)  avg LR: 7.088e-03  iter ratio: 0.0000  Data: 0.028 (0.050)
INFO:Train: 66 [ 200/625 ( 32%)]  Loss: 0.004964 (0.00444)  Time: 0.702s, 2917.55/s  (0.722s, 2836.46/s)  avg LR: 7.088e-03  iter ratio: 0.0000  Data: 0.026 (0.044)
INFO:Train: 66 [ 250/625 ( 40%)]  Loss: 0.004967 (0.00453)  Time: 0.703s, 2914.86/s  (0.718s, 2850.67/s)  avg LR: 7.088e-03  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 66 [ 300/625 ( 48%)]  Loss: 0.004585 (0.00454)  Time: 0.702s, 2915.84/s  (0.716s, 2860.09/s)  avg LR: 7.088e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 66 [ 350/625 ( 56%)]  Loss: 0.003875 (0.00446)  Time: 0.702s, 2916.90/s  (0.714s, 2866.67/s)  avg LR: 7.088e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 66 [ 400/625 ( 64%)]  Loss: 0.004685 (0.00448)  Time: 0.702s, 2918.13/s  (0.713s, 2871.82/s)  avg LR: 7.088e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 66 [ 450/625 ( 72%)]  Loss: 0.004800 (0.00451)  Time: 0.703s, 2914.38/s  (0.712s, 2875.86/s)  avg LR: 7.088e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 66 [ 500/625 ( 80%)]  Loss: 0.004515 (0.00451)  Time: 0.703s, 2913.06/s  (0.711s, 2879.19/s)  avg LR: 7.088e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 66 [ 550/625 ( 88%)]  Loss: 0.004048 (0.00447)  Time: 0.703s, 2914.23/s  (0.711s, 2881.79/s)  avg LR: 7.088e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 66 [ 600/625 ( 96%)]  Loss: 0.004756 (0.00450)  Time: 0.703s, 2912.68/s  (0.710s, 2884.06/s)  avg LR: 7.088e-03  iter ratio: 0.0000  Data: 0.029 (0.033)
INFO:Train: 66 [ 624/625 (100%)]  Loss: 0.004577 (0.00450)  Time: 0.672s, 3048.93/s  (0.710s, 2885.56/s)  avg LR: 7.088e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.296 (4.296)  Loss:  1.4023 (1.4023)  Acc@1: 68.1152 (68.1152)  Acc@5: 87.0605 (87.0605)
INFO:Test: [  24/24]  Time: 0.079 (0.495)  Loss:  1.0029 (1.8930)  Acc@1: 78.5377 (57.8140)  Acc@5: 91.0377 (81.8500)
INFO:66-epoch: remaining time 31.02 h
INFO:Train: 67 [   0/625 (  0%)]  Loss: 0.004495 (0.00450)  Time: 4.453s,  459.92/s  (4.453s,  459.92/s)  avg LR: 7.061e-03  iter ratio: 0.0000  Data: 3.751 (3.751)
INFO:Train: 67 [  50/625 (  8%)]  Loss: 0.005279 (0.00489)  Time: 0.702s, 2918.93/s  (0.777s, 2635.15/s)  avg LR: 7.061e-03  iter ratio: 0.0000  Data: 0.028 (0.102)
INFO:Train: 67 [ 100/625 ( 16%)]  Loss: 0.004798 (0.00486)  Time: 0.702s, 2919.35/s  (0.741s, 2763.69/s)  avg LR: 7.061e-03  iter ratio: 0.0000  Data: 0.027 (0.066)
INFO:Train: 67 [ 150/625 ( 24%)]  Loss: 0.004175 (0.00469)  Time: 0.702s, 2915.63/s  (0.729s, 2810.57/s)  avg LR: 7.061e-03  iter ratio: 0.0000  Data: 0.029 (0.053)
INFO:Train: 67 [ 200/625 ( 32%)]  Loss: 0.005259 (0.00480)  Time: 0.702s, 2919.09/s  (0.723s, 2834.13/s)  avg LR: 7.061e-03  iter ratio: 0.0000  Data: 0.028 (0.047)
INFO:Train: 67 [ 250/625 ( 40%)]  Loss: 0.004820 (0.00480)  Time: 0.701s, 2920.38/s  (0.719s, 2848.69/s)  avg LR: 7.061e-03  iter ratio: 0.0000  Data: 0.028 (0.044)
INFO:Train: 67 [ 300/625 ( 48%)]  Loss: 0.004345 (0.00474)  Time: 0.702s, 2918.24/s  (0.716s, 2858.57/s)  avg LR: 7.061e-03  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 67 [ 350/625 ( 56%)]  Loss: 0.004377 (0.00469)  Time: 0.702s, 2919.15/s  (0.715s, 2865.54/s)  avg LR: 7.061e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 67 [ 400/625 ( 64%)]  Loss: 0.004022 (0.00462)  Time: 0.702s, 2916.88/s  (0.713s, 2870.95/s)  avg LR: 7.061e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 67 [ 450/625 ( 72%)]  Loss: 0.005191 (0.00468)  Time: 0.700s, 2925.32/s  (0.712s, 2875.03/s)  avg LR: 7.061e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 67 [ 500/625 ( 80%)]  Loss: 0.005238 (0.00473)  Time: 0.701s, 2922.08/s  (0.712s, 2878.41/s)  avg LR: 7.061e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 67 [ 550/625 ( 88%)]  Loss: 0.004911 (0.00474)  Time: 0.701s, 2922.59/s  (0.711s, 2881.05/s)  avg LR: 7.061e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 67 [ 600/625 ( 96%)]  Loss: 0.004610 (0.00473)  Time: 0.701s, 2923.28/s  (0.710s, 2883.29/s)  avg LR: 7.061e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 67 [ 624/625 (100%)]  Loss: 0.004990 (0.00475)  Time: 0.672s, 3048.21/s  (0.710s, 2884.79/s)  avg LR: 7.061e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.381 (4.381)  Loss:  1.3252 (1.3252)  Acc@1: 70.4102 (70.4102)  Acc@5: 89.5508 (89.5508)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.0918 (1.8604)  Acc@1: 77.1226 (58.9980)  Acc@5: 91.0377 (82.4820)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-67.pth.tar', 58.99800001708984)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-64.pth.tar', 58.40999995605469)

INFO:67-epoch: remaining time 30.93 h
INFO:Train: 68 [   0/625 (  0%)]  Loss: 0.005207 (0.00521)  Time: 4.415s,  463.86/s  (4.415s,  463.86/s)  avg LR: 7.034e-03  iter ratio: 0.0000  Data: 3.494 (3.494)
INFO:Train: 68 [  50/625 (  8%)]  Loss: 0.004553 (0.00488)  Time: 0.700s, 2924.96/s  (0.775s, 2641.28/s)  avg LR: 7.034e-03  iter ratio: 0.0000  Data: 0.026 (0.096)
INFO:Train: 68 [ 100/625 ( 16%)]  Loss: 0.004033 (0.00460)  Time: 0.700s, 2924.52/s  (0.739s, 2770.82/s)  avg LR: 7.034e-03  iter ratio: 0.0000  Data: 0.027 (0.062)
INFO:Train: 68 [ 150/625 ( 24%)]  Loss: 0.005342 (0.00478)  Time: 0.703s, 2913.79/s  (0.727s, 2818.09/s)  avg LR: 7.034e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 68 [ 200/625 ( 32%)]  Loss: 0.005168 (0.00486)  Time: 0.700s, 2925.22/s  (0.721s, 2842.08/s)  avg LR: 7.034e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 68 [ 250/625 ( 40%)]  Loss: 0.004390 (0.00478)  Time: 0.701s, 2920.45/s  (0.717s, 2856.85/s)  avg LR: 7.034e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 68 [ 300/625 ( 48%)]  Loss: 0.004238 (0.00470)  Time: 0.701s, 2921.22/s  (0.714s, 2866.91/s)  avg LR: 7.034e-03  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 68 [ 350/625 ( 56%)]  Loss: 0.004610 (0.00469)  Time: 0.699s, 2928.19/s  (0.713s, 2874.15/s)  avg LR: 7.034e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 68 [ 400/625 ( 64%)]  Loss: 0.004631 (0.00469)  Time: 0.700s, 2924.59/s  (0.711s, 2879.52/s)  avg LR: 7.034e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 68 [ 450/625 ( 72%)]  Loss: 0.004660 (0.00468)  Time: 0.699s, 2929.89/s  (0.710s, 2883.56/s)  avg LR: 7.034e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 68 [ 500/625 ( 80%)]  Loss: 0.005058 (0.00472)  Time: 0.703s, 2914.34/s  (0.709s, 2886.92/s)  avg LR: 7.034e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 68 [ 550/625 ( 88%)]  Loss: 0.004584 (0.00471)  Time: 0.700s, 2924.20/s  (0.709s, 2889.66/s)  avg LR: 7.034e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 68 [ 600/625 ( 96%)]  Loss: 0.004768 (0.00471)  Time: 0.701s, 2920.37/s  (0.708s, 2892.06/s)  avg LR: 7.034e-03  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 68 [ 624/625 (100%)]  Loss: 0.004465 (0.00469)  Time: 0.672s, 3049.26/s  (0.708s, 2893.59/s)  avg LR: 7.034e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.329 (4.329)  Loss:  1.5176 (1.5176)  Acc@1: 67.7734 (67.7734)  Acc@5: 87.1582 (87.1582)
INFO:Test: [  24/24]  Time: 0.079 (0.495)  Loss:  1.3457 (2.0027)  Acc@1: 71.2264 (56.7040)  Acc@5: 87.2642 (81.0820)
INFO:68-epoch: remaining time 30.69 h
INFO:Train: 69 [   0/625 (  0%)]  Loss: 0.004619 (0.00462)  Time: 4.360s,  469.68/s  (4.360s,  469.68/s)  avg LR: 7.007e-03  iter ratio: 0.0000  Data: 3.678 (3.678)
INFO:Train: 69 [  50/625 (  8%)]  Loss: 0.004030 (0.00432)  Time: 0.701s, 2922.93/s  (0.776s, 2640.83/s)  avg LR: 7.007e-03  iter ratio: 0.0000  Data: 0.029 (0.100)
INFO:Train: 69 [ 100/625 ( 16%)]  Loss: 0.004654 (0.00443)  Time: 0.702s, 2917.91/s  (0.740s, 2767.65/s)  avg LR: 7.007e-03  iter ratio: 0.0000  Data: 0.029 (0.065)
INFO:Train: 69 [ 150/625 ( 24%)]  Loss: 0.004883 (0.00455)  Time: 0.702s, 2919.02/s  (0.728s, 2813.11/s)  avg LR: 7.007e-03  iter ratio: 0.0000  Data: 0.027 (0.053)
INFO:Train: 69 [ 200/625 ( 32%)]  Loss: 0.004392 (0.00452)  Time: 0.701s, 2922.70/s  (0.722s, 2836.80/s)  avg LR: 7.007e-03  iter ratio: 0.0000  Data: 0.025 (0.047)
INFO:Train: 69 [ 250/625 ( 40%)]  Loss: 0.004308 (0.00448)  Time: 0.702s, 2917.41/s  (0.718s, 2851.21/s)  avg LR: 7.007e-03  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 69 [ 300/625 ( 48%)]  Loss: 0.004425 (0.00447)  Time: 0.701s, 2921.99/s  (0.716s, 2860.86/s)  avg LR: 7.007e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 69 [ 350/625 ( 56%)]  Loss: 0.004602 (0.00449)  Time: 0.701s, 2921.04/s  (0.714s, 2867.76/s)  avg LR: 7.007e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 69 [ 400/625 ( 64%)]  Loss: 0.003785 (0.00441)  Time: 0.701s, 2920.97/s  (0.713s, 2872.98/s)  avg LR: 7.007e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 69 [ 450/625 ( 72%)]  Loss: 0.004674 (0.00444)  Time: 0.702s, 2918.48/s  (0.712s, 2877.00/s)  avg LR: 7.007e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 69 [ 500/625 ( 80%)]  Loss: 0.004954 (0.00448)  Time: 0.705s, 2904.42/s  (0.711s, 2880.25/s)  avg LR: 7.007e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 69 [ 550/625 ( 88%)]  Loss: 0.004166 (0.00446)  Time: 0.701s, 2919.70/s  (0.710s, 2882.83/s)  avg LR: 7.007e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 69 [ 600/625 ( 96%)]  Loss: 0.004678 (0.00447)  Time: 0.701s, 2922.40/s  (0.710s, 2885.11/s)  avg LR: 7.007e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 69 [ 624/625 (100%)]  Loss: 0.003980 (0.00444)  Time: 0.673s, 3042.44/s  (0.709s, 2886.66/s)  avg LR: 7.007e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.369 (4.369)  Loss:  1.6465 (1.6465)  Acc@1: 66.3086 (66.3086)  Acc@5: 84.7656 (84.7656)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.3008 (2.0896)  Acc@1: 71.9340 (55.6080)  Acc@5: 90.8019 (79.6400)
INFO:69-epoch: remaining time 30.63 h
INFO:Train: 70 [   0/625 (  0%)]  Loss: 0.004366 (0.00437)  Time: 4.555s,  449.60/s  (4.555s,  449.60/s)  avg LR: 6.979e-03  iter ratio: 0.0000  Data: 3.620 (3.620)
INFO:Train: 70 [  50/625 (  8%)]  Loss: 0.004889 (0.00463)  Time: 0.701s, 2923.37/s  (0.778s, 2632.33/s)  avg LR: 6.979e-03  iter ratio: 0.0000  Data: 0.027 (0.098)
INFO:Train: 70 [ 100/625 ( 16%)]  Loss: 0.004545 (0.00460)  Time: 0.701s, 2922.54/s  (0.740s, 2766.93/s)  avg LR: 6.979e-03  iter ratio: 0.0000  Data: 0.027 (0.063)
INFO:Train: 70 [ 150/625 ( 24%)]  Loss: 0.004995 (0.00470)  Time: 0.700s, 2926.08/s  (0.727s, 2815.73/s)  avg LR: 6.979e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 70 [ 200/625 ( 32%)]  Loss: 0.005015 (0.00476)  Time: 0.700s, 2924.95/s  (0.721s, 2840.77/s)  avg LR: 6.979e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 70 [ 250/625 ( 40%)]  Loss: 0.005164 (0.00483)  Time: 0.699s, 2927.98/s  (0.717s, 2856.12/s)  avg LR: 6.979e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 70 [ 300/625 ( 48%)]  Loss: 0.004621 (0.00480)  Time: 0.704s, 2909.15/s  (0.715s, 2866.18/s)  avg LR: 6.979e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 70 [ 350/625 ( 56%)]  Loss: 0.004455 (0.00476)  Time: 0.699s, 2927.93/s  (0.713s, 2873.64/s)  avg LR: 6.979e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 70 [ 400/625 ( 64%)]  Loss: 0.004686 (0.00475)  Time: 0.699s, 2930.27/s  (0.711s, 2879.45/s)  avg LR: 6.979e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 70 [ 450/625 ( 72%)]  Loss: 0.004693 (0.00474)  Time: 0.700s, 2924.24/s  (0.710s, 2883.75/s)  avg LR: 6.979e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 70 [ 500/625 ( 80%)]  Loss: 0.004724 (0.00474)  Time: 0.701s, 2920.95/s  (0.709s, 2887.34/s)  avg LR: 6.979e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 70 [ 550/625 ( 88%)]  Loss: 0.004317 (0.00471)  Time: 0.704s, 2908.67/s  (0.709s, 2890.18/s)  avg LR: 6.979e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 70 [ 600/625 ( 96%)]  Loss: 0.004938 (0.00472)  Time: 0.700s, 2926.37/s  (0.708s, 2892.59/s)  avg LR: 6.979e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 70 [ 624/625 (100%)]  Loss: 0.004404 (0.00470)  Time: 0.672s, 3048.18/s  (0.708s, 2894.23/s)  avg LR: 6.979e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.326 (4.326)  Loss:  1.3906 (1.3906)  Acc@1: 70.8496 (70.8496)  Acc@5: 89.2090 (89.2090)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  1.1396 (1.8814)  Acc@1: 75.2358 (59.2280)  Acc@5: 90.8019 (82.6600)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-70.pth.tar', 59.227999973144534)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-67.pth.tar', 58.99800001708984)

INFO:70-epoch: remaining time 30.47 h
INFO:Train: 71 [   0/625 (  0%)]  Loss: 0.004427 (0.00443)  Time: 4.182s,  489.76/s  (4.182s,  489.76/s)  avg LR: 6.951e-03  iter ratio: 0.0000  Data: 3.485 (3.485)
INFO:Train: 71 [  50/625 (  8%)]  Loss: 0.004990 (0.00471)  Time: 0.703s, 2911.78/s  (0.771s, 2655.66/s)  avg LR: 6.951e-03  iter ratio: 0.0000  Data: 0.029 (0.096)
INFO:Train: 71 [ 100/625 ( 16%)]  Loss: 0.004668 (0.00470)  Time: 0.704s, 2910.31/s  (0.737s, 2777.23/s)  avg LR: 6.951e-03  iter ratio: 0.0000  Data: 0.032 (0.063)
INFO:Train: 71 [ 150/625 ( 24%)]  Loss: 0.004793 (0.00472)  Time: 0.703s, 2914.80/s  (0.726s, 2820.89/s)  avg LR: 6.951e-03  iter ratio: 0.0000  Data: 0.028 (0.051)
INFO:Train: 71 [ 200/625 ( 32%)]  Loss: 0.004553 (0.00469)  Time: 0.703s, 2915.03/s  (0.720s, 2843.27/s)  avg LR: 6.951e-03  iter ratio: 0.0000  Data: 0.028 (0.046)
INFO:Train: 71 [ 250/625 ( 40%)]  Loss: 0.004804 (0.00471)  Time: 0.702s, 2918.47/s  (0.717s, 2856.91/s)  avg LR: 6.951e-03  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 71 [ 300/625 ( 48%)]  Loss: 0.004485 (0.00467)  Time: 0.703s, 2914.76/s  (0.715s, 2866.20/s)  avg LR: 6.951e-03  iter ratio: 0.0000  Data: 0.030 (0.040)
INFO:Train: 71 [ 350/625 ( 56%)]  Loss: 0.004507 (0.00465)  Time: 0.701s, 2920.47/s  (0.713s, 2872.94/s)  avg LR: 6.951e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 71 [ 400/625 ( 64%)]  Loss: 0.004961 (0.00469)  Time: 0.703s, 2912.30/s  (0.712s, 2877.88/s)  avg LR: 6.951e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 71 [ 450/625 ( 72%)]  Loss: 0.004516 (0.00467)  Time: 0.702s, 2915.56/s  (0.711s, 2881.72/s)  avg LR: 6.951e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 71 [ 500/625 ( 80%)]  Loss: 0.005196 (0.00472)  Time: 0.704s, 2909.37/s  (0.710s, 2884.74/s)  avg LR: 6.951e-03  iter ratio: 0.0000  Data: 0.031 (0.035)
INFO:Train: 71 [ 550/625 ( 88%)]  Loss: 0.004293 (0.00468)  Time: 0.702s, 2916.43/s  (0.709s, 2887.26/s)  avg LR: 6.951e-03  iter ratio: 0.0000  Data: 0.030 (0.035)
INFO:Train: 71 [ 600/625 ( 96%)]  Loss: 0.004432 (0.00466)  Time: 0.702s, 2917.05/s  (0.709s, 2889.31/s)  avg LR: 6.951e-03  iter ratio: 0.0000  Data: 0.030 (0.034)
INFO:Train: 71 [ 624/625 (100%)]  Loss: 0.005028 (0.00469)  Time: 0.672s, 3046.08/s  (0.708s, 2890.68/s)  avg LR: 6.951e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.362 (4.362)  Loss:  1.4180 (1.4180)  Acc@1: 66.1621 (66.1621)  Acc@5: 88.1348 (88.1348)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.2900 (1.8870)  Acc@1: 71.3443 (57.9160)  Acc@5: 88.2075 (81.9040)
INFO:71-epoch: remaining time 30.34 h
INFO:Train: 72 [   0/625 (  0%)]  Loss: 0.003709 (0.00371)  Time: 4.538s,  451.33/s  (4.538s,  451.33/s)  avg LR: 6.923e-03  iter ratio: 0.0000  Data: 3.618 (3.618)
INFO:Train: 72 [  50/625 (  8%)]  Loss: 0.005011 (0.00436)  Time: 0.702s, 2919.10/s  (0.778s, 2632.99/s)  avg LR: 6.923e-03  iter ratio: 0.0000  Data: 0.027 (0.099)
INFO:Train: 72 [ 100/625 ( 16%)]  Loss: 0.005037 (0.00459)  Time: 0.702s, 2919.03/s  (0.740s, 2765.98/s)  avg LR: 6.923e-03  iter ratio: 0.0000  Data: 0.028 (0.064)
INFO:Train: 72 [ 150/625 ( 24%)]  Loss: 0.004181 (0.00448)  Time: 0.701s, 2920.94/s  (0.728s, 2814.20/s)  avg LR: 6.923e-03  iter ratio: 0.0000  Data: 0.026 (0.052)
INFO:Train: 72 [ 200/625 ( 32%)]  Loss: 0.004645 (0.00452)  Time: 0.701s, 2920.06/s  (0.721s, 2839.17/s)  avg LR: 6.923e-03  iter ratio: 0.0000  Data: 0.027 (0.046)
INFO:Train: 72 [ 250/625 ( 40%)]  Loss: 0.005084 (0.00461)  Time: 0.702s, 2917.75/s  (0.717s, 2854.36/s)  avg LR: 6.923e-03  iter ratio: 0.0000  Data: 0.029 (0.043)
INFO:Train: 72 [ 300/625 ( 48%)]  Loss: 0.004260 (0.00456)  Time: 0.701s, 2923.21/s  (0.715s, 2864.62/s)  avg LR: 6.923e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 72 [ 350/625 ( 56%)]  Loss: 0.004453 (0.00455)  Time: 0.699s, 2928.87/s  (0.713s, 2872.01/s)  avg LR: 6.923e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 72 [ 400/625 ( 64%)]  Loss: 0.005122 (0.00461)  Time: 0.702s, 2916.31/s  (0.712s, 2877.61/s)  avg LR: 6.923e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 72 [ 450/625 ( 72%)]  Loss: 0.004916 (0.00464)  Time: 0.700s, 2925.44/s  (0.711s, 2881.97/s)  avg LR: 6.923e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 72 [ 500/625 ( 80%)]  Loss: 0.004779 (0.00465)  Time: 0.700s, 2923.63/s  (0.710s, 2885.50/s)  avg LR: 6.923e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 72 [ 550/625 ( 88%)]  Loss: 0.005190 (0.00470)  Time: 0.700s, 2926.76/s  (0.709s, 2888.28/s)  avg LR: 6.923e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 72 [ 600/625 ( 96%)]  Loss: 0.004429 (0.00468)  Time: 0.703s, 2914.01/s  (0.708s, 2890.65/s)  avg LR: 6.923e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 72 [ 624/625 (100%)]  Loss: 0.004624 (0.00467)  Time: 0.672s, 3048.80/s  (0.708s, 2892.16/s)  avg LR: 6.923e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.327 (4.327)  Loss:  1.4150 (1.4150)  Acc@1: 67.4805 (67.4805)  Acc@5: 87.7930 (87.7930)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  1.2637 (1.9380)  Acc@1: 72.6415 (57.0540)  Acc@5: 89.2689 (80.8900)
INFO:72-epoch: remaining time 30.23 h
INFO:Train: 73 [   0/625 (  0%)]  Loss: 0.004024 (0.00402)  Time: 4.223s,  484.93/s  (4.223s,  484.93/s)  avg LR: 6.894e-03  iter ratio: 0.0000  Data: 3.532 (3.532)
INFO:Train: 73 [  50/625 (  8%)]  Loss: 0.004080 (0.00405)  Time: 0.700s, 2923.86/s  (0.771s, 2655.40/s)  avg LR: 6.894e-03  iter ratio: 0.0000  Data: 0.028 (0.097)
INFO:Train: 73 [ 100/625 ( 16%)]  Loss: 0.004650 (0.00425)  Time: 0.699s, 2928.09/s  (0.737s, 2779.16/s)  avg LR: 6.894e-03  iter ratio: 0.0000  Data: 0.027 (0.063)
INFO:Train: 73 [ 150/625 ( 24%)]  Loss: 0.004712 (0.00437)  Time: 0.700s, 2925.10/s  (0.725s, 2823.68/s)  avg LR: 6.894e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 73 [ 200/625 ( 32%)]  Loss: 0.004391 (0.00437)  Time: 0.702s, 2919.42/s  (0.720s, 2846.04/s)  avg LR: 6.894e-03  iter ratio: 0.0000  Data: 0.029 (0.046)
INFO:Train: 73 [ 250/625 ( 40%)]  Loss: 0.004296 (0.00436)  Time: 0.704s, 2910.78/s  (0.716s, 2858.51/s)  avg LR: 6.894e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 73 [ 300/625 ( 48%)]  Loss: 0.004247 (0.00434)  Time: 0.701s, 2919.73/s  (0.714s, 2866.93/s)  avg LR: 6.894e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 73 [ 350/625 ( 56%)]  Loss: 0.004759 (0.00440)  Time: 0.701s, 2919.99/s  (0.713s, 2873.06/s)  avg LR: 6.894e-03  iter ratio: 0.0000  Data: 0.023 (0.037)
INFO:Train: 73 [ 400/625 ( 64%)]  Loss: 0.005278 (0.00449)  Time: 0.702s, 2918.73/s  (0.712s, 2877.72/s)  avg LR: 6.894e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 73 [ 450/625 ( 72%)]  Loss: 0.004855 (0.00453)  Time: 0.703s, 2913.07/s  (0.711s, 2881.27/s)  avg LR: 6.894e-03  iter ratio: 0.0000  Data: 0.023 (0.034)
INFO:Train: 73 [ 500/625 ( 80%)]  Loss: 0.005151 (0.00459)  Time: 0.700s, 2923.70/s  (0.710s, 2884.18/s)  avg LR: 6.894e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 73 [ 550/625 ( 88%)]  Loss: 0.004891 (0.00461)  Time: 0.700s, 2925.14/s  (0.710s, 2886.52/s)  avg LR: 6.894e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 73 [ 600/625 ( 96%)]  Loss: 0.004175 (0.00458)  Time: 0.704s, 2910.43/s  (0.709s, 2888.88/s)  avg LR: 6.894e-03  iter ratio: 0.0000  Data: 0.023 (0.032)
INFO:Train: 73 [ 624/625 (100%)]  Loss: 0.005266 (0.00463)  Time: 0.672s, 3046.90/s  (0.709s, 2890.20/s)  avg LR: 6.894e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.369 (4.369)  Loss:  1.4102 (1.4102)  Acc@1: 68.6035 (68.6035)  Acc@5: 88.3301 (88.3301)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.1191 (1.9417)  Acc@1: 76.6509 (57.6400)  Acc@5: 91.1557 (81.5340)
INFO:73-epoch: remaining time 30.10 h
INFO:Train: 74 [   0/625 (  0%)]  Loss: 0.004286 (0.00429)  Time: 4.485s,  456.66/s  (4.485s,  456.66/s)  avg LR: 6.865e-03  iter ratio: 0.0000  Data: 3.558 (3.558)
INFO:Train: 74 [  50/625 (  8%)]  Loss: 0.004879 (0.00458)  Time: 0.699s, 2928.61/s  (0.776s, 2638.12/s)  avg LR: 6.865e-03  iter ratio: 0.0000  Data: 0.027 (0.095)
INFO:Train: 74 [ 100/625 ( 16%)]  Loss: 0.004773 (0.00465)  Time: 0.701s, 2920.21/s  (0.739s, 2770.25/s)  avg LR: 6.865e-03  iter ratio: 0.0000  Data: 0.028 (0.061)
INFO:Train: 74 [ 150/625 ( 24%)]  Loss: 0.004326 (0.00457)  Time: 0.700s, 2927.13/s  (0.727s, 2817.05/s)  avg LR: 6.865e-03  iter ratio: 0.0000  Data: 0.028 (0.049)
INFO:Train: 74 [ 200/625 ( 32%)]  Loss: 0.004079 (0.00447)  Time: 0.701s, 2921.45/s  (0.721s, 2841.51/s)  avg LR: 6.865e-03  iter ratio: 0.0000  Data: 0.028 (0.044)
INFO:Train: 74 [ 250/625 ( 40%)]  Loss: 0.003765 (0.00435)  Time: 0.703s, 2913.32/s  (0.717s, 2856.45/s)  avg LR: 6.865e-03  iter ratio: 0.0000  Data: 0.031 (0.040)
INFO:Train: 74 [ 300/625 ( 48%)]  Loss: 0.004206 (0.00433)  Time: 0.700s, 2926.07/s  (0.714s, 2866.56/s)  avg LR: 6.865e-03  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 74 [ 350/625 ( 56%)]  Loss: 0.004136 (0.00431)  Time: 0.699s, 2931.69/s  (0.713s, 2873.95/s)  avg LR: 6.865e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 74 [ 400/625 ( 64%)]  Loss: 0.004448 (0.00432)  Time: 0.700s, 2925.22/s  (0.711s, 2879.41/s)  avg LR: 6.865e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 74 [ 450/625 ( 72%)]  Loss: 0.004267 (0.00432)  Time: 0.700s, 2927.11/s  (0.710s, 2883.82/s)  avg LR: 6.865e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 74 [ 500/625 ( 80%)]  Loss: 0.004903 (0.00437)  Time: 0.697s, 2936.22/s  (0.709s, 2887.43/s)  avg LR: 6.865e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 74 [ 550/625 ( 88%)]  Loss: 0.004299 (0.00436)  Time: 0.698s, 2932.01/s  (0.709s, 2890.31/s)  avg LR: 6.865e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 74 [ 600/625 ( 96%)]  Loss: 0.003927 (0.00433)  Time: 0.698s, 2932.01/s  (0.708s, 2892.77/s)  avg LR: 6.865e-03  iter ratio: 0.0000  Data: 0.027 (0.032)
INFO:Train: 74 [ 624/625 (100%)]  Loss: 0.004896 (0.00437)  Time: 0.671s, 3050.36/s  (0.708s, 2894.30/s)  avg LR: 6.865e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.327 (4.327)  Loss:  1.5039 (1.5039)  Acc@1: 68.7500 (68.7500)  Acc@5: 86.9141 (86.9141)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  1.2656 (1.9947)  Acc@1: 72.8774 (57.7580)  Acc@5: 88.7972 (81.0980)
INFO:74-epoch: remaining time 29.94 h
INFO:Train: 75 [   0/625 (  0%)]  Loss: 0.003823 (0.00382)  Time: 4.284s,  478.04/s  (4.284s,  478.04/s)  avg LR: 6.836e-03  iter ratio: 0.0000  Data: 3.594 (3.594)
INFO:Train: 75 [  50/625 (  8%)]  Loss: 0.004697 (0.00426)  Time: 0.702s, 2917.41/s  (0.773s, 2647.97/s)  avg LR: 6.836e-03  iter ratio: 0.0000  Data: 0.029 (0.099)
INFO:Train: 75 [ 100/625 ( 16%)]  Loss: 0.004787 (0.00444)  Time: 0.701s, 2923.06/s  (0.738s, 2773.22/s)  avg LR: 6.836e-03  iter ratio: 0.0000  Data: 0.027 (0.064)
INFO:Train: 75 [ 150/625 ( 24%)]  Loss: 0.005470 (0.00469)  Time: 0.700s, 2924.52/s  (0.726s, 2819.00/s)  avg LR: 6.836e-03  iter ratio: 0.0000  Data: 0.026 (0.051)
INFO:Train: 75 [ 200/625 ( 32%)]  Loss: 0.003805 (0.00452)  Time: 0.703s, 2912.58/s  (0.721s, 2842.30/s)  avg LR: 6.836e-03  iter ratio: 0.0000  Data: 0.026 (0.045)
INFO:Train: 75 [ 250/625 ( 40%)]  Loss: 0.005189 (0.00463)  Time: 0.703s, 2914.59/s  (0.717s, 2856.48/s)  avg LR: 6.836e-03  iter ratio: 0.0000  Data: 0.029 (0.042)
INFO:Train: 75 [ 300/625 ( 48%)]  Loss: 0.004398 (0.00460)  Time: 0.701s, 2920.34/s  (0.714s, 2866.37/s)  avg LR: 6.836e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 75 [ 350/625 ( 56%)]  Loss: 0.004491 (0.00458)  Time: 0.702s, 2918.16/s  (0.713s, 2873.25/s)  avg LR: 6.836e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 75 [ 400/625 ( 64%)]  Loss: 0.004661 (0.00459)  Time: 0.702s, 2918.79/s  (0.712s, 2878.42/s)  avg LR: 6.836e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 75 [ 450/625 ( 72%)]  Loss: 0.004317 (0.00456)  Time: 0.702s, 2919.18/s  (0.711s, 2882.45/s)  avg LR: 6.836e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 75 [ 500/625 ( 80%)]  Loss: 0.004510 (0.00456)  Time: 0.701s, 2921.26/s  (0.710s, 2885.78/s)  avg LR: 6.836e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 75 [ 550/625 ( 88%)]  Loss: 0.004731 (0.00457)  Time: 0.701s, 2922.79/s  (0.709s, 2888.45/s)  avg LR: 6.836e-03  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 75 [ 600/625 ( 96%)]  Loss: 0.004115 (0.00454)  Time: 0.702s, 2918.86/s  (0.708s, 2890.74/s)  avg LR: 6.836e-03  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 75 [ 624/625 (100%)]  Loss: 0.004727 (0.00455)  Time: 0.673s, 3042.78/s  (0.708s, 2892.08/s)  avg LR: 6.836e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.347 (4.347)  Loss:  1.5215 (1.5215)  Acc@1: 67.7246 (67.7246)  Acc@5: 87.5977 (87.5977)
INFO:Test: [  24/24]  Time: 0.080 (0.494)  Loss:  1.4365 (2.0290)  Acc@1: 71.6981 (56.6240)  Acc@5: 86.4387 (80.6260)
INFO:75-epoch: remaining time 29.84 h
INFO:Train: 76 [   0/625 (  0%)]  Loss: 0.004433 (0.00443)  Time: 4.622s,  443.09/s  (4.622s,  443.09/s)  avg LR: 6.806e-03  iter ratio: 0.0000  Data: 3.699 (3.699)
INFO:Train: 76 [  50/625 (  8%)]  Loss: 0.005265 (0.00485)  Time: 0.705s, 2904.10/s  (0.780s, 2626.77/s)  avg LR: 6.806e-03  iter ratio: 0.0000  Data: 0.030 (0.101)
INFO:Train: 76 [ 100/625 ( 16%)]  Loss: 0.004588 (0.00476)  Time: 0.701s, 2919.69/s  (0.741s, 2762.75/s)  avg LR: 6.806e-03  iter ratio: 0.0000  Data: 0.027 (0.065)
INFO:Train: 76 [ 150/625 ( 24%)]  Loss: 0.004491 (0.00469)  Time: 0.703s, 2912.86/s  (0.728s, 2811.76/s)  avg LR: 6.806e-03  iter ratio: 0.0000  Data: 0.028 (0.053)
INFO:Train: 76 [ 200/625 ( 32%)]  Loss: 0.004622 (0.00468)  Time: 0.702s, 2915.90/s  (0.722s, 2837.27/s)  avg LR: 6.806e-03  iter ratio: 0.0000  Data: 0.028 (0.046)
INFO:Train: 76 [ 250/625 ( 40%)]  Loss: 0.003672 (0.00451)  Time: 0.702s, 2917.77/s  (0.718s, 2852.73/s)  avg LR: 6.806e-03  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 76 [ 300/625 ( 48%)]  Loss: 0.003881 (0.00442)  Time: 0.702s, 2919.24/s  (0.715s, 2863.24/s)  avg LR: 6.806e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 76 [ 350/625 ( 56%)]  Loss: 0.004849 (0.00448)  Time: 0.701s, 2922.84/s  (0.713s, 2870.84/s)  avg LR: 6.806e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 76 [ 400/625 ( 64%)]  Loss: 0.004330 (0.00446)  Time: 0.702s, 2915.47/s  (0.712s, 2876.55/s)  avg LR: 6.806e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 76 [ 450/625 ( 72%)]  Loss: 0.005110 (0.00452)  Time: 0.703s, 2915.21/s  (0.711s, 2881.02/s)  avg LR: 6.806e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 76 [ 500/625 ( 80%)]  Loss: 0.004646 (0.00454)  Time: 0.702s, 2917.01/s  (0.710s, 2884.59/s)  avg LR: 6.806e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 76 [ 550/625 ( 88%)]  Loss: 0.004308 (0.00452)  Time: 0.701s, 2921.11/s  (0.709s, 2887.44/s)  avg LR: 6.806e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 76 [ 600/625 ( 96%)]  Loss: 0.004368 (0.00450)  Time: 0.700s, 2924.99/s  (0.709s, 2889.98/s)  avg LR: 6.806e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 76 [ 624/625 (100%)]  Loss: 0.004178 (0.00448)  Time: 0.672s, 3048.83/s  (0.708s, 2891.53/s)  avg LR: 6.806e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.312 (4.312)  Loss:  1.3613 (1.3613)  Acc@1: 69.0918 (69.0918)  Acc@5: 88.0859 (88.0859)
INFO:Test: [  24/24]  Time: 0.080 (0.494)  Loss:  1.0371 (1.7336)  Acc@1: 77.3585 (60.6600)  Acc@5: 90.4481 (83.7940)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-76.pth.tar', 60.660000119628904)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-70.pth.tar', 59.227999973144534)

INFO:76-epoch: remaining time 29.76 h
INFO:Train: 77 [   0/625 (  0%)]  Loss: 0.004230 (0.00423)  Time: 4.236s,  483.53/s  (4.236s,  483.53/s)  avg LR: 6.776e-03  iter ratio: 0.0000  Data: 3.547 (3.547)
INFO:Train: 77 [  50/625 (  8%)]  Loss: 0.003958 (0.00409)  Time: 0.704s, 2908.06/s  (0.773s, 2650.01/s)  avg LR: 6.776e-03  iter ratio: 0.0000  Data: 0.028 (0.097)
INFO:Train: 77 [ 100/625 ( 16%)]  Loss: 0.005454 (0.00455)  Time: 0.702s, 2918.48/s  (0.739s, 2772.53/s)  avg LR: 6.776e-03  iter ratio: 0.0000  Data: 0.026 (0.062)
INFO:Train: 77 [ 150/625 ( 24%)]  Loss: 0.004548 (0.00455)  Time: 0.705s, 2905.07/s  (0.727s, 2816.50/s)  avg LR: 6.776e-03  iter ratio: 0.0000  Data: 0.026 (0.051)
INFO:Train: 77 [ 200/625 ( 32%)]  Loss: 0.004736 (0.00459)  Time: 0.704s, 2907.29/s  (0.721s, 2838.88/s)  avg LR: 6.776e-03  iter ratio: 0.0000  Data: 0.029 (0.045)
INFO:Train: 77 [ 250/625 ( 40%)]  Loss: 0.005084 (0.00467)  Time: 0.703s, 2912.65/s  (0.718s, 2852.81/s)  avg LR: 6.776e-03  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 77 [ 300/625 ( 48%)]  Loss: 0.004388 (0.00463)  Time: 0.704s, 2910.88/s  (0.716s, 2861.98/s)  avg LR: 6.776e-03  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 77 [ 350/625 ( 56%)]  Loss: 0.004156 (0.00457)  Time: 0.704s, 2911.02/s  (0.714s, 2868.42/s)  avg LR: 6.776e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 77 [ 400/625 ( 64%)]  Loss: 0.004939 (0.00461)  Time: 0.703s, 2913.25/s  (0.713s, 2873.48/s)  avg LR: 6.776e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 77 [ 450/625 ( 72%)]  Loss: 0.005273 (0.00468)  Time: 0.703s, 2914.65/s  (0.712s, 2877.46/s)  avg LR: 6.776e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 77 [ 500/625 ( 80%)]  Loss: 0.004597 (0.00467)  Time: 0.702s, 2918.34/s  (0.711s, 2880.81/s)  avg LR: 6.776e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 77 [ 550/625 ( 88%)]  Loss: 0.004345 (0.00464)  Time: 0.705s, 2905.48/s  (0.710s, 2883.55/s)  avg LR: 6.776e-03  iter ratio: 0.0000  Data: 0.029 (0.034)
INFO:Train: 77 [ 600/625 ( 96%)]  Loss: 0.005336 (0.00470)  Time: 0.703s, 2914.05/s  (0.710s, 2886.09/s)  avg LR: 6.776e-03  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 77 [ 624/625 (100%)]  Loss: 0.004085 (0.00465)  Time: 0.671s, 3050.78/s  (0.709s, 2887.48/s)  avg LR: 6.776e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.388 (4.388)  Loss:  1.6465 (1.6465)  Acc@1: 64.8926 (64.8926)  Acc@5: 85.6445 (85.6445)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  1.3574 (2.1292)  Acc@1: 72.5236 (54.4660)  Acc@5: 86.9104 (78.7560)
INFO:77-epoch: remaining time 29.61 h
INFO:Train: 78 [   0/625 (  0%)]  Loss: 0.004332 (0.00433)  Time: 4.409s,  464.52/s  (4.409s,  464.52/s)  avg LR: 6.746e-03  iter ratio: 0.0000  Data: 3.495 (3.495)
INFO:Train: 78 [  50/625 (  8%)]  Loss: 0.004108 (0.00422)  Time: 0.700s, 2924.18/s  (0.775s, 2643.05/s)  avg LR: 6.746e-03  iter ratio: 0.0000  Data: 0.026 (0.096)
INFO:Train: 78 [ 100/625 ( 16%)]  Loss: 0.003868 (0.00410)  Time: 0.701s, 2922.28/s  (0.738s, 2774.69/s)  avg LR: 6.746e-03  iter ratio: 0.0000  Data: 0.025 (0.062)
INFO:Train: 78 [ 150/625 ( 24%)]  Loss: 0.004462 (0.00419)  Time: 0.703s, 2912.01/s  (0.726s, 2822.33/s)  avg LR: 6.746e-03  iter ratio: 0.0000  Data: 0.026 (0.050)
INFO:Train: 78 [ 200/625 ( 32%)]  Loss: 0.004697 (0.00429)  Time: 0.702s, 2917.31/s  (0.719s, 2846.51/s)  avg LR: 6.746e-03  iter ratio: 0.0000  Data: 0.027 (0.044)
INFO:Train: 78 [ 250/625 ( 40%)]  Loss: 0.004393 (0.00431)  Time: 0.703s, 2911.63/s  (0.716s, 2861.28/s)  avg LR: 6.746e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 78 [ 300/625 ( 48%)]  Loss: 0.004194 (0.00429)  Time: 0.700s, 2926.48/s  (0.713s, 2871.49/s)  avg LR: 6.746e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 78 [ 350/625 ( 56%)]  Loss: 0.004982 (0.00438)  Time: 0.700s, 2925.57/s  (0.711s, 2878.91/s)  avg LR: 6.746e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 78 [ 400/625 ( 64%)]  Loss: 0.004496 (0.00439)  Time: 0.700s, 2927.49/s  (0.710s, 2884.52/s)  avg LR: 6.746e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 78 [ 450/625 ( 72%)]  Loss: 0.004287 (0.00438)  Time: 0.700s, 2926.91/s  (0.709s, 2888.75/s)  avg LR: 6.746e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 78 [ 500/625 ( 80%)]  Loss: 0.004383 (0.00438)  Time: 0.700s, 2927.54/s  (0.708s, 2892.21/s)  avg LR: 6.746e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 78 [ 550/625 ( 88%)]  Loss: 0.004857 (0.00442)  Time: 0.700s, 2926.31/s  (0.707s, 2895.04/s)  avg LR: 6.746e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 78 [ 600/625 ( 96%)]  Loss: 0.005088 (0.00447)  Time: 0.701s, 2921.96/s  (0.707s, 2897.39/s)  avg LR: 6.746e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 78 [ 624/625 (100%)]  Loss: 0.005058 (0.00451)  Time: 0.670s, 3055.58/s  (0.706s, 2898.85/s)  avg LR: 6.746e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.337 (4.337)  Loss:  1.4785 (1.4785)  Acc@1: 67.9688 (67.9688)  Acc@5: 86.5234 (86.5234)
INFO:Test: [  24/24]  Time: 0.079 (0.495)  Loss:  1.1113 (1.8504)  Acc@1: 76.4151 (59.2300)  Acc@5: 90.2123 (82.7060)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-76.pth.tar', 60.660000119628904)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-78.pth.tar', 59.229999968261716)

INFO:78-epoch: remaining time 29.39 h
INFO:Train: 79 [   0/625 (  0%)]  Loss: 0.004605 (0.00460)  Time: 4.167s,  491.43/s  (4.167s,  491.43/s)  avg LR: 6.716e-03  iter ratio: 0.0000  Data: 3.467 (3.467)
INFO:Train: 79 [  50/625 (  8%)]  Loss: 0.005147 (0.00488)  Time: 0.701s, 2919.93/s  (0.771s, 2656.55/s)  avg LR: 6.716e-03  iter ratio: 0.0000  Data: 0.028 (0.095)
INFO:Train: 79 [ 100/625 ( 16%)]  Loss: 0.004514 (0.00476)  Time: 0.702s, 2918.17/s  (0.737s, 2779.53/s)  avg LR: 6.716e-03  iter ratio: 0.0000  Data: 0.029 (0.061)
INFO:Train: 79 [ 150/625 ( 24%)]  Loss: 0.004619 (0.00472)  Time: 0.701s, 2920.69/s  (0.725s, 2824.55/s)  avg LR: 6.716e-03  iter ratio: 0.0000  Data: 0.027 (0.049)
INFO:Train: 79 [ 200/625 ( 32%)]  Loss: 0.004466 (0.00467)  Time: 0.702s, 2916.50/s  (0.719s, 2847.57/s)  avg LR: 6.716e-03  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 79 [ 250/625 ( 40%)]  Loss: 0.004728 (0.00468)  Time: 0.701s, 2922.65/s  (0.716s, 2861.31/s)  avg LR: 6.716e-03  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 79 [ 300/625 ( 48%)]  Loss: 0.004143 (0.00460)  Time: 0.700s, 2925.29/s  (0.713s, 2870.76/s)  avg LR: 6.716e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 79 [ 350/625 ( 56%)]  Loss: 0.004248 (0.00456)  Time: 0.702s, 2917.53/s  (0.712s, 2877.53/s)  avg LR: 6.716e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 79 [ 400/625 ( 64%)]  Loss: 0.004731 (0.00458)  Time: 0.701s, 2922.56/s  (0.710s, 2882.64/s)  avg LR: 6.716e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 79 [ 450/625 ( 72%)]  Loss: 0.004210 (0.00454)  Time: 0.700s, 2924.52/s  (0.709s, 2886.74/s)  avg LR: 6.716e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 79 [ 500/625 ( 80%)]  Loss: 0.004648 (0.00455)  Time: 0.701s, 2919.58/s  (0.709s, 2890.00/s)  avg LR: 6.716e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 79 [ 550/625 ( 88%)]  Loss: 0.005189 (0.00460)  Time: 0.701s, 2923.49/s  (0.708s, 2892.72/s)  avg LR: 6.716e-03  iter ratio: 0.0000  Data: 0.027 (0.032)
INFO:Train: 79 [ 600/625 ( 96%)]  Loss: 0.004844 (0.00462)  Time: 0.701s, 2922.99/s  (0.707s, 2894.93/s)  avg LR: 6.716e-03  iter ratio: 0.0000  Data: 0.027 (0.032)
INFO:Train: 79 [ 624/625 (100%)]  Loss: 0.004669 (0.00463)  Time: 0.673s, 3045.00/s  (0.707s, 2896.26/s)  avg LR: 6.716e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.354 (4.354)  Loss:  1.1113 (1.1113)  Acc@1: 73.6328 (73.6328)  Acc@5: 91.0156 (91.0156)
INFO:Test: [  24/24]  Time: 0.080 (0.494)  Loss:  0.9058 (1.7298)  Acc@1: 79.7170 (60.7840)  Acc@5: 92.5708 (83.7300)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-79.pth.tar', 60.78399998046875)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-76.pth.tar', 60.660000119628904)

INFO:79-epoch: remaining time 29.31 h
INFO:Train: 80 [   0/625 (  0%)]  Loss: 0.004161 (0.00416)  Time: 4.459s,  459.28/s  (4.459s,  459.28/s)  avg LR: 6.685e-03  iter ratio: 0.0000  Data: 3.540 (3.540)
INFO:Train: 80 [  50/625 (  8%)]  Loss: 0.004793 (0.00448)  Time: 0.699s, 2928.69/s  (0.777s, 2635.36/s)  avg LR: 6.685e-03  iter ratio: 0.0000  Data: 0.026 (0.097)
INFO:Train: 80 [ 100/625 ( 16%)]  Loss: 0.004258 (0.00440)  Time: 0.700s, 2926.80/s  (0.740s, 2766.57/s)  avg LR: 6.685e-03  iter ratio: 0.0000  Data: 0.026 (0.062)
INFO:Train: 80 [ 150/625 ( 24%)]  Loss: 0.003746 (0.00424)  Time: 0.704s, 2910.39/s  (0.728s, 2814.48/s)  avg LR: 6.685e-03  iter ratio: 0.0000  Data: 0.028 (0.050)
INFO:Train: 80 [ 200/625 ( 32%)]  Loss: 0.004380 (0.00427)  Time: 0.700s, 2927.24/s  (0.721s, 2839.37/s)  avg LR: 6.685e-03  iter ratio: 0.0000  Data: 0.026 (0.044)
INFO:Train: 80 [ 250/625 ( 40%)]  Loss: 0.004565 (0.00432)  Time: 0.704s, 2910.89/s  (0.718s, 2854.33/s)  avg LR: 6.685e-03  iter ratio: 0.0000  Data: 0.030 (0.041)
INFO:Train: 80 [ 300/625 ( 48%)]  Loss: 0.004901 (0.00440)  Time: 0.702s, 2916.11/s  (0.715s, 2864.51/s)  avg LR: 6.685e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 80 [ 350/625 ( 56%)]  Loss: 0.004358 (0.00440)  Time: 0.699s, 2929.36/s  (0.713s, 2872.01/s)  avg LR: 6.685e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 80 [ 400/625 ( 64%)]  Loss: 0.003713 (0.00432)  Time: 0.701s, 2920.57/s  (0.712s, 2877.54/s)  avg LR: 6.685e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 80 [ 450/625 ( 72%)]  Loss: 0.004285 (0.00432)  Time: 0.701s, 2919.71/s  (0.711s, 2881.80/s)  avg LR: 6.685e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 80 [ 500/625 ( 80%)]  Loss: 0.004830 (0.00436)  Time: 0.700s, 2923.76/s  (0.710s, 2885.10/s)  avg LR: 6.685e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 80 [ 550/625 ( 88%)]  Loss: 0.004138 (0.00434)  Time: 0.703s, 2914.60/s  (0.709s, 2887.87/s)  avg LR: 6.685e-03  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 80 [ 600/625 ( 96%)]  Loss: 0.004642 (0.00437)  Time: 0.701s, 2920.61/s  (0.709s, 2890.22/s)  avg LR: 6.685e-03  iter ratio: 0.0000  Data: 0.028 (0.032)
INFO:Train: 80 [ 624/625 (100%)]  Loss: 0.004502 (0.00438)  Time: 0.672s, 3045.62/s  (0.708s, 2891.67/s)  avg LR: 6.685e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.307 (4.307)  Loss:  1.2842 (1.2842)  Acc@1: 70.8984 (70.8984)  Acc@5: 89.1113 (89.1113)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  1.0996 (1.8862)  Acc@1: 75.0000 (58.3320)  Acc@5: 91.2736 (81.8720)
INFO:80-epoch: remaining time 29.18 h
INFO:Train: 81 [   0/625 (  0%)]  Loss: 0.004606 (0.00461)  Time: 4.214s,  485.96/s  (4.214s,  485.96/s)  avg LR: 6.654e-03  iter ratio: 0.0000  Data: 3.528 (3.528)
INFO:Train: 81 [  50/625 (  8%)]  Loss: 0.004032 (0.00432)  Time: 0.701s, 2922.70/s  (0.771s, 2657.11/s)  avg LR: 6.654e-03  iter ratio: 0.0000  Data: 0.028 (0.097)
INFO:Train: 81 [ 100/625 ( 16%)]  Loss: 0.005018 (0.00455)  Time: 0.701s, 2920.89/s  (0.737s, 2780.43/s)  avg LR: 6.654e-03  iter ratio: 0.0000  Data: 0.029 (0.063)
INFO:Train: 81 [ 150/625 ( 24%)]  Loss: 0.004864 (0.00463)  Time: 0.701s, 2922.45/s  (0.725s, 2824.70/s)  avg LR: 6.654e-03  iter ratio: 0.0000  Data: 0.029 (0.051)
INFO:Train: 81 [ 200/625 ( 32%)]  Loss: 0.004139 (0.00453)  Time: 0.701s, 2921.20/s  (0.719s, 2847.92/s)  avg LR: 6.654e-03  iter ratio: 0.0000  Data: 0.029 (0.046)
INFO:Train: 81 [ 250/625 ( 40%)]  Loss: 0.004325 (0.00450)  Time: 0.702s, 2919.14/s  (0.716s, 2862.15/s)  avg LR: 6.654e-03  iter ratio: 0.0000  Data: 0.030 (0.042)
INFO:Train: 81 [ 300/625 ( 48%)]  Loss: 0.004209 (0.00446)  Time: 0.702s, 2918.00/s  (0.713s, 2871.32/s)  avg LR: 6.654e-03  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 81 [ 350/625 ( 56%)]  Loss: 0.004501 (0.00446)  Time: 0.703s, 2915.09/s  (0.712s, 2877.39/s)  avg LR: 6.654e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 81 [ 400/625 ( 64%)]  Loss: 0.003652 (0.00437)  Time: 0.702s, 2919.14/s  (0.711s, 2882.11/s)  avg LR: 6.654e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 81 [ 450/625 ( 72%)]  Loss: 0.004346 (0.00437)  Time: 0.703s, 2911.74/s  (0.710s, 2885.93/s)  avg LR: 6.654e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 81 [ 500/625 ( 80%)]  Loss: 0.005091 (0.00443)  Time: 0.702s, 2916.21/s  (0.709s, 2888.97/s)  avg LR: 6.654e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 81 [ 550/625 ( 88%)]  Loss: 0.003742 (0.00438)  Time: 0.704s, 2911.06/s  (0.708s, 2891.42/s)  avg LR: 6.654e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 81 [ 600/625 ( 96%)]  Loss: 0.004550 (0.00439)  Time: 0.703s, 2914.01/s  (0.708s, 2893.54/s)  avg LR: 6.654e-03  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 81 [ 624/625 (100%)]  Loss: 0.005314 (0.00446)  Time: 0.673s, 3041.58/s  (0.707s, 2894.89/s)  avg LR: 6.654e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.352 (4.352)  Loss:  1.4365 (1.4365)  Acc@1: 70.3613 (70.3613)  Acc@5: 88.5254 (88.5254)
INFO:Test: [  24/24]  Time: 0.080 (0.494)  Loss:  1.2188 (1.9341)  Acc@1: 75.4717 (59.2400)  Acc@5: 90.3302 (82.4180)
INFO:81-epoch: remaining time 29.06 h
INFO:Train: 82 [   0/625 (  0%)]  Loss: 0.005127 (0.00513)  Time: 4.235s,  483.64/s  (4.235s,  483.64/s)  avg LR: 6.622e-03  iter ratio: 0.0000  Data: 3.335 (3.335)
INFO:Train: 82 [  50/625 (  8%)]  Loss: 0.004072 (0.00460)  Time: 0.702s, 2916.56/s  (0.773s, 2650.73/s)  avg LR: 6.622e-03  iter ratio: 0.0000  Data: 0.029 (0.094)
INFO:Train: 82 [ 100/625 ( 16%)]  Loss: 0.004195 (0.00446)  Time: 0.702s, 2919.00/s  (0.737s, 2777.21/s)  avg LR: 6.622e-03  iter ratio: 0.0000  Data: 0.028 (0.061)
INFO:Train: 82 [ 150/625 ( 24%)]  Loss: 0.004474 (0.00447)  Time: 0.702s, 2915.77/s  (0.725s, 2822.95/s)  avg LR: 6.622e-03  iter ratio: 0.0000  Data: 0.028 (0.050)
INFO:Train: 82 [ 200/625 ( 32%)]  Loss: 0.004877 (0.00455)  Time: 0.703s, 2912.51/s  (0.719s, 2846.83/s)  avg LR: 6.622e-03  iter ratio: 0.0000  Data: 0.028 (0.045)
INFO:Train: 82 [ 250/625 ( 40%)]  Loss: 0.004778 (0.00459)  Time: 0.702s, 2917.80/s  (0.716s, 2861.11/s)  avg LR: 6.622e-03  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 82 [ 300/625 ( 48%)]  Loss: 0.004597 (0.00459)  Time: 0.702s, 2918.49/s  (0.713s, 2870.76/s)  avg LR: 6.622e-03  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 82 [ 350/625 ( 56%)]  Loss: 0.004808 (0.00462)  Time: 0.705s, 2906.15/s  (0.712s, 2877.66/s)  avg LR: 6.622e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 82 [ 400/625 ( 64%)]  Loss: 0.004455 (0.00460)  Time: 0.703s, 2914.08/s  (0.710s, 2882.94/s)  avg LR: 6.622e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 82 [ 450/625 ( 72%)]  Loss: 0.003827 (0.00452)  Time: 0.702s, 2915.72/s  (0.709s, 2887.15/s)  avg LR: 6.622e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 82 [ 500/625 ( 80%)]  Loss: 0.004962 (0.00456)  Time: 0.701s, 2919.80/s  (0.709s, 2890.39/s)  avg LR: 6.622e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 82 [ 550/625 ( 88%)]  Loss: 0.004099 (0.00452)  Time: 0.701s, 2919.74/s  (0.708s, 2893.10/s)  avg LR: 6.622e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 82 [ 600/625 ( 96%)]  Loss: 0.003923 (0.00448)  Time: 0.701s, 2919.81/s  (0.707s, 2895.23/s)  avg LR: 6.622e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 82 [ 624/625 (100%)]  Loss: 0.004347 (0.00447)  Time: 0.671s, 3053.38/s  (0.707s, 2896.71/s)  avg LR: 6.622e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.301 (4.301)  Loss:  1.7637 (1.7637)  Acc@1: 63.3301 (63.3301)  Acc@5: 83.6914 (83.6914)
INFO:Test: [  24/24]  Time: 0.079 (0.493)  Loss:  1.4111 (2.0841)  Acc@1: 70.4009 (55.7600)  Acc@5: 89.3868 (79.5460)
INFO:82-epoch: remaining time 28.91 h
INFO:Train: 83 [   0/625 (  0%)]  Loss: 0.004505 (0.00451)  Time: 4.357s,  470.08/s  (4.357s,  470.08/s)  avg LR: 6.591e-03  iter ratio: 0.0000  Data: 3.668 (3.668)
INFO:Train: 83 [  50/625 (  8%)]  Loss: 0.004569 (0.00454)  Time: 0.701s, 2921.48/s  (0.772s, 2651.53/s)  avg LR: 6.591e-03  iter ratio: 0.0000  Data: 0.029 (0.099)
INFO:Train: 83 [ 100/625 ( 16%)]  Loss: 0.004727 (0.00460)  Time: 0.699s, 2931.45/s  (0.737s, 2778.47/s)  avg LR: 6.591e-03  iter ratio: 0.0000  Data: 0.025 (0.063)
INFO:Train: 83 [ 150/625 ( 24%)]  Loss: 0.003698 (0.00437)  Time: 0.699s, 2930.30/s  (0.725s, 2824.41/s)  avg LR: 6.591e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 83 [ 200/625 ( 32%)]  Loss: 0.004586 (0.00442)  Time: 0.701s, 2922.94/s  (0.719s, 2847.91/s)  avg LR: 6.591e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 83 [ 250/625 ( 40%)]  Loss: 0.004047 (0.00436)  Time: 0.699s, 2928.33/s  (0.716s, 2862.23/s)  avg LR: 6.591e-03  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 83 [ 300/625 ( 48%)]  Loss: 0.004389 (0.00436)  Time: 0.699s, 2930.07/s  (0.713s, 2871.74/s)  avg LR: 6.591e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 83 [ 350/625 ( 56%)]  Loss: 0.004580 (0.00439)  Time: 0.699s, 2930.94/s  (0.711s, 2878.79/s)  avg LR: 6.591e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 83 [ 400/625 ( 64%)]  Loss: 0.004161 (0.00436)  Time: 0.701s, 2920.31/s  (0.710s, 2884.04/s)  avg LR: 6.591e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 83 [ 450/625 ( 72%)]  Loss: 0.004680 (0.00439)  Time: 0.699s, 2931.35/s  (0.709s, 2888.18/s)  avg LR: 6.591e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 83 [ 500/625 ( 80%)]  Loss: 0.004271 (0.00438)  Time: 0.699s, 2930.58/s  (0.708s, 2891.56/s)  avg LR: 6.591e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 83 [ 550/625 ( 88%)]  Loss: 0.004673 (0.00441)  Time: 0.700s, 2927.23/s  (0.708s, 2894.33/s)  avg LR: 6.591e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 83 [ 600/625 ( 96%)]  Loss: 0.004241 (0.00439)  Time: 0.700s, 2926.90/s  (0.707s, 2896.64/s)  avg LR: 6.591e-03  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 83 [ 624/625 (100%)]  Loss: 0.004474 (0.00440)  Time: 0.671s, 3051.65/s  (0.707s, 2898.09/s)  avg LR: 6.591e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.340 (4.340)  Loss:  1.4775 (1.4775)  Acc@1: 68.6523 (68.6523)  Acc@5: 87.1094 (87.1094)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  1.6299 (2.0454)  Acc@1: 66.5094 (56.2160)  Acc@5: 85.2594 (80.0740)
INFO:83-epoch: remaining time 28.77 h
INFO:Train: 84 [   0/625 (  0%)]  Loss: 0.004451 (0.00445)  Time: 4.499s,  455.21/s  (4.499s,  455.21/s)  avg LR: 6.559e-03  iter ratio: 0.0000  Data: 3.594 (3.594)
INFO:Train: 84 [  50/625 (  8%)]  Loss: 0.004999 (0.00472)  Time: 0.698s, 2933.88/s  (0.775s, 2642.30/s)  avg LR: 6.559e-03  iter ratio: 0.0000  Data: 0.026 (0.098)
INFO:Train: 84 [ 100/625 ( 16%)]  Loss: 0.004651 (0.00470)  Time: 0.697s, 2937.01/s  (0.738s, 2774.92/s)  avg LR: 6.559e-03  iter ratio: 0.0000  Data: 0.027 (0.063)
INFO:Train: 84 [ 150/625 ( 24%)]  Loss: 0.004536 (0.00466)  Time: 0.700s, 2926.68/s  (0.726s, 2822.42/s)  avg LR: 6.559e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 84 [ 200/625 ( 32%)]  Loss: 0.004106 (0.00455)  Time: 0.701s, 2920.37/s  (0.719s, 2846.62/s)  avg LR: 6.559e-03  iter ratio: 0.0000  Data: 0.028 (0.045)
INFO:Train: 84 [ 250/625 ( 40%)]  Loss: 0.004319 (0.00451)  Time: 0.699s, 2930.26/s  (0.716s, 2861.51/s)  avg LR: 6.559e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 84 [ 300/625 ( 48%)]  Loss: 0.005095 (0.00459)  Time: 0.700s, 2925.91/s  (0.713s, 2871.58/s)  avg LR: 6.559e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 84 [ 350/625 ( 56%)]  Loss: 0.004738 (0.00461)  Time: 0.699s, 2931.39/s  (0.711s, 2878.78/s)  avg LR: 6.559e-03  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 84 [ 400/625 ( 64%)]  Loss: 0.004671 (0.00462)  Time: 0.701s, 2923.08/s  (0.710s, 2884.20/s)  avg LR: 6.559e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 84 [ 450/625 ( 72%)]  Loss: 0.005093 (0.00467)  Time: 0.699s, 2929.63/s  (0.709s, 2888.46/s)  avg LR: 6.559e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 84 [ 500/625 ( 80%)]  Loss: 0.004388 (0.00464)  Time: 0.700s, 2926.76/s  (0.708s, 2891.89/s)  avg LR: 6.559e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 84 [ 550/625 ( 88%)]  Loss: 0.004860 (0.00466)  Time: 0.651s, 3144.23/s  (0.707s, 2895.45/s)  avg LR: 6.559e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 84 [ 600/625 ( 96%)]  Loss: 0.004640 (0.00466)  Time: 0.699s, 2931.14/s  (0.707s, 2897.85/s)  avg LR: 6.559e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 84 [ 624/625 (100%)]  Loss: 0.004828 (0.00467)  Time: 0.673s, 3042.66/s  (0.706s, 2899.29/s)  avg LR: 6.559e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.315 (4.315)  Loss:  1.3691 (1.3691)  Acc@1: 69.1895 (69.1895)  Acc@5: 89.0137 (89.0137)
INFO:Test: [  24/24]  Time: 0.079 (0.493)  Loss:  1.0107 (1.7709)  Acc@1: 77.4764 (60.5780)  Acc@5: 91.3915 (83.6160)
INFO:84-epoch: remaining time 28.61 h
INFO:Train: 85 [   0/625 (  0%)]  Loss: 0.005315 (0.00532)  Time: 4.255s,  481.30/s  (4.255s,  481.30/s)  avg LR: 6.527e-03  iter ratio: 0.0000  Data: 3.574 (3.574)
INFO:Train: 85 [  50/625 (  8%)]  Loss: 0.004035 (0.00468)  Time: 0.700s, 2926.68/s  (0.771s, 2657.80/s)  avg LR: 6.527e-03  iter ratio: 0.0000  Data: 0.027 (0.096)
INFO:Train: 85 [ 100/625 ( 16%)]  Loss: 0.004038 (0.00446)  Time: 0.698s, 2934.33/s  (0.736s, 2782.53/s)  avg LR: 6.527e-03  iter ratio: 0.0000  Data: 0.026 (0.062)
INFO:Train: 85 [ 150/625 ( 24%)]  Loss: 0.004506 (0.00447)  Time: 0.699s, 2927.89/s  (0.724s, 2827.06/s)  avg LR: 6.527e-03  iter ratio: 0.0000  Data: 0.028 (0.050)
INFO:Train: 85 [ 200/625 ( 32%)]  Loss: 0.005326 (0.00464)  Time: 0.699s, 2931.08/s  (0.719s, 2849.87/s)  avg LR: 6.527e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 85 [ 250/625 ( 40%)]  Loss: 0.004656 (0.00465)  Time: 0.699s, 2928.38/s  (0.715s, 2863.85/s)  avg LR: 6.527e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 85 [ 300/625 ( 48%)]  Loss: 0.004923 (0.00469)  Time: 0.698s, 2933.43/s  (0.713s, 2873.35/s)  avg LR: 6.527e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 85 [ 350/625 ( 56%)]  Loss: 0.004321 (0.00464)  Time: 0.701s, 2920.78/s  (0.711s, 2880.10/s)  avg LR: 6.527e-03  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 85 [ 400/625 ( 64%)]  Loss: 0.004697 (0.00465)  Time: 0.701s, 2921.37/s  (0.710s, 2885.22/s)  avg LR: 6.527e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 85 [ 450/625 ( 72%)]  Loss: 0.003769 (0.00456)  Time: 0.700s, 2924.86/s  (0.709s, 2889.19/s)  avg LR: 6.527e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 85 [ 500/625 ( 80%)]  Loss: 0.004342 (0.00454)  Time: 0.699s, 2929.50/s  (0.708s, 2892.38/s)  avg LR: 6.527e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 85 [ 550/625 ( 88%)]  Loss: 0.004230 (0.00451)  Time: 0.699s, 2928.63/s  (0.707s, 2895.03/s)  avg LR: 6.527e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 85 [ 600/625 ( 96%)]  Loss: 0.004596 (0.00452)  Time: 0.701s, 2922.37/s  (0.707s, 2897.16/s)  avg LR: 6.527e-03  iter ratio: 0.0000  Data: 0.029 (0.033)
INFO:Train: 85 [ 624/625 (100%)]  Loss: 0.003987 (0.00448)  Time: 0.671s, 3050.44/s  (0.707s, 2898.49/s)  avg LR: 6.527e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.351 (4.351)  Loss:  1.4316 (1.4316)  Acc@1: 67.7246 (67.7246)  Acc@5: 87.8418 (87.8418)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  1.3193 (1.9374)  Acc@1: 72.4057 (58.1920)  Acc@5: 88.3255 (81.1920)
INFO:85-epoch: remaining time 28.50 h
INFO:Train: 86 [   0/625 (  0%)]  Loss: 0.005155 (0.00516)  Time: 4.443s,  460.92/s  (4.443s,  460.92/s)  avg LR: 6.494e-03  iter ratio: 0.0000  Data: 3.501 (3.501)
INFO:Train: 86 [  50/625 (  8%)]  Loss: 0.004810 (0.00498)  Time: 0.699s, 2930.23/s  (0.774s, 2645.02/s)  avg LR: 6.494e-03  iter ratio: 0.0000  Data: 0.026 (0.096)
INFO:Train: 86 [ 100/625 ( 16%)]  Loss: 0.004436 (0.00480)  Time: 0.700s, 2925.08/s  (0.738s, 2776.16/s)  avg LR: 6.494e-03  iter ratio: 0.0000  Data: 0.026 (0.062)
INFO:Train: 86 [ 150/625 ( 24%)]  Loss: 0.004398 (0.00470)  Time: 0.699s, 2930.55/s  (0.725s, 2823.47/s)  avg LR: 6.494e-03  iter ratio: 0.0000  Data: 0.026 (0.051)
INFO:Train: 86 [ 200/625 ( 32%)]  Loss: 0.004328 (0.00463)  Time: 0.699s, 2930.67/s  (0.719s, 2847.78/s)  avg LR: 6.494e-03  iter ratio: 0.0000  Data: 0.026 (0.045)
INFO:Train: 86 [ 250/625 ( 40%)]  Loss: 0.004612 (0.00462)  Time: 0.699s, 2929.08/s  (0.715s, 2862.51/s)  avg LR: 6.494e-03  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 86 [ 300/625 ( 48%)]  Loss: 0.004168 (0.00456)  Time: 0.699s, 2927.81/s  (0.713s, 2872.44/s)  avg LR: 6.494e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 86 [ 350/625 ( 56%)]  Loss: 0.004516 (0.00455)  Time: 0.699s, 2931.40/s  (0.711s, 2879.54/s)  avg LR: 6.494e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 86 [ 400/625 ( 64%)]  Loss: 0.004117 (0.00450)  Time: 0.699s, 2930.23/s  (0.710s, 2885.02/s)  avg LR: 6.494e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 86 [ 450/625 ( 72%)]  Loss: 0.004591 (0.00451)  Time: 0.698s, 2934.85/s  (0.709s, 2888.94/s)  avg LR: 6.494e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 86 [ 500/625 ( 80%)]  Loss: 0.004829 (0.00454)  Time: 0.704s, 2907.49/s  (0.708s, 2892.22/s)  avg LR: 6.494e-03  iter ratio: 0.0000  Data: 0.031 (0.035)
INFO:Train: 86 [ 550/625 ( 88%)]  Loss: 0.004557 (0.00454)  Time: 0.698s, 2932.34/s  (0.707s, 2894.82/s)  avg LR: 6.494e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 86 [ 600/625 ( 96%)]  Loss: 0.005102 (0.00459)  Time: 0.701s, 2921.61/s  (0.707s, 2896.97/s)  avg LR: 6.494e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 86 [ 624/625 (100%)]  Loss: 0.004211 (0.00456)  Time: 0.671s, 3050.40/s  (0.707s, 2898.44/s)  avg LR: 6.494e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.309 (4.309)  Loss:  1.2549 (1.2549)  Acc@1: 73.1445 (73.1445)  Acc@5: 88.8184 (88.8184)
INFO:Test: [  24/24]  Time: 0.079 (0.495)  Loss:  0.9800 (1.6957)  Acc@1: 77.2406 (61.7540)  Acc@5: 92.3349 (84.6700)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-86.pth.tar', 61.753999938964846)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-79.pth.tar', 60.78399998046875)

INFO:86-epoch: remaining time 28.38 h
INFO:Train: 87 [   0/625 (  0%)]  Loss: 0.005255 (0.00526)  Time: 4.030s,  508.24/s  (4.030s,  508.24/s)  avg LR: 6.461e-03  iter ratio: 0.0000  Data: 3.337 (3.337)
INFO:Train: 87 [  50/625 (  8%)]  Loss: 0.004211 (0.00473)  Time: 0.699s, 2928.82/s  (0.766s, 2672.74/s)  avg LR: 6.461e-03  iter ratio: 0.0000  Data: 0.027 (0.092)
INFO:Train: 87 [ 100/625 ( 16%)]  Loss: 0.005074 (0.00485)  Time: 0.701s, 2921.93/s  (0.734s, 2790.02/s)  avg LR: 6.461e-03  iter ratio: 0.0000  Data: 0.027 (0.061)
INFO:Train: 87 [ 150/625 ( 24%)]  Loss: 0.005091 (0.00491)  Time: 0.701s, 2920.72/s  (0.723s, 2831.95/s)  avg LR: 6.461e-03  iter ratio: 0.0000  Data: 0.028 (0.050)
INFO:Train: 87 [ 200/625 ( 32%)]  Loss: 0.004609 (0.00485)  Time: 0.700s, 2924.71/s  (0.718s, 2853.25/s)  avg LR: 6.461e-03  iter ratio: 0.0000  Data: 0.027 (0.044)
INFO:Train: 87 [ 250/625 ( 40%)]  Loss: 0.004661 (0.00482)  Time: 0.701s, 2923.08/s  (0.715s, 2866.03/s)  avg LR: 6.461e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 87 [ 300/625 ( 48%)]  Loss: 0.003825 (0.00468)  Time: 0.699s, 2929.34/s  (0.712s, 2874.80/s)  avg LR: 6.461e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 87 [ 350/625 ( 56%)]  Loss: 0.004687 (0.00468)  Time: 0.701s, 2920.88/s  (0.711s, 2881.06/s)  avg LR: 6.461e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 87 [ 400/625 ( 64%)]  Loss: 0.003998 (0.00460)  Time: 0.702s, 2917.76/s  (0.710s, 2885.79/s)  avg LR: 6.461e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 87 [ 450/625 ( 72%)]  Loss: 0.003784 (0.00452)  Time: 0.702s, 2917.26/s  (0.709s, 2889.46/s)  avg LR: 6.461e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 87 [ 500/625 ( 80%)]  Loss: 0.004433 (0.00451)  Time: 0.700s, 2924.94/s  (0.708s, 2892.25/s)  avg LR: 6.461e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 87 [ 550/625 ( 88%)]  Loss: 0.003996 (0.00447)  Time: 0.700s, 2923.97/s  (0.708s, 2894.61/s)  avg LR: 6.461e-03  iter ratio: 0.0000  Data: 0.029 (0.034)
INFO:Train: 87 [ 600/625 ( 96%)]  Loss: 0.004662 (0.00448)  Time: 0.701s, 2922.07/s  (0.707s, 2896.65/s)  avg LR: 6.461e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 87 [ 624/625 (100%)]  Loss: 0.004345 (0.00447)  Time: 0.672s, 3047.67/s  (0.707s, 2897.98/s)  avg LR: 6.461e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.399 (4.399)  Loss:  1.2578 (1.2578)  Acc@1: 71.6797 (71.6797)  Acc@5: 90.2344 (90.2344)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.1934 (1.7576)  Acc@1: 74.0566 (61.5180)  Acc@5: 90.5660 (84.2620)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-86.pth.tar', 61.753999938964846)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-87.pth.tar', 61.51799997802734)

INFO:87-epoch: remaining time 28.26 h
INFO:Train: 88 [   0/625 (  0%)]  Loss: 0.004912 (0.00491)  Time: 4.472s,  457.92/s  (4.472s,  457.92/s)  avg LR: 6.428e-03  iter ratio: 0.0000  Data: 3.562 (3.562)
INFO:Train: 88 [  50/625 (  8%)]  Loss: 0.004520 (0.00472)  Time: 0.701s, 2919.92/s  (0.776s, 2640.04/s)  avg LR: 6.428e-03  iter ratio: 0.0000  Data: 0.029 (0.097)
INFO:Train: 88 [ 100/625 ( 16%)]  Loss: 0.004801 (0.00474)  Time: 0.700s, 2925.15/s  (0.739s, 2771.82/s)  avg LR: 6.428e-03  iter ratio: 0.0000  Data: 0.027 (0.063)
INFO:Train: 88 [ 150/625 ( 24%)]  Loss: 0.004753 (0.00475)  Time: 0.701s, 2922.63/s  (0.726s, 2819.18/s)  avg LR: 6.428e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 88 [ 200/625 ( 32%)]  Loss: 0.004405 (0.00468)  Time: 0.700s, 2925.44/s  (0.720s, 2842.63/s)  avg LR: 6.428e-03  iter ratio: 0.0000  Data: 0.025 (0.045)
INFO:Train: 88 [ 250/625 ( 40%)]  Loss: 0.004907 (0.00472)  Time: 0.702s, 2918.27/s  (0.717s, 2856.74/s)  avg LR: 6.428e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 88 [ 300/625 ( 48%)]  Loss: 0.003578 (0.00455)  Time: 0.701s, 2920.75/s  (0.715s, 2866.30/s)  avg LR: 6.428e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 88 [ 350/625 ( 56%)]  Loss: 0.004552 (0.00455)  Time: 0.702s, 2915.70/s  (0.713s, 2873.16/s)  avg LR: 6.428e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 88 [ 400/625 ( 64%)]  Loss: 0.004375 (0.00453)  Time: 0.700s, 2925.41/s  (0.712s, 2878.24/s)  avg LR: 6.428e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 88 [ 450/625 ( 72%)]  Loss: 0.003816 (0.00446)  Time: 0.701s, 2922.26/s  (0.711s, 2882.24/s)  avg LR: 6.428e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 88 [ 500/625 ( 80%)]  Loss: 0.005162 (0.00453)  Time: 0.701s, 2923.08/s  (0.710s, 2885.48/s)  avg LR: 6.428e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 88 [ 550/625 ( 88%)]  Loss: 0.003834 (0.00447)  Time: 0.700s, 2924.98/s  (0.709s, 2888.16/s)  avg LR: 6.428e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 88 [ 600/625 ( 96%)]  Loss: 0.004348 (0.00446)  Time: 0.701s, 2922.99/s  (0.709s, 2890.42/s)  avg LR: 6.428e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 88 [ 624/625 (100%)]  Loss: 0.004647 (0.00447)  Time: 0.673s, 3043.39/s  (0.708s, 2891.86/s)  avg LR: 6.428e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.319 (4.319)  Loss:  1.3945 (1.3945)  Acc@1: 68.9453 (68.9453)  Acc@5: 87.5000 (87.5000)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  1.1816 (1.7782)  Acc@1: 75.2359 (60.2380)  Acc@5: 88.3255 (83.3800)
INFO:88-epoch: remaining time 28.18 h
INFO:Train: 89 [   0/625 (  0%)]  Loss: 0.004023 (0.00402)  Time: 4.177s,  490.27/s  (4.177s,  490.27/s)  avg LR: 6.395e-03  iter ratio: 0.0000  Data: 3.488 (3.488)
INFO:Train: 89 [  50/625 (  8%)]  Loss: 0.004798 (0.00441)  Time: 0.701s, 2921.49/s  (0.770s, 2660.77/s)  avg LR: 6.395e-03  iter ratio: 0.0000  Data: 0.028 (0.095)
INFO:Train: 89 [ 100/625 ( 16%)]  Loss: 0.004912 (0.00458)  Time: 0.701s, 2920.50/s  (0.736s, 2782.69/s)  avg LR: 6.395e-03  iter ratio: 0.0000  Data: 0.028 (0.061)
INFO:Train: 89 [ 150/625 ( 24%)]  Loss: 0.004215 (0.00449)  Time: 0.701s, 2920.40/s  (0.725s, 2826.21/s)  avg LR: 6.395e-03  iter ratio: 0.0000  Data: 0.030 (0.050)
INFO:Train: 89 [ 200/625 ( 32%)]  Loss: 0.004356 (0.00446)  Time: 0.702s, 2917.92/s  (0.719s, 2849.15/s)  avg LR: 6.395e-03  iter ratio: 0.0000  Data: 0.030 (0.044)
INFO:Train: 89 [ 250/625 ( 40%)]  Loss: 0.004635 (0.00449)  Time: 0.700s, 2923.98/s  (0.715s, 2863.25/s)  avg LR: 6.395e-03  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 89 [ 300/625 ( 48%)]  Loss: 0.004363 (0.00447)  Time: 0.700s, 2926.14/s  (0.713s, 2872.65/s)  avg LR: 6.395e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 89 [ 350/625 ( 56%)]  Loss: 0.003820 (0.00439)  Time: 0.701s, 2920.27/s  (0.711s, 2879.22/s)  avg LR: 6.395e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 89 [ 400/625 ( 64%)]  Loss: 0.004792 (0.00443)  Time: 0.700s, 2924.23/s  (0.710s, 2884.32/s)  avg LR: 6.395e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 89 [ 450/625 ( 72%)]  Loss: 0.004799 (0.00447)  Time: 0.700s, 2926.18/s  (0.709s, 2888.18/s)  avg LR: 6.395e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 89 [ 500/625 ( 80%)]  Loss: 0.005253 (0.00454)  Time: 0.701s, 2920.32/s  (0.708s, 2891.32/s)  avg LR: 6.395e-03  iter ratio: 0.0000  Data: 0.029 (0.034)
INFO:Train: 89 [ 550/625 ( 88%)]  Loss: 0.004249 (0.00452)  Time: 0.701s, 2921.15/s  (0.708s, 2893.91/s)  avg LR: 6.395e-03  iter ratio: 0.0000  Data: 0.029 (0.033)
INFO:Train: 89 [ 600/625 ( 96%)]  Loss: 0.004625 (0.00453)  Time: 0.700s, 2924.02/s  (0.707s, 2896.13/s)  avg LR: 6.395e-03  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 89 [ 624/625 (100%)]  Loss: 0.004547 (0.00453)  Time: 0.672s, 3047.36/s  (0.707s, 2897.53/s)  avg LR: 6.395e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.378 (4.378)  Loss:  1.3057 (1.3057)  Acc@1: 69.9219 (69.9219)  Acc@5: 89.9902 (89.9902)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  1.1738 (1.8376)  Acc@1: 73.3491 (59.5880)  Acc@5: 90.9198 (83.0200)
INFO:89-epoch: remaining time 28.00 h
INFO:Train: 90 [   0/625 (  0%)]  Loss: 0.004431 (0.00443)  Time: 4.461s,  459.13/s  (4.461s,  459.13/s)  avg LR: 6.361e-03  iter ratio: 0.0000  Data: 3.532 (3.532)
INFO:Train: 90 [  50/625 (  8%)]  Loss: 0.004458 (0.00444)  Time: 0.701s, 2923.21/s  (0.776s, 2637.52/s)  avg LR: 6.361e-03  iter ratio: 0.0000  Data: 0.026 (0.096)
INFO:Train: 90 [ 100/625 ( 16%)]  Loss: 0.005254 (0.00471)  Time: 0.703s, 2915.21/s  (0.740s, 2768.07/s)  avg LR: 6.361e-03  iter ratio: 0.0000  Data: 0.028 (0.062)
INFO:Train: 90 [ 150/625 ( 24%)]  Loss: 0.003738 (0.00447)  Time: 0.703s, 2915.19/s  (0.727s, 2815.60/s)  avg LR: 6.361e-03  iter ratio: 0.0000  Data: 0.026 (0.051)
INFO:Train: 90 [ 200/625 ( 32%)]  Loss: 0.004381 (0.00445)  Time: 0.700s, 2924.14/s  (0.721s, 2840.04/s)  avg LR: 6.361e-03  iter ratio: 0.0000  Data: 0.026 (0.045)
INFO:Train: 90 [ 250/625 ( 40%)]  Loss: 0.004993 (0.00454)  Time: 0.703s, 2911.77/s  (0.717s, 2855.27/s)  avg LR: 6.361e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 90 [ 300/625 ( 48%)]  Loss: 0.004861 (0.00459)  Time: 0.703s, 2913.05/s  (0.715s, 2864.83/s)  avg LR: 6.361e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 90 [ 350/625 ( 56%)]  Loss: 0.004275 (0.00455)  Time: 0.701s, 2923.02/s  (0.713s, 2871.93/s)  avg LR: 6.361e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 90 [ 400/625 ( 64%)]  Loss: 0.004901 (0.00459)  Time: 0.703s, 2913.81/s  (0.712s, 2877.28/s)  avg LR: 6.361e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 90 [ 450/625 ( 72%)]  Loss: 0.004903 (0.00462)  Time: 0.701s, 2919.47/s  (0.711s, 2881.40/s)  avg LR: 6.361e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 90 [ 500/625 ( 80%)]  Loss: 0.004750 (0.00463)  Time: 0.701s, 2919.53/s  (0.710s, 2884.73/s)  avg LR: 6.361e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 90 [ 550/625 ( 88%)]  Loss: 0.004640 (0.00463)  Time: 0.702s, 2917.42/s  (0.709s, 2887.54/s)  avg LR: 6.361e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 90 [ 600/625 ( 96%)]  Loss: 0.003879 (0.00457)  Time: 0.704s, 2910.36/s  (0.709s, 2889.83/s)  avg LR: 6.361e-03  iter ratio: 0.0000  Data: 0.029 (0.033)
INFO:Train: 90 [ 624/625 (100%)]  Loss: 0.004066 (0.00454)  Time: 0.672s, 3047.54/s  (0.708s, 2891.41/s)  avg LR: 6.361e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.325 (4.325)  Loss:  1.4199 (1.4199)  Acc@1: 68.4082 (68.4082)  Acc@5: 87.9883 (87.9883)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  1.0723 (1.7542)  Acc@1: 75.9434 (61.2420)  Acc@5: 91.8632 (84.0020)
INFO:90-epoch: remaining time 27.94 h
INFO:Train: 91 [   0/625 (  0%)]  Loss: 0.004321 (0.00432)  Time: 4.103s,  499.15/s  (4.103s,  499.15/s)  avg LR: 6.328e-03  iter ratio: 0.0000  Data: 3.403 (3.403)
INFO:Train: 91 [  50/625 (  8%)]  Loss: 0.004697 (0.00451)  Time: 0.702s, 2917.71/s  (0.770s, 2658.15/s)  avg LR: 6.328e-03  iter ratio: 0.0000  Data: 0.029 (0.091)
INFO:Train: 91 [ 100/625 ( 16%)]  Loss: 0.004752 (0.00459)  Time: 0.702s, 2918.87/s  (0.736s, 2780.86/s)  avg LR: 6.328e-03  iter ratio: 0.0000  Data: 0.029 (0.060)
INFO:Train: 91 [ 150/625 ( 24%)]  Loss: 0.004600 (0.00459)  Time: 0.704s, 2908.50/s  (0.725s, 2824.68/s)  avg LR: 6.328e-03  iter ratio: 0.0000  Data: 0.032 (0.050)
INFO:Train: 91 [ 200/625 ( 32%)]  Loss: 0.004796 (0.00463)  Time: 0.704s, 2910.55/s  (0.719s, 2847.12/s)  avg LR: 6.328e-03  iter ratio: 0.0000  Data: 0.028 (0.044)
INFO:Train: 91 [ 250/625 ( 40%)]  Loss: 0.004729 (0.00465)  Time: 0.702s, 2915.64/s  (0.716s, 2860.64/s)  avg LR: 6.328e-03  iter ratio: 0.0000  Data: 0.030 (0.041)
INFO:Train: 91 [ 300/625 ( 48%)]  Loss: 0.004242 (0.00459)  Time: 0.702s, 2918.54/s  (0.714s, 2869.95/s)  avg LR: 6.328e-03  iter ratio: 0.0000  Data: 0.029 (0.039)
INFO:Train: 91 [ 350/625 ( 56%)]  Loss: 0.004509 (0.00458)  Time: 0.701s, 2923.15/s  (0.712s, 2876.57/s)  avg LR: 6.328e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 91 [ 400/625 ( 64%)]  Loss: 0.003661 (0.00448)  Time: 0.702s, 2916.74/s  (0.711s, 2881.45/s)  avg LR: 6.328e-03  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 91 [ 450/625 ( 72%)]  Loss: 0.003581 (0.00439)  Time: 0.703s, 2914.07/s  (0.710s, 2885.25/s)  avg LR: 6.328e-03  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 91 [ 500/625 ( 80%)]  Loss: 0.004932 (0.00444)  Time: 0.704s, 2910.91/s  (0.709s, 2888.44/s)  avg LR: 6.328e-03  iter ratio: 0.0000  Data: 0.030 (0.035)
INFO:Train: 91 [ 550/625 ( 88%)]  Loss: 0.004349 (0.00443)  Time: 0.702s, 2918.17/s  (0.708s, 2891.09/s)  avg LR: 6.328e-03  iter ratio: 0.0000  Data: 0.030 (0.034)
INFO:Train: 91 [ 600/625 ( 96%)]  Loss: 0.004479 (0.00443)  Time: 0.702s, 2917.56/s  (0.708s, 2893.26/s)  avg LR: 6.328e-03  iter ratio: 0.0000  Data: 0.030 (0.034)
INFO:Train: 91 [ 624/625 (100%)]  Loss: 0.004727 (0.00446)  Time: 0.674s, 3038.64/s  (0.708s, 2894.63/s)  avg LR: 6.328e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.321 (4.321)  Loss:  1.3896 (1.3896)  Acc@1: 70.8984 (70.8984)  Acc@5: 88.5742 (88.5742)
INFO:Test: [  24/24]  Time: 0.080 (0.494)  Loss:  1.0732 (1.8418)  Acc@1: 77.5943 (59.6220)  Acc@5: 89.9764 (82.5880)
INFO:91-epoch: remaining time 27.77 h
INFO:Train: 92 [   0/625 (  0%)]  Loss: 0.004545 (0.00454)  Time: 4.674s,  438.20/s  (4.674s,  438.20/s)  avg LR: 6.294e-03  iter ratio: 0.0000  Data: 3.732 (3.732)
INFO:Train: 92 [  50/625 (  8%)]  Loss: 0.004760 (0.00465)  Time: 0.700s, 2924.20/s  (0.780s, 2625.27/s)  avg LR: 6.294e-03  iter ratio: 0.0000  Data: 0.027 (0.101)
INFO:Train: 92 [ 100/625 ( 16%)]  Loss: 0.003987 (0.00443)  Time: 0.701s, 2923.02/s  (0.741s, 2764.46/s)  avg LR: 6.294e-03  iter ratio: 0.0000  Data: 0.028 (0.064)
INFO:Train: 92 [ 150/625 ( 24%)]  Loss: 0.004078 (0.00434)  Time: 0.702s, 2918.36/s  (0.728s, 2814.82/s)  avg LR: 6.294e-03  iter ratio: 0.0000  Data: 0.028 (0.052)
INFO:Train: 92 [ 200/625 ( 32%)]  Loss: 0.004665 (0.00441)  Time: 0.701s, 2921.43/s  (0.721s, 2840.36/s)  avg LR: 6.294e-03  iter ratio: 0.0000  Data: 0.027 (0.046)
INFO:Train: 92 [ 250/625 ( 40%)]  Loss: 0.004883 (0.00449)  Time: 0.702s, 2919.00/s  (0.717s, 2856.24/s)  avg LR: 6.294e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 92 [ 300/625 ( 48%)]  Loss: 0.004218 (0.00445)  Time: 0.703s, 2911.87/s  (0.714s, 2866.84/s)  avg LR: 6.294e-03  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 92 [ 350/625 ( 56%)]  Loss: 0.004056 (0.00440)  Time: 0.702s, 2916.03/s  (0.712s, 2874.51/s)  avg LR: 6.294e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 92 [ 400/625 ( 64%)]  Loss: 0.004955 (0.00446)  Time: 0.701s, 2919.55/s  (0.711s, 2880.18/s)  avg LR: 6.294e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 92 [ 450/625 ( 72%)]  Loss: 0.004833 (0.00450)  Time: 0.703s, 2911.81/s  (0.710s, 2884.49/s)  avg LR: 6.294e-03  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 92 [ 500/625 ( 80%)]  Loss: 0.004771 (0.00452)  Time: 0.701s, 2921.04/s  (0.709s, 2888.14/s)  avg LR: 6.294e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 92 [ 550/625 ( 88%)]  Loss: 0.004508 (0.00452)  Time: 0.702s, 2915.76/s  (0.708s, 2891.00/s)  avg LR: 6.294e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 92 [ 600/625 ( 96%)]  Loss: 0.004612 (0.00453)  Time: 0.701s, 2920.88/s  (0.708s, 2893.28/s)  avg LR: 6.294e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 92 [ 624/625 (100%)]  Loss: 0.003958 (0.00449)  Time: 0.672s, 3048.34/s  (0.707s, 2894.81/s)  avg LR: 6.294e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.343 (4.343)  Loss:  1.1738 (1.1738)  Acc@1: 72.9492 (72.9492)  Acc@5: 90.5762 (90.5762)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  0.9658 (1.6867)  Acc@1: 78.4198 (62.4820)  Acc@5: 92.6887 (84.8260)
ERROR:Exception '[Errno 2] No such file or directory: './exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-87.pth.tar'' while deleting checkpoint
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-92.pth.tar', 62.48200006347656)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-86.pth.tar', 61.753999938964846)

INFO:92-epoch: remaining time 27.68 h
INFO:Train: 93 [   0/625 (  0%)]  Loss: 0.004798 (0.00480)  Time: 4.202s,  487.40/s  (4.202s,  487.40/s)  avg LR: 6.259e-03  iter ratio: 0.0000  Data: 3.508 (3.508)
INFO:Train: 93 [  50/625 (  8%)]  Loss: 0.004033 (0.00442)  Time: 0.700s, 2925.55/s  (0.770s, 2659.01/s)  avg LR: 6.259e-03  iter ratio: 0.0000  Data: 0.027 (0.095)
INFO:Train: 93 [ 100/625 ( 16%)]  Loss: 0.004567 (0.00447)  Time: 0.700s, 2927.64/s  (0.736s, 2782.49/s)  avg LR: 6.259e-03  iter ratio: 0.0000  Data: 0.027 (0.062)
INFO:Train: 93 [ 150/625 ( 24%)]  Loss: 0.004524 (0.00448)  Time: 0.700s, 2924.60/s  (0.724s, 2827.35/s)  avg LR: 6.259e-03  iter ratio: 0.0000  Data: 0.026 (0.050)
INFO:Train: 93 [ 200/625 ( 32%)]  Loss: 0.004754 (0.00454)  Time: 0.700s, 2925.97/s  (0.718s, 2850.60/s)  avg LR: 6.259e-03  iter ratio: 0.0000  Data: 0.027 (0.044)
INFO:Train: 93 [ 250/625 ( 40%)]  Loss: 0.004916 (0.00460)  Time: 0.700s, 2923.82/s  (0.715s, 2864.45/s)  avg LR: 6.259e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 93 [ 300/625 ( 48%)]  Loss: 0.004011 (0.00451)  Time: 0.700s, 2923.96/s  (0.713s, 2873.92/s)  avg LR: 6.259e-03  iter ratio: 0.0000  Data: 0.029 (0.039)
INFO:Train: 93 [ 350/625 ( 56%)]  Loss: 0.004567 (0.00452)  Time: 0.700s, 2925.88/s  (0.711s, 2880.67/s)  avg LR: 6.259e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 93 [ 400/625 ( 64%)]  Loss: 0.004795 (0.00455)  Time: 0.699s, 2930.13/s  (0.710s, 2885.73/s)  avg LR: 6.259e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 93 [ 450/625 ( 72%)]  Loss: 0.004812 (0.00458)  Time: 0.701s, 2922.52/s  (0.709s, 2890.31/s)  avg LR: 6.259e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 93 [ 500/625 ( 80%)]  Loss: 0.003956 (0.00452)  Time: 0.700s, 2925.91/s  (0.708s, 2893.46/s)  avg LR: 6.259e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 93 [ 550/625 ( 88%)]  Loss: 0.004377 (0.00451)  Time: 0.705s, 2906.51/s  (0.707s, 2896.05/s)  avg LR: 6.259e-03  iter ratio: 0.0000  Data: 0.032 (0.033)
INFO:Train: 93 [ 600/625 ( 96%)]  Loss: 0.004327 (0.00450)  Time: 0.700s, 2925.46/s  (0.707s, 2898.24/s)  avg LR: 6.259e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 93 [ 624/625 (100%)]  Loss: 0.004141 (0.00447)  Time: 0.671s, 3050.25/s  (0.706s, 2899.66/s)  avg LR: 6.259e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.397 (4.397)  Loss:  1.2520 (1.2520)  Acc@1: 71.9727 (71.9727)  Acc@5: 90.4785 (90.4785)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.0010 (1.7957)  Acc@1: 77.5943 (60.5300)  Acc@5: 91.6274 (83.5920)
INFO:93-epoch: remaining time 27.46 h
INFO:Train: 94 [   0/625 (  0%)]  Loss: 0.004547 (0.00455)  Time: 4.774s,  429.00/s  (4.774s,  429.00/s)  avg LR: 6.225e-03  iter ratio: 0.0000  Data: 3.855 (3.855)
INFO:Train: 94 [  50/625 (  8%)]  Loss: 0.004601 (0.00457)  Time: 0.700s, 2923.76/s  (0.782s, 2619.98/s)  avg LR: 6.225e-03  iter ratio: 0.0000  Data: 0.027 (0.103)
INFO:Train: 94 [ 100/625 ( 16%)]  Loss: 0.004404 (0.00452)  Time: 0.702s, 2915.32/s  (0.742s, 2761.45/s)  avg LR: 6.225e-03  iter ratio: 0.0000  Data: 0.025 (0.065)
INFO:Train: 94 [ 150/625 ( 24%)]  Loss: 0.004351 (0.00448)  Time: 0.703s, 2914.43/s  (0.728s, 2812.59/s)  avg LR: 6.225e-03  iter ratio: 0.0000  Data: 0.027 (0.052)
INFO:Train: 94 [ 200/625 ( 32%)]  Loss: 0.003791 (0.00434)  Time: 0.700s, 2927.56/s  (0.721s, 2839.07/s)  avg LR: 6.225e-03  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 94 [ 250/625 ( 40%)]  Loss: 0.004048 (0.00429)  Time: 0.699s, 2928.74/s  (0.717s, 2855.05/s)  avg LR: 6.225e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 94 [ 300/625 ( 48%)]  Loss: 0.004365 (0.00430)  Time: 0.700s, 2926.86/s  (0.715s, 2865.93/s)  avg LR: 6.225e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 94 [ 350/625 ( 56%)]  Loss: 0.004899 (0.00438)  Time: 0.700s, 2927.55/s  (0.713s, 2873.68/s)  avg LR: 6.225e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 94 [ 400/625 ( 64%)]  Loss: 0.004738 (0.00442)  Time: 0.701s, 2920.53/s  (0.711s, 2879.44/s)  avg LR: 6.225e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 94 [ 450/625 ( 72%)]  Loss: 0.004833 (0.00446)  Time: 0.700s, 2926.68/s  (0.710s, 2883.89/s)  avg LR: 6.225e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 94 [ 500/625 ( 80%)]  Loss: 0.005137 (0.00452)  Time: 0.698s, 2932.17/s  (0.709s, 2887.48/s)  avg LR: 6.225e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 94 [ 550/625 ( 88%)]  Loss: 0.004243 (0.00450)  Time: 0.700s, 2926.55/s  (0.709s, 2890.49/s)  avg LR: 6.225e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 94 [ 600/625 ( 96%)]  Loss: 0.004440 (0.00449)  Time: 0.699s, 2930.04/s  (0.708s, 2893.05/s)  avg LR: 6.225e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 94 [ 624/625 (100%)]  Loss: 0.004496 (0.00449)  Time: 0.672s, 3048.75/s  (0.708s, 2894.61/s)  avg LR: 6.225e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.292 (4.292)  Loss:  1.3115 (1.3115)  Acc@1: 71.7773 (71.7773)  Acc@5: 88.5254 (88.5254)
INFO:Test: [  24/24]  Time: 0.079 (0.493)  Loss:  1.1270 (1.8108)  Acc@1: 74.7642 (59.7580)  Acc@5: 89.9764 (83.0240)
INFO:94-epoch: remaining time 27.43 h
INFO:Train: 95 [   0/625 (  0%)]  Loss: 0.004883 (0.00488)  Time: 4.539s,  451.17/s  (4.539s,  451.17/s)  avg LR: 6.190e-03  iter ratio: 0.0000  Data: 3.842 (3.842)
INFO:Train: 95 [  50/625 (  8%)]  Loss: 0.004302 (0.00459)  Time: 0.701s, 2923.55/s  (0.776s, 2639.39/s)  avg LR: 6.190e-03  iter ratio: 0.0000  Data: 0.029 (0.103)
INFO:Train: 95 [ 100/625 ( 16%)]  Loss: 0.004391 (0.00453)  Time: 0.701s, 2919.49/s  (0.739s, 2771.23/s)  avg LR: 6.190e-03  iter ratio: 0.0000  Data: 0.029 (0.066)
INFO:Train: 95 [ 150/625 ( 24%)]  Loss: 0.003932 (0.00438)  Time: 0.702s, 2915.35/s  (0.726s, 2819.53/s)  avg LR: 6.190e-03  iter ratio: 0.0000  Data: 0.030 (0.054)
INFO:Train: 95 [ 200/625 ( 32%)]  Loss: 0.004817 (0.00447)  Time: 0.701s, 2921.78/s  (0.720s, 2843.72/s)  avg LR: 6.190e-03  iter ratio: 0.0000  Data: 0.029 (0.047)
INFO:Train: 95 [ 250/625 ( 40%)]  Loss: 0.004418 (0.00446)  Time: 0.702s, 2918.68/s  (0.716s, 2859.12/s)  avg LR: 6.190e-03  iter ratio: 0.0000  Data: 0.030 (0.043)
INFO:Train: 95 [ 300/625 ( 48%)]  Loss: 0.004350 (0.00444)  Time: 0.703s, 2914.72/s  (0.714s, 2869.39/s)  avg LR: 6.190e-03  iter ratio: 0.0000  Data: 0.022 (0.041)
INFO:Train: 95 [ 350/625 ( 56%)]  Loss: 0.005394 (0.00456)  Time: 0.701s, 2920.47/s  (0.712s, 2876.89/s)  avg LR: 6.190e-03  iter ratio: 0.0000  Data: 0.029 (0.039)
INFO:Train: 95 [ 400/625 ( 64%)]  Loss: 0.004620 (0.00457)  Time: 0.702s, 2918.77/s  (0.710s, 2882.77/s)  avg LR: 6.190e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 95 [ 450/625 ( 72%)]  Loss: 0.005093 (0.00462)  Time: 0.702s, 2916.22/s  (0.709s, 2887.32/s)  avg LR: 6.190e-03  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 95 [ 500/625 ( 80%)]  Loss: 0.004627 (0.00462)  Time: 0.701s, 2921.66/s  (0.708s, 2890.90/s)  avg LR: 6.190e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 95 [ 550/625 ( 88%)]  Loss: 0.004295 (0.00459)  Time: 0.701s, 2921.62/s  (0.708s, 2893.73/s)  avg LR: 6.190e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 95 [ 600/625 ( 96%)]  Loss: 0.004463 (0.00458)  Time: 0.700s, 2926.09/s  (0.707s, 2896.30/s)  avg LR: 6.190e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 95 [ 624/625 (100%)]  Loss: 0.004865 (0.00460)  Time: 0.672s, 3049.67/s  (0.707s, 2897.85/s)  avg LR: 6.190e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.341 (4.341)  Loss:  1.2900 (1.2900)  Acc@1: 70.9473 (70.9473)  Acc@5: 89.5508 (89.5508)
INFO:Test: [  24/24]  Time: 0.080 (0.494)  Loss:  0.9795 (1.8106)  Acc@1: 77.9481 (60.4500)  Acc@5: 91.9811 (83.3700)
INFO:95-epoch: remaining time 27.22 h
INFO:Train: 96 [   0/625 (  0%)]  Loss: 0.004092 (0.00409)  Time: 4.232s,  483.90/s  (4.232s,  483.90/s)  avg LR: 6.155e-03  iter ratio: 0.0000  Data: 3.330 (3.330)
INFO:Train: 96 [  50/625 (  8%)]  Loss: 0.005070 (0.00458)  Time: 0.700s, 2925.39/s  (0.771s, 2654.78/s)  avg LR: 6.155e-03  iter ratio: 0.0000  Data: 0.027 (0.092)
INFO:Train: 96 [ 100/625 ( 16%)]  Loss: 0.004402 (0.00452)  Time: 0.701s, 2922.15/s  (0.737s, 2780.22/s)  avg LR: 6.155e-03  iter ratio: 0.0000  Data: 0.029 (0.060)
INFO:Train: 96 [ 150/625 ( 24%)]  Loss: 0.004686 (0.00456)  Time: 0.700s, 2927.45/s  (0.725s, 2825.60/s)  avg LR: 6.155e-03  iter ratio: 0.0000  Data: 0.028 (0.049)
INFO:Train: 96 [ 200/625 ( 32%)]  Loss: 0.003825 (0.00441)  Time: 0.700s, 2923.96/s  (0.719s, 2849.14/s)  avg LR: 6.155e-03  iter ratio: 0.0000  Data: 0.028 (0.044)
INFO:Train: 96 [ 250/625 ( 40%)]  Loss: 0.003534 (0.00427)  Time: 0.701s, 2921.60/s  (0.715s, 2863.65/s)  avg LR: 6.155e-03  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 96 [ 300/625 ( 48%)]  Loss: 0.004461 (0.00430)  Time: 0.702s, 2917.29/s  (0.713s, 2873.20/s)  avg LR: 6.155e-03  iter ratio: 0.0000  Data: 0.030 (0.038)
INFO:Train: 96 [ 350/625 ( 56%)]  Loss: 0.004470 (0.00432)  Time: 0.700s, 2925.58/s  (0.711s, 2879.95/s)  avg LR: 6.155e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 96 [ 400/625 ( 64%)]  Loss: 0.004908 (0.00438)  Time: 0.699s, 2928.82/s  (0.710s, 2885.18/s)  avg LR: 6.155e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 96 [ 450/625 ( 72%)]  Loss: 0.004476 (0.00439)  Time: 0.702s, 2917.42/s  (0.709s, 2889.18/s)  avg LR: 6.155e-03  iter ratio: 0.0000  Data: 0.030 (0.035)
INFO:Train: 96 [ 500/625 ( 80%)]  Loss: 0.005031 (0.00445)  Time: 0.701s, 2922.15/s  (0.708s, 2892.51/s)  avg LR: 6.155e-03  iter ratio: 0.0000  Data: 0.029 (0.034)
INFO:Train: 96 [ 550/625 ( 88%)]  Loss: 0.004389 (0.00445)  Time: 0.701s, 2922.88/s  (0.707s, 2895.12/s)  avg LR: 6.155e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 96 [ 600/625 ( 96%)]  Loss: 0.004163 (0.00442)  Time: 0.700s, 2927.51/s  (0.707s, 2897.29/s)  avg LR: 6.155e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 96 [ 624/625 (100%)]  Loss: 0.003698 (0.00437)  Time: 0.671s, 3052.97/s  (0.707s, 2898.74/s)  avg LR: 6.155e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.304 (4.304)  Loss:  1.1660 (1.1660)  Acc@1: 73.3887 (73.3887)  Acc@5: 91.4551 (91.4551)
INFO:Test: [  24/24]  Time: 0.079 (0.494)  Loss:  0.9775 (1.6557)  Acc@1: 79.0094 (63.1440)  Acc@5: 92.3349 (85.5080)
ERROR:Exception '[Errno 2] No such file or directory: './exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-86.pth.tar'' while deleting checkpoint
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-96.pth.tar', 63.14399993164062)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-92.pth.tar', 62.48200006347656)

INFO:96-epoch: remaining time 27.10 h
INFO:Train: 97 [   0/625 (  0%)]  Loss: 0.004002 (0.00400)  Time: 4.195s,  488.16/s  (4.195s,  488.16/s)  avg LR: 6.120e-03  iter ratio: 0.0000  Data: 3.514 (3.514)
INFO:Train: 97 [  50/625 (  8%)]  Loss: 0.004475 (0.00424)  Time: 0.703s, 2914.61/s  (0.771s, 2657.95/s)  avg LR: 6.120e-03  iter ratio: 0.0000  Data: 0.029 (0.097)
INFO:Train: 97 [ 100/625 ( 16%)]  Loss: 0.004734 (0.00440)  Time: 0.701s, 2921.95/s  (0.736s, 2781.93/s)  avg LR: 6.120e-03  iter ratio: 0.0000  Data: 0.028 (0.063)
INFO:Train: 97 [ 150/625 ( 24%)]  Loss: 0.003917 (0.00428)  Time: 0.700s, 2924.64/s  (0.725s, 2826.74/s)  avg LR: 6.120e-03  iter ratio: 0.0000  Data: 0.028 (0.051)
INFO:Train: 97 [ 200/625 ( 32%)]  Loss: 0.004562 (0.00434)  Time: 0.701s, 2922.83/s  (0.719s, 2849.86/s)  avg LR: 6.120e-03  iter ratio: 0.0000  Data: 0.028 (0.045)
INFO:Train: 97 [ 250/625 ( 40%)]  Loss: 0.004509 (0.00437)  Time: 0.699s, 2928.13/s  (0.715s, 2863.63/s)  avg LR: 6.120e-03  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 97 [ 300/625 ( 48%)]  Loss: 0.004199 (0.00434)  Time: 0.703s, 2913.12/s  (0.713s, 2873.01/s)  avg LR: 6.120e-03  iter ratio: 0.0000  Data: 0.031 (0.039)
INFO:Train: 97 [ 350/625 ( 56%)]  Loss: 0.004519 (0.00436)  Time: 0.701s, 2922.20/s  (0.711s, 2879.79/s)  avg LR: 6.120e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 97 [ 400/625 ( 64%)]  Loss: 0.004338 (0.00436)  Time: 0.700s, 2925.81/s  (0.710s, 2884.92/s)  avg LR: 6.120e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 97 [ 450/625 ( 72%)]  Loss: 0.003993 (0.00432)  Time: 0.700s, 2925.99/s  (0.709s, 2888.79/s)  avg LR: 6.120e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 97 [ 500/625 ( 80%)]  Loss: 0.005104 (0.00440)  Time: 0.700s, 2926.78/s  (0.708s, 2892.00/s)  avg LR: 6.120e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 97 [ 550/625 ( 88%)]  Loss: 0.004369 (0.00439)  Time: 0.701s, 2921.69/s  (0.708s, 2894.52/s)  avg LR: 6.120e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 97 [ 600/625 ( 96%)]  Loss: 0.003973 (0.00436)  Time: 0.701s, 2923.00/s  (0.707s, 2896.69/s)  avg LR: 6.120e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 97 [ 624/625 (100%)]  Loss: 0.004096 (0.00434)  Time: 0.671s, 3053.36/s  (0.707s, 2897.97/s)  avg LR: 6.120e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.351 (4.351)  Loss:  1.2402 (1.2402)  Acc@1: 71.1426 (71.1426)  Acc@5: 89.8926 (89.8926)
INFO:Test: [  24/24]  Time: 0.080 (0.496)  Loss:  1.0479 (1.5965)  Acc@1: 76.2972 (63.5180)  Acc@5: 91.5094 (85.8760)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-97.pth.tar', 63.51800004638672)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-96.pth.tar', 63.14399993164062)

INFO:97-epoch: remaining time 26.98 h
INFO:Train: 98 [   0/625 (  0%)]  Loss: 0.004192 (0.00419)  Time: 4.411s,  464.27/s  (4.411s,  464.27/s)  avg LR: 6.084e-03  iter ratio: 0.0000  Data: 3.496 (3.496)
INFO:Train: 98 [  50/625 (  8%)]  Loss: 0.003639 (0.00392)  Time: 0.699s, 2927.87/s  (0.775s, 2643.58/s)  avg LR: 6.084e-03  iter ratio: 0.0000  Data: 0.027 (0.096)
INFO:Train: 98 [ 100/625 ( 16%)]  Loss: 0.004162 (0.00400)  Time: 0.700s, 2923.77/s  (0.739s, 2772.90/s)  avg LR: 6.084e-03  iter ratio: 0.0000  Data: 0.028 (0.062)
INFO:Train: 98 [ 150/625 ( 24%)]  Loss: 0.004926 (0.00423)  Time: 0.699s, 2928.35/s  (0.726s, 2820.23/s)  avg LR: 6.084e-03  iter ratio: 0.0000  Data: 0.027 (0.050)
INFO:Train: 98 [ 200/625 ( 32%)]  Loss: 0.004124 (0.00421)  Time: 0.701s, 2922.12/s  (0.720s, 2844.05/s)  avg LR: 6.084e-03  iter ratio: 0.0000  Data: 0.027 (0.044)
INFO:Train: 98 [ 250/625 ( 40%)]  Loss: 0.004815 (0.00431)  Time: 0.702s, 2917.85/s  (0.716s, 2858.78/s)  avg LR: 6.084e-03  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 98 [ 300/625 ( 48%)]  Loss: 0.004084 (0.00428)  Time: 0.701s, 2921.01/s  (0.714s, 2868.56/s)  avg LR: 6.084e-03  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 98 [ 350/625 ( 56%)]  Loss: 0.003961 (0.00424)  Time: 0.701s, 2923.48/s  (0.712s, 2875.90/s)  avg LR: 6.084e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 98 [ 400/625 ( 64%)]  Loss: 0.005004 (0.00432)  Time: 0.699s, 2930.89/s  (0.711s, 2881.32/s)  avg LR: 6.084e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 98 [ 450/625 ( 72%)]  Loss: 0.004235 (0.00431)  Time: 0.701s, 2922.82/s  (0.710s, 2885.46/s)  avg LR: 6.084e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 98 [ 500/625 ( 80%)]  Loss: 0.004213 (0.00430)  Time: 0.699s, 2928.46/s  (0.709s, 2888.92/s)  avg LR: 6.084e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 98 [ 550/625 ( 88%)]  Loss: 0.004977 (0.00436)  Time: 0.700s, 2926.46/s  (0.708s, 2891.70/s)  avg LR: 6.084e-03  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 98 [ 600/625 ( 96%)]  Loss: 0.004600 (0.00438)  Time: 0.699s, 2927.82/s  (0.708s, 2894.02/s)  avg LR: 6.084e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 98 [ 624/625 (100%)]  Loss: 0.004900 (0.00442)  Time: 0.671s, 3050.84/s  (0.707s, 2895.54/s)  avg LR: 6.084e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.371 (4.371)  Loss:  1.3740 (1.3740)  Acc@1: 70.8496 (70.8496)  Acc@5: 89.2578 (89.2578)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  1.1719 (1.8138)  Acc@1: 75.9434 (60.6140)  Acc@5: 91.0377 (83.5320)
INFO:98-epoch: remaining time 26.87 h
INFO:Train: 99 [   0/625 (  0%)]  Loss: 0.004034 (0.00403)  Time: 4.380s,  467.61/s  (4.380s,  467.61/s)  avg LR: 6.048e-03  iter ratio: 0.0000  Data: 3.689 (3.689)
INFO:Train: 99 [  50/625 (  8%)]  Loss: 0.004135 (0.00408)  Time: 0.703s, 2915.07/s  (0.775s, 2641.99/s)  avg LR: 6.048e-03  iter ratio: 0.0000  Data: 0.026 (0.096)
INFO:Train: 99 [ 100/625 ( 16%)]  Loss: 0.005008 (0.00439)  Time: 0.703s, 2914.42/s  (0.740s, 2768.48/s)  avg LR: 6.048e-03  iter ratio: 0.0000  Data: 0.025 (0.060)
INFO:Train: 99 [ 150/625 ( 24%)]  Loss: 0.004211 (0.00435)  Time: 0.703s, 2912.59/s  (0.728s, 2814.22/s)  avg LR: 6.048e-03  iter ratio: 0.0000  Data: 0.025 (0.048)
INFO:Train: 99 [ 200/625 ( 32%)]  Loss: 0.004645 (0.00441)  Time: 0.704s, 2909.18/s  (0.722s, 2838.06/s)  avg LR: 6.048e-03  iter ratio: 0.0000  Data: 0.025 (0.042)
INFO:Train: 99 [ 250/625 ( 40%)]  Loss: 0.004480 (0.00442)  Time: 0.704s, 2907.99/s  (0.718s, 2852.32/s)  avg LR: 6.048e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 99 [ 300/625 ( 48%)]  Loss: 0.004674 (0.00446)  Time: 0.703s, 2912.00/s  (0.716s, 2861.81/s)  avg LR: 6.048e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 99 [ 350/625 ( 56%)]  Loss: 0.004023 (0.00440)  Time: 0.704s, 2907.05/s  (0.714s, 2868.85/s)  avg LR: 6.048e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 99 [ 400/625 ( 64%)]  Loss: 0.004234 (0.00438)  Time: 0.703s, 2912.64/s  (0.713s, 2874.11/s)  avg LR: 6.048e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 99 [ 450/625 ( 72%)]  Loss: 0.004769 (0.00442)  Time: 0.702s, 2916.53/s  (0.712s, 2878.30/s)  avg LR: 6.048e-03  iter ratio: 0.0000  Data: 0.026 (0.032)
INFO:Train: 99 [ 500/625 ( 80%)]  Loss: 0.004798 (0.00446)  Time: 0.702s, 2915.33/s  (0.711s, 2881.68/s)  avg LR: 6.048e-03  iter ratio: 0.0000  Data: 0.025 (0.031)
INFO:Train: 99 [ 550/625 ( 88%)]  Loss: 0.004257 (0.00444)  Time: 0.702s, 2915.42/s  (0.710s, 2884.52/s)  avg LR: 6.048e-03  iter ratio: 0.0000  Data: 0.026 (0.030)
INFO:Train: 99 [ 600/625 ( 96%)]  Loss: 0.005098 (0.00449)  Time: 0.703s, 2912.05/s  (0.709s, 2886.89/s)  avg LR: 6.048e-03  iter ratio: 0.0000  Data: 0.025 (0.030)
INFO:Train: 99 [ 624/625 (100%)]  Loss: 0.005059 (0.00453)  Time: 0.672s, 3049.72/s  (0.709s, 2888.40/s)  avg LR: 6.048e-03  iter ratio: 0.0000  Data: 0.000 (0.029)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.329 (4.329)  Loss:  1.1699 (1.1699)  Acc@1: 74.7559 (74.7559)  Acc@5: 90.3320 (90.3320)
INFO:Test: [  24/24]  Time: 0.080 (0.495)  Loss:  0.9746 (1.6155)  Acc@1: 77.8302 (63.4220)  Acc@5: 91.9811 (85.8400)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-97.pth.tar', 63.51800004638672)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-99.pth.tar', 63.42200006591797)

INFO:99-epoch: remaining time 26.82 h
INFO:Train: 100 [   0/625 (  0%)]  Loss: 0.004312 (0.00431)  Time: 4.763s,  429.96/s  (4.763s,  429.96/s)  avg LR: 6.013e-03  iter ratio: 0.0000  Data: 3.833 (3.833)
INFO:Train: 100 [  50/625 (  8%)]  Loss: 0.003991 (0.00415)  Time: 0.699s, 2928.15/s  (0.782s, 2619.92/s)  avg LR: 6.013e-03  iter ratio: 0.0000  Data: 0.027 (0.102)
INFO:Train: 100 [ 100/625 ( 16%)]  Loss: 0.004072 (0.00412)  Time: 0.701s, 2923.35/s  (0.742s, 2760.62/s)  avg LR: 6.013e-03  iter ratio: 0.0000  Data: 0.026 (0.065)
INFO:Train: 100 [ 150/625 ( 24%)]  Loss: 0.004135 (0.00413)  Time: 0.701s, 2923.32/s  (0.728s, 2811.51/s)  avg LR: 6.013e-03  iter ratio: 0.0000  Data: 0.027 (0.053)
INFO:Train: 100 [ 200/625 ( 32%)]  Loss: 0.004811 (0.00426)  Time: 0.700s, 2926.18/s  (0.722s, 2838.16/s)  avg LR: 6.013e-03  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 100 [ 250/625 ( 40%)]  Loss: 0.004719 (0.00434)  Time: 0.700s, 2924.92/s  (0.717s, 2854.40/s)  avg LR: 6.013e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 100 [ 300/625 ( 48%)]  Loss: 0.004572 (0.00437)  Time: 0.700s, 2925.20/s  (0.715s, 2865.23/s)  avg LR: 6.013e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 100 [ 350/625 ( 56%)]  Loss: 0.004727 (0.00442)  Time: 0.700s, 2924.20/s  (0.713s, 2873.49/s)  avg LR: 6.013e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 100 [ 400/625 ( 64%)]  Loss: 0.004658 (0.00444)  Time: 0.703s, 2915.00/s  (0.711s, 2879.24/s)  avg LR: 6.013e-03  iter ratio: 0.0000  Data: 0.029 (0.037)
INFO:Train: 100 [ 450/625 ( 72%)]  Loss: 0.004057 (0.00441)  Time: 0.700s, 2926.24/s  (0.710s, 2883.85/s)  avg LR: 6.013e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 100 [ 500/625 ( 80%)]  Loss: 0.004454 (0.00441)  Time: 0.701s, 2921.63/s  (0.709s, 2887.53/s)  avg LR: 6.013e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 100 [ 550/625 ( 88%)]  Loss: 0.004266 (0.00440)  Time: 0.701s, 2921.79/s  (0.709s, 2890.51/s)  avg LR: 6.013e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 100 [ 600/625 ( 96%)]  Loss: 0.005046 (0.00445)  Time: 0.703s, 2914.68/s  (0.708s, 2892.90/s)  avg LR: 6.013e-03  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 100 [ 624/625 (100%)]  Loss: 0.004361 (0.00444)  Time: 0.671s, 3051.75/s  (0.708s, 2894.48/s)  avg LR: 6.013e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.379 (4.379)  Loss:  1.3828 (1.3828)  Acc@1: 71.0449 (71.0449)  Acc@5: 88.2812 (88.2812)
INFO:Test: [  24/24]  Time: 0.079 (0.495)  Loss:  1.2207 (1.8113)  Acc@1: 74.5283 (60.3140)  Acc@5: 90.4481 (83.3260)
INFO:100-epoch: remaining time 26.63 h
INFO:Train: 101 [   0/625 (  0%)]  Loss: 0.004721 (0.00472)  Time: 4.068s,  503.46/s  (4.068s,  503.46/s)  avg LR: 5.976e-03  iter ratio: 0.0000  Data: 3.387 (3.387)
INFO:Train: 101 [  50/625 (  8%)]  Loss: 0.004228 (0.00447)  Time: 0.704s, 2910.82/s  (0.768s, 2665.19/s)  avg LR: 5.976e-03  iter ratio: 0.0000  Data: 0.025 (0.090)
INFO:Train: 101 [ 100/625 ( 16%)]  Loss: 0.004132 (0.00436)  Time: 0.703s, 2913.24/s  (0.736s, 2783.48/s)  avg LR: 5.976e-03  iter ratio: 0.0000  Data: 0.024 (0.057)
INFO:Train: 101 [ 150/625 ( 24%)]  Loss: 0.003505 (0.00415)  Time: 0.703s, 2911.18/s  (0.725s, 2826.05/s)  avg LR: 5.976e-03  iter ratio: 0.0000  Data: 0.024 (0.046)
INFO:Train: 101 [ 200/625 ( 32%)]  Loss: 0.004460 (0.00421)  Time: 0.706s, 2900.14/s  (0.719s, 2848.07/s)  avg LR: 5.976e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 101 [ 250/625 ( 40%)]  Loss: 0.004049 (0.00418)  Time: 0.702s, 2917.31/s  (0.716s, 2861.57/s)  avg LR: 5.976e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 101 [ 300/625 ( 48%)]  Loss: 0.004632 (0.00425)  Time: 0.703s, 2913.44/s  (0.713s, 2871.22/s)  avg LR: 5.976e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 101 [ 350/625 ( 56%)]  Loss: 0.004383 (0.00426)  Time: 0.704s, 2908.83/s  (0.712s, 2878.12/s)  avg LR: 5.976e-03  iter ratio: 0.0000  Data: 0.029 (0.034)
INFO:Train: 101 [ 400/625 ( 64%)]  Loss: 0.004484 (0.00429)  Time: 0.702s, 2916.58/s  (0.710s, 2883.30/s)  avg LR: 5.976e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 101 [ 450/625 ( 72%)]  Loss: 0.004557 (0.00432)  Time: 0.704s, 2910.94/s  (0.709s, 2887.37/s)  avg LR: 5.976e-03  iter ratio: 0.0000  Data: 0.026 (0.032)
INFO:Train: 101 [ 500/625 ( 80%)]  Loss: 0.004271 (0.00431)  Time: 0.704s, 2909.35/s  (0.708s, 2890.75/s)  avg LR: 5.976e-03  iter ratio: 0.0000  Data: 0.025 (0.032)
INFO:Train: 101 [ 550/625 ( 88%)]  Loss: 0.004599 (0.00434)  Time: 0.702s, 2917.49/s  (0.708s, 2893.35/s)  avg LR: 5.976e-03  iter ratio: 0.0000  Data: 0.027 (0.031)
INFO:Train: 101 [ 600/625 ( 96%)]  Loss: 0.004074 (0.00432)  Time: 0.702s, 2918.83/s  (0.707s, 2895.60/s)  avg LR: 5.976e-03  iter ratio: 0.0000  Data: 0.025 (0.031)
INFO:Train: 101 [ 624/625 (100%)]  Loss: 0.004014 (0.00429)  Time: 0.671s, 3050.74/s  (0.707s, 2896.94/s)  avg LR: 5.976e-03  iter ratio: 0.0000  Data: 0.000 (0.031)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.334 (4.334)  Loss:  1.2002 (1.2002)  Acc@1: 73.8770 (73.8770)  Acc@5: 90.8203 (90.8203)
INFO:Test: [  24/24]  Time: 0.080 (0.497)  Loss:  1.0479 (1.6647)  Acc@1: 77.1226 (62.4640)  Acc@5: 92.3349 (84.9160)
INFO:101-epoch: remaining time 26.54 h
INFO:Train: 102 [   0/625 (  0%)]  Loss: 0.004527 (0.00453)  Time: 4.362s,  469.47/s  (4.362s,  469.47/s)  avg LR: 5.940e-03  iter ratio: 0.0000  Data: 3.460 (3.460)
INFO:Train: 102 [  50/625 (  8%)]  Loss: 0.004845 (0.00469)  Time: 0.700s, 2927.76/s  (0.773s, 2650.19/s)  avg LR: 5.940e-03  iter ratio: 0.0000  Data: 0.027 (0.096)
INFO:Train: 102 [ 100/625 ( 16%)]  Loss: 0.003773 (0.00438)  Time: 0.700s, 2926.91/s  (0.737s, 2779.15/s)  avg LR: 5.940e-03  iter ratio: 0.0000  Data: 0.027 (0.062)
INFO:Train: 102 [ 150/625 ( 24%)]  Loss: 0.004720 (0.00447)  Time: 0.707s, 2898.02/s  (0.725s, 2825.31/s)  avg LR: 5.940e-03  iter ratio: 0.0000  Data: 0.025 (0.051)
INFO:Train: 102 [ 200/625 ( 32%)]  Loss: 0.003678 (0.00431)  Time: 0.699s, 2928.53/s  (0.719s, 2848.27/s)  avg LR: 5.940e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 102 [ 250/625 ( 40%)]  Loss: 0.004776 (0.00439)  Time: 0.701s, 2921.19/s  (0.716s, 2862.14/s)  avg LR: 5.940e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 102 [ 300/625 ( 48%)]  Loss: 0.004305 (0.00437)  Time: 0.703s, 2912.84/s  (0.713s, 2871.49/s)  avg LR: 5.940e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 102 [ 350/625 ( 56%)]  Loss: 0.004181 (0.00435)  Time: 0.701s, 2920.88/s  (0.712s, 2878.13/s)  avg LR: 5.940e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 102 [ 400/625 ( 64%)]  Loss: 0.004332 (0.00435)  Time: 0.703s, 2913.95/s  (0.710s, 2883.17/s)  avg LR: 5.940e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 102 [ 450/625 ( 72%)]  Loss: 0.004092 (0.00432)  Time: 0.701s, 2920.60/s  (0.709s, 2887.05/s)  avg LR: 5.940e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 102 [ 500/625 ( 80%)]  Loss: 0.004394 (0.00433)  Time: 0.701s, 2921.38/s  (0.709s, 2890.17/s)  avg LR: 5.940e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 102 [ 550/625 ( 88%)]  Loss: 0.004410 (0.00434)  Time: 0.701s, 2920.31/s  (0.708s, 2892.79/s)  avg LR: 5.940e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 102 [ 600/625 ( 96%)]  Loss: 0.004069 (0.00432)  Time: 0.701s, 2922.43/s  (0.707s, 2894.94/s)  avg LR: 5.940e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 102 [ 624/625 (100%)]  Loss: 0.004441 (0.00432)  Time: 0.672s, 3048.23/s  (0.707s, 2896.37/s)  avg LR: 5.940e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.349 (4.349)  Loss:  1.1152 (1.1152)  Acc@1: 76.0254 (76.0254)  Acc@5: 91.7480 (91.7480)
INFO:Test: [  24/24]  Time: 0.079 (0.495)  Loss:  0.9194 (1.6757)  Acc@1: 80.4245 (63.4760)  Acc@5: 93.3962 (85.3300)
ERROR:Exception '[Errno 2] No such file or directory: './exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-99.pth.tar'' while deleting checkpoint
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-97.pth.tar', 63.51800004638672)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-102.pth.tar', 63.47600002929688)

INFO:102-epoch: remaining time 26.39 h
INFO:Train: 103 [   0/625 (  0%)]  Loss: 0.004433 (0.00443)  Time: 4.453s,  459.88/s  (4.453s,  459.88/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 3.761 (3.761)
INFO:Train: 103 [  50/625 (  8%)]  Loss: 0.005047 (0.00474)  Time: 0.700s, 2924.25/s  (0.775s, 2643.02/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.028 (0.101)
INFO:Train: 103 [ 100/625 ( 16%)]  Loss: 0.004151 (0.00454)  Time: 0.701s, 2923.25/s  (0.738s, 2775.17/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.028 (0.065)
INFO:Train: 103 [ 150/625 ( 24%)]  Loss: 0.004444 (0.00452)  Time: 0.700s, 2924.82/s  (0.726s, 2822.39/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.029 (0.053)
INFO:Train: 103 [ 200/625 ( 32%)]  Loss: 0.004513 (0.00452)  Time: 0.701s, 2921.54/s  (0.719s, 2846.78/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.029 (0.047)
INFO:Namespace(aa='rand-m7-mstd0.5-inc1', acceleration_all=True, acceleration_mode='win2', amp=True, apex_amp=False, aug_repeats=3, aug_splits=0, batch_size=512, bce_loss=True, bias_decay=False, bn_eps=None, bn_momentum=None, channels_last=False, checkpoint_hist=2, clip_grad=None, clip_mode='norm', color_jitter=0.4, configure='job_lamb_res101_7.yaml', cooldown_epochs=10, crop_pct=None, cutmix=1.0, cutmix_minmax=None, dampening=0.0, data_dir='/dataset/imagenet', dataset='', decay_epochs=100, decay_rate=0.1, device='cuda:0', dist_bn='reduce', distributed=True, drop=0.0, drop_block=None, drop_connect=None, drop_path=0.1, epoch_repeats=0.0, epochs=300, eval_metric='top1', experiment='resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0', gp=None, hflip=0.5, img_size=None, initial_checkpoint='', input_size=None, interpolation='', jsd_loss=False, local_rank=0, log_interval=50, log_wandb=False, lr=0.008, lr_cycle_decay=0.5, lr_cycle_limit=1, lr_cycle_mul=1.0, lr_k_decay=1.0, lr_mode='cos', lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, max_grad_norm=1.0, mean=None, min_lr=5e-05, mixup=0.1, mixup_mode='batch', mixup_off_epoch=0, mixup_prob=1.0, mixup_switch_prob=0.5, model='resnet101', model_ema=False, model_ema_decay=0.9998, model_ema_force_cpu=False, momentum=0.9, native_amp=False, no_aug=False, no_prefetcher=False, no_prox=False, no_resume_opt=False, num_classes=None, opt='lamb4', opt_betas=[0.9, 0.999, 2.0, 8.0], opt_eps=None, output='./exp_lamb_resnet101_6/', p=0.5, patience_epochs=10, pin_mem=False, prefetcher=True, pretrained=False, rank=0, ratio=[0.75, 1.3333333333333333], recount=1, recovery_interval=0, remode='pixel', reprob=0.0, resplit=False, resume='last.pth.tar', save_images=False, scale=[0.08, 1.0], sched='cosine', seed=42, smoothing=0.1, split_bn=False, start_epoch=None, std=None, sync_bn=False, torchscript=False, train_interpolation='random', train_split='train', tta=0, update_mode='', use_multi_epochs_loader=False, val_split='validation', validation_batch_size=None, vflip=0.0, warmup_epochs=30, warmup_lr=1e-10, weight_decay=0.01, workers=10, world_size=4)
INFO:Namespace(aa='rand-m7-mstd0.5-inc1', acceleration_all=True, acceleration_mode='win2', amp=True, apex_amp=False, aug_repeats=3, aug_splits=0, batch_size=512, bce_loss=True, bias_decay=False, bn_eps=None, bn_momentum=None, channels_last=False, checkpoint_hist=2, clip_grad=None, clip_mode='norm', color_jitter=0.4, configure='job_lamb_res101_7.yaml', cooldown_epochs=10, crop_pct=None, cutmix=1.0, cutmix_minmax=None, dampening=0.0, data_dir='/dataset/imagenet', dataset='', decay_epochs=100, decay_rate=0.1, device='cuda:1', dist_bn='reduce', distributed=True, drop=0.0, drop_block=None, drop_connect=None, drop_path=0.1, epoch_repeats=0.0, epochs=300, eval_metric='top1', experiment='resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0', gp=None, hflip=0.5, img_size=None, initial_checkpoint='', input_size=None, interpolation='', jsd_loss=False, local_rank=1, log_interval=50, log_wandb=False, lr=0.008, lr_cycle_decay=0.5, lr_cycle_limit=1, lr_cycle_mul=1.0, lr_k_decay=1.0, lr_mode='cos', lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, max_grad_norm=1.0, mean=None, min_lr=5e-05, mixup=0.1, mixup_mode='batch', mixup_off_epoch=0, mixup_prob=1.0, mixup_switch_prob=0.5, model='resnet101', model_ema=False, model_ema_decay=0.9998, model_ema_force_cpu=False, momentum=0.9, native_amp=False, no_aug=False, no_prefetcher=False, no_prox=False, no_resume_opt=False, num_classes=None, opt='lamb4', opt_betas=[0.9, 0.999, 2.0, 8.0], opt_eps=None, output='./exp_lamb_resnet101_6/', p=0.5, patience_epochs=10, pin_mem=False, prefetcher=True, pretrained=False, rank=1, ratio=[0.75, 1.3333333333333333], recount=1, recovery_interval=0, remode='pixel', reprob=0.0, resplit=False, resume='last.pth.tar', save_images=False, scale=[0.08, 1.0], sched='cosine', seed=42, smoothing=0.1, split_bn=False, start_epoch=None, std=None, sync_bn=False, torchscript=False, train_interpolation='random', train_split='train', tta=0, update_mode='', use_multi_epochs_loader=False, val_split='validation', validation_batch_size=None, vflip=0.0, warmup_epochs=30, warmup_lr=1e-10, weight_decay=0.01, workers=10, world_size=4)
INFO:Namespace(aa='rand-m7-mstd0.5-inc1', acceleration_all=True, acceleration_mode='win2', amp=True, apex_amp=False, aug_repeats=3, aug_splits=0, batch_size=512, bce_loss=True, bias_decay=False, bn_eps=None, bn_momentum=None, channels_last=False, checkpoint_hist=2, clip_grad=None, clip_mode='norm', color_jitter=0.4, configure='job_lamb_res101_7.yaml', cooldown_epochs=10, crop_pct=None, cutmix=1.0, cutmix_minmax=None, dampening=0.0, data_dir='/dataset/imagenet', dataset='', decay_epochs=100, decay_rate=0.1, device='cuda:2', dist_bn='reduce', distributed=True, drop=0.0, drop_block=None, drop_connect=None, drop_path=0.1, epoch_repeats=0.0, epochs=300, eval_metric='top1', experiment='resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0', gp=None, hflip=0.5, img_size=None, initial_checkpoint='', input_size=None, interpolation='', jsd_loss=False, local_rank=2, log_interval=50, log_wandb=False, lr=0.008, lr_cycle_decay=0.5, lr_cycle_limit=1, lr_cycle_mul=1.0, lr_k_decay=1.0, lr_mode='cos', lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, max_grad_norm=1.0, mean=None, min_lr=5e-05, mixup=0.1, mixup_mode='batch', mixup_off_epoch=0, mixup_prob=1.0, mixup_switch_prob=0.5, model='resnet101', model_ema=False, model_ema_decay=0.9998, model_ema_force_cpu=False, momentum=0.9, native_amp=False, no_aug=False, no_prefetcher=False, no_prox=False, no_resume_opt=False, num_classes=None, opt='lamb4', opt_betas=[0.9, 0.999, 2.0, 8.0], opt_eps=None, output='./exp_lamb_resnet101_6/', p=0.5, patience_epochs=10, pin_mem=False, prefetcher=True, pretrained=False, rank=2, ratio=[0.75, 1.3333333333333333], recount=1, recovery_interval=0, remode='pixel', reprob=0.0, resplit=False, resume='last.pth.tar', save_images=False, scale=[0.08, 1.0], sched='cosine', seed=42, smoothing=0.1, split_bn=False, start_epoch=None, std=None, sync_bn=False, torchscript=False, train_interpolation='random', train_split='train', tta=0, update_mode='', use_multi_epochs_loader=False, val_split='validation', validation_batch_size=None, vflip=0.0, warmup_epochs=30, warmup_lr=1e-10, weight_decay=0.01, workers=10, world_size=4)
INFO:Namespace(aa='rand-m7-mstd0.5-inc1', acceleration_all=True, acceleration_mode='win2', amp=True, apex_amp=False, aug_repeats=3, aug_splits=0, batch_size=512, bce_loss=True, bias_decay=False, bn_eps=None, bn_momentum=None, channels_last=False, checkpoint_hist=2, clip_grad=None, clip_mode='norm', color_jitter=0.4, configure='job_lamb_res101_7.yaml', cooldown_epochs=10, crop_pct=None, cutmix=1.0, cutmix_minmax=None, dampening=0.0, data_dir='/dataset/imagenet', dataset='', decay_epochs=100, decay_rate=0.1, device='cuda:3', dist_bn='reduce', distributed=True, drop=0.0, drop_block=None, drop_connect=None, drop_path=0.1, epoch_repeats=0.0, epochs=300, eval_metric='top1', experiment='resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0', gp=None, hflip=0.5, img_size=None, initial_checkpoint='', input_size=None, interpolation='', jsd_loss=False, local_rank=3, log_interval=50, log_wandb=False, lr=0.008, lr_cycle_decay=0.5, lr_cycle_limit=1, lr_cycle_mul=1.0, lr_k_decay=1.0, lr_mode='cos', lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, max_grad_norm=1.0, mean=None, min_lr=5e-05, mixup=0.1, mixup_mode='batch', mixup_off_epoch=0, mixup_prob=1.0, mixup_switch_prob=0.5, model='resnet101', model_ema=False, model_ema_decay=0.9998, model_ema_force_cpu=False, momentum=0.9, native_amp=False, no_aug=False, no_prefetcher=False, no_prox=False, no_resume_opt=False, num_classes=None, opt='lamb4', opt_betas=[0.9, 0.999, 2.0, 8.0], opt_eps=None, output='./exp_lamb_resnet101_6/', p=0.5, patience_epochs=10, pin_mem=False, prefetcher=True, pretrained=False, rank=3, ratio=[0.75, 1.3333333333333333], recount=1, recovery_interval=0, remode='pixel', reprob=0.0, resplit=False, resume='last.pth.tar', save_images=False, scale=[0.08, 1.0], sched='cosine', seed=42, smoothing=0.1, split_bn=False, start_epoch=None, std=None, sync_bn=False, torchscript=False, train_interpolation='random', train_split='train', tta=0, update_mode='', use_multi_epochs_loader=False, val_split='validation', validation_batch_size=None, vflip=0.0, warmup_epochs=30, warmup_lr=1e-10, weight_decay=0.01, workers=10, world_size=4)
INFO:Model resnet101 created, param count:44549160
INFO:Data processing configuration for current model + dataset:
INFO:	input_size: (3, 224, 224)
INFO:	interpolation: bicubic
INFO:	mean: (0.485, 0.456, 0.406)
INFO:	std: (0.229, 0.224, 0.225)
INFO:	crop_pct: 0.95
INFO:Lamb4 (
Parameter Group 0
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: no_acceleration
    trust_clip: False
    weight_decay: 0.0

Parameter Group 1
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: acceleration
    trust_clip: False
    weight_decay: 0.01
)
INFO:Lamb4 (
Parameter Group 0
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: no_acceleration
    trust_clip: False
    weight_decay: 0.0

Parameter Group 1
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: acceleration
    trust_clip: False
    weight_decay: 0.01
)
INFO:Using native Torch AMP. Training in mixed precision.
INFO:Lamb4 (
Parameter Group 0
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: no_acceleration
    trust_clip: False
    weight_decay: 0.0

Parameter Group 1
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: acceleration
    trust_clip: False
    weight_decay: 0.01
)
INFO:Lamb4 (
Parameter Group 0
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: no_acceleration
    trust_clip: False
    weight_decay: 0.0

Parameter Group 1
    acceleration_mode: win2
    always_adapt: False
    betas: [0.9, 0.999, 2.0, 8.0]
    bias_correction: True
    eps: 1e-06
    grad_averaging: True
    lr: 0.008
    lr_mode: cos
    max_grad_norm: 1.0
    name: acceleration
    trust_clip: False
    weight_decay: 0.01
)
INFO:Restoring model state from checkpoint...
INFO:Restoring optimizer state from checkpoint...
INFO:Restoring AMP loss scaler state from checkpoint...
INFO:Loaded checkpoint './exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/last.pth.tar' (epoch 102)
INFO:Using native Torch DistributedDataParallel.
INFO:Scheduled epochs: 310
INFO:Train: 103 [   0/625 (  0%)]  Loss: 0.004715 (0.00472)  Time: 15.468s,  132.40/s  (15.468s,  132.40/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 6.224 (6.224)
INFO:Reducer buckets have been rebuilt in this iteration.
INFO:Reducer buckets have been rebuilt in this iteration.
INFO:Reducer buckets have been rebuilt in this iteration.
INFO:Reducer buckets have been rebuilt in this iteration.
INFO:Train: 103 [  50/625 (  8%)]  Loss: 0.003650 (0.00418)  Time: 0.703s, 2911.73/s  (0.995s, 2057.50/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.023 (0.148)
INFO:Train: 103 [ 100/625 ( 16%)]  Loss: 0.004256 (0.00421)  Time: 0.721s, 2841.94/s  (0.853s, 2401.60/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.045 (0.089)
INFO:Train: 103 [ 150/625 ( 24%)]  Loss: 0.004283 (0.00423)  Time: 0.706s, 2899.83/s  (0.804s, 2546.38/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.030 (0.069)
INFO:Train: 103 [ 200/625 ( 32%)]  Loss: 0.004359 (0.00425)  Time: 0.714s, 2869.62/s  (0.779s, 2627.37/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.039 (0.058)
INFO:Train: 103 [ 250/625 ( 40%)]  Loss: 0.003973 (0.00421)  Time: 0.709s, 2887.89/s  (0.765s, 2678.40/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.034 (0.052)
INFO:Train: 103 [ 300/625 ( 48%)]  Loss: 0.004904 (0.00431)  Time: 0.705s, 2905.34/s  (0.754s, 2714.73/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.032 (0.047)
INFO:Train: 103 [ 350/625 ( 56%)]  Loss: 0.004093 (0.00428)  Time: 0.705s, 2904.45/s  (0.747s, 2740.67/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.031 (0.044)
INFO:Train: 103 [ 400/625 ( 64%)]  Loss: 0.004494 (0.00430)  Time: 0.706s, 2899.99/s  (0.742s, 2760.66/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.032 (0.042)
INFO:Train: 103 [ 450/625 ( 72%)]  Loss: 0.003645 (0.00424)  Time: 0.712s, 2878.30/s  (0.738s, 2775.85/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.036 (0.041)
INFO:Train: 103 [ 500/625 ( 80%)]  Loss: 0.004274 (0.00424)  Time: 0.716s, 2861.38/s  (0.734s, 2788.77/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.042 (0.039)
INFO:Train: 103 [ 550/625 ( 88%)]  Loss: 0.004154 (0.00423)  Time: 0.709s, 2887.93/s  (0.732s, 2798.57/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.036 (0.039)
INFO:Train: 103 [ 600/625 ( 96%)]  Loss: 0.005079 (0.00430)  Time: 0.711s, 2878.93/s  (0.729s, 2807.67/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.038 (0.038)
INFO:Train: 103 [ 624/625 (100%)]  Loss: 0.004514 (0.00431)  Time: 0.672s, 3046.11/s  (0.728s, 2812.08/s)  avg LR: 5.903e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 7.312 (7.312)  Loss:  1.1309 (1.1309)  Acc@1: 74.0723 (74.0723)  Acc@5: 92.2363 (92.2363)
INFO:Test: [  24/24]  Time: 0.834 (0.647)  Loss:  0.9478 (1.6010)  Acc@1: 79.1274 (64.3280)  Acc@5: 92.6887 (86.2180)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-103.pth.tar', 64.32799998291016)

INFO:103-epoch: remaining time 27.25 h
INFO:Train: 104 [   0/625 (  0%)]  Loss: 0.004321 (0.00432)  Time: 4.382s,  467.32/s  (4.382s,  467.32/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 3.674 (3.674)
INFO:Train: 104 [  50/625 (  8%)]  Loss: 0.004373 (0.00435)  Time: 0.700s, 2925.53/s  (0.774s, 2645.16/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.026 (0.097)
INFO:Train: 104 [ 100/625 ( 16%)]  Loss: 0.004271 (0.00432)  Time: 0.698s, 2935.58/s  (0.737s, 2777.06/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.024 (0.062)
INFO:Train: 104 [ 150/625 ( 24%)]  Loss: 0.004269 (0.00431)  Time: 0.700s, 2926.99/s  (0.726s, 2822.33/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.025 (0.049)
INFO:Train: 104 [ 200/625 ( 32%)]  Loss: 0.005080 (0.00446)  Time: 0.698s, 2935.49/s  (0.720s, 2844.69/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.021 (0.043)
INFO:Train: 104 [ 250/625 ( 40%)]  Loss: 0.004215 (0.00442)  Time: 0.703s, 2911.49/s  (0.716s, 2859.08/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 104 [ 300/625 ( 48%)]  Loss: 0.004972 (0.00450)  Time: 0.701s, 2921.02/s  (0.714s, 2868.32/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 104 [ 350/625 ( 56%)]  Loss: 0.004954 (0.00456)  Time: 0.700s, 2924.50/s  (0.712s, 2875.24/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 104 [ 400/625 ( 64%)]  Loss: 0.004374 (0.00454)  Time: 0.700s, 2925.66/s  (0.712s, 2876.38/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 104 [ 450/625 ( 72%)]  Loss: 0.003991 (0.00448)  Time: 0.707s, 2895.52/s  (0.711s, 2880.54/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 104 [ 500/625 ( 80%)]  Loss: 0.004242 (0.00446)  Time: 0.704s, 2907.73/s  (0.710s, 2883.65/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.029 (0.033)
INFO:Train: 104 [ 550/625 ( 88%)]  Loss: 0.004322 (0.00445)  Time: 0.717s, 2854.73/s  (0.710s, 2886.17/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.045 (0.032)
INFO:Train: 104 [ 600/625 ( 96%)]  Loss: 0.005037 (0.00449)  Time: 0.700s, 2925.83/s  (0.710s, 2884.51/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.024 (0.033)
INFO:Train: 104 [ 624/625 (100%)]  Loss: 0.004679 (0.00451)  Time: 0.675s, 3032.32/s  (0.710s, 2886.46/s)  avg LR: 5.867e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.331 (4.331)  Loss:  1.2695 (1.2695)  Acc@1: 72.1191 (72.1191)  Acc@5: 89.1113 (89.1113)
INFO:Test: [  24/24]  Time: 0.080 (0.497)  Loss:  1.0137 (1.7064)  Acc@1: 78.0660 (61.9220)  Acc@5: 92.3349 (84.4360)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-103.pth.tar', 64.32799998291016)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-104.pth.tar', 61.9220000390625)

INFO:104-epoch: remaining time 26.18 h
INFO:Train: 105 [   0/625 (  0%)]  Loss: 0.004310 (0.00431)  Time: 4.267s,  479.93/s  (4.267s,  479.93/s)  avg LR: 5.830e-03  iter ratio: 0.0000  Data: 3.568 (3.568)
INFO:Train: 105 [  50/625 (  8%)]  Loss: 0.005013 (0.00466)  Time: 0.709s, 2889.45/s  (0.776s, 2639.75/s)  avg LR: 5.830e-03  iter ratio: 0.0000  Data: 0.028 (0.098)
INFO:Train: 105 [ 100/625 ( 16%)]  Loss: 0.004304 (0.00454)  Time: 0.701s, 2922.92/s  (0.742s, 2760.52/s)  avg LR: 5.830e-03  iter ratio: 0.0000  Data: 0.027 (0.064)
INFO:Train: 105 [ 150/625 ( 24%)]  Loss: 0.004660 (0.00457)  Time: 0.716s, 2860.26/s  (0.729s, 2808.06/s)  avg LR: 5.830e-03  iter ratio: 0.0000  Data: 0.037 (0.051)
INFO:Train: 105 [ 200/625 ( 32%)]  Loss: 0.004110 (0.00448)  Time: 0.717s, 2857.28/s  (0.726s, 2820.73/s)  avg LR: 5.830e-03  iter ratio: 0.0000  Data: 0.036 (0.047)
INFO:Train: 105 [ 250/625 ( 40%)]  Loss: 0.003943 (0.00439)  Time: 0.718s, 2851.05/s  (0.724s, 2828.64/s)  avg LR: 5.830e-03  iter ratio: 0.0000  Data: 0.043 (0.045)
INFO:Train: 105 [ 300/625 ( 48%)]  Loss: 0.003598 (0.00428)  Time: 0.718s, 2852.57/s  (0.722s, 2835.24/s)  avg LR: 5.830e-03  iter ratio: 0.0000  Data: 0.041 (0.043)
INFO:Train: 105 [ 350/625 ( 56%)]  Loss: 0.004268 (0.00428)  Time: 0.717s, 2855.58/s  (0.721s, 2839.38/s)  avg LR: 5.830e-03  iter ratio: 0.0000  Data: 0.037 (0.042)
INFO:Train: 105 [ 400/625 ( 64%)]  Loss: 0.003869 (0.00423)  Time: 0.717s, 2856.33/s  (0.720s, 2842.75/s)  avg LR: 5.830e-03  iter ratio: 0.0000  Data: 0.037 (0.041)
INFO:Train: 105 [ 450/625 ( 72%)]  Loss: 0.003855 (0.00419)  Time: 0.720s, 2842.87/s  (0.720s, 2844.95/s)  avg LR: 5.830e-03  iter ratio: 0.0000  Data: 0.041 (0.040)
INFO:Train: 105 [ 500/625 ( 80%)]  Loss: 0.004903 (0.00426)  Time: 0.720s, 2846.19/s  (0.719s, 2846.49/s)  avg LR: 5.830e-03  iter ratio: 0.0000  Data: 0.040 (0.040)
INFO:Train: 105 [ 550/625 ( 88%)]  Loss: 0.004415 (0.00427)  Time: 0.719s, 2847.41/s  (0.719s, 2848.01/s)  avg LR: 5.830e-03  iter ratio: 0.0000  Data: 0.038 (0.040)
INFO:Train: 105 [ 600/625 ( 96%)]  Loss: 0.004682 (0.00430)  Time: 0.715s, 2863.31/s  (0.719s, 2849.28/s)  avg LR: 5.830e-03  iter ratio: 0.0000  Data: 0.035 (0.039)
INFO:Train: 105 [ 624/625 (100%)]  Loss: 0.004268 (0.00430)  Time: 0.677s, 3027.28/s  (0.718s, 2850.55/s)  avg LR: 5.830e-03  iter ratio: 0.0000  Data: 0.000 (0.039)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.393 (4.393)  Loss:  1.2520 (1.2520)  Acc@1: 72.7051 (72.7051)  Acc@5: 90.1855 (90.1855)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  1.2324 (1.6667)  Acc@1: 73.9387 (63.0220)  Acc@5: 89.2689 (85.2620)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-103.pth.tar', 64.32799998291016)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-105.pth.tar', 63.021999926757815)

INFO:105-epoch: remaining time 26.41 h
INFO:Train: 106 [   0/625 (  0%)]  Loss: 0.004102 (0.00410)  Time: 4.515s,  453.64/s  (4.515s,  453.64/s)  avg LR: 5.792e-03  iter ratio: 0.0000  Data: 3.807 (3.807)
INFO:Train: 106 [  50/625 (  8%)]  Loss: 0.005055 (0.00458)  Time: 0.701s, 2922.52/s  (0.777s, 2636.57/s)  avg LR: 5.792e-03  iter ratio: 0.0000  Data: 0.027 (0.101)
INFO:Train: 106 [ 100/625 ( 16%)]  Loss: 0.003630 (0.00426)  Time: 0.697s, 2938.61/s  (0.740s, 2767.30/s)  avg LR: 5.792e-03  iter ratio: 0.0000  Data: 0.023 (0.064)
INFO:Train: 106 [ 150/625 ( 24%)]  Loss: 0.004341 (0.00428)  Time: 0.703s, 2914.83/s  (0.728s, 2813.81/s)  avg LR: 5.792e-03  iter ratio: 0.0000  Data: 0.028 (0.052)
INFO:Train: 106 [ 200/625 ( 32%)]  Loss: 0.004317 (0.00429)  Time: 0.710s, 2882.48/s  (0.722s, 2835.33/s)  avg LR: 5.792e-03  iter ratio: 0.0000  Data: 0.036 (0.046)
INFO:Train: 106 [ 250/625 ( 40%)]  Loss: 0.004589 (0.00434)  Time: 0.697s, 2938.47/s  (0.718s, 2851.25/s)  avg LR: 5.792e-03  iter ratio: 0.0000  Data: 0.023 (0.042)
INFO:Train: 106 [ 300/625 ( 48%)]  Loss: 0.003859 (0.00427)  Time: 0.699s, 2928.91/s  (0.716s, 2861.07/s)  avg LR: 5.792e-03  iter ratio: 0.0000  Data: 0.022 (0.039)
INFO:Train: 106 [ 350/625 ( 56%)]  Loss: 0.004677 (0.00432)  Time: 0.714s, 2869.22/s  (0.715s, 2864.43/s)  avg LR: 5.792e-03  iter ratio: 0.0000  Data: 0.039 (0.039)
INFO:Train: 106 [ 400/625 ( 64%)]  Loss: 0.004317 (0.00432)  Time: 0.708s, 2891.69/s  (0.715s, 2863.91/s)  avg LR: 5.792e-03  iter ratio: 0.0000  Data: 0.033 (0.039)
INFO:Train: 106 [ 450/625 ( 72%)]  Loss: 0.004973 (0.00439)  Time: 0.698s, 2932.37/s  (0.715s, 2864.37/s)  avg LR: 5.792e-03  iter ratio: 0.0000  Data: 0.021 (0.039)
INFO:Train: 106 [ 500/625 ( 80%)]  Loss: 0.004657 (0.00441)  Time: 0.697s, 2937.02/s  (0.714s, 2870.00/s)  avg LR: 5.792e-03  iter ratio: 0.0000  Data: 0.023 (0.038)
INFO:Train: 106 [ 550/625 ( 88%)]  Loss: 0.004773 (0.00444)  Time: 0.698s, 2932.37/s  (0.713s, 2873.96/s)  avg LR: 5.792e-03  iter ratio: 0.0000  Data: 0.024 (0.037)
INFO:Train: 106 [ 600/625 ( 96%)]  Loss: 0.003559 (0.00437)  Time: 0.699s, 2930.80/s  (0.712s, 2877.77/s)  avg LR: 5.792e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 106 [ 624/625 (100%)]  Loss: 0.004251 (0.00436)  Time: 0.677s, 3024.68/s  (0.711s, 2879.73/s)  avg LR: 5.792e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.319 (4.319)  Loss:  1.2002 (1.2002)  Acc@1: 72.8027 (72.8027)  Acc@5: 90.4297 (90.4297)
INFO:Test: [  24/24]  Time: 0.080 (0.502)  Loss:  1.1338 (1.6565)  Acc@1: 74.7642 (63.1620)  Acc@5: 90.4481 (85.3240)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-103.pth.tar', 64.32799998291016)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-106.pth.tar', 63.162000026855466)

INFO:106-epoch: remaining time 26.01 h
INFO:Train: 107 [   0/625 (  0%)]  Loss: 0.004113 (0.00411)  Time: 4.539s,  451.22/s  (4.539s,  451.22/s)  avg LR: 5.755e-03  iter ratio: 0.0000  Data: 3.837 (3.837)
INFO:Train: 107 [  50/625 (  8%)]  Loss: 0.004550 (0.00433)  Time: 0.710s, 2885.95/s  (0.785s, 2609.93/s)  avg LR: 5.755e-03  iter ratio: 0.0000  Data: 0.035 (0.105)
INFO:Train: 107 [ 100/625 ( 16%)]  Loss: 0.003814 (0.00416)  Time: 0.701s, 2921.67/s  (0.744s, 2753.31/s)  avg LR: 5.755e-03  iter ratio: 0.0000  Data: 0.026 (0.066)
INFO:Train: 107 [ 150/625 ( 24%)]  Loss: 0.004451 (0.00423)  Time: 0.708s, 2892.20/s  (0.730s, 2804.45/s)  avg LR: 5.755e-03  iter ratio: 0.0000  Data: 0.033 (0.052)
INFO:Train: 107 [ 200/625 ( 32%)]  Loss: 0.004480 (0.00428)  Time: 0.706s, 2899.85/s  (0.724s, 2828.76/s)  avg LR: 5.755e-03  iter ratio: 0.0000  Data: 0.030 (0.046)
INFO:Train: 107 [ 250/625 ( 40%)]  Loss: 0.004500 (0.00432)  Time: 0.700s, 2925.31/s  (0.720s, 2844.23/s)  avg LR: 5.755e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 107 [ 300/625 ( 48%)]  Loss: 0.004823 (0.00439)  Time: 0.703s, 2912.81/s  (0.717s, 2854.65/s)  avg LR: 5.755e-03  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 107 [ 350/625 ( 56%)]  Loss: 0.004577 (0.00441)  Time: 0.714s, 2869.05/s  (0.716s, 2862.07/s)  avg LR: 5.755e-03  iter ratio: 0.0000  Data: 0.038 (0.038)
INFO:Train: 107 [ 400/625 ( 64%)]  Loss: 0.004459 (0.00442)  Time: 0.706s, 2901.55/s  (0.714s, 2867.38/s)  avg LR: 5.755e-03  iter ratio: 0.0000  Data: 0.031 (0.037)
INFO:Train: 107 [ 450/625 ( 72%)]  Loss: 0.004968 (0.00447)  Time: 0.708s, 2891.92/s  (0.713s, 2872.20/s)  avg LR: 5.755e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 107 [ 500/625 ( 80%)]  Loss: 0.004754 (0.00450)  Time: 0.717s, 2855.47/s  (0.713s, 2870.77/s)  avg LR: 5.755e-03  iter ratio: 0.0000  Data: 0.042 (0.036)
INFO:Train: 107 [ 550/625 ( 88%)]  Loss: 0.004296 (0.00448)  Time: 0.706s, 2901.96/s  (0.713s, 2872.95/s)  avg LR: 5.755e-03  iter ratio: 0.0000  Data: 0.032 (0.035)
INFO:Train: 107 [ 600/625 ( 96%)]  Loss: 0.004398 (0.00448)  Time: 0.710s, 2886.45/s  (0.712s, 2875.80/s)  avg LR: 5.755e-03  iter ratio: 0.0000  Data: 0.035 (0.035)
INFO:Train: 107 [ 624/625 (100%)]  Loss: 0.004348 (0.00447)  Time: 0.675s, 3033.34/s  (0.712s, 2877.67/s)  avg LR: 5.755e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.335 (4.335)  Loss:  1.3008 (1.3008)  Acc@1: 70.7520 (70.7520)  Acc@5: 89.3555 (89.3555)
INFO:Test: [  24/24]  Time: 0.080 (0.500)  Loss:  1.0566 (1.7450)  Acc@1: 76.2972 (62.1540)  Acc@5: 91.6274 (84.5720)
INFO:107-epoch: remaining time 25.90 h
INFO:Train: 108 [   0/625 (  0%)]  Loss: 0.004815 (0.00482)  Time: 4.148s,  493.69/s  (4.148s,  493.69/s)  avg LR: 5.717e-03  iter ratio: 0.0000  Data: 3.448 (3.448)
INFO:Train: 108 [  50/625 (  8%)]  Loss: 0.003951 (0.00438)  Time: 0.706s, 2901.26/s  (0.775s, 2641.18/s)  avg LR: 5.717e-03  iter ratio: 0.0000  Data: 0.030 (0.098)
INFO:Train: 108 [ 100/625 ( 16%)]  Loss: 0.004185 (0.00432)  Time: 0.702s, 2918.63/s  (0.741s, 2762.97/s)  avg LR: 5.717e-03  iter ratio: 0.0000  Data: 0.027 (0.065)
INFO:Train: 108 [ 150/625 ( 24%)]  Loss: 0.004706 (0.00441)  Time: 0.705s, 2904.34/s  (0.729s, 2809.24/s)  avg LR: 5.717e-03  iter ratio: 0.0000  Data: 0.030 (0.053)
INFO:Train: 108 [ 200/625 ( 32%)]  Loss: 0.004699 (0.00447)  Time: 0.704s, 2908.48/s  (0.723s, 2834.38/s)  avg LR: 5.717e-03  iter ratio: 0.0000  Data: 0.029 (0.046)
INFO:Train: 108 [ 250/625 ( 40%)]  Loss: 0.003993 (0.00439)  Time: 0.701s, 2920.76/s  (0.719s, 2850.26/s)  avg LR: 5.717e-03  iter ratio: 0.0000  Data: 0.025 (0.042)
INFO:Train: 108 [ 300/625 ( 48%)]  Loss: 0.004425 (0.00440)  Time: 0.720s, 2846.28/s  (0.718s, 2851.02/s)  avg LR: 5.717e-03  iter ratio: 0.0000  Data: 0.044 (0.042)
INFO:Train: 108 [ 350/625 ( 56%)]  Loss: 0.003774 (0.00432)  Time: 0.715s, 2865.48/s  (0.718s, 2850.79/s)  avg LR: 5.717e-03  iter ratio: 0.0000  Data: 0.041 (0.042)
INFO:Train: 108 [ 400/625 ( 64%)]  Loss: 0.004477 (0.00434)  Time: 0.716s, 2859.60/s  (0.718s, 2850.72/s)  avg LR: 5.717e-03  iter ratio: 0.0000  Data: 0.042 (0.042)
INFO:Train: 108 [ 450/625 ( 72%)]  Loss: 0.004729 (0.00438)  Time: 0.714s, 2867.14/s  (0.718s, 2850.63/s)  avg LR: 5.717e-03  iter ratio: 0.0000  Data: 0.040 (0.042)
INFO:Train: 108 [ 500/625 ( 80%)]  Loss: 0.004378 (0.00438)  Time: 0.705s, 2905.85/s  (0.717s, 2857.02/s)  avg LR: 5.717e-03  iter ratio: 0.0000  Data: 0.029 (0.041)
INFO:Train: 108 [ 550/625 ( 88%)]  Loss: 0.004708 (0.00440)  Time: 0.704s, 2909.14/s  (0.716s, 2861.87/s)  avg LR: 5.717e-03  iter ratio: 0.0000  Data: 0.029 (0.039)
INFO:Train: 108 [ 600/625 ( 96%)]  Loss: 0.004709 (0.00443)  Time: 0.700s, 2926.42/s  (0.715s, 2866.16/s)  avg LR: 5.717e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 108 [ 624/625 (100%)]  Loss: 0.004255 (0.00441)  Time: 0.676s, 3028.60/s  (0.714s, 2868.17/s)  avg LR: 5.717e-03  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.336 (4.336)  Loss:  1.1387 (1.1387)  Acc@1: 73.7793 (73.7793)  Acc@5: 91.4062 (91.4062)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.9673 (1.6180)  Acc@1: 78.3019 (64.0700)  Acc@5: 92.4528 (85.8100)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-103.pth.tar', 64.32799998291016)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-108.pth.tar', 64.07000001220703)

INFO:108-epoch: remaining time 25.86 h
INFO:Train: 109 [   0/625 (  0%)]  Loss: 0.004592 (0.00459)  Time: 4.128s,  496.17/s  (4.128s,  496.17/s)  avg LR: 5.680e-03  iter ratio: 0.0000  Data: 3.441 (3.441)
INFO:Train: 109 [  50/625 (  8%)]  Loss: 0.004722 (0.00466)  Time: 0.725s, 2825.02/s  (0.772s, 2652.42/s)  avg LR: 5.680e-03  iter ratio: 0.0000  Data: 0.048 (0.092)
INFO:Train: 109 [ 100/625 ( 16%)]  Loss: 0.003968 (0.00443)  Time: 0.718s, 2851.93/s  (0.745s, 2748.53/s)  avg LR: 5.680e-03  iter ratio: 0.0000  Data: 0.041 (0.067)
INFO:Train: 109 [ 150/625 ( 24%)]  Loss: 0.004786 (0.00452)  Time: 0.704s, 2908.42/s  (0.732s, 2797.87/s)  avg LR: 5.680e-03  iter ratio: 0.0000  Data: 0.030 (0.054)
INFO:Train: 109 [ 200/625 ( 32%)]  Loss: 0.004724 (0.00456)  Time: 0.715s, 2865.16/s  (0.725s, 2826.03/s)  avg LR: 5.680e-03  iter ratio: 0.0000  Data: 0.034 (0.047)
INFO:Train: 109 [ 250/625 ( 40%)]  Loss: 0.004332 (0.00452)  Time: 0.717s, 2854.89/s  (0.721s, 2842.32/s)  avg LR: 5.680e-03  iter ratio: 0.0000  Data: 0.034 (0.042)
INFO:Train: 109 [ 300/625 ( 48%)]  Loss: 0.004658 (0.00454)  Time: 0.708s, 2892.24/s  (0.718s, 2853.77/s)  avg LR: 5.680e-03  iter ratio: 0.0000  Data: 0.035 (0.039)
INFO:Train: 109 [ 350/625 ( 56%)]  Loss: 0.004297 (0.00451)  Time: 0.706s, 2902.19/s  (0.716s, 2861.90/s)  avg LR: 5.680e-03  iter ratio: 0.0000  Data: 0.032 (0.037)
INFO:Train: 109 [ 400/625 ( 64%)]  Loss: 0.004383 (0.00450)  Time: 0.708s, 2893.06/s  (0.714s, 2868.52/s)  avg LR: 5.680e-03  iter ratio: 0.0000  Data: 0.034 (0.035)
INFO:Train: 109 [ 450/625 ( 72%)]  Loss: 0.004887 (0.00453)  Time: 0.708s, 2893.65/s  (0.713s, 2873.40/s)  avg LR: 5.680e-03  iter ratio: 0.0000  Data: 0.032 (0.034)
INFO:Train: 109 [ 500/625 ( 80%)]  Loss: 0.004159 (0.00450)  Time: 0.709s, 2890.22/s  (0.712s, 2876.67/s)  avg LR: 5.680e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 109 [ 550/625 ( 88%)]  Loss: 0.005200 (0.00456)  Time: 0.708s, 2892.30/s  (0.711s, 2879.24/s)  avg LR: 5.680e-03  iter ratio: 0.0000  Data: 0.030 (0.032)
INFO:Train: 109 [ 600/625 ( 96%)]  Loss: 0.004677 (0.00457)  Time: 0.704s, 2909.13/s  (0.711s, 2882.09/s)  avg LR: 5.680e-03  iter ratio: 0.0000  Data: 0.021 (0.032)
INFO:Train: 109 [ 624/625 (100%)]  Loss: 0.004561 (0.00457)  Time: 0.673s, 3043.66/s  (0.710s, 2882.87/s)  avg LR: 5.680e-03  iter ratio: 0.0000  Data: 0.000 (0.031)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.307 (4.307)  Loss:  1.4873 (1.4873)  Acc@1: 68.4082 (68.4082)  Acc@5: 86.7188 (86.7188)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  1.2041 (1.8922)  Acc@1: 74.7642 (58.9500)  Acc@5: 89.2689 (81.5540)
INFO:109-epoch: remaining time 25.62 h
INFO:Train: 110 [   0/625 (  0%)]  Loss: 0.004445 (0.00444)  Time: 4.506s,  454.54/s  (4.506s,  454.54/s)  avg LR: 5.642e-03  iter ratio: 0.0000  Data: 3.806 (3.806)
INFO:Train: 110 [  50/625 (  8%)]  Loss: 0.004882 (0.00466)  Time: 0.700s, 2925.26/s  (0.782s, 2617.84/s)  avg LR: 5.642e-03  iter ratio: 0.0000  Data: 0.024 (0.103)
INFO:Train: 110 [ 100/625 ( 16%)]  Loss: 0.004307 (0.00454)  Time: 0.697s, 2936.66/s  (0.744s, 2753.32/s)  avg LR: 5.642e-03  iter ratio: 0.0000  Data: 0.022 (0.066)
INFO:Train: 110 [ 150/625 ( 24%)]  Loss: 0.004160 (0.00445)  Time: 0.701s, 2921.31/s  (0.730s, 2807.02/s)  avg LR: 5.642e-03  iter ratio: 0.0000  Data: 0.026 (0.053)
INFO:Train: 110 [ 200/625 ( 32%)]  Loss: 0.004246 (0.00441)  Time: 0.695s, 2944.68/s  (0.723s, 2833.71/s)  avg LR: 5.642e-03  iter ratio: 0.0000  Data: 0.021 (0.046)
INFO:Train: 110 [ 250/625 ( 40%)]  Loss: 0.003528 (0.00426)  Time: 0.697s, 2938.26/s  (0.720s, 2844.36/s)  avg LR: 5.642e-03  iter ratio: 0.0000  Data: 0.021 (0.044)
INFO:Train: 110 [ 300/625 ( 48%)]  Loss: 0.004767 (0.00433)  Time: 0.700s, 2924.97/s  (0.717s, 2856.56/s)  avg LR: 5.642e-03  iter ratio: 0.0000  Data: 0.025 (0.040)
INFO:Train: 110 [ 350/625 ( 56%)]  Loss: 0.004646 (0.00437)  Time: 0.698s, 2932.75/s  (0.715s, 2864.65/s)  avg LR: 5.642e-03  iter ratio: 0.0000  Data: 0.022 (0.039)
INFO:Train: 110 [ 400/625 ( 64%)]  Loss: 0.003565 (0.00428)  Time: 0.699s, 2929.83/s  (0.713s, 2871.59/s)  avg LR: 5.642e-03  iter ratio: 0.0000  Data: 0.023 (0.037)
INFO:Train: 110 [ 450/625 ( 72%)]  Loss: 0.004283 (0.00428)  Time: 0.696s, 2942.69/s  (0.712s, 2876.79/s)  avg LR: 5.642e-03  iter ratio: 0.0000  Data: 0.022 (0.036)
INFO:Train: 110 [ 500/625 ( 80%)]  Loss: 0.004809 (0.00433)  Time: 0.698s, 2935.00/s  (0.711s, 2881.07/s)  avg LR: 5.642e-03  iter ratio: 0.0000  Data: 0.022 (0.035)
INFO:Train: 110 [ 550/625 ( 88%)]  Loss: 0.005262 (0.00441)  Time: 0.697s, 2940.16/s  (0.710s, 2884.66/s)  avg LR: 5.642e-03  iter ratio: 0.0000  Data: 0.021 (0.034)
INFO:Train: 110 [ 600/625 ( 96%)]  Loss: 0.003943 (0.00437)  Time: 0.703s, 2914.57/s  (0.709s, 2887.48/s)  avg LR: 5.642e-03  iter ratio: 0.0000  Data: 0.023 (0.033)
INFO:Train: 110 [ 624/625 (100%)]  Loss: 0.004425 (0.00438)  Time: 0.672s, 3045.95/s  (0.709s, 2888.87/s)  avg LR: 5.642e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.332 (4.332)  Loss:  1.1592 (1.1592)  Acc@1: 74.9512 (74.9512)  Acc@5: 90.8691 (90.8691)
INFO:Test: [  24/24]  Time: 0.082 (0.504)  Loss:  1.0830 (1.6825)  Acc@1: 76.7689 (63.0460)  Acc@5: 90.6840 (85.1500)
INFO:110-epoch: remaining time 25.42 h
INFO:Train: 111 [   0/625 (  0%)]  Loss: 0.004836 (0.00484)  Time: 4.328s,  473.15/s  (4.328s,  473.15/s)  avg LR: 5.604e-03  iter ratio: 0.0000  Data: 3.634 (3.634)
INFO:Train: 111 [  50/625 (  8%)]  Loss: 0.003881 (0.00436)  Time: 0.708s, 2892.65/s  (0.776s, 2640.10/s)  avg LR: 5.604e-03  iter ratio: 0.0000  Data: 0.033 (0.095)
INFO:Train: 111 [ 100/625 ( 16%)]  Loss: 0.004275 (0.00433)  Time: 0.702s, 2916.91/s  (0.739s, 2770.44/s)  avg LR: 5.604e-03  iter ratio: 0.0000  Data: 0.027 (0.059)
INFO:Train: 111 [ 150/625 ( 24%)]  Loss: 0.005077 (0.00452)  Time: 0.720s, 2842.79/s  (0.727s, 2816.10/s)  avg LR: 5.604e-03  iter ratio: 0.0000  Data: 0.042 (0.047)
INFO:Train: 111 [ 200/625 ( 32%)]  Loss: 0.004094 (0.00443)  Time: 0.705s, 2906.54/s  (0.722s, 2837.35/s)  avg LR: 5.604e-03  iter ratio: 0.0000  Data: 0.029 (0.042)
INFO:Train: 111 [ 250/625 ( 40%)]  Loss: 0.003916 (0.00435)  Time: 0.707s, 2896.62/s  (0.718s, 2851.14/s)  avg LR: 5.604e-03  iter ratio: 0.0000  Data: 0.032 (0.039)
INFO:Train: 111 [ 300/625 ( 48%)]  Loss: 0.003882 (0.00428)  Time: 0.705s, 2903.60/s  (0.716s, 2860.38/s)  avg LR: 5.604e-03  iter ratio: 0.0000  Data: 0.031 (0.037)
INFO:Train: 111 [ 350/625 ( 56%)]  Loss: 0.004975 (0.00437)  Time: 0.720s, 2844.18/s  (0.715s, 2863.61/s)  avg LR: 5.604e-03  iter ratio: 0.0000  Data: 0.046 (0.036)
INFO:Train: 111 [ 400/625 ( 64%)]  Loss: 0.004444 (0.00438)  Time: 0.715s, 2865.68/s  (0.714s, 2869.59/s)  avg LR: 5.604e-03  iter ratio: 0.0000  Data: 0.040 (0.035)
INFO:Train: 111 [ 450/625 ( 72%)]  Loss: 0.003598 (0.00430)  Time: 0.703s, 2913.45/s  (0.713s, 2873.90/s)  avg LR: 5.604e-03  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 111 [ 500/625 ( 80%)]  Loss: 0.004474 (0.00431)  Time: 0.715s, 2864.83/s  (0.712s, 2877.87/s)  avg LR: 5.604e-03  iter ratio: 0.0000  Data: 0.041 (0.033)
INFO:Train: 111 [ 550/625 ( 88%)]  Loss: 0.004123 (0.00430)  Time: 0.704s, 2909.93/s  (0.711s, 2881.28/s)  avg LR: 5.604e-03  iter ratio: 0.0000  Data: 0.027 (0.032)
INFO:Train: 111 [ 600/625 ( 96%)]  Loss: 0.004183 (0.00429)  Time: 0.698s, 2934.34/s  (0.710s, 2883.93/s)  avg LR: 5.604e-03  iter ratio: 0.0000  Data: 0.020 (0.031)
INFO:Train: 111 [ 624/625 (100%)]  Loss: 0.004407 (0.00430)  Time: 0.674s, 3036.71/s  (0.710s, 2885.59/s)  avg LR: 5.604e-03  iter ratio: 0.0000  Data: 0.000 (0.031)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.330 (4.330)  Loss:  1.1172 (1.1172)  Acc@1: 74.8047 (74.8047)  Acc@5: 91.1133 (91.1133)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.9185 (1.6034)  Acc@1: 78.6557 (64.1740)  Acc@5: 92.5708 (85.9160)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-103.pth.tar', 64.32799998291016)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-111.pth.tar', 64.1740000366211)

INFO:111-epoch: remaining time 25.34 h
INFO:Train: 112 [   0/625 (  0%)]  Loss: 0.003903 (0.00390)  Time: 4.235s,  483.61/s  (4.235s,  483.61/s)  avg LR: 5.565e-03  iter ratio: 0.0000  Data: 3.531 (3.531)
INFO:Train: 112 [  50/625 (  8%)]  Loss: 0.003950 (0.00393)  Time: 0.701s, 2920.69/s  (0.771s, 2655.33/s)  avg LR: 5.565e-03  iter ratio: 0.0000  Data: 0.024 (0.093)
INFO:Train: 112 [ 100/625 ( 16%)]  Loss: 0.004443 (0.00410)  Time: 0.700s, 2926.78/s  (0.737s, 2778.64/s)  avg LR: 5.565e-03  iter ratio: 0.0000  Data: 0.021 (0.058)
INFO:Train: 112 [ 150/625 ( 24%)]  Loss: 0.004456 (0.00419)  Time: 0.716s, 2861.68/s  (0.727s, 2816.47/s)  avg LR: 5.565e-03  iter ratio: 0.0000  Data: 0.027 (0.048)
INFO:Train: 112 [ 200/625 ( 32%)]  Loss: 0.005087 (0.00437)  Time: 0.706s, 2901.83/s  (0.722s, 2836.30/s)  avg LR: 5.565e-03  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 112 [ 250/625 ( 40%)]  Loss: 0.004264 (0.00435)  Time: 0.705s, 2904.54/s  (0.718s, 2850.64/s)  avg LR: 5.565e-03  iter ratio: 0.0000  Data: 0.024 (0.039)
INFO:Train: 112 [ 300/625 ( 48%)]  Loss: 0.004077 (0.00431)  Time: 0.702s, 2917.38/s  (0.716s, 2860.06/s)  avg LR: 5.565e-03  iter ratio: 0.0000  Data: 0.023 (0.037)
INFO:Train: 112 [ 350/625 ( 56%)]  Loss: 0.004573 (0.00434)  Time: 0.702s, 2915.87/s  (0.714s, 2866.40/s)  avg LR: 5.565e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 112 [ 400/625 ( 64%)]  Loss: 0.005109 (0.00443)  Time: 0.704s, 2909.34/s  (0.713s, 2871.22/s)  avg LR: 5.565e-03  iter ratio: 0.0000  Data: 0.022 (0.033)
INFO:Train: 112 [ 450/625 ( 72%)]  Loss: 0.004886 (0.00447)  Time: 0.704s, 2910.29/s  (0.712s, 2874.82/s)  avg LR: 5.565e-03  iter ratio: 0.0000  Data: 0.021 (0.032)
INFO:Train: 112 [ 500/625 ( 80%)]  Loss: 0.004257 (0.00445)  Time: 0.703s, 2913.40/s  (0.712s, 2877.94/s)  avg LR: 5.565e-03  iter ratio: 0.0000  Data: 0.022 (0.031)
INFO:Train: 112 [ 550/625 ( 88%)]  Loss: 0.004275 (0.00444)  Time: 0.704s, 2911.09/s  (0.711s, 2880.19/s)  avg LR: 5.565e-03  iter ratio: 0.0000  Data: 0.023 (0.030)
INFO:Train: 112 [ 600/625 ( 96%)]  Loss: 0.004414 (0.00444)  Time: 0.712s, 2877.32/s  (0.711s, 2881.97/s)  avg LR: 5.565e-03  iter ratio: 0.0000  Data: 0.037 (0.030)
INFO:Train: 112 [ 624/625 (100%)]  Loss: 0.004115 (0.00441)  Time: 0.675s, 3035.39/s  (0.711s, 2881.59/s)  avg LR: 5.565e-03  iter ratio: 0.0000  Data: 0.000 (0.030)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.286 (4.286)  Loss:  1.0352 (1.0352)  Acc@1: 76.2695 (76.2695)  Acc@5: 91.9922 (91.9922)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.9341 (1.5666)  Acc@1: 79.0094 (64.7520)  Acc@5: 92.0991 (86.4740)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-112.pth.tar', 64.75200006103516)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-103.pth.tar', 64.32799998291016)

INFO:112-epoch: remaining time 25.24 h
INFO:Train: 113 [   0/625 (  0%)]  Loss: 0.004611 (0.00461)  Time: 4.093s,  500.31/s  (4.093s,  500.31/s)  avg LR: 5.527e-03  iter ratio: 0.0000  Data: 3.393 (3.393)
INFO:Train: 113 [  50/625 (  8%)]  Loss: 0.004506 (0.00456)  Time: 0.705s, 2905.06/s  (0.776s, 2640.50/s)  avg LR: 5.527e-03  iter ratio: 0.0000  Data: 0.028 (0.096)
INFO:Train: 113 [ 100/625 ( 16%)]  Loss: 0.004499 (0.00454)  Time: 0.700s, 2925.80/s  (0.740s, 2767.48/s)  avg LR: 5.527e-03  iter ratio: 0.0000  Data: 0.023 (0.060)
INFO:Train: 113 [ 150/625 ( 24%)]  Loss: 0.004248 (0.00447)  Time: 0.699s, 2927.81/s  (0.727s, 2817.17/s)  avg LR: 5.527e-03  iter ratio: 0.0000  Data: 0.023 (0.048)
INFO:Train: 113 [ 200/625 ( 32%)]  Loss: 0.003675 (0.00431)  Time: 0.714s, 2867.76/s  (0.724s, 2827.67/s)  avg LR: 5.527e-03  iter ratio: 0.0000  Data: 0.039 (0.046)
INFO:Train: 113 [ 250/625 ( 40%)]  Loss: 0.003894 (0.00424)  Time: 0.715s, 2865.90/s  (0.723s, 2832.27/s)  avg LR: 5.527e-03  iter ratio: 0.0000  Data: 0.041 (0.045)
INFO:Train: 113 [ 300/625 ( 48%)]  Loss: 0.004499 (0.00428)  Time: 0.718s, 2851.33/s  (0.722s, 2836.31/s)  avg LR: 5.527e-03  iter ratio: 0.0000  Data: 0.044 (0.044)
INFO:Train: 113 [ 350/625 ( 56%)]  Loss: 0.004866 (0.00435)  Time: 0.703s, 2912.70/s  (0.719s, 2847.18/s)  avg LR: 5.527e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 113 [ 400/625 ( 64%)]  Loss: 0.005315 (0.00446)  Time: 0.712s, 2874.67/s  (0.717s, 2854.72/s)  avg LR: 5.527e-03  iter ratio: 0.0000  Data: 0.033 (0.040)
INFO:Train: 113 [ 450/625 ( 72%)]  Loss: 0.004095 (0.00442)  Time: 0.702s, 2916.64/s  (0.716s, 2861.28/s)  avg LR: 5.527e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 113 [ 500/625 ( 80%)]  Loss: 0.004445 (0.00442)  Time: 0.712s, 2874.79/s  (0.715s, 2862.84/s)  avg LR: 5.527e-03  iter ratio: 0.0000  Data: 0.022 (0.038)
INFO:Train: 113 [ 550/625 ( 88%)]  Loss: 0.003828 (0.00437)  Time: 0.726s, 2820.49/s  (0.716s, 2862.17/s)  avg LR: 5.527e-03  iter ratio: 0.0000  Data: 0.047 (0.038)
INFO:Train: 113 [ 600/625 ( 96%)]  Loss: 0.004814 (0.00441)  Time: 0.718s, 2852.23/s  (0.716s, 2861.84/s)  avg LR: 5.527e-03  iter ratio: 0.0000  Data: 0.044 (0.038)
INFO:Train: 113 [ 624/625 (100%)]  Loss: 0.003884 (0.00437)  Time: 0.674s, 3039.29/s  (0.715s, 2863.57/s)  avg LR: 5.527e-03  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.482 (4.482)  Loss:  1.1680 (1.1680)  Acc@1: 74.3652 (74.3652)  Acc@5: 91.9434 (91.9434)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.9795 (1.6302)  Acc@1: 79.2453 (64.6000)  Acc@5: 93.3962 (86.3160)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-112.pth.tar', 64.75200006103516)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-113.pth.tar', 64.60000003417969)

INFO:113-epoch: remaining time 25.28 h
INFO:Train: 114 [   0/625 (  0%)]  Loss: 0.004847 (0.00485)  Time: 4.247s,  482.18/s  (4.247s,  482.18/s)  avg LR: 5.488e-03  iter ratio: 0.0000  Data: 3.555 (3.555)
INFO:Train: 114 [  50/625 (  8%)]  Loss: 0.004100 (0.00447)  Time: 0.715s, 2865.13/s  (0.783s, 2616.06/s)  avg LR: 5.488e-03  iter ratio: 0.0000  Data: 0.037 (0.104)
INFO:Train: 114 [ 100/625 ( 16%)]  Loss: 0.004529 (0.00449)  Time: 0.713s, 2871.06/s  (0.749s, 2732.90/s)  avg LR: 5.488e-03  iter ratio: 0.0000  Data: 0.036 (0.072)
INFO:Train: 114 [ 150/625 ( 24%)]  Loss: 0.004562 (0.00451)  Time: 0.699s, 2930.44/s  (0.735s, 2784.53/s)  avg LR: 5.488e-03  iter ratio: 0.0000  Data: 0.025 (0.058)
INFO:Train: 114 [ 200/625 ( 32%)]  Loss: 0.004187 (0.00444)  Time: 0.701s, 2921.49/s  (0.727s, 2815.90/s)  avg LR: 5.488e-03  iter ratio: 0.0000  Data: 0.023 (0.050)
INFO:Train: 114 [ 250/625 ( 40%)]  Loss: 0.003941 (0.00436)  Time: 0.702s, 2917.01/s  (0.723s, 2833.73/s)  avg LR: 5.488e-03  iter ratio: 0.0000  Data: 0.027 (0.046)
INFO:Train: 114 [ 300/625 ( 48%)]  Loss: 0.004345 (0.00436)  Time: 0.696s, 2940.76/s  (0.719s, 2846.81/s)  avg LR: 5.488e-03  iter ratio: 0.0000  Data: 0.019 (0.042)
INFO:Train: 114 [ 350/625 ( 56%)]  Loss: 0.004959 (0.00443)  Time: 0.717s, 2857.56/s  (0.718s, 2852.09/s)  avg LR: 5.488e-03  iter ratio: 0.0000  Data: 0.039 (0.041)
INFO:Train: 114 [ 400/625 ( 64%)]  Loss: 0.004093 (0.00440)  Time: 0.703s, 2914.63/s  (0.718s, 2853.02/s)  avg LR: 5.488e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 114 [ 450/625 ( 72%)]  Loss: 0.003874 (0.00434)  Time: 0.701s, 2921.84/s  (0.716s, 2860.35/s)  avg LR: 5.488e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 114 [ 500/625 ( 80%)]  Loss: 0.003969 (0.00431)  Time: 0.702s, 2918.30/s  (0.715s, 2865.34/s)  avg LR: 5.488e-03  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 114 [ 550/625 ( 88%)]  Loss: 0.004577 (0.00433)  Time: 0.701s, 2922.81/s  (0.714s, 2869.95/s)  avg LR: 5.488e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 114 [ 600/625 ( 96%)]  Loss: 0.004648 (0.00436)  Time: 0.708s, 2891.42/s  (0.714s, 2869.17/s)  avg LR: 5.488e-03  iter ratio: 0.0000  Data: 0.024 (0.037)
INFO:Train: 114 [ 624/625 (100%)]  Loss: 0.004130 (0.00434)  Time: 0.676s, 3028.60/s  (0.713s, 2871.47/s)  avg LR: 5.488e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.358 (4.358)  Loss:  1.3203 (1.3203)  Acc@1: 71.2891 (71.2891)  Acc@5: 88.0371 (88.0371)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  1.0684 (1.6593)  Acc@1: 77.2406 (63.0520)  Acc@5: 91.3915 (85.2400)
INFO:114-epoch: remaining time 25.11 h
INFO:Train: 115 [   0/625 (  0%)]  Loss: 0.004516 (0.00452)  Time: 4.001s,  511.83/s  (4.001s,  511.83/s)  avg LR: 5.450e-03  iter ratio: 0.0000  Data: 3.300 (3.300)
INFO:Train: 115 [  50/625 (  8%)]  Loss: 0.004021 (0.00427)  Time: 0.717s, 2855.18/s  (0.771s, 2655.34/s)  avg LR: 5.450e-03  iter ratio: 0.0000  Data: 0.037 (0.089)
INFO:Train: 115 [ 100/625 ( 16%)]  Loss: 0.004793 (0.00444)  Time: 0.719s, 2848.76/s  (0.745s, 2750.73/s)  avg LR: 5.450e-03  iter ratio: 0.0000  Data: 0.041 (0.061)
INFO:Train: 115 [ 150/625 ( 24%)]  Loss: 0.004475 (0.00445)  Time: 0.704s, 2907.79/s  (0.733s, 2794.38/s)  avg LR: 5.450e-03  iter ratio: 0.0000  Data: 0.021 (0.050)
INFO:Train: 115 [ 200/625 ( 32%)]  Loss: 0.003946 (0.00435)  Time: 0.702s, 2918.32/s  (0.725s, 2823.56/s)  avg LR: 5.450e-03  iter ratio: 0.0000  Data: 0.018 (0.042)
INFO:Train: 115 [ 250/625 ( 40%)]  Loss: 0.004621 (0.00440)  Time: 0.720s, 2844.21/s  (0.723s, 2833.44/s)  avg LR: 5.450e-03  iter ratio: 0.0000  Data: 0.030 (0.041)
INFO:Train: 115 [ 300/625 ( 48%)]  Loss: 0.004763 (0.00445)  Time: 0.717s, 2856.66/s  (0.722s, 2836.82/s)  avg LR: 5.450e-03  iter ratio: 0.0000  Data: 0.038 (0.040)
INFO:Train: 115 [ 350/625 ( 56%)]  Loss: 0.003732 (0.00436)  Time: 0.714s, 2867.21/s  (0.721s, 2839.54/s)  avg LR: 5.450e-03  iter ratio: 0.0000  Data: 0.033 (0.040)
INFO:Train: 115 [ 400/625 ( 64%)]  Loss: 0.004494 (0.00437)  Time: 0.700s, 2924.54/s  (0.719s, 2847.79/s)  avg LR: 5.450e-03  iter ratio: 0.0000  Data: 0.020 (0.038)
INFO:Train: 115 [ 450/625 ( 72%)]  Loss: 0.004571 (0.00439)  Time: 0.701s, 2920.37/s  (0.717s, 2855.24/s)  avg LR: 5.450e-03  iter ratio: 0.0000  Data: 0.019 (0.036)
INFO:Train: 115 [ 500/625 ( 80%)]  Loss: 0.004201 (0.00438)  Time: 0.716s, 2861.36/s  (0.717s, 2857.75/s)  avg LR: 5.450e-03  iter ratio: 0.0000  Data: 0.032 (0.036)
INFO:Train: 115 [ 550/625 ( 88%)]  Loss: 0.004370 (0.00438)  Time: 0.720s, 2842.76/s  (0.717s, 2857.55/s)  avg LR: 5.450e-03  iter ratio: 0.0000  Data: 0.039 (0.036)
INFO:Train: 115 [ 600/625 ( 96%)]  Loss: 0.003967 (0.00434)  Time: 0.723s, 2832.58/s  (0.717s, 2857.33/s)  avg LR: 5.450e-03  iter ratio: 0.0000  Data: 0.047 (0.036)
INFO:Train: 115 [ 624/625 (100%)]  Loss: 0.005000 (0.00439)  Time: 0.675s, 3034.60/s  (0.716s, 2859.42/s)  avg LR: 5.450e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.312 (4.312)  Loss:  1.1699 (1.1699)  Acc@1: 73.2910 (73.2910)  Acc@5: 91.0156 (91.0156)
INFO:Test: [  24/24]  Time: 0.080 (0.497)  Loss:  1.0205 (1.6156)  Acc@1: 76.2972 (64.0340)  Acc@5: 92.4528 (85.9760)
INFO:115-epoch: remaining time 25.10 h
INFO:Train: 116 [   0/625 (  0%)]  Loss: 0.004142 (0.00414)  Time: 4.125s,  496.51/s  (4.125s,  496.51/s)  avg LR: 5.411e-03  iter ratio: 0.0000  Data: 3.420 (3.420)
INFO:Train: 116 [  50/625 (  8%)]  Loss: 0.004240 (0.00419)  Time: 0.703s, 2912.93/s  (0.779s, 2630.04/s)  avg LR: 5.411e-03  iter ratio: 0.0000  Data: 0.024 (0.095)
INFO:Train: 116 [ 100/625 ( 16%)]  Loss: 0.004439 (0.00427)  Time: 0.705s, 2902.92/s  (0.742s, 2759.18/s)  avg LR: 5.411e-03  iter ratio: 0.0000  Data: 0.023 (0.060)
INFO:Train: 116 [ 150/625 ( 24%)]  Loss: 0.003433 (0.00406)  Time: 0.698s, 2933.01/s  (0.729s, 2807.93/s)  avg LR: 5.411e-03  iter ratio: 0.0000  Data: 0.021 (0.048)
INFO:Train: 116 [ 200/625 ( 32%)]  Loss: 0.004692 (0.00419)  Time: 0.700s, 2927.03/s  (0.722s, 2835.08/s)  avg LR: 5.411e-03  iter ratio: 0.0000  Data: 0.022 (0.043)
INFO:Train: 116 [ 250/625 ( 40%)]  Loss: 0.004578 (0.00425)  Time: 0.698s, 2933.81/s  (0.718s, 2850.56/s)  avg LR: 5.411e-03  iter ratio: 0.0000  Data: 0.021 (0.039)
INFO:Train: 116 [ 300/625 ( 48%)]  Loss: 0.004026 (0.00422)  Time: 0.700s, 2924.78/s  (0.716s, 2862.12/s)  avg LR: 5.411e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 116 [ 350/625 ( 56%)]  Loss: 0.004705 (0.00428)  Time: 0.698s, 2932.73/s  (0.714s, 2869.85/s)  avg LR: 5.411e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 116 [ 400/625 ( 64%)]  Loss: 0.004310 (0.00428)  Time: 0.703s, 2912.56/s  (0.712s, 2876.00/s)  avg LR: 5.411e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 116 [ 450/625 ( 72%)]  Loss: 0.004430 (0.00430)  Time: 0.700s, 2924.49/s  (0.711s, 2881.11/s)  avg LR: 5.411e-03  iter ratio: 0.0000  Data: 0.024 (0.033)
INFO:Train: 116 [ 500/625 ( 80%)]  Loss: 0.003929 (0.00427)  Time: 0.706s, 2902.32/s  (0.710s, 2885.05/s)  avg LR: 5.411e-03  iter ratio: 0.0000  Data: 0.030 (0.032)
INFO:Train: 116 [ 550/625 ( 88%)]  Loss: 0.004360 (0.00427)  Time: 0.699s, 2930.51/s  (0.709s, 2888.09/s)  avg LR: 5.411e-03  iter ratio: 0.0000  Data: 0.025 (0.032)
INFO:Train: 116 [ 600/625 ( 96%)]  Loss: 0.004832 (0.00432)  Time: 0.698s, 2935.41/s  (0.708s, 2890.95/s)  avg LR: 5.411e-03  iter ratio: 0.0000  Data: 0.023 (0.031)
INFO:Train: 116 [ 624/625 (100%)]  Loss: 0.004984 (0.00436)  Time: 0.675s, 3033.16/s  (0.708s, 2892.35/s)  avg LR: 5.411e-03  iter ratio: 0.0000  Data: 0.000 (0.031)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.383 (4.383)  Loss:  1.1777 (1.1777)  Acc@1: 73.9746 (73.9746)  Acc@5: 90.6738 (90.6738)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  1.0830 (1.6315)  Acc@1: 75.1179 (63.6480)  Acc@5: 92.3349 (85.8200)
INFO:116-epoch: remaining time 24.65 h
INFO:Train: 117 [   0/625 (  0%)]  Loss: 0.004274 (0.00427)  Time: 4.285s,  477.94/s  (4.285s,  477.94/s)  avg LR: 5.371e-03  iter ratio: 0.0000  Data: 3.599 (3.599)
INFO:Train: 117 [  50/625 (  8%)]  Loss: 0.004994 (0.00463)  Time: 0.707s, 2897.65/s  (0.774s, 2644.95/s)  avg LR: 5.371e-03  iter ratio: 0.0000  Data: 0.030 (0.098)
INFO:Train: 117 [ 100/625 ( 16%)]  Loss: 0.003882 (0.00438)  Time: 0.716s, 2861.83/s  (0.746s, 2746.44/s)  avg LR: 5.371e-03  iter ratio: 0.0000  Data: 0.041 (0.070)
INFO:Train: 117 [ 150/625 ( 24%)]  Loss: 0.004150 (0.00432)  Time: 0.710s, 2885.06/s  (0.733s, 2795.56/s)  avg LR: 5.371e-03  iter ratio: 0.0000  Data: 0.030 (0.057)
INFO:Train: 117 [ 200/625 ( 32%)]  Loss: 0.004142 (0.00429)  Time: 0.699s, 2931.70/s  (0.725s, 2824.07/s)  avg LR: 5.371e-03  iter ratio: 0.0000  Data: 0.023 (0.050)
INFO:Train: 117 [ 250/625 ( 40%)]  Loss: 0.004741 (0.00436)  Time: 0.706s, 2901.61/s  (0.721s, 2842.25/s)  avg LR: 5.371e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 117 [ 300/625 ( 48%)]  Loss: 0.004462 (0.00438)  Time: 0.698s, 2935.46/s  (0.718s, 2853.96/s)  avg LR: 5.371e-03  iter ratio: 0.0000  Data: 0.023 (0.042)
INFO:Train: 117 [ 350/625 ( 56%)]  Loss: 0.004027 (0.00433)  Time: 0.701s, 2922.66/s  (0.715s, 2862.65/s)  avg LR: 5.371e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 117 [ 400/625 ( 64%)]  Loss: 0.004145 (0.00431)  Time: 0.701s, 2922.32/s  (0.714s, 2869.53/s)  avg LR: 5.371e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 117 [ 450/625 ( 72%)]  Loss: 0.004629 (0.00434)  Time: 0.705s, 2906.59/s  (0.712s, 2875.02/s)  avg LR: 5.371e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 117 [ 500/625 ( 80%)]  Loss: 0.004058 (0.00432)  Time: 0.699s, 2929.02/s  (0.711s, 2879.59/s)  avg LR: 5.371e-03  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 117 [ 550/625 ( 88%)]  Loss: 0.004363 (0.00432)  Time: 0.704s, 2909.63/s  (0.710s, 2883.05/s)  avg LR: 5.371e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 117 [ 600/625 ( 96%)]  Loss: 0.003742 (0.00428)  Time: 0.703s, 2911.99/s  (0.710s, 2885.26/s)  avg LR: 5.371e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 117 [ 624/625 (100%)]  Loss: 0.004149 (0.00427)  Time: 0.674s, 3036.55/s  (0.709s, 2887.24/s)  avg LR: 5.371e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.361 (4.361)  Loss:  1.0078 (1.0078)  Acc@1: 76.0742 (76.0742)  Acc@5: 92.9199 (92.9199)
INFO:Test: [  24/24]  Time: 0.080 (0.500)  Loss:  0.9556 (1.5926)  Acc@1: 80.0708 (64.3860)  Acc@5: 92.5708 (86.3580)
INFO:117-epoch: remaining time 24.54 h
INFO:Train: 118 [   0/625 (  0%)]  Loss: 0.004851 (0.00485)  Time: 4.554s,  449.75/s  (4.554s,  449.75/s)  avg LR: 5.332e-03  iter ratio: 0.0000  Data: 3.853 (3.853)
INFO:Train: 118 [  50/625 (  8%)]  Loss: 0.004313 (0.00458)  Time: 0.699s, 2928.10/s  (0.780s, 2626.52/s)  avg LR: 5.332e-03  iter ratio: 0.0000  Data: 0.021 (0.100)
INFO:Train: 118 [ 100/625 ( 16%)]  Loss: 0.004576 (0.00458)  Time: 0.699s, 2930.49/s  (0.741s, 2762.35/s)  avg LR: 5.332e-03  iter ratio: 0.0000  Data: 0.022 (0.062)
INFO:Train: 118 [ 150/625 ( 24%)]  Loss: 0.004122 (0.00447)  Time: 0.699s, 2930.92/s  (0.728s, 2813.24/s)  avg LR: 5.332e-03  iter ratio: 0.0000  Data: 0.022 (0.049)
INFO:Train: 118 [ 200/625 ( 32%)]  Loss: 0.003947 (0.00436)  Time: 0.699s, 2929.49/s  (0.722s, 2835.12/s)  avg LR: 5.332e-03  iter ratio: 0.0000  Data: 0.021 (0.043)
INFO:Train: 118 [ 250/625 ( 40%)]  Loss: 0.004420 (0.00437)  Time: 0.707s, 2895.11/s  (0.718s, 2851.24/s)  avg LR: 5.332e-03  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 118 [ 300/625 ( 48%)]  Loss: 0.004412 (0.00438)  Time: 0.698s, 2934.08/s  (0.716s, 2860.53/s)  avg LR: 5.332e-03  iter ratio: 0.0000  Data: 0.020 (0.036)
INFO:Train: 118 [ 350/625 ( 56%)]  Loss: 0.004325 (0.00437)  Time: 0.703s, 2911.78/s  (0.714s, 2868.29/s)  avg LR: 5.332e-03  iter ratio: 0.0000  Data: 0.021 (0.034)
INFO:Train: 118 [ 400/625 ( 64%)]  Loss: 0.005237 (0.00447)  Time: 0.700s, 2925.22/s  (0.713s, 2873.65/s)  avg LR: 5.332e-03  iter ratio: 0.0000  Data: 0.020 (0.033)
INFO:Train: 118 [ 450/625 ( 72%)]  Loss: 0.003957 (0.00442)  Time: 0.703s, 2911.86/s  (0.712s, 2878.01/s)  avg LR: 5.332e-03  iter ratio: 0.0000  Data: 0.021 (0.032)
INFO:Train: 118 [ 500/625 ( 80%)]  Loss: 0.004673 (0.00444)  Time: 0.717s, 2854.38/s  (0.711s, 2879.62/s)  avg LR: 5.332e-03  iter ratio: 0.0000  Data: 0.035 (0.031)
INFO:Train: 118 [ 550/625 ( 88%)]  Loss: 0.004774 (0.00447)  Time: 0.719s, 2850.36/s  (0.712s, 2877.19/s)  avg LR: 5.332e-03  iter ratio: 0.0000  Data: 0.039 (0.032)
INFO:Train: 118 [ 600/625 ( 96%)]  Loss: 0.004894 (0.00450)  Time: 0.699s, 2931.21/s  (0.712s, 2876.30/s)  avg LR: 5.332e-03  iter ratio: 0.0000  Data: 0.019 (0.032)
INFO:Train: 118 [ 624/625 (100%)]  Loss: 0.004171 (0.00448)  Time: 0.676s, 3029.24/s  (0.712s, 2878.40/s)  avg LR: 5.332e-03  iter ratio: 0.0000  Data: 0.000 (0.031)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.306 (4.306)  Loss:  1.1240 (1.1240)  Acc@1: 74.1699 (74.1699)  Acc@5: 91.3574 (91.3574)
INFO:Test: [  24/24]  Time: 0.080 (0.499)  Loss:  0.9771 (1.5946)  Acc@1: 78.4198 (64.3100)  Acc@5: 91.7453 (86.2160)
INFO:118-epoch: remaining time 24.49 h
INFO:Train: 119 [   0/625 (  0%)]  Loss: 0.004149 (0.00415)  Time: 3.983s,  514.14/s  (3.983s,  514.14/s)  avg LR: 5.293e-03  iter ratio: 0.0000  Data: 3.286 (3.286)
INFO:Train: 119 [  50/625 (  8%)]  Loss: 0.004160 (0.00415)  Time: 0.702s, 2919.35/s  (0.774s, 2644.85/s)  avg LR: 5.293e-03  iter ratio: 0.0000  Data: 0.022 (0.090)
INFO:Train: 119 [ 100/625 ( 16%)]  Loss: 0.005024 (0.00444)  Time: 0.704s, 2908.42/s  (0.741s, 2764.70/s)  avg LR: 5.293e-03  iter ratio: 0.0000  Data: 0.025 (0.058)
INFO:Train: 119 [ 150/625 ( 24%)]  Loss: 0.004146 (0.00437)  Time: 0.701s, 2922.38/s  (0.728s, 2812.39/s)  avg LR: 5.293e-03  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 119 [ 200/625 ( 32%)]  Loss: 0.004336 (0.00436)  Time: 0.704s, 2909.56/s  (0.722s, 2838.35/s)  avg LR: 5.293e-03  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 119 [ 250/625 ( 40%)]  Loss: 0.003963 (0.00430)  Time: 0.708s, 2892.81/s  (0.718s, 2852.71/s)  avg LR: 5.293e-03  iter ratio: 0.0000  Data: 0.032 (0.037)
INFO:Train: 119 [ 300/625 ( 48%)]  Loss: 0.004220 (0.00429)  Time: 0.706s, 2900.47/s  (0.715s, 2863.52/s)  avg LR: 5.293e-03  iter ratio: 0.0000  Data: 0.030 (0.035)
INFO:Train: 119 [ 350/625 ( 56%)]  Loss: 0.004547 (0.00432)  Time: 0.712s, 2875.23/s  (0.714s, 2869.61/s)  avg LR: 5.293e-03  iter ratio: 0.0000  Data: 0.034 (0.034)
INFO:Train: 119 [ 400/625 ( 64%)]  Loss: 0.004996 (0.00439)  Time: 0.700s, 2924.71/s  (0.712s, 2875.46/s)  avg LR: 5.293e-03  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 119 [ 450/625 ( 72%)]  Loss: 0.004185 (0.00437)  Time: 0.699s, 2931.78/s  (0.711s, 2879.41/s)  avg LR: 5.293e-03  iter ratio: 0.0000  Data: 0.024 (0.032)
INFO:Train: 119 [ 500/625 ( 80%)]  Loss: 0.005132 (0.00444)  Time: 0.699s, 2930.17/s  (0.710s, 2883.14/s)  avg LR: 5.293e-03  iter ratio: 0.0000  Data: 0.024 (0.031)
INFO:Train: 119 [ 550/625 ( 88%)]  Loss: 0.004703 (0.00446)  Time: 0.700s, 2927.53/s  (0.710s, 2885.72/s)  avg LR: 5.293e-03  iter ratio: 0.0000  Data: 0.024 (0.031)
INFO:Train: 119 [ 600/625 ( 96%)]  Loss: 0.004141 (0.00444)  Time: 0.712s, 2875.86/s  (0.709s, 2887.72/s)  avg LR: 5.293e-03  iter ratio: 0.0000  Data: 0.039 (0.030)
INFO:Train: 119 [ 624/625 (100%)]  Loss: 0.004190 (0.00442)  Time: 0.674s, 3038.54/s  (0.709s, 2889.11/s)  avg LR: 5.293e-03  iter ratio: 0.0000  Data: 0.000 (0.030)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.330 (4.330)  Loss:  1.0732 (1.0732)  Acc@1: 76.3184 (76.3184)  Acc@5: 91.8945 (91.8945)
INFO:Test: [  24/24]  Time: 0.080 (0.500)  Loss:  0.9243 (1.5943)  Acc@1: 77.7123 (64.2740)  Acc@5: 93.5142 (86.3200)
INFO:119-epoch: remaining time 24.28 h
INFO:Train: 120 [   0/625 (  0%)]  Loss: 0.004196 (0.00420)  Time: 4.366s,  469.10/s  (4.366s,  469.10/s)  avg LR: 5.253e-03  iter ratio: 0.0000  Data: 3.682 (3.682)
INFO:Train: 120 [  50/625 (  8%)]  Loss: 0.004367 (0.00428)  Time: 0.699s, 2930.14/s  (0.775s, 2643.00/s)  avg LR: 5.253e-03  iter ratio: 0.0000  Data: 0.022 (0.096)
INFO:Train: 120 [ 100/625 ( 16%)]  Loss: 0.003805 (0.00412)  Time: 0.699s, 2928.44/s  (0.739s, 2769.97/s)  avg LR: 5.253e-03  iter ratio: 0.0000  Data: 0.024 (0.061)
INFO:Train: 120 [ 150/625 ( 24%)]  Loss: 0.004503 (0.00422)  Time: 0.697s, 2937.59/s  (0.727s, 2817.15/s)  avg LR: 5.253e-03  iter ratio: 0.0000  Data: 0.023 (0.050)
INFO:Train: 120 [ 200/625 ( 32%)]  Loss: 0.003821 (0.00414)  Time: 0.701s, 2920.33/s  (0.721s, 2840.68/s)  avg LR: 5.253e-03  iter ratio: 0.0000  Data: 0.027 (0.044)
INFO:Train: 120 [ 250/625 ( 40%)]  Loss: 0.004549 (0.00421)  Time: 0.699s, 2928.81/s  (0.718s, 2853.85/s)  avg LR: 5.253e-03  iter ratio: 0.0000  Data: 0.024 (0.041)
INFO:Train: 120 [ 300/625 ( 48%)]  Loss: 0.003801 (0.00415)  Time: 0.701s, 2919.99/s  (0.715s, 2864.15/s)  avg LR: 5.253e-03  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 120 [ 350/625 ( 56%)]  Loss: 0.004818 (0.00423)  Time: 0.706s, 2899.73/s  (0.713s, 2871.77/s)  avg LR: 5.253e-03  iter ratio: 0.0000  Data: 0.023 (0.036)
INFO:Train: 120 [ 400/625 ( 64%)]  Loss: 0.004137 (0.00422)  Time: 0.703s, 2911.34/s  (0.712s, 2877.06/s)  avg LR: 5.253e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 120 [ 450/625 ( 72%)]  Loss: 0.004054 (0.00420)  Time: 0.702s, 2916.40/s  (0.711s, 2881.51/s)  avg LR: 5.253e-03  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 120 [ 500/625 ( 80%)]  Loss: 0.004258 (0.00421)  Time: 0.705s, 2906.69/s  (0.710s, 2885.09/s)  avg LR: 5.253e-03  iter ratio: 0.0000  Data: 0.030 (0.033)
INFO:Train: 120 [ 550/625 ( 88%)]  Loss: 0.003736 (0.00417)  Time: 0.700s, 2925.39/s  (0.709s, 2888.10/s)  avg LR: 5.253e-03  iter ratio: 0.0000  Data: 0.027 (0.032)
INFO:Train: 120 [ 600/625 ( 96%)]  Loss: 0.004259 (0.00418)  Time: 0.703s, 2915.15/s  (0.709s, 2890.59/s)  avg LR: 5.253e-03  iter ratio: 0.0000  Data: 0.028 (0.031)
INFO:Train: 120 [ 624/625 (100%)]  Loss: 0.004803 (0.00422)  Time: 0.677s, 3024.04/s  (0.708s, 2892.10/s)  avg LR: 5.253e-03  iter ratio: 0.0000  Data: 0.000 (0.031)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.394 (4.394)  Loss:  1.1553 (1.1553)  Acc@1: 74.5117 (74.5117)  Acc@5: 92.0410 (92.0410)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  1.1182 (1.5824)  Acc@1: 77.7123 (65.7380)  Acc@5: 90.8019 (86.8880)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-120.pth.tar', 65.73800001464843)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-112.pth.tar', 64.75200006103516)

INFO:120-epoch: remaining time 24.18 h
INFO:Train: 121 [   0/625 (  0%)]  Loss: 0.004310 (0.00431)  Time: 4.436s,  461.68/s  (4.436s,  461.68/s)  avg LR: 5.214e-03  iter ratio: 0.0000  Data: 3.743 (3.743)
INFO:Train: 121 [  50/625 (  8%)]  Loss: 0.004137 (0.00422)  Time: 0.709s, 2888.29/s  (0.783s, 2616.05/s)  avg LR: 5.214e-03  iter ratio: 0.0000  Data: 0.032 (0.101)
INFO:Train: 121 [ 100/625 ( 16%)]  Loss: 0.004569 (0.00434)  Time: 0.715s, 2862.95/s  (0.749s, 2733.81/s)  avg LR: 5.214e-03  iter ratio: 0.0000  Data: 0.035 (0.067)
INFO:Train: 121 [ 150/625 ( 24%)]  Loss: 0.004723 (0.00443)  Time: 0.710s, 2885.75/s  (0.737s, 2778.12/s)  avg LR: 5.214e-03  iter ratio: 0.0000  Data: 0.031 (0.056)
INFO:Train: 121 [ 200/625 ( 32%)]  Loss: 0.004282 (0.00440)  Time: 0.702s, 2916.05/s  (0.730s, 2805.75/s)  avg LR: 5.214e-03  iter ratio: 0.0000  Data: 0.019 (0.048)
INFO:Train: 121 [ 250/625 ( 40%)]  Loss: 0.004939 (0.00449)  Time: 0.704s, 2909.20/s  (0.725s, 2825.62/s)  avg LR: 5.214e-03  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 121 [ 300/625 ( 48%)]  Loss: 0.004097 (0.00444)  Time: 0.703s, 2914.93/s  (0.722s, 2838.49/s)  avg LR: 5.214e-03  iter ratio: 0.0000  Data: 0.022 (0.040)
INFO:Train: 121 [ 350/625 ( 56%)]  Loss: 0.004520 (0.00445)  Time: 0.704s, 2911.01/s  (0.719s, 2847.11/s)  avg LR: 5.214e-03  iter ratio: 0.0000  Data: 0.022 (0.037)
INFO:Train: 121 [ 400/625 ( 64%)]  Loss: 0.003797 (0.00437)  Time: 0.705s, 2905.69/s  (0.717s, 2854.91/s)  avg LR: 5.214e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 121 [ 450/625 ( 72%)]  Loss: 0.003806 (0.00432)  Time: 0.712s, 2877.68/s  (0.717s, 2858.10/s)  avg LR: 5.214e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 121 [ 500/625 ( 80%)]  Loss: 0.003999 (0.00429)  Time: 0.719s, 2846.89/s  (0.716s, 2858.70/s)  avg LR: 5.214e-03  iter ratio: 0.0000  Data: 0.044 (0.034)
INFO:Train: 121 [ 550/625 ( 88%)]  Loss: 0.004712 (0.00432)  Time: 0.717s, 2856.86/s  (0.716s, 2858.50/s)  avg LR: 5.214e-03  iter ratio: 0.0000  Data: 0.039 (0.035)
INFO:Train: 121 [ 600/625 ( 96%)]  Loss: 0.004110 (0.00431)  Time: 0.711s, 2878.91/s  (0.716s, 2858.36/s)  avg LR: 5.214e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 121 [ 624/625 (100%)]  Loss: 0.004841 (0.00435)  Time: 0.677s, 3024.27/s  (0.716s, 2859.38/s)  avg LR: 5.214e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.406 (4.406)  Loss:  1.2666 (1.2666)  Acc@1: 73.5840 (73.5840)  Acc@5: 89.7949 (89.7949)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  1.2344 (1.7620)  Acc@1: 74.0566 (61.5280)  Acc@5: 89.5047 (83.7880)
INFO:121-epoch: remaining time 24.26 h
INFO:Train: 122 [   0/625 (  0%)]  Loss: 0.004166 (0.00417)  Time: 4.338s,  472.13/s  (4.338s,  472.13/s)  avg LR: 5.174e-03  iter ratio: 0.0000  Data: 3.638 (3.638)
INFO:Train: 122 [  50/625 (  8%)]  Loss: 0.004510 (0.00434)  Time: 0.703s, 2915.16/s  (0.781s, 2622.23/s)  avg LR: 5.174e-03  iter ratio: 0.0000  Data: 0.024 (0.098)
INFO:Train: 122 [ 100/625 ( 16%)]  Loss: 0.003892 (0.00419)  Time: 0.718s, 2854.06/s  (0.746s, 2744.56/s)  avg LR: 5.174e-03  iter ratio: 0.0000  Data: 0.037 (0.062)
INFO:Train: 122 [ 150/625 ( 24%)]  Loss: 0.004844 (0.00435)  Time: 0.698s, 2933.35/s  (0.733s, 2793.36/s)  avg LR: 5.174e-03  iter ratio: 0.0000  Data: 0.023 (0.050)
INFO:Train: 122 [ 200/625 ( 32%)]  Loss: 0.004187 (0.00432)  Time: 0.701s, 2920.77/s  (0.726s, 2821.14/s)  avg LR: 5.174e-03  iter ratio: 0.0000  Data: 0.024 (0.043)
INFO:Train: 122 [ 250/625 ( 40%)]  Loss: 0.005023 (0.00444)  Time: 0.705s, 2905.29/s  (0.722s, 2838.02/s)  avg LR: 5.174e-03  iter ratio: 0.0000  Data: 0.031 (0.040)
INFO:Train: 122 [ 300/625 ( 48%)]  Loss: 0.004222 (0.00441)  Time: 0.710s, 2883.23/s  (0.719s, 2848.75/s)  avg LR: 5.174e-03  iter ratio: 0.0000  Data: 0.035 (0.037)
INFO:Train: 122 [ 350/625 ( 56%)]  Loss: 0.004297 (0.00439)  Time: 0.717s, 2855.11/s  (0.717s, 2856.41/s)  avg LR: 5.174e-03  iter ratio: 0.0000  Data: 0.043 (0.035)
INFO:Train: 122 [ 400/625 ( 64%)]  Loss: 0.003548 (0.00430)  Time: 0.704s, 2908.71/s  (0.716s, 2859.76/s)  avg LR: 5.174e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 122 [ 450/625 ( 72%)]  Loss: 0.003482 (0.00422)  Time: 0.706s, 2902.64/s  (0.715s, 2864.71/s)  avg LR: 5.174e-03  iter ratio: 0.0000  Data: 0.029 (0.034)
INFO:Train: 122 [ 500/625 ( 80%)]  Loss: 0.004536 (0.00425)  Time: 0.720s, 2844.62/s  (0.714s, 2868.80/s)  avg LR: 5.174e-03  iter ratio: 0.0000  Data: 0.045 (0.033)
INFO:Train: 122 [ 550/625 ( 88%)]  Loss: 0.004190 (0.00424)  Time: 0.706s, 2901.10/s  (0.714s, 2869.24/s)  avg LR: 5.174e-03  iter ratio: 0.0000  Data: 0.031 (0.033)
INFO:Train: 122 [ 600/625 ( 96%)]  Loss: 0.004188 (0.00424)  Time: 0.705s, 2903.73/s  (0.713s, 2872.55/s)  avg LR: 5.174e-03  iter ratio: 0.0000  Data: 0.027 (0.032)
INFO:Train: 122 [ 624/625 (100%)]  Loss: 0.004716 (0.00427)  Time: 0.676s, 3027.81/s  (0.713s, 2874.26/s)  avg LR: 5.174e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.394 (4.394)  Loss:  1.2715 (1.2715)  Acc@1: 73.3398 (73.3398)  Acc@5: 89.0137 (89.0137)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  1.0996 (1.6232)  Acc@1: 76.1792 (63.5380)  Acc@5: 90.2123 (85.4040)
INFO:122-epoch: remaining time 24.04 h
INFO:Train: 123 [   0/625 (  0%)]  Loss: 0.003728 (0.00373)  Time: 4.228s,  484.33/s  (4.228s,  484.33/s)  avg LR: 5.134e-03  iter ratio: 0.0000  Data: 3.546 (3.546)
INFO:Train: 123 [  50/625 (  8%)]  Loss: 0.004954 (0.00434)  Time: 0.704s, 2907.28/s  (0.772s, 2651.15/s)  avg LR: 5.134e-03  iter ratio: 0.0000  Data: 0.029 (0.095)
INFO:Train: 123 [ 100/625 ( 16%)]  Loss: 0.004596 (0.00443)  Time: 0.710s, 2884.89/s  (0.739s, 2772.75/s)  avg LR: 5.134e-03  iter ratio: 0.0000  Data: 0.034 (0.062)
INFO:Train: 123 [ 150/625 ( 24%)]  Loss: 0.004359 (0.00441)  Time: 0.701s, 2921.74/s  (0.727s, 2818.27/s)  avg LR: 5.134e-03  iter ratio: 0.0000  Data: 0.027 (0.050)
INFO:Train: 123 [ 200/625 ( 32%)]  Loss: 0.004103 (0.00435)  Time: 0.703s, 2914.41/s  (0.721s, 2841.28/s)  avg LR: 5.134e-03  iter ratio: 0.0000  Data: 0.027 (0.044)
INFO:Train: 123 [ 250/625 ( 40%)]  Loss: 0.004312 (0.00434)  Time: 0.705s, 2905.42/s  (0.717s, 2854.96/s)  avg LR: 5.134e-03  iter ratio: 0.0000  Data: 0.031 (0.040)
INFO:Train: 123 [ 300/625 ( 48%)]  Loss: 0.004280 (0.00433)  Time: 0.707s, 2898.61/s  (0.715s, 2864.17/s)  avg LR: 5.134e-03  iter ratio: 0.0000  Data: 0.032 (0.038)
INFO:Train: 123 [ 350/625 ( 56%)]  Loss: 0.004409 (0.00434)  Time: 0.704s, 2907.39/s  (0.713s, 2870.78/s)  avg LR: 5.134e-03  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 123 [ 400/625 ( 64%)]  Loss: 0.004181 (0.00432)  Time: 0.711s, 2880.50/s  (0.712s, 2875.91/s)  avg LR: 5.134e-03  iter ratio: 0.0000  Data: 0.035 (0.035)
INFO:Train: 123 [ 450/625 ( 72%)]  Loss: 0.004062 (0.00430)  Time: 0.708s, 2894.26/s  (0.711s, 2879.62/s)  avg LR: 5.134e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 123 [ 500/625 ( 80%)]  Loss: 0.005062 (0.00437)  Time: 0.704s, 2908.57/s  (0.711s, 2882.03/s)  avg LR: 5.134e-03  iter ratio: 0.0000  Data: 0.029 (0.034)
INFO:Train: 123 [ 550/625 ( 88%)]  Loss: 0.004167 (0.00435)  Time: 0.714s, 2867.11/s  (0.710s, 2884.14/s)  avg LR: 5.134e-03  iter ratio: 0.0000  Data: 0.031 (0.033)
INFO:Train: 123 [ 600/625 ( 96%)]  Loss: 0.004173 (0.00434)  Time: 0.706s, 2902.86/s  (0.710s, 2885.89/s)  avg LR: 5.134e-03  iter ratio: 0.0000  Data: 0.028 (0.032)
INFO:Train: 123 [ 624/625 (100%)]  Loss: 0.004344 (0.00434)  Time: 0.676s, 3030.45/s  (0.709s, 2887.41/s)  avg LR: 5.134e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.352 (4.352)  Loss:  1.0791 (1.0791)  Acc@1: 75.6836 (75.6836)  Acc@5: 91.5527 (91.5527)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  1.0127 (1.5420)  Acc@1: 77.1226 (64.8280)  Acc@5: 90.4481 (86.3340)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-120.pth.tar', 65.73800001464843)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-123.pth.tar', 64.82800001708985)

INFO:123-epoch: remaining time 23.80 h
INFO:Train: 124 [   0/625 (  0%)]  Loss: 0.003530 (0.00353)  Time: 4.611s,  444.11/s  (4.611s,  444.11/s)  avg LR: 5.094e-03  iter ratio: 0.0000  Data: 3.920 (3.920)
INFO:Train: 124 [  50/625 (  8%)]  Loss: 0.003518 (0.00352)  Time: 0.708s, 2892.96/s  (0.783s, 2614.77/s)  avg LR: 5.094e-03  iter ratio: 0.0000  Data: 0.033 (0.103)
INFO:Train: 124 [ 100/625 ( 16%)]  Loss: 0.004120 (0.00372)  Time: 0.706s, 2901.00/s  (0.744s, 2750.85/s)  avg LR: 5.094e-03  iter ratio: 0.0000  Data: 0.031 (0.064)
INFO:Train: 124 [ 150/625 ( 24%)]  Loss: 0.004282 (0.00386)  Time: 0.713s, 2873.74/s  (0.732s, 2798.75/s)  avg LR: 5.094e-03  iter ratio: 0.0000  Data: 0.028 (0.052)
INFO:Train: 124 [ 200/625 ( 32%)]  Loss: 0.003955 (0.00388)  Time: 0.716s, 2859.45/s  (0.725s, 2824.96/s)  avg LR: 5.094e-03  iter ratio: 0.0000  Data: 0.031 (0.045)
INFO:Train: 124 [ 250/625 ( 40%)]  Loss: 0.004594 (0.00400)  Time: 0.715s, 2865.39/s  (0.723s, 2830.82/s)  avg LR: 5.094e-03  iter ratio: 0.0000  Data: 0.036 (0.044)
INFO:Train: 124 [ 300/625 ( 48%)]  Loss: 0.004347 (0.00405)  Time: 0.717s, 2855.94/s  (0.723s, 2833.89/s)  avg LR: 5.094e-03  iter ratio: 0.0000  Data: 0.037 (0.043)
INFO:Train: 124 [ 350/625 ( 56%)]  Loss: 0.003945 (0.00404)  Time: 0.712s, 2875.16/s  (0.722s, 2837.04/s)  avg LR: 5.094e-03  iter ratio: 0.0000  Data: 0.035 (0.042)
INFO:Train: 124 [ 400/625 ( 64%)]  Loss: 0.004618 (0.00410)  Time: 0.717s, 2857.27/s  (0.721s, 2839.73/s)  avg LR: 5.094e-03  iter ratio: 0.0000  Data: 0.038 (0.042)
INFO:Train: 124 [ 450/625 ( 72%)]  Loss: 0.004157 (0.00411)  Time: 0.716s, 2859.30/s  (0.721s, 2840.61/s)  avg LR: 5.094e-03  iter ratio: 0.0000  Data: 0.042 (0.042)
INFO:Train: 124 [ 500/625 ( 80%)]  Loss: 0.004755 (0.00417)  Time: 0.707s, 2896.48/s  (0.720s, 2845.17/s)  avg LR: 5.094e-03  iter ratio: 0.0000  Data: 0.030 (0.041)
INFO:Train: 124 [ 550/625 ( 88%)]  Loss: 0.004151 (0.00416)  Time: 0.708s, 2894.35/s  (0.719s, 2850.06/s)  avg LR: 5.094e-03  iter ratio: 0.0000  Data: 0.032 (0.040)
INFO:Train: 124 [ 600/625 ( 96%)]  Loss: 0.004136 (0.00416)  Time: 0.709s, 2888.22/s  (0.718s, 2853.80/s)  avg LR: 5.094e-03  iter ratio: 0.0000  Data: 0.034 (0.039)
INFO:Train: 124 [ 624/625 (100%)]  Loss: 0.004299 (0.00417)  Time: 0.677s, 3025.41/s  (0.717s, 2855.96/s)  avg LR: 5.094e-03  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.344 (4.344)  Loss:  1.0439 (1.0439)  Acc@1: 76.0254 (76.0254)  Acc@5: 91.7969 (91.7969)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.7695 (1.5289)  Acc@1: 81.7217 (65.2480)  Acc@5: 94.4575 (86.8020)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-120.pth.tar', 65.73800001464843)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-124.pth.tar', 65.24799994628906)

INFO:124-epoch: remaining time 23.97 h
INFO:Train: 125 [   0/625 (  0%)]  Loss: 0.003343 (0.00334)  Time: 4.286s,  477.78/s  (4.286s,  477.78/s)  avg LR: 5.054e-03  iter ratio: 0.0000  Data: 3.601 (3.601)
INFO:Train: 125 [  50/625 (  8%)]  Loss: 0.005182 (0.00426)  Time: 0.710s, 2885.96/s  (0.782s, 2619.46/s)  avg LR: 5.054e-03  iter ratio: 0.0000  Data: 0.033 (0.102)
INFO:Train: 125 [ 100/625 ( 16%)]  Loss: 0.003556 (0.00403)  Time: 0.709s, 2890.26/s  (0.744s, 2753.24/s)  avg LR: 5.054e-03  iter ratio: 0.0000  Data: 0.029 (0.063)
INFO:Train: 125 [ 150/625 ( 24%)]  Loss: 0.004089 (0.00404)  Time: 0.712s, 2876.73/s  (0.731s, 2800.68/s)  avg LR: 5.054e-03  iter ratio: 0.0000  Data: 0.034 (0.050)
INFO:Train: 125 [ 200/625 ( 32%)]  Loss: 0.004163 (0.00407)  Time: 0.713s, 2871.76/s  (0.725s, 2826.15/s)  avg LR: 5.054e-03  iter ratio: 0.0000  Data: 0.038 (0.045)
INFO:Train: 125 [ 250/625 ( 40%)]  Loss: 0.004626 (0.00416)  Time: 0.713s, 2871.86/s  (0.721s, 2842.22/s)  avg LR: 5.054e-03  iter ratio: 0.0000  Data: 0.036 (0.041)
INFO:Train: 125 [ 300/625 ( 48%)]  Loss: 0.003698 (0.00409)  Time: 0.700s, 2926.91/s  (0.718s, 2854.14/s)  avg LR: 5.054e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 125 [ 350/625 ( 56%)]  Loss: 0.003944 (0.00407)  Time: 0.701s, 2921.83/s  (0.716s, 2860.70/s)  avg LR: 5.054e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 125 [ 400/625 ( 64%)]  Loss: 0.004217 (0.00409)  Time: 0.705s, 2903.74/s  (0.714s, 2867.37/s)  avg LR: 5.054e-03  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 125 [ 450/625 ( 72%)]  Loss: 0.004127 (0.00409)  Time: 0.703s, 2914.43/s  (0.713s, 2871.86/s)  avg LR: 5.054e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 125 [ 500/625 ( 80%)]  Loss: 0.004445 (0.00413)  Time: 0.718s, 2852.82/s  (0.712s, 2874.52/s)  avg LR: 5.054e-03  iter ratio: 0.0000  Data: 0.044 (0.035)
INFO:Train: 125 [ 550/625 ( 88%)]  Loss: 0.004193 (0.00413)  Time: 0.701s, 2920.80/s  (0.712s, 2874.41/s)  avg LR: 5.054e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 125 [ 600/625 ( 96%)]  Loss: 0.005064 (0.00420)  Time: 0.704s, 2910.30/s  (0.712s, 2877.86/s)  avg LR: 5.054e-03  iter ratio: 0.0000  Data: 0.029 (0.034)
INFO:Train: 125 [ 624/625 (100%)]  Loss: 0.004425 (0.00422)  Time: 0.675s, 3035.43/s  (0.711s, 2879.61/s)  avg LR: 5.054e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.400 (4.400)  Loss:  0.9136 (0.9136)  Acc@1: 78.0762 (78.0762)  Acc@5: 94.4336 (94.4336)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.8813 (1.4756)  Acc@1: 80.4245 (66.4040)  Acc@5: 93.7500 (87.8020)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-125.pth.tar', 66.40400002929688)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-120.pth.tar', 65.73800001464843)

INFO:125-epoch: remaining time 23.59 h
INFO:Train: 126 [   0/625 (  0%)]  Loss: 0.004028 (0.00403)  Time: 4.158s,  492.59/s  (4.158s,  492.59/s)  avg LR: 5.014e-03  iter ratio: 0.0000  Data: 3.442 (3.442)
INFO:Train: 126 [  50/625 (  8%)]  Loss: 0.003934 (0.00398)  Time: 0.700s, 2925.73/s  (0.771s, 2655.42/s)  avg LR: 5.014e-03  iter ratio: 0.0000  Data: 0.026 (0.094)
INFO:Train: 126 [ 100/625 ( 16%)]  Loss: 0.004596 (0.00419)  Time: 0.702s, 2916.23/s  (0.737s, 2777.71/s)  avg LR: 5.014e-03  iter ratio: 0.0000  Data: 0.027 (0.060)
INFO:Train: 126 [ 150/625 ( 24%)]  Loss: 0.004535 (0.00427)  Time: 0.709s, 2886.79/s  (0.726s, 2820.43/s)  avg LR: 5.014e-03  iter ratio: 0.0000  Data: 0.033 (0.049)
INFO:Train: 126 [ 200/625 ( 32%)]  Loss: 0.005246 (0.00447)  Time: 0.705s, 2906.43/s  (0.720s, 2843.48/s)  avg LR: 5.014e-03  iter ratio: 0.0000  Data: 0.030 (0.043)
INFO:Train: 126 [ 250/625 ( 40%)]  Loss: 0.004275 (0.00444)  Time: 0.701s, 2920.06/s  (0.717s, 2856.83/s)  avg LR: 5.014e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 126 [ 300/625 ( 48%)]  Loss: 0.004383 (0.00443)  Time: 0.702s, 2916.49/s  (0.715s, 2866.31/s)  avg LR: 5.014e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 126 [ 350/625 ( 56%)]  Loss: 0.003876 (0.00436)  Time: 0.711s, 2879.40/s  (0.713s, 2871.99/s)  avg LR: 5.014e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 126 [ 400/625 ( 64%)]  Loss: 0.003594 (0.00427)  Time: 0.701s, 2921.06/s  (0.712s, 2876.74/s)  avg LR: 5.014e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 126 [ 450/625 ( 72%)]  Loss: 0.004213 (0.00427)  Time: 0.719s, 2848.99/s  (0.711s, 2879.99/s)  avg LR: 5.014e-03  iter ratio: 0.0000  Data: 0.043 (0.034)
INFO:Train: 126 [ 500/625 ( 80%)]  Loss: 0.004263 (0.00427)  Time: 0.703s, 2911.39/s  (0.711s, 2879.65/s)  avg LR: 5.014e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 126 [ 550/625 ( 88%)]  Loss: 0.004742 (0.00431)  Time: 0.703s, 2912.01/s  (0.711s, 2882.27/s)  avg LR: 5.014e-03  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 126 [ 600/625 ( 96%)]  Loss: 0.004751 (0.00434)  Time: 0.702s, 2916.79/s  (0.710s, 2884.23/s)  avg LR: 5.014e-03  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 126 [ 624/625 (100%)]  Loss: 0.003846 (0.00431)  Time: 0.675s, 3034.56/s  (0.710s, 2886.01/s)  avg LR: 5.014e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.379 (4.379)  Loss:  1.1602 (1.1602)  Acc@1: 75.3906 (75.3906)  Acc@5: 91.8457 (91.8457)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.9727 (1.5948)  Acc@1: 78.4198 (64.9520)  Acc@5: 93.2783 (86.7280)
INFO:126-epoch: remaining time 23.41 h
INFO:Train: 127 [   0/625 (  0%)]  Loss: 0.003764 (0.00376)  Time: 4.335s,  472.41/s  (4.335s,  472.41/s)  avg LR: 4.973e-03  iter ratio: 0.0000  Data: 3.640 (3.640)
INFO:Train: 127 [  50/625 (  8%)]  Loss: 0.004942 (0.00435)  Time: 0.707s, 2896.53/s  (0.776s, 2639.74/s)  avg LR: 4.973e-03  iter ratio: 0.0000  Data: 0.030 (0.098)
INFO:Train: 127 [ 100/625 ( 16%)]  Loss: 0.004229 (0.00431)  Time: 0.706s, 2902.10/s  (0.740s, 2766.35/s)  avg LR: 4.973e-03  iter ratio: 0.0000  Data: 0.031 (0.063)
INFO:Train: 127 [ 150/625 ( 24%)]  Loss: 0.004681 (0.00440)  Time: 0.703s, 2913.08/s  (0.728s, 2813.42/s)  avg LR: 4.973e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 127 [ 200/625 ( 32%)]  Loss: 0.003554 (0.00423)  Time: 0.700s, 2925.49/s  (0.721s, 2838.86/s)  avg LR: 4.973e-03  iter ratio: 0.0000  Data: 0.026 (0.045)
INFO:Train: 127 [ 250/625 ( 40%)]  Loss: 0.003958 (0.00419)  Time: 0.701s, 2921.28/s  (0.718s, 2852.15/s)  avg LR: 4.973e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 127 [ 300/625 ( 48%)]  Loss: 0.004062 (0.00417)  Time: 0.718s, 2854.04/s  (0.717s, 2857.92/s)  avg LR: 4.973e-03  iter ratio: 0.0000  Data: 0.042 (0.040)
INFO:Train: 127 [ 350/625 ( 56%)]  Loss: 0.004593 (0.00422)  Time: 0.721s, 2838.83/s  (0.717s, 2857.17/s)  avg LR: 4.973e-03  iter ratio: 0.0000  Data: 0.045 (0.040)
INFO:Train: 127 [ 400/625 ( 64%)]  Loss: 0.004271 (0.00423)  Time: 0.702s, 2917.42/s  (0.716s, 2859.99/s)  avg LR: 4.973e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 127 [ 450/625 ( 72%)]  Loss: 0.004713 (0.00428)  Time: 0.703s, 2913.68/s  (0.715s, 2865.37/s)  avg LR: 4.973e-03  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 127 [ 500/625 ( 80%)]  Loss: 0.003922 (0.00424)  Time: 0.709s, 2887.10/s  (0.714s, 2868.61/s)  avg LR: 4.973e-03  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 127 [ 550/625 ( 88%)]  Loss: 0.004043 (0.00423)  Time: 0.708s, 2893.08/s  (0.713s, 2871.81/s)  avg LR: 4.973e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 127 [ 600/625 ( 96%)]  Loss: 0.004440 (0.00424)  Time: 0.702s, 2916.58/s  (0.712s, 2874.49/s)  avg LR: 4.973e-03  iter ratio: 0.0000  Data: 0.021 (0.034)
INFO:Train: 127 [ 624/625 (100%)]  Loss: 0.004419 (0.00426)  Time: 0.674s, 3039.35/s  (0.712s, 2876.03/s)  avg LR: 4.973e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.356 (4.356)  Loss:  1.1064 (1.1064)  Acc@1: 75.6348 (75.6348)  Acc@5: 91.8945 (91.8945)
INFO:Test: [  24/24]  Time: 0.080 (0.507)  Loss:  0.9639 (1.5636)  Acc@1: 77.9481 (65.3040)  Acc@5: 92.8066 (87.1360)
INFO:127-epoch: remaining time 23.37 h
INFO:Train: 128 [   0/625 (  0%)]  Loss: 0.004735 (0.00474)  Time: 4.161s,  492.17/s  (4.161s,  492.17/s)  avg LR: 4.933e-03  iter ratio: 0.0000  Data: 3.473 (3.473)
INFO:Train: 128 [  50/625 (  8%)]  Loss: 0.004694 (0.00471)  Time: 0.701s, 2921.10/s  (0.777s, 2637.02/s)  avg LR: 4.933e-03  iter ratio: 0.0000  Data: 0.025 (0.098)
INFO:Train: 128 [ 100/625 ( 16%)]  Loss: 0.003759 (0.00440)  Time: 0.701s, 2920.39/s  (0.740s, 2767.92/s)  avg LR: 4.933e-03  iter ratio: 0.0000  Data: 0.024 (0.062)
INFO:Train: 128 [ 150/625 ( 24%)]  Loss: 0.003943 (0.00428)  Time: 0.702s, 2915.72/s  (0.728s, 2812.94/s)  avg LR: 4.933e-03  iter ratio: 0.0000  Data: 0.022 (0.051)
INFO:Train: 128 [ 200/625 ( 32%)]  Loss: 0.004674 (0.00436)  Time: 0.703s, 2913.30/s  (0.721s, 2838.71/s)  avg LR: 4.933e-03  iter ratio: 0.0000  Data: 0.024 (0.045)
INFO:Train: 128 [ 250/625 ( 40%)]  Loss: 0.003722 (0.00425)  Time: 0.697s, 2936.78/s  (0.718s, 2853.62/s)  avg LR: 4.933e-03  iter ratio: 0.0000  Data: 0.023 (0.041)
INFO:Train: 128 [ 300/625 ( 48%)]  Loss: 0.004740 (0.00432)  Time: 0.698s, 2934.54/s  (0.715s, 2864.56/s)  avg LR: 4.933e-03  iter ratio: 0.0000  Data: 0.024 (0.039)
INFO:Train: 128 [ 350/625 ( 56%)]  Loss: 0.004140 (0.00430)  Time: 0.710s, 2883.86/s  (0.713s, 2871.85/s)  avg LR: 4.933e-03  iter ratio: 0.0000  Data: 0.032 (0.037)
INFO:Train: 128 [ 400/625 ( 64%)]  Loss: 0.004440 (0.00432)  Time: 0.699s, 2930.08/s  (0.712s, 2877.61/s)  avg LR: 4.933e-03  iter ratio: 0.0000  Data: 0.023 (0.036)
INFO:Train: 128 [ 450/625 ( 72%)]  Loss: 0.004861 (0.00437)  Time: 0.697s, 2939.26/s  (0.711s, 2881.16/s)  avg LR: 4.933e-03  iter ratio: 0.0000  Data: 0.023 (0.035)
INFO:Train: 128 [ 500/625 ( 80%)]  Loss: 0.004819 (0.00441)  Time: 0.698s, 2932.91/s  (0.710s, 2883.88/s)  avg LR: 4.933e-03  iter ratio: 0.0000  Data: 0.022 (0.034)
INFO:Train: 128 [ 550/625 ( 88%)]  Loss: 0.003809 (0.00436)  Time: 0.700s, 2925.97/s  (0.710s, 2886.19/s)  avg LR: 4.933e-03  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 128 [ 600/625 ( 96%)]  Loss: 0.004103 (0.00434)  Time: 0.699s, 2931.48/s  (0.709s, 2888.53/s)  avg LR: 4.933e-03  iter ratio: 0.0000  Data: 0.024 (0.033)
INFO:Train: 128 [ 624/625 (100%)]  Loss: 0.003980 (0.00432)  Time: 0.676s, 3028.97/s  (0.709s, 2890.09/s)  avg LR: 4.933e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.345 (4.345)  Loss:  1.1445 (1.1445)  Acc@1: 75.8789 (75.8789)  Acc@5: 91.6992 (91.6992)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  1.0381 (1.5834)  Acc@1: 78.1840 (65.0720)  Acc@5: 90.8019 (86.4660)
INFO:128-epoch: remaining time 23.14 h
INFO:Train: 129 [   0/625 (  0%)]  Loss: 0.003385 (0.00339)  Time: 4.384s,  467.20/s  (4.384s,  467.20/s)  avg LR: 4.892e-03  iter ratio: 0.0000  Data: 3.692 (3.692)
INFO:Train: 129 [  50/625 (  8%)]  Loss: 0.004490 (0.00394)  Time: 0.715s, 2862.67/s  (0.777s, 2636.88/s)  avg LR: 4.892e-03  iter ratio: 0.0000  Data: 0.041 (0.100)
INFO:Train: 129 [ 100/625 ( 16%)]  Loss: 0.004194 (0.00402)  Time: 0.706s, 2900.04/s  (0.741s, 2763.59/s)  avg LR: 4.892e-03  iter ratio: 0.0000  Data: 0.031 (0.064)
INFO:Train: 129 [ 150/625 ( 24%)]  Loss: 0.003950 (0.00400)  Time: 0.699s, 2929.51/s  (0.729s, 2810.31/s)  avg LR: 4.892e-03  iter ratio: 0.0000  Data: 0.024 (0.052)
INFO:Train: 129 [ 200/625 ( 32%)]  Loss: 0.004662 (0.00414)  Time: 0.711s, 2879.56/s  (0.722s, 2836.24/s)  avg LR: 4.892e-03  iter ratio: 0.0000  Data: 0.031 (0.046)
INFO:Train: 129 [ 250/625 ( 40%)]  Loss: 0.003627 (0.00405)  Time: 0.702s, 2917.55/s  (0.718s, 2850.91/s)  avg LR: 4.892e-03  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 129 [ 300/625 ( 48%)]  Loss: 0.004297 (0.00409)  Time: 0.700s, 2924.01/s  (0.716s, 2860.65/s)  avg LR: 4.892e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 129 [ 350/625 ( 56%)]  Loss: 0.003767 (0.00405)  Time: 0.703s, 2913.25/s  (0.714s, 2867.68/s)  avg LR: 4.892e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 129 [ 400/625 ( 64%)]  Loss: 0.004178 (0.00406)  Time: 0.704s, 2909.06/s  (0.713s, 2872.48/s)  avg LR: 4.892e-03  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 129 [ 450/625 ( 72%)]  Loss: 0.003381 (0.00399)  Time: 0.706s, 2902.86/s  (0.712s, 2876.54/s)  avg LR: 4.892e-03  iter ratio: 0.0000  Data: 0.031 (0.036)
INFO:Train: 129 [ 500/625 ( 80%)]  Loss: 0.003840 (0.00398)  Time: 0.697s, 2936.90/s  (0.711s, 2879.76/s)  avg LR: 4.892e-03  iter ratio: 0.0000  Data: 0.023 (0.035)
INFO:Train: 129 [ 550/625 ( 88%)]  Loss: 0.005372 (0.00410)  Time: 0.704s, 2907.30/s  (0.710s, 2882.73/s)  avg LR: 4.892e-03  iter ratio: 0.0000  Data: 0.031 (0.034)
INFO:Train: 129 [ 600/625 ( 96%)]  Loss: 0.003774 (0.00407)  Time: 0.713s, 2872.17/s  (0.710s, 2885.04/s)  avg LR: 4.892e-03  iter ratio: 0.0000  Data: 0.036 (0.034)
INFO:Train: 129 [ 624/625 (100%)]  Loss: 0.004686 (0.00411)  Time: 0.674s, 3039.55/s  (0.710s, 2886.25/s)  avg LR: 4.892e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.411 (4.411)  Loss:  0.9717 (0.9717)  Acc@1: 78.9062 (78.9062)  Acc@5: 93.6035 (93.6035)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.7417 (1.4400)  Acc@1: 82.6651 (67.8380)  Acc@5: 95.5189 (88.5140)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-129.pth.tar', 67.83800009765625)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-125.pth.tar', 66.40400002929688)

INFO:129-epoch: remaining time 23.08 h
INFO:Train: 130 [   0/625 (  0%)]  Loss: 0.004716 (0.00472)  Time: 4.290s,  477.36/s  (4.290s,  477.36/s)  avg LR: 4.851e-03  iter ratio: 0.0000  Data: 3.605 (3.605)
INFO:Train: 130 [  50/625 (  8%)]  Loss: 0.004476 (0.00460)  Time: 0.698s, 2935.98/s  (0.774s, 2644.33/s)  avg LR: 4.851e-03  iter ratio: 0.0000  Data: 0.020 (0.098)
INFO:Train: 130 [ 100/625 ( 16%)]  Loss: 0.003885 (0.00436)  Time: 0.698s, 2935.31/s  (0.742s, 2758.54/s)  avg LR: 4.851e-03  iter ratio: 0.0000  Data: 0.022 (0.065)
INFO:Train: 130 [ 150/625 ( 24%)]  Loss: 0.004018 (0.00427)  Time: 0.700s, 2927.17/s  (0.730s, 2806.39/s)  avg LR: 4.851e-03  iter ratio: 0.0000  Data: 0.024 (0.053)
INFO:Train: 130 [ 200/625 ( 32%)]  Loss: 0.004102 (0.00424)  Time: 0.698s, 2935.92/s  (0.723s, 2833.23/s)  avg LR: 4.851e-03  iter ratio: 0.0000  Data: 0.024 (0.046)
INFO:Train: 130 [ 250/625 ( 40%)]  Loss: 0.004449 (0.00427)  Time: 0.701s, 2922.58/s  (0.719s, 2847.04/s)  avg LR: 4.851e-03  iter ratio: 0.0000  Data: 0.023 (0.043)
INFO:Train: 130 [ 300/625 ( 48%)]  Loss: 0.004544 (0.00431)  Time: 0.697s, 2936.86/s  (0.717s, 2857.38/s)  avg LR: 4.851e-03  iter ratio: 0.0000  Data: 0.022 (0.040)
INFO:Train: 130 [ 350/625 ( 56%)]  Loss: 0.004180 (0.00430)  Time: 0.701s, 2919.50/s  (0.715s, 2865.08/s)  avg LR: 4.851e-03  iter ratio: 0.0000  Data: 0.024 (0.039)
INFO:Train: 130 [ 400/625 ( 64%)]  Loss: 0.004224 (0.00429)  Time: 0.698s, 2934.15/s  (0.713s, 2870.83/s)  avg LR: 4.851e-03  iter ratio: 0.0000  Data: 0.022 (0.037)
INFO:Train: 130 [ 450/625 ( 72%)]  Loss: 0.005191 (0.00438)  Time: 0.704s, 2907.57/s  (0.712s, 2875.48/s)  avg LR: 4.851e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 130 [ 500/625 ( 80%)]  Loss: 0.003797 (0.00433)  Time: 0.702s, 2917.18/s  (0.712s, 2877.97/s)  avg LR: 4.851e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 130 [ 550/625 ( 88%)]  Loss: 0.004185 (0.00431)  Time: 0.705s, 2904.05/s  (0.711s, 2880.73/s)  avg LR: 4.851e-03  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 130 [ 600/625 ( 96%)]  Loss: 0.004021 (0.00429)  Time: 0.700s, 2926.73/s  (0.710s, 2882.79/s)  avg LR: 4.851e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 130 [ 624/625 (100%)]  Loss: 0.003744 (0.00425)  Time: 0.675s, 3035.38/s  (0.710s, 2884.34/s)  avg LR: 4.851e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.443 (4.443)  Loss:  1.0225 (1.0225)  Acc@1: 77.0996 (77.0996)  Acc@5: 92.9199 (92.9199)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.8418 (1.4719)  Acc@1: 80.1887 (66.8000)  Acc@5: 94.6934 (87.8240)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-129.pth.tar', 67.83800009765625)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-130.pth.tar', 66.80000005615234)

INFO:130-epoch: remaining time 22.92 h
INFO:Train: 131 [   0/625 (  0%)]  Loss: 0.004179 (0.00418)  Time: 4.184s,  489.53/s  (4.184s,  489.53/s)  avg LR: 4.811e-03  iter ratio: 0.0000  Data: 3.492 (3.492)
INFO:Train: 131 [  50/625 (  8%)]  Loss: 0.004123 (0.00415)  Time: 0.699s, 2929.84/s  (0.776s, 2638.01/s)  avg LR: 4.811e-03  iter ratio: 0.0000  Data: 0.025 (0.099)
INFO:Train: 131 [ 100/625 ( 16%)]  Loss: 0.004154 (0.00415)  Time: 0.699s, 2930.74/s  (0.740s, 2767.49/s)  avg LR: 4.811e-03  iter ratio: 0.0000  Data: 0.022 (0.063)
INFO:Train: 131 [ 150/625 ( 24%)]  Loss: 0.004099 (0.00414)  Time: 0.704s, 2907.03/s  (0.728s, 2813.14/s)  avg LR: 4.811e-03  iter ratio: 0.0000  Data: 0.024 (0.052)
INFO:Train: 131 [ 200/625 ( 32%)]  Loss: 0.004051 (0.00412)  Time: 0.701s, 2920.10/s  (0.721s, 2839.59/s)  avg LR: 4.811e-03  iter ratio: 0.0000  Data: 0.026 (0.045)
INFO:Train: 131 [ 250/625 ( 40%)]  Loss: 0.004241 (0.00414)  Time: 0.704s, 2907.30/s  (0.718s, 2853.76/s)  avg LR: 4.811e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 131 [ 300/625 ( 48%)]  Loss: 0.004695 (0.00422)  Time: 0.700s, 2925.19/s  (0.715s, 2863.54/s)  avg LR: 4.811e-03  iter ratio: 0.0000  Data: 0.023 (0.039)
INFO:Train: 131 [ 350/625 ( 56%)]  Loss: 0.004172 (0.00421)  Time: 0.724s, 2829.24/s  (0.715s, 2865.37/s)  avg LR: 4.811e-03  iter ratio: 0.0000  Data: 0.050 (0.039)
INFO:Train: 131 [ 400/625 ( 64%)]  Loss: 0.004160 (0.00421)  Time: 0.716s, 2861.05/s  (0.715s, 2864.30/s)  avg LR: 4.811e-03  iter ratio: 0.0000  Data: 0.043 (0.039)
INFO:Train: 131 [ 450/625 ( 72%)]  Loss: 0.004687 (0.00426)  Time: 0.717s, 2857.31/s  (0.715s, 2863.40/s)  avg LR: 4.811e-03  iter ratio: 0.0000  Data: 0.044 (0.040)
INFO:Train: 131 [ 500/625 ( 80%)]  Loss: 0.004306 (0.00426)  Time: 0.721s, 2839.22/s  (0.715s, 2863.63/s)  avg LR: 4.811e-03  iter ratio: 0.0000  Data: 0.047 (0.040)
INFO:Train: 131 [ 550/625 ( 88%)]  Loss: 0.004020 (0.00424)  Time: 0.719s, 2846.77/s  (0.715s, 2862.83/s)  avg LR: 4.811e-03  iter ratio: 0.0000  Data: 0.046 (0.040)
INFO:Train: 131 [ 600/625 ( 96%)]  Loss: 0.004680 (0.00427)  Time: 0.701s, 2921.33/s  (0.715s, 2866.00/s)  avg LR: 4.811e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 131 [ 624/625 (100%)]  Loss: 0.003754 (0.00424)  Time: 0.674s, 3039.24/s  (0.714s, 2868.20/s)  avg LR: 4.811e-03  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.429 (4.429)  Loss:  1.1055 (1.1055)  Acc@1: 75.5371 (75.5371)  Acc@5: 90.7715 (90.7715)
INFO:Test: [  24/24]  Time: 0.080 (0.502)  Loss:  0.9888 (1.4834)  Acc@1: 77.2406 (66.0320)  Acc@5: 91.9811 (87.2100)
INFO:131-epoch: remaining time 22.96 h
INFO:Train: 132 [   0/625 (  0%)]  Loss: 0.004113 (0.00411)  Time: 4.041s,  506.81/s  (4.041s,  506.81/s)  avg LR: 4.770e-03  iter ratio: 0.0000  Data: 3.356 (3.356)
INFO:Train: 132 [  50/625 (  8%)]  Loss: 0.004177 (0.00414)  Time: 0.698s, 2934.46/s  (0.768s, 2664.98/s)  avg LR: 4.770e-03  iter ratio: 0.0000  Data: 0.022 (0.092)
INFO:Train: 132 [ 100/625 ( 16%)]  Loss: 0.003730 (0.00401)  Time: 0.700s, 2923.65/s  (0.736s, 2783.32/s)  avg LR: 4.770e-03  iter ratio: 0.0000  Data: 0.024 (0.060)
INFO:Train: 132 [ 150/625 ( 24%)]  Loss: 0.004318 (0.00408)  Time: 0.702s, 2917.93/s  (0.725s, 2823.90/s)  avg LR: 4.770e-03  iter ratio: 0.0000  Data: 0.028 (0.049)
INFO:Train: 132 [ 200/625 ( 32%)]  Loss: 0.004038 (0.00408)  Time: 0.707s, 2898.19/s  (0.720s, 2844.15/s)  avg LR: 4.770e-03  iter ratio: 0.0000  Data: 0.033 (0.044)
INFO:Train: 132 [ 250/625 ( 40%)]  Loss: 0.005406 (0.00430)  Time: 0.701s, 2921.35/s  (0.717s, 2857.25/s)  avg LR: 4.770e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 132 [ 300/625 ( 48%)]  Loss: 0.003749 (0.00422)  Time: 0.707s, 2897.60/s  (0.714s, 2866.45/s)  avg LR: 4.770e-03  iter ratio: 0.0000  Data: 0.032 (0.038)
INFO:Train: 132 [ 350/625 ( 56%)]  Loss: 0.004388 (0.00424)  Time: 0.701s, 2920.50/s  (0.713s, 2872.89/s)  avg LR: 4.770e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 132 [ 400/625 ( 64%)]  Loss: 0.003717 (0.00418)  Time: 0.704s, 2907.36/s  (0.712s, 2877.47/s)  avg LR: 4.770e-03  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 132 [ 450/625 ( 72%)]  Loss: 0.003803 (0.00414)  Time: 0.702s, 2915.42/s  (0.711s, 2881.62/s)  avg LR: 4.770e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 132 [ 500/625 ( 80%)]  Loss: 0.004578 (0.00418)  Time: 0.701s, 2921.21/s  (0.710s, 2883.46/s)  avg LR: 4.770e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 132 [ 550/625 ( 88%)]  Loss: 0.004671 (0.00422)  Time: 0.706s, 2901.32/s  (0.710s, 2886.48/s)  avg LR: 4.770e-03  iter ratio: 0.0000  Data: 0.031 (0.033)
INFO:Train: 132 [ 600/625 ( 96%)]  Loss: 0.003700 (0.00418)  Time: 0.715s, 2864.64/s  (0.709s, 2888.20/s)  avg LR: 4.770e-03  iter ratio: 0.0000  Data: 0.038 (0.033)
INFO:Train: 132 [ 624/625 (100%)]  Loss: 0.004230 (0.00419)  Time: 0.676s, 3030.59/s  (0.709s, 2889.23/s)  avg LR: 4.770e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.370 (4.370)  Loss:  0.9639 (0.9639)  Acc@1: 79.1016 (79.1016)  Acc@5: 93.4082 (93.4082)
INFO:Test: [  24/24]  Time: 0.080 (0.507)  Loss:  0.9521 (1.4630)  Acc@1: 79.3632 (67.9440)  Acc@5: 93.0424 (88.4580)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-132.pth.tar', 67.94399995605468)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-129.pth.tar', 67.83800009765625)

INFO:132-epoch: remaining time 22.63 h
INFO:Train: 133 [   0/625 (  0%)]  Loss: 0.004472 (0.00447)  Time: 3.900s,  525.18/s  (3.900s,  525.18/s)  avg LR: 4.729e-03  iter ratio: 0.0000  Data: 3.202 (3.202)
INFO:Train: 133 [  50/625 (  8%)]  Loss: 0.003646 (0.00406)  Time: 0.719s, 2850.24/s  (0.768s, 2665.96/s)  avg LR: 4.729e-03  iter ratio: 0.0000  Data: 0.040 (0.088)
INFO:Train: 133 [ 100/625 ( 16%)]  Loss: 0.004524 (0.00421)  Time: 0.706s, 2901.01/s  (0.736s, 2782.69/s)  avg LR: 4.729e-03  iter ratio: 0.0000  Data: 0.031 (0.058)
INFO:Train: 133 [ 150/625 ( 24%)]  Loss: 0.003766 (0.00410)  Time: 0.711s, 2882.41/s  (0.725s, 2822.90/s)  avg LR: 4.729e-03  iter ratio: 0.0000  Data: 0.032 (0.048)
INFO:Train: 133 [ 200/625 ( 32%)]  Loss: 0.004588 (0.00420)  Time: 0.708s, 2891.55/s  (0.720s, 2843.18/s)  avg LR: 4.729e-03  iter ratio: 0.0000  Data: 0.034 (0.043)
INFO:Train: 133 [ 250/625 ( 40%)]  Loss: 0.004416 (0.00424)  Time: 0.708s, 2892.17/s  (0.718s, 2854.26/s)  avg LR: 4.729e-03  iter ratio: 0.0000  Data: 0.033 (0.040)
INFO:Train: 133 [ 300/625 ( 48%)]  Loss: 0.004355 (0.00425)  Time: 0.701s, 2919.91/s  (0.715s, 2863.86/s)  avg LR: 4.729e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 133 [ 350/625 ( 56%)]  Loss: 0.004115 (0.00424)  Time: 0.705s, 2906.69/s  (0.714s, 2870.17/s)  avg LR: 4.729e-03  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 133 [ 400/625 ( 64%)]  Loss: 0.004178 (0.00423)  Time: 0.704s, 2909.33/s  (0.712s, 2875.62/s)  avg LR: 4.729e-03  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 133 [ 450/625 ( 72%)]  Loss: 0.003990 (0.00420)  Time: 0.721s, 2842.25/s  (0.711s, 2878.57/s)  avg LR: 4.729e-03  iter ratio: 0.0000  Data: 0.046 (0.035)
INFO:Train: 133 [ 500/625 ( 80%)]  Loss: 0.003832 (0.00417)  Time: 0.708s, 2891.06/s  (0.711s, 2882.16/s)  avg LR: 4.729e-03  iter ratio: 0.0000  Data: 0.032 (0.034)
INFO:Train: 133 [ 550/625 ( 88%)]  Loss: 0.003895 (0.00415)  Time: 0.716s, 2862.18/s  (0.710s, 2884.65/s)  avg LR: 4.729e-03  iter ratio: 0.0000  Data: 0.040 (0.034)
INFO:Train: 133 [ 600/625 ( 96%)]  Loss: 0.005129 (0.00422)  Time: 0.706s, 2899.96/s  (0.709s, 2886.85/s)  avg LR: 4.729e-03  iter ratio: 0.0000  Data: 0.030 (0.033)
INFO:Train: 133 [ 624/625 (100%)]  Loss: 0.004609 (0.00425)  Time: 0.674s, 3037.56/s  (0.709s, 2888.21/s)  avg LR: 4.729e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.364 (4.364)  Loss:  1.1367 (1.1367)  Acc@1: 76.9043 (76.9043)  Acc@5: 91.6992 (91.6992)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.8945 (1.4776)  Acc@1: 80.3066 (67.6600)  Acc@5: 93.9859 (88.2380)
INFO:133-epoch: remaining time 22.52 h
INFO:Train: 134 [   0/625 (  0%)]  Loss: 0.003946 (0.00395)  Time: 4.242s,  482.75/s  (4.242s,  482.75/s)  avg LR: 4.688e-03  iter ratio: 0.0000  Data: 3.555 (3.555)
INFO:Train: 134 [  50/625 (  8%)]  Loss: 0.004126 (0.00404)  Time: 0.701s, 2920.75/s  (0.779s, 2627.38/s)  avg LR: 4.688e-03  iter ratio: 0.0000  Data: 0.026 (0.101)
INFO:Train: 134 [ 100/625 ( 16%)]  Loss: 0.003666 (0.00391)  Time: 0.706s, 2900.14/s  (0.742s, 2759.70/s)  avg LR: 4.688e-03  iter ratio: 0.0000  Data: 0.032 (0.065)
INFO:Train: 134 [ 150/625 ( 24%)]  Loss: 0.003886 (0.00391)  Time: 0.701s, 2920.35/s  (0.730s, 2807.25/s)  avg LR: 4.688e-03  iter ratio: 0.0000  Data: 0.025 (0.053)
INFO:Train: 134 [ 200/625 ( 32%)]  Loss: 0.003292 (0.00378)  Time: 0.700s, 2926.45/s  (0.723s, 2834.22/s)  avg LR: 4.688e-03  iter ratio: 0.0000  Data: 0.028 (0.046)
INFO:Train: 134 [ 250/625 ( 40%)]  Loss: 0.004225 (0.00386)  Time: 0.704s, 2909.54/s  (0.719s, 2849.59/s)  avg LR: 4.688e-03  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 134 [ 300/625 ( 48%)]  Loss: 0.003553 (0.00381)  Time: 0.702s, 2918.53/s  (0.716s, 2859.81/s)  avg LR: 4.688e-03  iter ratio: 0.0000  Data: 0.023 (0.040)
INFO:Train: 134 [ 350/625 ( 56%)]  Loss: 0.003594 (0.00379)  Time: 0.716s, 2861.94/s  (0.716s, 2861.49/s)  avg LR: 4.688e-03  iter ratio: 0.0000  Data: 0.038 (0.040)
INFO:Train: 134 [ 400/625 ( 64%)]  Loss: 0.003931 (0.00380)  Time: 0.716s, 2859.40/s  (0.716s, 2860.84/s)  avg LR: 4.688e-03  iter ratio: 0.0000  Data: 0.043 (0.040)
INFO:Train: 134 [ 450/625 ( 72%)]  Loss: 0.004645 (0.00389)  Time: 0.717s, 2856.78/s  (0.716s, 2860.46/s)  avg LR: 4.688e-03  iter ratio: 0.0000  Data: 0.043 (0.040)
INFO:Train: 134 [ 500/625 ( 80%)]  Loss: 0.003998 (0.00390)  Time: 0.701s, 2920.45/s  (0.716s, 2861.27/s)  avg LR: 4.688e-03  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 134 [ 550/625 ( 88%)]  Loss: 0.004467 (0.00394)  Time: 0.713s, 2871.03/s  (0.716s, 2861.15/s)  avg LR: 4.688e-03  iter ratio: 0.0000  Data: 0.037 (0.040)
INFO:Train: 134 [ 600/625 ( 96%)]  Loss: 0.003612 (0.00392)  Time: 0.711s, 2879.03/s  (0.716s, 2860.91/s)  avg LR: 4.688e-03  iter ratio: 0.0000  Data: 0.036 (0.040)
INFO:Train: 134 [ 624/625 (100%)]  Loss: 0.004067 (0.00393)  Time: 0.674s, 3037.29/s  (0.715s, 2863.11/s)  avg LR: 4.688e-03  iter ratio: 0.0000  Data: 0.000 (0.040)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.343 (4.343)  Loss:  0.9146 (0.9146)  Acc@1: 79.6387 (79.6387)  Acc@5: 93.7500 (93.7500)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  1.1113 (1.4799)  Acc@1: 75.9434 (67.1200)  Acc@5: 90.8019 (87.7520)
INFO:134-epoch: remaining time 22.57 h
INFO:Train: 135 [   0/625 (  0%)]  Loss: 0.004016 (0.00402)  Time: 4.118s,  497.28/s  (4.118s,  497.28/s)  avg LR: 4.647e-03  iter ratio: 0.0000  Data: 3.423 (3.423)
INFO:Train: 135 [  50/625 (  8%)]  Loss: 0.003673 (0.00384)  Time: 0.705s, 2903.59/s  (0.772s, 2651.54/s)  avg LR: 4.647e-03  iter ratio: 0.0000  Data: 0.022 (0.091)
INFO:Train: 135 [ 100/625 ( 16%)]  Loss: 0.003575 (0.00375)  Time: 0.709s, 2889.92/s  (0.739s, 2770.89/s)  avg LR: 4.647e-03  iter ratio: 0.0000  Data: 0.023 (0.058)
INFO:Train: 135 [ 150/625 ( 24%)]  Loss: 0.004702 (0.00399)  Time: 0.709s, 2888.97/s  (0.728s, 2812.27/s)  avg LR: 4.647e-03  iter ratio: 0.0000  Data: 0.020 (0.047)
INFO:Train: 135 [ 200/625 ( 32%)]  Loss: 0.003358 (0.00387)  Time: 0.715s, 2863.64/s  (0.724s, 2827.43/s)  avg LR: 4.647e-03  iter ratio: 0.0000  Data: 0.041 (0.044)
INFO:Train: 135 [ 250/625 ( 40%)]  Loss: 0.003947 (0.00388)  Time: 0.700s, 2924.12/s  (0.721s, 2840.29/s)  avg LR: 4.647e-03  iter ratio: 0.0000  Data: 0.019 (0.041)
INFO:Train: 135 [ 300/625 ( 48%)]  Loss: 0.004527 (0.00397)  Time: 0.705s, 2905.30/s  (0.718s, 2850.79/s)  avg LR: 4.647e-03  iter ratio: 0.0000  Data: 0.017 (0.038)
INFO:Train: 135 [ 350/625 ( 56%)]  Loss: 0.004147 (0.00399)  Time: 0.702s, 2916.12/s  (0.717s, 2857.81/s)  avg LR: 4.647e-03  iter ratio: 0.0000  Data: 0.022 (0.036)
INFO:Train: 135 [ 400/625 ( 64%)]  Loss: 0.004068 (0.00400)  Time: 0.725s, 2824.14/s  (0.716s, 2861.12/s)  avg LR: 4.647e-03  iter ratio: 0.0000  Data: 0.052 (0.035)
INFO:Train: 135 [ 450/625 ( 72%)]  Loss: 0.004207 (0.00402)  Time: 0.708s, 2894.11/s  (0.716s, 2859.99/s)  avg LR: 4.647e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 135 [ 500/625 ( 80%)]  Loss: 0.004546 (0.00407)  Time: 0.702s, 2919.46/s  (0.715s, 2864.07/s)  avg LR: 4.647e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 135 [ 550/625 ( 88%)]  Loss: 0.004263 (0.00409)  Time: 0.702s, 2915.55/s  (0.714s, 2867.91/s)  avg LR: 4.647e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 135 [ 600/625 ( 96%)]  Loss: 0.003892 (0.00407)  Time: 0.716s, 2859.02/s  (0.714s, 2869.49/s)  avg LR: 4.647e-03  iter ratio: 0.0000  Data: 0.041 (0.035)
INFO:Train: 135 [ 624/625 (100%)]  Loss: 0.004507 (0.00410)  Time: 0.680s, 3011.25/s  (0.714s, 2869.84/s)  avg LR: 4.647e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.345 (4.345)  Loss:  1.0684 (1.0684)  Acc@1: 76.7578 (76.7578)  Acc@5: 92.0898 (92.0898)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.9360 (1.5288)  Acc@1: 78.7736 (66.4240)  Acc@5: 92.9245 (87.5720)
INFO:135-epoch: remaining time 22.42 h
INFO:Train: 136 [   0/625 (  0%)]  Loss: 0.004301 (0.00430)  Time: 4.121s,  496.92/s  (4.121s,  496.92/s)  avg LR: 4.606e-03  iter ratio: 0.0000  Data: 3.435 (3.435)
INFO:Train: 136 [  50/625 (  8%)]  Loss: 0.003780 (0.00404)  Time: 0.717s, 2858.17/s  (0.780s, 2626.44/s)  avg LR: 4.606e-03  iter ratio: 0.0000  Data: 0.041 (0.103)
INFO:Train: 136 [ 100/625 ( 16%)]  Loss: 0.004788 (0.00429)  Time: 0.718s, 2851.62/s  (0.750s, 2732.08/s)  avg LR: 4.606e-03  iter ratio: 0.0000  Data: 0.044 (0.074)
INFO:Train: 136 [ 150/625 ( 24%)]  Loss: 0.004081 (0.00424)  Time: 0.699s, 2928.86/s  (0.739s, 2772.33/s)  avg LR: 4.606e-03  iter ratio: 0.0000  Data: 0.025 (0.063)
INFO:Train: 136 [ 200/625 ( 32%)]  Loss: 0.003976 (0.00419)  Time: 0.709s, 2888.54/s  (0.733s, 2793.09/s)  avg LR: 4.606e-03  iter ratio: 0.0000  Data: 0.035 (0.058)
INFO:Train: 136 [ 250/625 ( 40%)]  Loss: 0.003498 (0.00407)  Time: 0.704s, 2907.38/s  (0.728s, 2814.65/s)  avg LR: 4.606e-03  iter ratio: 0.0000  Data: 0.029 (0.052)
INFO:Train: 136 [ 300/625 ( 48%)]  Loss: 0.003789 (0.00403)  Time: 0.706s, 2900.63/s  (0.723s, 2831.51/s)  avg LR: 4.606e-03  iter ratio: 0.0000  Data: 0.032 (0.048)
INFO:Train: 136 [ 350/625 ( 56%)]  Loss: 0.003791 (0.00400)  Time: 0.707s, 2895.22/s  (0.721s, 2842.37/s)  avg LR: 4.606e-03  iter ratio: 0.0000  Data: 0.032 (0.045)
INFO:Train: 136 [ 400/625 ( 64%)]  Loss: 0.003748 (0.00397)  Time: 0.702s, 2916.58/s  (0.718s, 2850.77/s)  avg LR: 4.606e-03  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 136 [ 450/625 ( 72%)]  Loss: 0.004270 (0.00400)  Time: 0.720s, 2844.64/s  (0.717s, 2855.43/s)  avg LR: 4.606e-03  iter ratio: 0.0000  Data: 0.046 (0.041)
INFO:Train: 136 [ 500/625 ( 80%)]  Loss: 0.004753 (0.00407)  Time: 0.718s, 2853.83/s  (0.717s, 2855.78/s)  avg LR: 4.606e-03  iter ratio: 0.0000  Data: 0.044 (0.042)
INFO:Train: 136 [ 550/625 ( 88%)]  Loss: 0.003530 (0.00403)  Time: 0.723s, 2832.68/s  (0.717s, 2855.89/s)  avg LR: 4.606e-03  iter ratio: 0.0000  Data: 0.049 (0.042)
INFO:Train: 136 [ 600/625 ( 96%)]  Loss: 0.003545 (0.00399)  Time: 0.719s, 2847.35/s  (0.717s, 2856.09/s)  avg LR: 4.606e-03  iter ratio: 0.0000  Data: 0.046 (0.042)
INFO:Train: 136 [ 624/625 (100%)]  Loss: 0.004834 (0.00405)  Time: 0.675s, 3035.75/s  (0.717s, 2856.81/s)  avg LR: 4.606e-03  iter ratio: 0.0000  Data: 0.000 (0.042)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.410 (4.410)  Loss:  0.9751 (0.9751)  Acc@1: 78.8574 (78.8574)  Acc@5: 93.1152 (93.1152)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.9243 (1.4287)  Acc@1: 77.3585 (67.4580)  Acc@5: 92.6887 (88.0320)
INFO:136-epoch: remaining time 22.36 h
INFO:Train: 137 [   0/625 (  0%)]  Loss: 0.004401 (0.00440)  Time: 4.126s,  496.36/s  (4.126s,  496.36/s)  avg LR: 4.564e-03  iter ratio: 0.0000  Data: 3.428 (3.428)
INFO:Train: 137 [  50/625 (  8%)]  Loss: 0.003887 (0.00414)  Time: 0.704s, 2910.47/s  (0.777s, 2637.32/s)  avg LR: 4.564e-03  iter ratio: 0.0000  Data: 0.024 (0.098)
INFO:Train: 137 [ 100/625 ( 16%)]  Loss: 0.003760 (0.00402)  Time: 0.699s, 2931.67/s  (0.741s, 2765.35/s)  avg LR: 4.564e-03  iter ratio: 0.0000  Data: 0.023 (0.063)
INFO:Train: 137 [ 150/625 ( 24%)]  Loss: 0.004260 (0.00408)  Time: 0.715s, 2865.71/s  (0.730s, 2804.86/s)  avg LR: 4.564e-03  iter ratio: 0.0000  Data: 0.040 (0.053)
INFO:Train: 137 [ 200/625 ( 32%)]  Loss: 0.004261 (0.00411)  Time: 0.715s, 2865.67/s  (0.727s, 2817.39/s)  avg LR: 4.564e-03  iter ratio: 0.0000  Data: 0.040 (0.051)
INFO:Train: 137 [ 250/625 ( 40%)]  Loss: 0.003702 (0.00404)  Time: 0.703s, 2911.26/s  (0.723s, 2833.99/s)  avg LR: 4.564e-03  iter ratio: 0.0000  Data: 0.027 (0.047)
INFO:Train: 137 [ 300/625 ( 48%)]  Loss: 0.003258 (0.00393)  Time: 0.699s, 2930.75/s  (0.719s, 2846.77/s)  avg LR: 4.564e-03  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 137 [ 350/625 ( 56%)]  Loss: 0.004188 (0.00396)  Time: 0.702s, 2916.78/s  (0.717s, 2856.20/s)  avg LR: 4.564e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 137 [ 400/625 ( 64%)]  Loss: 0.003811 (0.00395)  Time: 0.701s, 2921.79/s  (0.715s, 2862.56/s)  avg LR: 4.564e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 137 [ 450/625 ( 72%)]  Loss: 0.005032 (0.00406)  Time: 0.701s, 2922.83/s  (0.714s, 2868.17/s)  avg LR: 4.564e-03  iter ratio: 0.0000  Data: 0.024 (0.038)
INFO:Train: 137 [ 500/625 ( 80%)]  Loss: 0.004824 (0.00413)  Time: 0.710s, 2886.44/s  (0.713s, 2872.17/s)  avg LR: 4.564e-03  iter ratio: 0.0000  Data: 0.034 (0.037)
INFO:Train: 137 [ 550/625 ( 88%)]  Loss: 0.004308 (0.00414)  Time: 0.701s, 2920.98/s  (0.712s, 2876.18/s)  avg LR: 4.564e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 137 [ 600/625 ( 96%)]  Loss: 0.004565 (0.00417)  Time: 0.701s, 2923.45/s  (0.711s, 2879.25/s)  avg LR: 4.564e-03  iter ratio: 0.0000  Data: 0.021 (0.036)
INFO:Train: 137 [ 624/625 (100%)]  Loss: 0.003690 (0.00414)  Time: 0.674s, 3038.33/s  (0.711s, 2880.76/s)  avg LR: 4.564e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.356 (4.356)  Loss:  1.0107 (1.0107)  Acc@1: 78.3203 (78.3203)  Acc@5: 92.1387 (92.1387)
INFO:Test: [  24/24]  Time: 0.080 (0.510)  Loss:  0.9009 (1.4264)  Acc@1: 80.4245 (67.8520)  Acc@5: 93.1604 (88.4000)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-132.pth.tar', 67.94399995605468)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-137.pth.tar', 67.85200002929687)

INFO:137-epoch: remaining time 22.09 h
INFO:Train: 138 [   0/625 (  0%)]  Loss: 0.004131 (0.00413)  Time: 4.429s,  462.36/s  (4.429s,  462.36/s)  avg LR: 4.523e-03  iter ratio: 0.0000  Data: 3.746 (3.746)
INFO:Train: 138 [  50/625 (  8%)]  Loss: 0.004151 (0.00414)  Time: 0.703s, 2911.72/s  (0.776s, 2640.36/s)  avg LR: 4.523e-03  iter ratio: 0.0000  Data: 0.022 (0.099)
INFO:Train: 138 [ 100/625 ( 16%)]  Loss: 0.004898 (0.00439)  Time: 0.698s, 2934.68/s  (0.739s, 2772.83/s)  avg LR: 4.523e-03  iter ratio: 0.0000  Data: 0.023 (0.062)
INFO:Train: 138 [ 150/625 ( 24%)]  Loss: 0.003966 (0.00429)  Time: 0.696s, 2940.62/s  (0.727s, 2818.68/s)  avg LR: 4.523e-03  iter ratio: 0.0000  Data: 0.022 (0.050)
INFO:Train: 138 [ 200/625 ( 32%)]  Loss: 0.004063 (0.00424)  Time: 0.701s, 2921.41/s  (0.721s, 2842.06/s)  avg LR: 4.523e-03  iter ratio: 0.0000  Data: 0.026 (0.044)
INFO:Train: 138 [ 250/625 ( 40%)]  Loss: 0.003742 (0.00416)  Time: 0.701s, 2920.37/s  (0.717s, 2856.92/s)  avg LR: 4.523e-03  iter ratio: 0.0000  Data: 0.023 (0.041)
INFO:Train: 138 [ 300/625 ( 48%)]  Loss: 0.004637 (0.00423)  Time: 0.699s, 2929.78/s  (0.714s, 2867.91/s)  avg LR: 4.523e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 138 [ 350/625 ( 56%)]  Loss: 0.003702 (0.00416)  Time: 0.702s, 2916.81/s  (0.713s, 2873.29/s)  avg LR: 4.523e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 138 [ 400/625 ( 64%)]  Loss: 0.003763 (0.00412)  Time: 0.697s, 2937.06/s  (0.712s, 2878.29/s)  avg LR: 4.523e-03  iter ratio: 0.0000  Data: 0.023 (0.035)
INFO:Train: 138 [ 450/625 ( 72%)]  Loss: 0.003999 (0.00411)  Time: 0.714s, 2867.45/s  (0.711s, 2881.02/s)  avg LR: 4.523e-03  iter ratio: 0.0000  Data: 0.041 (0.035)
INFO:Train: 138 [ 500/625 ( 80%)]  Loss: 0.003970 (0.00409)  Time: 0.700s, 2927.48/s  (0.710s, 2883.58/s)  avg LR: 4.523e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 138 [ 550/625 ( 88%)]  Loss: 0.004058 (0.00409)  Time: 0.705s, 2905.99/s  (0.710s, 2886.17/s)  avg LR: 4.523e-03  iter ratio: 0.0000  Data: 0.029 (0.033)
INFO:Train: 138 [ 600/625 ( 96%)]  Loss: 0.003635 (0.00406)  Time: 0.712s, 2878.10/s  (0.709s, 2887.53/s)  avg LR: 4.523e-03  iter ratio: 0.0000  Data: 0.036 (0.033)
INFO:Train: 138 [ 624/625 (100%)]  Loss: 0.003984 (0.00405)  Time: 0.674s, 3038.86/s  (0.709s, 2887.35/s)  avg LR: 4.523e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.351 (4.351)  Loss:  0.9829 (0.9829)  Acc@1: 77.1973 (77.1973)  Acc@5: 92.7734 (92.7734)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.9268 (1.4801)  Acc@1: 78.5377 (66.7020)  Acc@5: 92.0991 (87.5900)
INFO:138-epoch: remaining time 21.87 h
INFO:Train: 139 [   0/625 (  0%)]  Loss: 0.004369 (0.00437)  Time: 4.006s,  511.27/s  (4.006s,  511.27/s)  avg LR: 4.482e-03  iter ratio: 0.0000  Data: 3.316 (3.316)
INFO:Train: 139 [  50/625 (  8%)]  Loss: 0.004010 (0.00419)  Time: 0.704s, 2907.12/s  (0.769s, 2664.35/s)  avg LR: 4.482e-03  iter ratio: 0.0000  Data: 0.030 (0.092)
INFO:Train: 139 [ 100/625 ( 16%)]  Loss: 0.004448 (0.00428)  Time: 0.698s, 2932.59/s  (0.736s, 2781.62/s)  avg LR: 4.482e-03  iter ratio: 0.0000  Data: 0.023 (0.059)
INFO:Train: 139 [ 150/625 ( 24%)]  Loss: 0.003316 (0.00404)  Time: 0.704s, 2911.11/s  (0.725s, 2826.06/s)  avg LR: 4.482e-03  iter ratio: 0.0000  Data: 0.027 (0.047)
INFO:Train: 139 [ 200/625 ( 32%)]  Loss: 0.004735 (0.00418)  Time: 0.704s, 2908.30/s  (0.719s, 2846.59/s)  avg LR: 4.482e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 139 [ 250/625 ( 40%)]  Loss: 0.003736 (0.00410)  Time: 0.703s, 2912.39/s  (0.716s, 2861.82/s)  avg LR: 4.482e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 139 [ 300/625 ( 48%)]  Loss: 0.003778 (0.00406)  Time: 0.700s, 2926.22/s  (0.713s, 2870.58/s)  avg LR: 4.482e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 139 [ 350/625 ( 56%)]  Loss: 0.004318 (0.00409)  Time: 0.713s, 2873.94/s  (0.712s, 2877.03/s)  avg LR: 4.482e-03  iter ratio: 0.0000  Data: 0.035 (0.035)
INFO:Train: 139 [ 400/625 ( 64%)]  Loss: 0.004291 (0.00411)  Time: 0.701s, 2920.66/s  (0.711s, 2882.09/s)  avg LR: 4.482e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 139 [ 450/625 ( 72%)]  Loss: 0.003624 (0.00406)  Time: 0.701s, 2920.93/s  (0.710s, 2886.10/s)  avg LR: 4.482e-03  iter ratio: 0.0000  Data: 0.020 (0.033)
INFO:Train: 139 [ 500/625 ( 80%)]  Loss: 0.004251 (0.00408)  Time: 0.701s, 2920.02/s  (0.709s, 2888.98/s)  avg LR: 4.482e-03  iter ratio: 0.0000  Data: 0.026 (0.032)
INFO:Train: 139 [ 550/625 ( 88%)]  Loss: 0.004875 (0.00415)  Time: 0.703s, 2912.81/s  (0.708s, 2891.49/s)  avg LR: 4.482e-03  iter ratio: 0.0000  Data: 0.023 (0.031)
INFO:Train: 139 [ 600/625 ( 96%)]  Loss: 0.004527 (0.00418)  Time: 0.700s, 2926.14/s  (0.708s, 2893.75/s)  avg LR: 4.482e-03  iter ratio: 0.0000  Data: 0.023 (0.031)
INFO:Train: 139 [ 624/625 (100%)]  Loss: 0.003605 (0.00413)  Time: 0.675s, 3035.13/s  (0.707s, 2895.33/s)  avg LR: 4.482e-03  iter ratio: 0.0000  Data: 0.000 (0.030)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.370 (4.370)  Loss:  0.9058 (0.9058)  Acc@1: 78.4180 (78.4180)  Acc@5: 94.3848 (94.3848)
INFO:Test: [  24/24]  Time: 0.080 (0.505)  Loss:  0.8447 (1.3572)  Acc@1: 80.7783 (68.7040)  Acc@5: 93.9858 (89.1140)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-139.pth.tar', 68.70400005371094)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-132.pth.tar', 67.94399995605468)

INFO:139-epoch: remaining time 21.72 h
INFO:Train: 140 [   0/625 (  0%)]  Loss: 0.004376 (0.00438)  Time: 4.228s,  484.44/s  (4.228s,  484.44/s)  avg LR: 4.441e-03  iter ratio: 0.0000  Data: 3.535 (3.535)
INFO:Train: 140 [  50/625 (  8%)]  Loss: 0.003833 (0.00410)  Time: 0.723s, 2833.12/s  (0.792s, 2586.58/s)  avg LR: 4.441e-03  iter ratio: 0.0000  Data: 0.040 (0.112)
INFO:Train: 140 [ 100/625 ( 16%)]  Loss: 0.004031 (0.00408)  Time: 0.703s, 2915.18/s  (0.753s, 2719.53/s)  avg LR: 4.441e-03  iter ratio: 0.0000  Data: 0.029 (0.076)
INFO:Train: 140 [ 150/625 ( 24%)]  Loss: 0.004036 (0.00407)  Time: 0.703s, 2914.21/s  (0.736s, 2780.94/s)  avg LR: 4.441e-03  iter ratio: 0.0000  Data: 0.029 (0.060)
INFO:Train: 140 [ 200/625 ( 32%)]  Loss: 0.003886 (0.00403)  Time: 0.703s, 2911.45/s  (0.728s, 2811.90/s)  avg LR: 4.441e-03  iter ratio: 0.0000  Data: 0.029 (0.052)
INFO:Train: 140 [ 250/625 ( 40%)]  Loss: 0.003851 (0.00400)  Time: 0.698s, 2933.14/s  (0.723s, 2832.44/s)  avg LR: 4.441e-03  iter ratio: 0.0000  Data: 0.023 (0.046)
INFO:Train: 140 [ 300/625 ( 48%)]  Loss: 0.004168 (0.00403)  Time: 0.701s, 2920.52/s  (0.720s, 2845.09/s)  avg LR: 4.441e-03  iter ratio: 0.0000  Data: 0.024 (0.043)
INFO:Train: 140 [ 350/625 ( 56%)]  Loss: 0.004321 (0.00406)  Time: 0.700s, 2926.13/s  (0.717s, 2854.61/s)  avg LR: 4.441e-03  iter ratio: 0.0000  Data: 0.024 (0.040)
INFO:Train: 140 [ 400/625 ( 64%)]  Loss: 0.003753 (0.00403)  Time: 0.701s, 2919.73/s  (0.716s, 2861.44/s)  avg LR: 4.441e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 140 [ 450/625 ( 72%)]  Loss: 0.003928 (0.00402)  Time: 0.703s, 2913.44/s  (0.715s, 2865.86/s)  avg LR: 4.441e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 140 [ 500/625 ( 80%)]  Loss: 0.003471 (0.00397)  Time: 0.720s, 2844.87/s  (0.714s, 2870.16/s)  avg LR: 4.441e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 140 [ 550/625 ( 88%)]  Loss: 0.003938 (0.00397)  Time: 0.701s, 2919.66/s  (0.713s, 2873.77/s)  avg LR: 4.441e-03  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 140 [ 600/625 ( 96%)]  Loss: 0.004251 (0.00399)  Time: 0.698s, 2935.39/s  (0.712s, 2876.99/s)  avg LR: 4.441e-03  iter ratio: 0.0000  Data: 0.021 (0.034)
INFO:Train: 140 [ 624/625 (100%)]  Loss: 0.004375 (0.00402)  Time: 0.677s, 3023.60/s  (0.711s, 2878.82/s)  avg LR: 4.441e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.375 (4.375)  Loss:  1.0537 (1.0537)  Acc@1: 75.8789 (75.8789)  Acc@5: 91.9922 (91.9922)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.9102 (1.4639)  Acc@1: 78.8915 (66.7640)  Acc@5: 92.4528 (87.6480)
INFO:140-epoch: remaining time 21.69 h
INFO:Train: 141 [   0/625 (  0%)]  Loss: 0.003955 (0.00395)  Time: 4.161s,  492.22/s  (4.161s,  492.22/s)  avg LR: 4.399e-03  iter ratio: 0.0000  Data: 3.463 (3.463)
INFO:Train: 141 [  50/625 (  8%)]  Loss: 0.004047 (0.00400)  Time: 0.719s, 2847.01/s  (0.777s, 2634.39/s)  avg LR: 4.399e-03  iter ratio: 0.0000  Data: 0.030 (0.099)
INFO:Train: 141 [ 100/625 ( 16%)]  Loss: 0.004187 (0.00406)  Time: 0.707s, 2894.96/s  (0.743s, 2758.14/s)  avg LR: 4.399e-03  iter ratio: 0.0000  Data: 0.031 (0.064)
INFO:Train: 141 [ 150/625 ( 24%)]  Loss: 0.004162 (0.00409)  Time: 0.704s, 2907.30/s  (0.729s, 2808.50/s)  avg LR: 4.399e-03  iter ratio: 0.0000  Data: 0.030 (0.051)
INFO:Train: 141 [ 200/625 ( 32%)]  Loss: 0.003535 (0.00398)  Time: 0.712s, 2875.97/s  (0.723s, 2833.63/s)  avg LR: 4.399e-03  iter ratio: 0.0000  Data: 0.034 (0.045)
INFO:Train: 141 [ 250/625 ( 40%)]  Loss: 0.003953 (0.00397)  Time: 0.701s, 2920.93/s  (0.719s, 2850.38/s)  avg LR: 4.399e-03  iter ratio: 0.0000  Data: 0.022 (0.041)
INFO:Train: 141 [ 300/625 ( 48%)]  Loss: 0.003760 (0.00394)  Time: 0.704s, 2910.22/s  (0.716s, 2860.34/s)  avg LR: 4.399e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 141 [ 350/625 ( 56%)]  Loss: 0.003643 (0.00391)  Time: 0.708s, 2894.32/s  (0.714s, 2868.09/s)  avg LR: 4.399e-03  iter ratio: 0.0000  Data: 0.032 (0.036)
INFO:Train: 141 [ 400/625 ( 64%)]  Loss: 0.004124 (0.00393)  Time: 0.699s, 2928.28/s  (0.714s, 2868.32/s)  avg LR: 4.399e-03  iter ratio: 0.0000  Data: 0.022 (0.036)
INFO:Train: 141 [ 450/625 ( 72%)]  Loss: 0.003749 (0.00391)  Time: 0.705s, 2905.96/s  (0.713s, 2873.99/s)  avg LR: 4.399e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 141 [ 500/625 ( 80%)]  Loss: 0.003240 (0.00385)  Time: 0.707s, 2896.14/s  (0.712s, 2877.86/s)  avg LR: 4.399e-03  iter ratio: 0.0000  Data: 0.022 (0.034)
INFO:Train: 141 [ 550/625 ( 88%)]  Loss: 0.004408 (0.00390)  Time: 0.713s, 2871.13/s  (0.712s, 2877.25/s)  avg LR: 4.399e-03  iter ratio: 0.0000  Data: 0.037 (0.034)
INFO:Train: 141 [ 600/625 ( 96%)]  Loss: 0.003729 (0.00388)  Time: 0.703s, 2912.70/s  (0.712s, 2877.99/s)  avg LR: 4.399e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 141 [ 624/625 (100%)]  Loss: 0.004323 (0.00392)  Time: 0.676s, 3029.41/s  (0.711s, 2879.83/s)  avg LR: 4.399e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.397 (4.397)  Loss:  1.1357 (1.1357)  Acc@1: 74.3652 (74.3652)  Acc@5: 91.0156 (91.0156)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.9644 (1.5098)  Acc@1: 78.3019 (66.5580)  Acc@5: 93.2783 (87.3140)
INFO:141-epoch: remaining time 21.56 h
INFO:Train: 142 [   0/625 (  0%)]  Loss: 0.003976 (0.00398)  Time: 4.312s,  474.92/s  (4.312s,  474.92/s)  avg LR: 4.358e-03  iter ratio: 0.0000  Data: 3.623 (3.623)
INFO:Train: 142 [  50/625 (  8%)]  Loss: 0.004398 (0.00419)  Time: 0.700s, 2926.68/s  (0.776s, 2638.49/s)  avg LR: 4.358e-03  iter ratio: 0.0000  Data: 0.025 (0.098)
INFO:Train: 142 [ 100/625 ( 16%)]  Loss: 0.004312 (0.00423)  Time: 0.704s, 2907.98/s  (0.740s, 2767.27/s)  avg LR: 4.358e-03  iter ratio: 0.0000  Data: 0.028 (0.063)
INFO:Train: 142 [ 150/625 ( 24%)]  Loss: 0.004254 (0.00423)  Time: 0.699s, 2930.49/s  (0.728s, 2813.64/s)  avg LR: 4.358e-03  iter ratio: 0.0000  Data: 0.024 (0.051)
INFO:Train: 142 [ 200/625 ( 32%)]  Loss: 0.004194 (0.00423)  Time: 0.701s, 2923.46/s  (0.722s, 2837.20/s)  avg LR: 4.358e-03  iter ratio: 0.0000  Data: 0.025 (0.045)
INFO:Train: 142 [ 250/625 ( 40%)]  Loss: 0.005006 (0.00436)  Time: 0.712s, 2876.85/s  (0.718s, 2852.25/s)  avg LR: 4.358e-03  iter ratio: 0.0000  Data: 0.036 (0.041)
INFO:Train: 142 [ 300/625 ( 48%)]  Loss: 0.004276 (0.00435)  Time: 0.723s, 2832.73/s  (0.716s, 2859.56/s)  avg LR: 4.358e-03  iter ratio: 0.0000  Data: 0.046 (0.040)
INFO:Train: 142 [ 350/625 ( 56%)]  Loss: 0.004459 (0.00436)  Time: 0.703s, 2912.20/s  (0.716s, 2861.51/s)  avg LR: 4.358e-03  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 142 [ 400/625 ( 64%)]  Loss: 0.004902 (0.00442)  Time: 0.701s, 2919.70/s  (0.714s, 2867.91/s)  avg LR: 4.358e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 142 [ 450/625 ( 72%)]  Loss: 0.004712 (0.00445)  Time: 0.694s, 2949.87/s  (0.713s, 2872.91/s)  avg LR: 4.358e-03  iter ratio: 0.0000  Data: 0.020 (0.036)
INFO:Train: 142 [ 500/625 ( 80%)]  Loss: 0.004800 (0.00448)  Time: 0.701s, 2919.67/s  (0.712s, 2876.07/s)  avg LR: 4.358e-03  iter ratio: 0.0000  Data: 0.023 (0.035)
INFO:Train: 142 [ 550/625 ( 88%)]  Loss: 0.003710 (0.00442)  Time: 0.703s, 2912.29/s  (0.711s, 2879.67/s)  avg LR: 4.358e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 142 [ 600/625 ( 96%)]  Loss: 0.003986 (0.00438)  Time: 0.701s, 2921.80/s  (0.711s, 2881.93/s)  avg LR: 4.358e-03  iter ratio: 0.0000  Data: 0.023 (0.034)
INFO:Train: 142 [ 624/625 (100%)]  Loss: 0.004421 (0.00439)  Time: 0.675s, 3034.27/s  (0.710s, 2883.73/s)  avg LR: 4.358e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.373 (4.373)  Loss:  1.0391 (1.0391)  Acc@1: 75.6836 (75.6836)  Acc@5: 92.2852 (92.2852)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.9048 (1.4439)  Acc@1: 78.1840 (67.2540)  Acc@5: 92.9245 (87.8460)
INFO:142-epoch: remaining time 21.40 h
INFO:Train: 143 [   0/625 (  0%)]  Loss: 0.003571 (0.00357)  Time: 4.128s,  496.18/s  (4.128s,  496.18/s)  avg LR: 4.316e-03  iter ratio: 0.0000  Data: 3.445 (3.445)
INFO:Train: 143 [  50/625 (  8%)]  Loss: 0.004162 (0.00387)  Time: 0.700s, 2924.71/s  (0.778s, 2632.03/s)  avg LR: 4.316e-03  iter ratio: 0.0000  Data: 0.026 (0.101)
INFO:Train: 143 [ 100/625 ( 16%)]  Loss: 0.003488 (0.00374)  Time: 0.698s, 2934.99/s  (0.742s, 2759.80/s)  avg LR: 4.316e-03  iter ratio: 0.0000  Data: 0.022 (0.064)
INFO:Train: 143 [ 150/625 ( 24%)]  Loss: 0.004174 (0.00385)  Time: 0.702s, 2915.54/s  (0.729s, 2809.18/s)  avg LR: 4.316e-03  iter ratio: 0.0000  Data: 0.024 (0.052)
INFO:Train: 143 [ 200/625 ( 32%)]  Loss: 0.003840 (0.00385)  Time: 0.697s, 2938.66/s  (0.722s, 2835.30/s)  avg LR: 4.316e-03  iter ratio: 0.0000  Data: 0.022 (0.045)
INFO:Train: 143 [ 250/625 ( 40%)]  Loss: 0.004201 (0.00391)  Time: 0.711s, 2880.61/s  (0.718s, 2851.38/s)  avg LR: 4.316e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 143 [ 300/625 ( 48%)]  Loss: 0.004115 (0.00394)  Time: 0.705s, 2903.42/s  (0.716s, 2861.54/s)  avg LR: 4.316e-03  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 143 [ 350/625 ( 56%)]  Loss: 0.004374 (0.00399)  Time: 0.699s, 2931.95/s  (0.714s, 2869.05/s)  avg LR: 4.316e-03  iter ratio: 0.0000  Data: 0.024 (0.037)
INFO:Train: 143 [ 400/625 ( 64%)]  Loss: 0.003826 (0.00397)  Time: 0.719s, 2850.18/s  (0.714s, 2868.40/s)  avg LR: 4.316e-03  iter ratio: 0.0000  Data: 0.037 (0.037)
INFO:Train: 143 [ 450/625 ( 72%)]  Loss: 0.004167 (0.00399)  Time: 0.703s, 2914.08/s  (0.713s, 2872.20/s)  avg LR: 4.316e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 143 [ 500/625 ( 80%)]  Loss: 0.004356 (0.00402)  Time: 0.698s, 2933.85/s  (0.712s, 2876.45/s)  avg LR: 4.316e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 143 [ 550/625 ( 88%)]  Loss: 0.003999 (0.00402)  Time: 0.701s, 2921.85/s  (0.711s, 2880.02/s)  avg LR: 4.316e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 143 [ 600/625 ( 96%)]  Loss: 0.004045 (0.00402)  Time: 0.700s, 2924.78/s  (0.710s, 2883.17/s)  avg LR: 4.316e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 143 [ 624/625 (100%)]  Loss: 0.004015 (0.00402)  Time: 0.675s, 3033.57/s  (0.710s, 2884.82/s)  avg LR: 4.316e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.298 (4.298)  Loss:  0.9512 (0.9512)  Acc@1: 78.7598 (78.7598)  Acc@5: 93.1152 (93.1152)
INFO:Test: [  24/24]  Time: 0.080 (0.511)  Loss:  0.8613 (1.3988)  Acc@1: 81.7217 (68.4680)  Acc@5: 93.0424 (88.5000)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-139.pth.tar', 68.70400005371094)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-143.pth.tar', 68.46800007568359)

INFO:143-epoch: remaining time 21.29 h
INFO:Train: 144 [   0/625 (  0%)]  Loss: 0.004131 (0.00413)  Time: 4.543s,  450.82/s  (4.543s,  450.82/s)  avg LR: 4.275e-03  iter ratio: 0.0000  Data: 3.839 (3.839)
INFO:Train: 144 [  50/625 (  8%)]  Loss: 0.003795 (0.00396)  Time: 0.708s, 2893.71/s  (0.781s, 2621.06/s)  avg LR: 4.275e-03  iter ratio: 0.0000  Data: 0.027 (0.100)
INFO:Train: 144 [ 100/625 ( 16%)]  Loss: 0.003967 (0.00396)  Time: 0.721s, 2839.91/s  (0.745s, 2748.17/s)  avg LR: 4.275e-03  iter ratio: 0.0000  Data: 0.023 (0.062)
INFO:Train: 144 [ 150/625 ( 24%)]  Loss: 0.005056 (0.00424)  Time: 0.700s, 2925.47/s  (0.733s, 2795.82/s)  avg LR: 4.275e-03  iter ratio: 0.0000  Data: 0.022 (0.049)
INFO:Train: 144 [ 200/625 ( 32%)]  Loss: 0.004318 (0.00425)  Time: 0.710s, 2882.75/s  (0.726s, 2822.20/s)  avg LR: 4.275e-03  iter ratio: 0.0000  Data: 0.029 (0.042)
INFO:Train: 144 [ 250/625 ( 40%)]  Loss: 0.003522 (0.00413)  Time: 0.712s, 2875.11/s  (0.722s, 2837.70/s)  avg LR: 4.275e-03  iter ratio: 0.0000  Data: 0.037 (0.039)
INFO:Train: 144 [ 300/625 ( 48%)]  Loss: 0.004063 (0.00412)  Time: 0.721s, 2838.90/s  (0.720s, 2844.15/s)  avg LR: 4.275e-03  iter ratio: 0.0000  Data: 0.046 (0.038)
INFO:Train: 144 [ 350/625 ( 56%)]  Loss: 0.003859 (0.00409)  Time: 0.721s, 2839.31/s  (0.719s, 2849.42/s)  avg LR: 4.275e-03  iter ratio: 0.0000  Data: 0.044 (0.038)
INFO:Train: 144 [ 400/625 ( 64%)]  Loss: 0.003836 (0.00406)  Time: 0.719s, 2849.16/s  (0.718s, 2853.47/s)  avg LR: 4.275e-03  iter ratio: 0.0000  Data: 0.041 (0.037)
INFO:Train: 144 [ 450/625 ( 72%)]  Loss: 0.004188 (0.00407)  Time: 0.721s, 2839.02/s  (0.717s, 2856.46/s)  avg LR: 4.275e-03  iter ratio: 0.0000  Data: 0.045 (0.036)
INFO:Train: 144 [ 500/625 ( 80%)]  Loss: 0.004516 (0.00411)  Time: 0.721s, 2841.02/s  (0.716s, 2858.91/s)  avg LR: 4.275e-03  iter ratio: 0.0000  Data: 0.044 (0.036)
INFO:Train: 144 [ 550/625 ( 88%)]  Loss: 0.003849 (0.00409)  Time: 0.733s, 2792.51/s  (0.716s, 2860.87/s)  avg LR: 4.275e-03  iter ratio: 0.0000  Data: 0.047 (0.036)
INFO:Train: 144 [ 600/625 ( 96%)]  Loss: 0.004583 (0.00413)  Time: 0.721s, 2842.01/s  (0.715s, 2862.89/s)  avg LR: 4.275e-03  iter ratio: 0.0000  Data: 0.044 (0.036)
INFO:Train: 144 [ 624/625 (100%)]  Loss: 0.004479 (0.00415)  Time: 0.677s, 3024.48/s  (0.715s, 2864.27/s)  avg LR: 4.275e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.376 (4.376)  Loss:  0.9443 (0.9443)  Acc@1: 77.5391 (77.5391)  Acc@5: 93.2617 (93.2617)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.8760 (1.3974)  Acc@1: 80.7783 (67.9500)  Acc@5: 92.4528 (88.4660)
INFO:144-epoch: remaining time 21.29 h
INFO:Train: 145 [   0/625 (  0%)]  Loss: 0.004846 (0.00485)  Time: 4.602s,  444.99/s  (4.602s,  444.99/s)  avg LR: 4.233e-03  iter ratio: 0.0000  Data: 3.914 (3.914)
INFO:Train: 145 [  50/625 (  8%)]  Loss: 0.003697 (0.00427)  Time: 0.706s, 2899.72/s  (0.781s, 2622.94/s)  avg LR: 4.233e-03  iter ratio: 0.0000  Data: 0.031 (0.105)
INFO:Train: 145 [ 100/625 ( 16%)]  Loss: 0.003899 (0.00415)  Time: 0.705s, 2904.36/s  (0.743s, 2756.55/s)  avg LR: 4.233e-03  iter ratio: 0.0000  Data: 0.028 (0.067)
INFO:Train: 145 [ 150/625 ( 24%)]  Loss: 0.004021 (0.00412)  Time: 0.705s, 2905.89/s  (0.730s, 2805.16/s)  avg LR: 4.233e-03  iter ratio: 0.0000  Data: 0.026 (0.054)
INFO:Train: 145 [ 200/625 ( 32%)]  Loss: 0.004964 (0.00429)  Time: 0.702s, 2917.28/s  (0.724s, 2828.18/s)  avg LR: 4.233e-03  iter ratio: 0.0000  Data: 0.027 (0.048)
INFO:Train: 145 [ 250/625 ( 40%)]  Loss: 0.003773 (0.00420)  Time: 0.706s, 2901.10/s  (0.720s, 2844.22/s)  avg LR: 4.233e-03  iter ratio: 0.0000  Data: 0.031 (0.044)
INFO:Train: 145 [ 300/625 ( 48%)]  Loss: 0.004013 (0.00417)  Time: 0.702s, 2917.95/s  (0.718s, 2852.48/s)  avg LR: 4.233e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 145 [ 350/625 ( 56%)]  Loss: 0.004153 (0.00417)  Time: 0.703s, 2914.47/s  (0.716s, 2858.66/s)  avg LR: 4.233e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 145 [ 400/625 ( 64%)]  Loss: 0.003623 (0.00411)  Time: 0.702s, 2919.14/s  (0.715s, 2864.37/s)  avg LR: 4.233e-03  iter ratio: 0.0000  Data: 0.023 (0.039)
INFO:Train: 145 [ 450/625 ( 72%)]  Loss: 0.003217 (0.00402)  Time: 0.700s, 2924.30/s  (0.714s, 2868.72/s)  avg LR: 4.233e-03  iter ratio: 0.0000  Data: 0.021 (0.037)
INFO:Train: 145 [ 500/625 ( 80%)]  Loss: 0.004388 (0.00405)  Time: 0.713s, 2873.83/s  (0.714s, 2869.04/s)  avg LR: 4.233e-03  iter ratio: 0.0000  Data: 0.039 (0.037)
INFO:Train: 145 [ 550/625 ( 88%)]  Loss: 0.003378 (0.00400)  Time: 0.700s, 2925.19/s  (0.713s, 2870.95/s)  avg LR: 4.233e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 145 [ 600/625 ( 96%)]  Loss: 0.003540 (0.00396)  Time: 0.700s, 2925.09/s  (0.713s, 2873.81/s)  avg LR: 4.233e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 145 [ 624/625 (100%)]  Loss: 0.004335 (0.00399)  Time: 0.674s, 3040.74/s  (0.712s, 2875.73/s)  avg LR: 4.233e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.346 (4.346)  Loss:  1.0703 (1.0703)  Acc@1: 76.7578 (76.7578)  Acc@5: 91.9922 (91.9922)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.9551 (1.4215)  Acc@1: 78.6557 (67.5100)  Acc@5: 91.3915 (88.2560)
INFO:145-epoch: remaining time 21.06 h
INFO:Train: 146 [   0/625 (  0%)]  Loss: 0.004459 (0.00446)  Time: 4.141s,  494.60/s  (4.141s,  494.60/s)  avg LR: 4.191e-03  iter ratio: 0.0000  Data: 3.448 (3.448)
INFO:Train: 146 [  50/625 (  8%)]  Loss: 0.004169 (0.00431)  Time: 0.702s, 2918.58/s  (0.781s, 2623.03/s)  avg LR: 4.191e-03  iter ratio: 0.0000  Data: 0.023 (0.095)
INFO:Train: 146 [ 100/625 ( 16%)]  Loss: 0.004271 (0.00430)  Time: 0.708s, 2890.74/s  (0.744s, 2751.42/s)  avg LR: 4.191e-03  iter ratio: 0.0000  Data: 0.022 (0.060)
INFO:Train: 146 [ 150/625 ( 24%)]  Loss: 0.003971 (0.00422)  Time: 0.703s, 2913.44/s  (0.732s, 2798.10/s)  avg LR: 4.191e-03  iter ratio: 0.0000  Data: 0.023 (0.048)
INFO:Train: 146 [ 200/625 ( 32%)]  Loss: 0.004170 (0.00421)  Time: 0.710s, 2884.49/s  (0.728s, 2814.56/s)  avg LR: 4.191e-03  iter ratio: 0.0000  Data: 0.028 (0.045)
INFO:Train: 146 [ 250/625 ( 40%)]  Loss: 0.003897 (0.00416)  Time: 0.702s, 2917.20/s  (0.725s, 2826.18/s)  avg LR: 4.191e-03  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 146 [ 300/625 ( 48%)]  Loss: 0.003979 (0.00413)  Time: 0.704s, 2909.56/s  (0.722s, 2837.06/s)  avg LR: 4.191e-03  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 146 [ 350/625 ( 56%)]  Loss: 0.004086 (0.00413)  Time: 0.715s, 2864.21/s  (0.720s, 2844.49/s)  avg LR: 4.191e-03  iter ratio: 0.0000  Data: 0.041 (0.039)
INFO:Train: 146 [ 400/625 ( 64%)]  Loss: 0.004440 (0.00416)  Time: 0.717s, 2855.41/s  (0.720s, 2845.31/s)  avg LR: 4.191e-03  iter ratio: 0.0000  Data: 0.043 (0.039)
INFO:Train: 146 [ 450/625 ( 72%)]  Loss: 0.003656 (0.00411)  Time: 0.714s, 2867.61/s  (0.720s, 2846.09/s)  avg LR: 4.191e-03  iter ratio: 0.0000  Data: 0.041 (0.040)
INFO:Train: 146 [ 500/625 ( 80%)]  Loss: 0.004820 (0.00417)  Time: 0.710s, 2884.49/s  (0.719s, 2846.49/s)  avg LR: 4.191e-03  iter ratio: 0.0000  Data: 0.032 (0.040)
INFO:Train: 146 [ 550/625 ( 88%)]  Loss: 0.003865 (0.00415)  Time: 0.717s, 2857.47/s  (0.719s, 2847.15/s)  avg LR: 4.191e-03  iter ratio: 0.0000  Data: 0.043 (0.040)
INFO:Train: 146 [ 600/625 ( 96%)]  Loss: 0.004057 (0.00414)  Time: 0.715s, 2864.91/s  (0.719s, 2847.22/s)  avg LR: 4.191e-03  iter ratio: 0.0000  Data: 0.040 (0.040)
INFO:Train: 146 [ 624/625 (100%)]  Loss: 0.004893 (0.00420)  Time: 0.676s, 3031.79/s  (0.719s, 2849.53/s)  avg LR: 4.191e-03  iter ratio: 0.0000  Data: 0.000 (0.040)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.383 (4.383)  Loss:  0.9541 (0.9541)  Acc@1: 77.8320 (77.8320)  Acc@5: 93.6523 (93.6523)
INFO:Test: [  24/24]  Time: 0.080 (0.511)  Loss:  0.8853 (1.4036)  Acc@1: 80.3066 (68.2860)  Acc@5: 94.3396 (88.5860)
INFO:146-epoch: remaining time 21.19 h
INFO:Train: 147 [   0/625 (  0%)]  Loss: 0.004270 (0.00427)  Time: 4.186s,  489.26/s  (4.186s,  489.26/s)  avg LR: 4.150e-03  iter ratio: 0.0000  Data: 3.492 (3.492)
INFO:Train: 147 [  50/625 (  8%)]  Loss: 0.004001 (0.00414)  Time: 0.709s, 2886.87/s  (0.774s, 2647.29/s)  avg LR: 4.150e-03  iter ratio: 0.0000  Data: 0.023 (0.097)
INFO:Train: 147 [ 100/625 ( 16%)]  Loss: 0.004095 (0.00412)  Time: 0.700s, 2925.87/s  (0.741s, 2764.46/s)  avg LR: 4.150e-03  iter ratio: 0.0000  Data: 0.023 (0.064)
INFO:Train: 147 [ 150/625 ( 24%)]  Loss: 0.003819 (0.00405)  Time: 0.704s, 2908.69/s  (0.729s, 2808.87/s)  avg LR: 4.150e-03  iter ratio: 0.0000  Data: 0.027 (0.052)
INFO:Train: 147 [ 200/625 ( 32%)]  Loss: 0.004012 (0.00404)  Time: 0.722s, 2838.27/s  (0.724s, 2828.84/s)  avg LR: 4.150e-03  iter ratio: 0.0000  Data: 0.047 (0.047)
INFO:Train: 147 [ 250/625 ( 40%)]  Loss: 0.004021 (0.00404)  Time: 0.701s, 2920.25/s  (0.722s, 2835.02/s)  avg LR: 4.150e-03  iter ratio: 0.0000  Data: 0.025 (0.046)
INFO:Train: 147 [ 300/625 ( 48%)]  Loss: 0.004574 (0.00411)  Time: 0.711s, 2881.30/s  (0.720s, 2845.45/s)  avg LR: 4.150e-03  iter ratio: 0.0000  Data: 0.031 (0.043)
INFO:Train: 147 [ 350/625 ( 56%)]  Loss: 0.004119 (0.00411)  Time: 0.708s, 2893.20/s  (0.718s, 2853.90/s)  avg LR: 4.150e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 147 [ 400/625 ( 64%)]  Loss: 0.004424 (0.00415)  Time: 0.713s, 2870.41/s  (0.716s, 2861.12/s)  avg LR: 4.150e-03  iter ratio: 0.0000  Data: 0.038 (0.039)
INFO:Train: 147 [ 450/625 ( 72%)]  Loss: 0.004291 (0.00416)  Time: 0.706s, 2898.81/s  (0.714s, 2867.16/s)  avg LR: 4.150e-03  iter ratio: 0.0000  Data: 0.030 (0.038)
INFO:Train: 147 [ 500/625 ( 80%)]  Loss: 0.004710 (0.00421)  Time: 0.706s, 2900.49/s  (0.713s, 2871.53/s)  avg LR: 4.150e-03  iter ratio: 0.0000  Data: 0.031 (0.037)
INFO:Train: 147 [ 550/625 ( 88%)]  Loss: 0.004446 (0.00423)  Time: 0.707s, 2895.12/s  (0.712s, 2875.06/s)  avg LR: 4.150e-03  iter ratio: 0.0000  Data: 0.032 (0.036)
INFO:Train: 147 [ 600/625 ( 96%)]  Loss: 0.003738 (0.00419)  Time: 0.711s, 2879.65/s  (0.712s, 2877.94/s)  avg LR: 4.150e-03  iter ratio: 0.0000  Data: 0.035 (0.035)
INFO:Train: 147 [ 624/625 (100%)]  Loss: 0.003795 (0.00417)  Time: 0.677s, 3025.83/s  (0.711s, 2879.68/s)  avg LR: 4.150e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.335 (4.335)  Loss:  0.8740 (0.8740)  Acc@1: 80.0293 (80.0293)  Acc@5: 93.9941 (93.9941)
INFO:Test: [  24/24]  Time: 0.080 (0.509)  Loss:  0.8701 (1.3531)  Acc@1: 80.4245 (68.9220)  Acc@5: 93.3962 (89.2760)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-147.pth.tar', 68.92200002929688)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-139.pth.tar', 68.70400005371094)

INFO:147-epoch: remaining time 20.81 h
INFO:Train: 148 [   0/625 (  0%)]  Loss: 0.004305 (0.00430)  Time: 4.281s,  478.34/s  (4.281s,  478.34/s)  avg LR: 4.108e-03  iter ratio: 0.0000  Data: 3.585 (3.585)
INFO:Train: 148 [  50/625 (  8%)]  Loss: 0.004445 (0.00438)  Time: 0.717s, 2856.63/s  (0.785s, 2609.60/s)  avg LR: 4.108e-03  iter ratio: 0.0000  Data: 0.042 (0.109)
INFO:Train: 148 [ 100/625 ( 16%)]  Loss: 0.004251 (0.00433)  Time: 0.714s, 2867.38/s  (0.752s, 2724.27/s)  avg LR: 4.108e-03  iter ratio: 0.0000  Data: 0.039 (0.076)
INFO:Train: 148 [ 150/625 ( 24%)]  Loss: 0.003939 (0.00423)  Time: 0.717s, 2855.48/s  (0.740s, 2766.91/s)  avg LR: 4.108e-03  iter ratio: 0.0000  Data: 0.043 (0.065)
INFO:Train: 148 [ 200/625 ( 32%)]  Loss: 0.003810 (0.00415)  Time: 0.718s, 2851.84/s  (0.735s, 2787.96/s)  avg LR: 4.108e-03  iter ratio: 0.0000  Data: 0.044 (0.059)
INFO:Train: 148 [ 250/625 ( 40%)]  Loss: 0.004391 (0.00419)  Time: 0.700s, 2927.71/s  (0.730s, 2804.13/s)  avg LR: 4.108e-03  iter ratio: 0.0000  Data: 0.026 (0.055)
INFO:Train: 148 [ 300/625 ( 48%)]  Loss: 0.003759 (0.00413)  Time: 0.703s, 2913.21/s  (0.726s, 2819.45/s)  avg LR: 4.108e-03  iter ratio: 0.0000  Data: 0.028 (0.051)
INFO:Train: 148 [ 350/625 ( 56%)]  Loss: 0.004315 (0.00415)  Time: 0.701s, 2921.01/s  (0.723s, 2831.85/s)  avg LR: 4.108e-03  iter ratio: 0.0000  Data: 0.025 (0.048)
INFO:Train: 148 [ 400/625 ( 64%)]  Loss: 0.003913 (0.00413)  Time: 0.702s, 2917.26/s  (0.721s, 2840.83/s)  avg LR: 4.108e-03  iter ratio: 0.0000  Data: 0.025 (0.045)
INFO:Train: 148 [ 450/625 ( 72%)]  Loss: 0.003891 (0.00410)  Time: 0.718s, 2853.73/s  (0.719s, 2847.46/s)  avg LR: 4.108e-03  iter ratio: 0.0000  Data: 0.044 (0.043)
INFO:Train: 148 [ 500/625 ( 80%)]  Loss: 0.004940 (0.00418)  Time: 0.693s, 2953.14/s  (0.719s, 2848.08/s)  avg LR: 4.108e-03  iter ratio: 0.0000  Data: 0.018 (0.043)
INFO:Train: 148 [ 550/625 ( 88%)]  Loss: 0.003920 (0.00416)  Time: 0.718s, 2850.99/s  (0.718s, 2851.18/s)  avg LR: 4.108e-03  iter ratio: 0.0000  Data: 0.044 (0.042)
INFO:Train: 148 [ 600/625 ( 96%)]  Loss: 0.004318 (0.00417)  Time: 0.704s, 2910.76/s  (0.718s, 2854.17/s)  avg LR: 4.108e-03  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 148 [ 624/625 (100%)]  Loss: 0.004349 (0.00418)  Time: 0.674s, 3039.12/s  (0.717s, 2855.98/s)  avg LR: 4.108e-03  iter ratio: 0.0000  Data: 0.000 (0.041)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.384 (4.384)  Loss:  0.8594 (0.8594)  Acc@1: 78.7598 (78.7598)  Acc@5: 94.2871 (94.2871)
INFO:Test: [  24/24]  Time: 0.080 (0.513)  Loss:  0.7388 (1.2851)  Acc@1: 81.2500 (70.1380)  Acc@5: 94.3396 (89.7900)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-148.pth.tar', 70.138)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-147.pth.tar', 68.92200002929688)

INFO:148-epoch: remaining time 20.84 h
INFO:Train: 149 [   0/625 (  0%)]  Loss: 0.004519 (0.00452)  Time: 4.257s,  481.12/s  (4.257s,  481.12/s)  avg LR: 4.067e-03  iter ratio: 0.0000  Data: 3.563 (3.563)
INFO:Train: 149 [  50/625 (  8%)]  Loss: 0.003412 (0.00397)  Time: 0.701s, 2922.96/s  (0.780s, 2625.28/s)  avg LR: 4.067e-03  iter ratio: 0.0000  Data: 0.024 (0.102)
INFO:Train: 149 [ 100/625 ( 16%)]  Loss: 0.004113 (0.00401)  Time: 0.701s, 2922.35/s  (0.743s, 2755.82/s)  avg LR: 4.067e-03  iter ratio: 0.0000  Data: 0.025 (0.066)
INFO:Train: 149 [ 150/625 ( 24%)]  Loss: 0.004746 (0.00420)  Time: 0.704s, 2910.21/s  (0.730s, 2803.91/s)  avg LR: 4.067e-03  iter ratio: 0.0000  Data: 0.028 (0.054)
INFO:Train: 149 [ 200/625 ( 32%)]  Loss: 0.004452 (0.00425)  Time: 0.705s, 2906.42/s  (0.724s, 2827.46/s)  avg LR: 4.067e-03  iter ratio: 0.0000  Data: 0.030 (0.048)
INFO:Train: 149 [ 250/625 ( 40%)]  Loss: 0.004119 (0.00423)  Time: 0.698s, 2935.90/s  (0.720s, 2843.43/s)  avg LR: 4.067e-03  iter ratio: 0.0000  Data: 0.024 (0.044)
INFO:Train: 149 [ 300/625 ( 48%)]  Loss: 0.003452 (0.00412)  Time: 0.707s, 2898.14/s  (0.718s, 2852.23/s)  avg LR: 4.067e-03  iter ratio: 0.0000  Data: 0.032 (0.042)
INFO:Train: 149 [ 350/625 ( 56%)]  Loss: 0.004182 (0.00412)  Time: 0.700s, 2926.73/s  (0.716s, 2859.27/s)  avg LR: 4.067e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 149 [ 400/625 ( 64%)]  Loss: 0.004199 (0.00413)  Time: 0.701s, 2922.70/s  (0.715s, 2864.73/s)  avg LR: 4.067e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 149 [ 450/625 ( 72%)]  Loss: 0.004166 (0.00414)  Time: 0.704s, 2909.51/s  (0.714s, 2868.72/s)  avg LR: 4.067e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 149 [ 500/625 ( 80%)]  Loss: 0.003918 (0.00412)  Time: 0.700s, 2923.69/s  (0.713s, 2872.02/s)  avg LR: 4.067e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 149 [ 550/625 ( 88%)]  Loss: 0.003716 (0.00408)  Time: 0.704s, 2907.06/s  (0.712s, 2875.28/s)  avg LR: 4.067e-03  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 149 [ 600/625 ( 96%)]  Loss: 0.004350 (0.00410)  Time: 0.704s, 2911.11/s  (0.712s, 2877.27/s)  avg LR: 4.067e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 149 [ 624/625 (100%)]  Loss: 0.003833 (0.00408)  Time: 0.673s, 3044.96/s  (0.711s, 2878.78/s)  avg LR: 4.067e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.407 (4.407)  Loss:  0.9360 (0.9360)  Acc@1: 79.6387 (79.6387)  Acc@5: 93.9941 (93.9941)
INFO:Test: [  24/24]  Time: 0.080 (0.517)  Loss:  0.7461 (1.3760)  Acc@1: 81.7217 (69.2660)  Acc@5: 94.4576 (89.2940)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-148.pth.tar', 70.138)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-149.pth.tar', 69.26599994628906)

INFO:149-epoch: remaining time 20.56 h
INFO:Train: 150 [   0/625 (  0%)]  Loss: 0.003357 (0.00336)  Time: 4.093s,  500.42/s  (4.093s,  500.42/s)  avg LR: 4.025e-03  iter ratio: 0.0000  Data: 3.399 (3.399)
INFO:Train: 150 [  50/625 (  8%)]  Loss: 0.004333 (0.00384)  Time: 0.702s, 2917.60/s  (0.770s, 2658.57/s)  avg LR: 4.025e-03  iter ratio: 0.0000  Data: 0.025 (0.094)
INFO:Train: 150 [ 100/625 ( 16%)]  Loss: 0.003816 (0.00384)  Time: 0.707s, 2897.88/s  (0.738s, 2774.95/s)  avg LR: 4.025e-03  iter ratio: 0.0000  Data: 0.029 (0.062)
INFO:Train: 150 [ 150/625 ( 24%)]  Loss: 0.003847 (0.00384)  Time: 0.702s, 2918.76/s  (0.727s, 2818.47/s)  avg LR: 4.025e-03  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 150 [ 200/625 ( 32%)]  Loss: 0.004558 (0.00398)  Time: 0.702s, 2915.59/s  (0.721s, 2840.32/s)  avg LR: 4.025e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 150 [ 250/625 ( 40%)]  Loss: 0.004854 (0.00413)  Time: 0.700s, 2924.41/s  (0.717s, 2854.52/s)  avg LR: 4.025e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 150 [ 300/625 ( 48%)]  Loss: 0.004151 (0.00413)  Time: 0.702s, 2915.50/s  (0.715s, 2862.92/s)  avg LR: 4.025e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 150 [ 350/625 ( 56%)]  Loss: 0.004540 (0.00418)  Time: 0.703s, 2915.12/s  (0.714s, 2869.63/s)  avg LR: 4.025e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 150 [ 400/625 ( 64%)]  Loss: 0.004368 (0.00420)  Time: 0.711s, 2880.04/s  (0.713s, 2874.17/s)  avg LR: 4.025e-03  iter ratio: 0.0000  Data: 0.037 (0.037)
INFO:Train: 150 [ 450/625 ( 72%)]  Loss: 0.004745 (0.00426)  Time: 0.701s, 2923.00/s  (0.712s, 2878.23/s)  avg LR: 4.025e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 150 [ 500/625 ( 80%)]  Loss: 0.003663 (0.00420)  Time: 0.700s, 2925.78/s  (0.711s, 2881.08/s)  avg LR: 4.025e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 150 [ 550/625 ( 88%)]  Loss: 0.004236 (0.00421)  Time: 0.702s, 2916.67/s  (0.710s, 2883.00/s)  avg LR: 4.025e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 150 [ 600/625 ( 96%)]  Loss: 0.003770 (0.00417)  Time: 0.702s, 2917.50/s  (0.710s, 2885.40/s)  avg LR: 4.025e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 150 [ 624/625 (100%)]  Loss: 0.004305 (0.00418)  Time: 0.676s, 3031.03/s  (0.710s, 2886.35/s)  avg LR: 4.025e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.459 (4.459)  Loss:  0.8369 (0.8369)  Acc@1: 81.9336 (81.9336)  Acc@5: 94.7754 (94.7754)
INFO:Test: [  24/24]  Time: 0.080 (0.505)  Loss:  0.7783 (1.3285)  Acc@1: 82.4292 (70.1100)  Acc@5: 94.3396 (89.7800)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-148.pth.tar', 70.138)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-150.pth.tar', 70.10999999511719)

INFO:150-epoch: remaining time 20.38 h
INFO:Train: 151 [   0/625 (  0%)]  Loss: 0.003788 (0.00379)  Time: 4.276s,  478.91/s  (4.276s,  478.91/s)  avg LR: 3.983e-03  iter ratio: 0.0000  Data: 3.586 (3.586)
INFO:Train: 151 [  50/625 (  8%)]  Loss: 0.004128 (0.00396)  Time: 0.700s, 2926.13/s  (0.773s, 2647.80/s)  avg LR: 3.983e-03  iter ratio: 0.0000  Data: 0.026 (0.098)
INFO:Train: 151 [ 100/625 ( 16%)]  Loss: 0.004278 (0.00406)  Time: 0.700s, 2927.03/s  (0.739s, 2771.82/s)  avg LR: 3.983e-03  iter ratio: 0.0000  Data: 0.026 (0.063)
INFO:Train: 151 [ 150/625 ( 24%)]  Loss: 0.003795 (0.00400)  Time: 0.703s, 2914.58/s  (0.727s, 2817.34/s)  avg LR: 3.983e-03  iter ratio: 0.0000  Data: 0.025 (0.052)
INFO:Train: 151 [ 200/625 ( 32%)]  Loss: 0.003938 (0.00399)  Time: 0.699s, 2930.92/s  (0.721s, 2839.25/s)  avg LR: 3.983e-03  iter ratio: 0.0000  Data: 0.025 (0.046)
INFO:Train: 151 [ 250/625 ( 40%)]  Loss: 0.004570 (0.00408)  Time: 0.699s, 2927.99/s  (0.718s, 2853.96/s)  avg LR: 3.983e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 151 [ 300/625 ( 48%)]  Loss: 0.004317 (0.00412)  Time: 0.701s, 2920.61/s  (0.715s, 2863.11/s)  avg LR: 3.983e-03  iter ratio: 0.0000  Data: 0.023 (0.040)
INFO:Train: 151 [ 350/625 ( 56%)]  Loss: 0.003921 (0.00409)  Time: 0.700s, 2927.47/s  (0.714s, 2868.48/s)  avg LR: 3.983e-03  iter ratio: 0.0000  Data: 0.024 (0.038)
INFO:Train: 151 [ 400/625 ( 64%)]  Loss: 0.003466 (0.00402)  Time: 0.704s, 2909.70/s  (0.713s, 2873.59/s)  avg LR: 3.983e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 151 [ 450/625 ( 72%)]  Loss: 0.004665 (0.00409)  Time: 0.699s, 2928.39/s  (0.712s, 2877.83/s)  avg LR: 3.983e-03  iter ratio: 0.0000  Data: 0.023 (0.036)
INFO:Train: 151 [ 500/625 ( 80%)]  Loss: 0.004073 (0.00409)  Time: 0.700s, 2927.62/s  (0.711s, 2879.51/s)  avg LR: 3.983e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 151 [ 550/625 ( 88%)]  Loss: 0.004256 (0.00410)  Time: 0.702s, 2916.57/s  (0.711s, 2882.21/s)  avg LR: 3.983e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 151 [ 600/625 ( 96%)]  Loss: 0.004160 (0.00410)  Time: 0.707s, 2895.93/s  (0.710s, 2884.47/s)  avg LR: 3.983e-03  iter ratio: 0.0000  Data: 0.023 (0.034)
INFO:Train: 151 [ 624/625 (100%)]  Loss: 0.004898 (0.00416)  Time: 0.675s, 3032.39/s  (0.710s, 2884.95/s)  avg LR: 3.983e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.312 (4.312)  Loss:  0.9326 (0.9326)  Acc@1: 77.7832 (77.7832)  Acc@5: 93.7500 (93.7500)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.7881 (1.3529)  Acc@1: 82.5472 (69.5660)  Acc@5: 94.6934 (89.5320)
INFO:151-epoch: remaining time 20.24 h
INFO:Train: 152 [   0/625 (  0%)]  Loss: 0.004543 (0.00454)  Time: 4.547s,  450.36/s  (4.547s,  450.36/s)  avg LR: 3.942e-03  iter ratio: 0.0000  Data: 3.851 (3.851)
INFO:Train: 152 [  50/625 (  8%)]  Loss: 0.004295 (0.00442)  Time: 0.702s, 2918.96/s  (0.786s, 2607.22/s)  avg LR: 3.942e-03  iter ratio: 0.0000  Data: 0.027 (0.107)
INFO:Train: 152 [ 100/625 ( 16%)]  Loss: 0.003928 (0.00426)  Time: 0.702s, 2915.89/s  (0.745s, 2749.32/s)  avg LR: 3.942e-03  iter ratio: 0.0000  Data: 0.027 (0.067)
INFO:Train: 152 [ 150/625 ( 24%)]  Loss: 0.004461 (0.00431)  Time: 0.714s, 2868.93/s  (0.731s, 2801.33/s)  avg LR: 3.942e-03  iter ratio: 0.0000  Data: 0.040 (0.054)
INFO:Train: 152 [ 200/625 ( 32%)]  Loss: 0.003953 (0.00424)  Time: 0.706s, 2900.88/s  (0.724s, 2827.98/s)  avg LR: 3.942e-03  iter ratio: 0.0000  Data: 0.027 (0.047)
INFO:Train: 152 [ 250/625 ( 40%)]  Loss: 0.003797 (0.00416)  Time: 0.700s, 2924.45/s  (0.720s, 2843.85/s)  avg LR: 3.942e-03  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 152 [ 300/625 ( 48%)]  Loss: 0.004540 (0.00422)  Time: 0.701s, 2923.28/s  (0.717s, 2855.35/s)  avg LR: 3.942e-03  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 152 [ 350/625 ( 56%)]  Loss: 0.004811 (0.00429)  Time: 0.706s, 2901.86/s  (0.716s, 2860.12/s)  avg LR: 3.942e-03  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 152 [ 400/625 ( 64%)]  Loss: 0.003442 (0.00420)  Time: 0.704s, 2910.77/s  (0.715s, 2865.21/s)  avg LR: 3.942e-03  iter ratio: 0.0000  Data: 0.023 (0.037)
INFO:Train: 152 [ 450/625 ( 72%)]  Loss: 0.004662 (0.00424)  Time: 0.705s, 2905.15/s  (0.714s, 2868.96/s)  avg LR: 3.942e-03  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 152 [ 500/625 ( 80%)]  Loss: 0.004104 (0.00423)  Time: 0.705s, 2906.61/s  (0.713s, 2872.54/s)  avg LR: 3.942e-03  iter ratio: 0.0000  Data: 0.023 (0.034)
INFO:Train: 152 [ 550/625 ( 88%)]  Loss: 0.004359 (0.00424)  Time: 0.717s, 2856.15/s  (0.713s, 2872.85/s)  avg LR: 3.942e-03  iter ratio: 0.0000  Data: 0.041 (0.034)
INFO:Train: 152 [ 600/625 ( 96%)]  Loss: 0.004297 (0.00425)  Time: 0.714s, 2869.16/s  (0.713s, 2871.84/s)  avg LR: 3.942e-03  iter ratio: 0.0000  Data: 0.037 (0.035)
INFO:Train: 152 [ 624/625 (100%)]  Loss: 0.004338 (0.00425)  Time: 0.674s, 3037.96/s  (0.713s, 2872.05/s)  avg LR: 3.942e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.417 (4.417)  Loss:  0.9590 (0.9590)  Acc@1: 78.9062 (78.9062)  Acc@5: 93.2129 (93.2129)
INFO:Test: [  24/24]  Time: 0.080 (0.507)  Loss:  0.9062 (1.3560)  Acc@1: 79.3632 (69.5480)  Acc@5: 93.5141 (89.5000)
INFO:152-epoch: remaining time 20.23 h
INFO:Train: 153 [   0/625 (  0%)]  Loss: 0.004673 (0.00467)  Time: 4.217s,  485.64/s  (4.217s,  485.64/s)  avg LR: 3.900e-03  iter ratio: 0.0000  Data: 3.513 (3.513)
INFO:Train: 153 [  50/625 (  8%)]  Loss: 0.003924 (0.00430)  Time: 0.717s, 2857.24/s  (0.774s, 2646.76/s)  avg LR: 3.900e-03  iter ratio: 0.0000  Data: 0.042 (0.096)
INFO:Train: 153 [ 100/625 ( 16%)]  Loss: 0.003513 (0.00404)  Time: 0.718s, 2853.85/s  (0.746s, 2745.80/s)  avg LR: 3.900e-03  iter ratio: 0.0000  Data: 0.042 (0.069)
INFO:Train: 153 [ 150/625 ( 24%)]  Loss: 0.003566 (0.00392)  Time: 0.718s, 2850.52/s  (0.737s, 2780.60/s)  avg LR: 3.900e-03  iter ratio: 0.0000  Data: 0.043 (0.060)
INFO:Train: 153 [ 200/625 ( 32%)]  Loss: 0.004490 (0.00403)  Time: 0.715s, 2864.33/s  (0.732s, 2797.99/s)  avg LR: 3.900e-03  iter ratio: 0.0000  Data: 0.040 (0.056)
INFO:Train: 153 [ 250/625 ( 40%)]  Loss: 0.004688 (0.00414)  Time: 0.715s, 2864.26/s  (0.729s, 2808.97/s)  avg LR: 3.900e-03  iter ratio: 0.0000  Data: 0.040 (0.053)
INFO:Train: 153 [ 300/625 ( 48%)]  Loss: 0.004458 (0.00419)  Time: 0.705s, 2903.97/s  (0.725s, 2823.06/s)  avg LR: 3.900e-03  iter ratio: 0.0000  Data: 0.030 (0.049)
INFO:Train: 153 [ 350/625 ( 56%)]  Loss: 0.004030 (0.00417)  Time: 0.718s, 2851.93/s  (0.723s, 2833.08/s)  avg LR: 3.900e-03  iter ratio: 0.0000  Data: 0.043 (0.047)
INFO:Train: 153 [ 400/625 ( 64%)]  Loss: 0.003969 (0.00415)  Time: 0.721s, 2841.51/s  (0.722s, 2835.33/s)  avg LR: 3.900e-03  iter ratio: 0.0000  Data: 0.045 (0.046)
INFO:Train: 153 [ 450/625 ( 72%)]  Loss: 0.004238 (0.00415)  Time: 0.723s, 2834.24/s  (0.722s, 2837.04/s)  avg LR: 3.900e-03  iter ratio: 0.0000  Data: 0.046 (0.046)
INFO:Train: 153 [ 500/625 ( 80%)]  Loss: 0.004198 (0.00416)  Time: 0.718s, 2853.23/s  (0.722s, 2838.36/s)  avg LR: 3.900e-03  iter ratio: 0.0000  Data: 0.044 (0.046)
INFO:Train: 153 [ 550/625 ( 88%)]  Loss: 0.003922 (0.00414)  Time: 0.715s, 2865.47/s  (0.721s, 2839.60/s)  avg LR: 3.900e-03  iter ratio: 0.0000  Data: 0.041 (0.045)
INFO:Train: 153 [ 600/625 ( 96%)]  Loss: 0.003731 (0.00411)  Time: 0.716s, 2860.96/s  (0.721s, 2840.89/s)  avg LR: 3.900e-03  iter ratio: 0.0000  Data: 0.041 (0.045)
INFO:Train: 153 [ 624/625 (100%)]  Loss: 0.004338 (0.00412)  Time: 0.673s, 3042.63/s  (0.720s, 2843.18/s)  avg LR: 3.900e-03  iter ratio: 0.0000  Data: 0.000 (0.044)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.312 (4.312)  Loss:  0.9893 (0.9893)  Acc@1: 78.5156 (78.5156)  Acc@5: 93.3105 (93.3105)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.8457 (1.4410)  Acc@1: 80.4245 (67.8760)  Acc@5: 94.9293 (88.4780)
INFO:153-epoch: remaining time 20.28 h
INFO:Train: 154 [   0/625 (  0%)]  Loss: 0.004251 (0.00425)  Time: 4.225s,  484.70/s  (4.225s,  484.70/s)  avg LR: 3.859e-03  iter ratio: 0.0000  Data: 3.536 (3.536)
INFO:Train: 154 [  50/625 (  8%)]  Loss: 0.003231 (0.00374)  Time: 0.701s, 2922.12/s  (0.774s, 2647.15/s)  avg LR: 3.859e-03  iter ratio: 0.0000  Data: 0.025 (0.096)
INFO:Train: 154 [ 100/625 ( 16%)]  Loss: 0.004003 (0.00383)  Time: 0.718s, 2850.98/s  (0.740s, 2767.86/s)  avg LR: 3.859e-03  iter ratio: 0.0000  Data: 0.023 (0.062)
INFO:Train: 154 [ 150/625 ( 24%)]  Loss: 0.003933 (0.00385)  Time: 0.700s, 2924.67/s  (0.729s, 2810.56/s)  avg LR: 3.859e-03  iter ratio: 0.0000  Data: 0.024 (0.051)
INFO:Train: 154 [ 200/625 ( 32%)]  Loss: 0.003713 (0.00383)  Time: 0.707s, 2895.34/s  (0.723s, 2831.45/s)  avg LR: 3.859e-03  iter ratio: 0.0000  Data: 0.028 (0.045)
INFO:Train: 154 [ 250/625 ( 40%)]  Loss: 0.003933 (0.00384)  Time: 0.718s, 2852.90/s  (0.720s, 2842.78/s)  avg LR: 3.859e-03  iter ratio: 0.0000  Data: 0.041 (0.042)
INFO:Train: 154 [ 300/625 ( 48%)]  Loss: 0.004661 (0.00396)  Time: 0.706s, 2899.33/s  (0.718s, 2850.39/s)  avg LR: 3.859e-03  iter ratio: 0.0000  Data: 0.023 (0.040)
INFO:Train: 154 [ 350/625 ( 56%)]  Loss: 0.004347 (0.00401)  Time: 0.705s, 2907.00/s  (0.717s, 2857.23/s)  avg LR: 3.859e-03  iter ratio: 0.0000  Data: 0.023 (0.038)
INFO:Train: 154 [ 400/625 ( 64%)]  Loss: 0.004043 (0.00401)  Time: 0.707s, 2895.65/s  (0.715s, 2862.97/s)  avg LR: 3.859e-03  iter ratio: 0.0000  Data: 0.023 (0.036)
INFO:Train: 154 [ 450/625 ( 72%)]  Loss: 0.003616 (0.00397)  Time: 0.707s, 2897.72/s  (0.714s, 2867.22/s)  avg LR: 3.859e-03  iter ratio: 0.0000  Data: 0.021 (0.034)
INFO:Train: 154 [ 500/625 ( 80%)]  Loss: 0.004218 (0.00400)  Time: 0.719s, 2847.53/s  (0.714s, 2868.35/s)  avg LR: 3.859e-03  iter ratio: 0.0000  Data: 0.044 (0.034)
INFO:Train: 154 [ 550/625 ( 88%)]  Loss: 0.003874 (0.00399)  Time: 0.721s, 2838.93/s  (0.714s, 2868.14/s)  avg LR: 3.859e-03  iter ratio: 0.0000  Data: 0.044 (0.034)
INFO:Train: 154 [ 600/625 ( 96%)]  Loss: 0.004085 (0.00399)  Time: 0.728s, 2812.16/s  (0.714s, 2867.81/s)  avg LR: 3.859e-03  iter ratio: 0.0000  Data: 0.044 (0.035)
INFO:Train: 154 [ 624/625 (100%)]  Loss: 0.003599 (0.00396)  Time: 0.675s, 3034.84/s  (0.714s, 2868.53/s)  avg LR: 3.859e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.350 (4.350)  Loss:  0.9619 (0.9619)  Acc@1: 78.5156 (78.5156)  Acc@5: 93.9453 (93.9453)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.8809 (1.3604)  Acc@1: 80.8962 (69.9860)  Acc@5: 93.5141 (89.8160)
INFO:154-epoch: remaining time 20.02 h
INFO:Train: 155 [   0/625 (  0%)]  Loss: 0.004165 (0.00417)  Time: 4.450s,  460.27/s  (4.450s,  460.27/s)  avg LR: 3.817e-03  iter ratio: 0.0000  Data: 3.755 (3.755)
INFO:Train: 155 [  50/625 (  8%)]  Loss: 0.003796 (0.00398)  Time: 0.716s, 2858.44/s  (0.785s, 2609.45/s)  avg LR: 3.817e-03  iter ratio: 0.0000  Data: 0.041 (0.107)
INFO:Train: 155 [ 100/625 ( 16%)]  Loss: 0.003931 (0.00396)  Time: 0.710s, 2884.28/s  (0.746s, 2747.11/s)  avg LR: 3.817e-03  iter ratio: 0.0000  Data: 0.035 (0.069)
INFO:Train: 155 [ 150/625 ( 24%)]  Loss: 0.003731 (0.00391)  Time: 0.711s, 2880.55/s  (0.732s, 2796.83/s)  avg LR: 3.817e-03  iter ratio: 0.0000  Data: 0.035 (0.056)
INFO:Train: 155 [ 200/625 ( 32%)]  Loss: 0.003756 (0.00388)  Time: 0.714s, 2870.24/s  (0.725s, 2824.26/s)  avg LR: 3.817e-03  iter ratio: 0.0000  Data: 0.038 (0.049)
INFO:Train: 155 [ 250/625 ( 40%)]  Loss: 0.003594 (0.00383)  Time: 0.720s, 2844.68/s  (0.721s, 2839.46/s)  avg LR: 3.817e-03  iter ratio: 0.0000  Data: 0.036 (0.045)
INFO:Train: 155 [ 300/625 ( 48%)]  Loss: 0.004000 (0.00385)  Time: 0.711s, 2879.08/s  (0.719s, 2850.25/s)  avg LR: 3.817e-03  iter ratio: 0.0000  Data: 0.033 (0.042)
INFO:Train: 155 [ 350/625 ( 56%)]  Loss: 0.004785 (0.00397)  Time: 0.709s, 2887.18/s  (0.717s, 2857.48/s)  avg LR: 3.817e-03  iter ratio: 0.0000  Data: 0.035 (0.040)
INFO:Train: 155 [ 400/625 ( 64%)]  Loss: 0.003838 (0.00396)  Time: 0.711s, 2878.72/s  (0.715s, 2863.68/s)  avg LR: 3.817e-03  iter ratio: 0.0000  Data: 0.034 (0.039)
INFO:Train: 155 [ 450/625 ( 72%)]  Loss: 0.003286 (0.00389)  Time: 0.706s, 2899.72/s  (0.714s, 2868.43/s)  avg LR: 3.817e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 155 [ 500/625 ( 80%)]  Loss: 0.004470 (0.00394)  Time: 0.716s, 2861.90/s  (0.714s, 2868.19/s)  avg LR: 3.817e-03  iter ratio: 0.0000  Data: 0.038 (0.038)
INFO:Train: 155 [ 550/625 ( 88%)]  Loss: 0.003973 (0.00394)  Time: 0.720s, 2845.60/s  (0.714s, 2866.45/s)  avg LR: 3.817e-03  iter ratio: 0.0000  Data: 0.044 (0.038)
INFO:Train: 155 [ 600/625 ( 96%)]  Loss: 0.003850 (0.00394)  Time: 0.715s, 2865.83/s  (0.715s, 2864.73/s)  avg LR: 3.817e-03  iter ratio: 0.0000  Data: 0.034 (0.039)
INFO:Train: 155 [ 624/625 (100%)]  Loss: 0.003795 (0.00393)  Time: 0.674s, 3040.81/s  (0.714s, 2866.49/s)  avg LR: 3.817e-03  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.342 (4.342)  Loss:  0.9019 (0.9019)  Acc@1: 81.0059 (81.0059)  Acc@5: 94.3359 (94.3359)
INFO:Test: [  24/24]  Time: 0.080 (0.502)  Loss:  0.8223 (1.3739)  Acc@1: 81.7217 (69.9780)  Acc@5: 94.8113 (89.5180)
INFO:155-epoch: remaining time 19.86 h
INFO:Train: 156 [   0/625 (  0%)]  Loss: 0.003653 (0.00365)  Time: 4.279s,  478.56/s  (4.279s,  478.56/s)  avg LR: 3.775e-03  iter ratio: 0.0000  Data: 3.590 (3.590)
INFO:Train: 156 [  50/625 (  8%)]  Loss: 0.004329 (0.00399)  Time: 0.703s, 2913.63/s  (0.775s, 2643.72/s)  avg LR: 3.775e-03  iter ratio: 0.0000  Data: 0.023 (0.098)
INFO:Train: 156 [ 100/625 ( 16%)]  Loss: 0.004216 (0.00407)  Time: 0.707s, 2897.56/s  (0.740s, 2768.01/s)  avg LR: 3.775e-03  iter ratio: 0.0000  Data: 0.031 (0.064)
INFO:Train: 156 [ 150/625 ( 24%)]  Loss: 0.003497 (0.00392)  Time: 0.708s, 2893.60/s  (0.728s, 2812.11/s)  avg LR: 3.775e-03  iter ratio: 0.0000  Data: 0.033 (0.053)
INFO:Train: 156 [ 200/625 ( 32%)]  Loss: 0.003210 (0.00378)  Time: 0.705s, 2906.42/s  (0.722s, 2834.74/s)  avg LR: 3.775e-03  iter ratio: 0.0000  Data: 0.030 (0.047)
INFO:Train: 156 [ 250/625 ( 40%)]  Loss: 0.004288 (0.00387)  Time: 0.706s, 2901.08/s  (0.719s, 2848.23/s)  avg LR: 3.775e-03  iter ratio: 0.0000  Data: 0.031 (0.043)
INFO:Train: 156 [ 300/625 ( 48%)]  Loss: 0.003789 (0.00385)  Time: 0.704s, 2910.04/s  (0.716s, 2858.45/s)  avg LR: 3.775e-03  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 156 [ 350/625 ( 56%)]  Loss: 0.003962 (0.00387)  Time: 0.707s, 2896.28/s  (0.715s, 2864.65/s)  avg LR: 3.775e-03  iter ratio: 0.0000  Data: 0.032 (0.039)
INFO:Train: 156 [ 400/625 ( 64%)]  Loss: 0.004033 (0.00389)  Time: 0.704s, 2909.71/s  (0.714s, 2869.26/s)  avg LR: 3.775e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 156 [ 450/625 ( 72%)]  Loss: 0.004828 (0.00398)  Time: 0.703s, 2914.19/s  (0.713s, 2873.21/s)  avg LR: 3.775e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 156 [ 500/625 ( 80%)]  Loss: 0.004165 (0.00400)  Time: 0.710s, 2883.19/s  (0.712s, 2876.50/s)  avg LR: 3.775e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 156 [ 550/625 ( 88%)]  Loss: 0.004193 (0.00401)  Time: 0.707s, 2898.41/s  (0.711s, 2878.73/s)  avg LR: 3.775e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 156 [ 600/625 ( 96%)]  Loss: 0.003777 (0.00400)  Time: 0.712s, 2876.96/s  (0.711s, 2880.31/s)  avg LR: 3.775e-03  iter ratio: 0.0000  Data: 0.033 (0.035)
INFO:Train: 156 [ 624/625 (100%)]  Loss: 0.004143 (0.00401)  Time: 0.680s, 3013.78/s  (0.711s, 2880.24/s)  avg LR: 3.775e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.366 (4.366)  Loss:  0.8745 (0.8745)  Acc@1: 80.8594 (80.8594)  Acc@5: 94.7754 (94.7754)
INFO:Test: [  24/24]  Time: 0.080 (0.505)  Loss:  0.7598 (1.2963)  Acc@1: 82.7830 (71.0200)  Acc@5: 95.4009 (90.3920)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-156.pth.tar', 71.02000001953125)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-148.pth.tar', 70.138)

INFO:156-epoch: remaining time 19.73 h
INFO:Train: 157 [   0/625 (  0%)]  Loss: 0.004379 (0.00438)  Time: 4.307s,  475.48/s  (4.307s,  475.48/s)  avg LR: 3.734e-03  iter ratio: 0.0000  Data: 3.616 (3.616)
INFO:Train: 157 [  50/625 (  8%)]  Loss: 0.003918 (0.00415)  Time: 0.704s, 2907.12/s  (0.776s, 2638.27/s)  avg LR: 3.734e-03  iter ratio: 0.0000  Data: 0.029 (0.099)
INFO:Train: 157 [ 100/625 ( 16%)]  Loss: 0.004095 (0.00413)  Time: 0.709s, 2890.17/s  (0.741s, 2762.56/s)  avg LR: 3.734e-03  iter ratio: 0.0000  Data: 0.035 (0.065)
INFO:Train: 157 [ 150/625 ( 24%)]  Loss: 0.003417 (0.00395)  Time: 0.699s, 2929.98/s  (0.731s, 2801.71/s)  avg LR: 3.734e-03  iter ratio: 0.0000  Data: 0.025 (0.055)
INFO:Train: 157 [ 200/625 ( 32%)]  Loss: 0.004142 (0.00399)  Time: 0.709s, 2887.21/s  (0.724s, 2828.16/s)  avg LR: 3.734e-03  iter ratio: 0.0000  Data: 0.034 (0.048)
INFO:Train: 157 [ 250/625 ( 40%)]  Loss: 0.004558 (0.00408)  Time: 0.701s, 2922.47/s  (0.720s, 2844.29/s)  avg LR: 3.734e-03  iter ratio: 0.0000  Data: 0.022 (0.044)
INFO:Train: 157 [ 300/625 ( 48%)]  Loss: 0.003866 (0.00405)  Time: 0.705s, 2905.74/s  (0.718s, 2854.32/s)  avg LR: 3.734e-03  iter ratio: 0.0000  Data: 0.029 (0.041)
INFO:Train: 157 [ 350/625 ( 56%)]  Loss: 0.004393 (0.00410)  Time: 0.701s, 2921.99/s  (0.716s, 2861.89/s)  avg LR: 3.734e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 157 [ 400/625 ( 64%)]  Loss: 0.003850 (0.00407)  Time: 0.717s, 2856.69/s  (0.715s, 2865.83/s)  avg LR: 3.734e-03  iter ratio: 0.0000  Data: 0.043 (0.038)
INFO:Train: 157 [ 450/625 ( 72%)]  Loss: 0.003881 (0.00405)  Time: 0.714s, 2870.16/s  (0.715s, 2864.61/s)  avg LR: 3.734e-03  iter ratio: 0.0000  Data: 0.039 (0.039)
INFO:Train: 157 [ 500/625 ( 80%)]  Loss: 0.004469 (0.00409)  Time: 0.719s, 2846.73/s  (0.715s, 2863.61/s)  avg LR: 3.734e-03  iter ratio: 0.0000  Data: 0.045 (0.039)
INFO:Train: 157 [ 550/625 ( 88%)]  Loss: 0.004355 (0.00411)  Time: 0.714s, 2868.25/s  (0.715s, 2863.04/s)  avg LR: 3.734e-03  iter ratio: 0.0000  Data: 0.038 (0.039)
INFO:Train: 157 [ 600/625 ( 96%)]  Loss: 0.003728 (0.00408)  Time: 0.711s, 2882.26/s  (0.716s, 2862.18/s)  avg LR: 3.734e-03  iter ratio: 0.0000  Data: 0.035 (0.040)
INFO:Train: 157 [ 624/625 (100%)]  Loss: 0.004430 (0.00411)  Time: 0.674s, 3040.20/s  (0.715s, 2862.83/s)  avg LR: 3.734e-03  iter ratio: 0.0000  Data: 0.000 (0.039)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.307 (4.307)  Loss:  1.0840 (1.0840)  Acc@1: 75.8789 (75.8789)  Acc@5: 91.3574 (91.3574)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.8545 (1.3843)  Acc@1: 79.2453 (68.5400)  Acc@5: 93.9858 (88.7280)
INFO:157-epoch: remaining time 19.62 h
INFO:Train: 158 [   0/625 (  0%)]  Loss: 0.003552 (0.00355)  Time: 4.540s,  451.14/s  (4.540s,  451.14/s)  avg LR: 3.692e-03  iter ratio: 0.0000  Data: 3.855 (3.855)
INFO:Train: 158 [  50/625 (  8%)]  Loss: 0.003265 (0.00341)  Time: 0.715s, 2863.71/s  (0.793s, 2581.16/s)  avg LR: 3.692e-03  iter ratio: 0.0000  Data: 0.041 (0.112)
INFO:Train: 158 [ 100/625 ( 16%)]  Loss: 0.003344 (0.00339)  Time: 0.716s, 2859.32/s  (0.756s, 2709.96/s)  avg LR: 3.692e-03  iter ratio: 0.0000  Data: 0.043 (0.076)
INFO:Train: 158 [ 150/625 ( 24%)]  Loss: 0.003882 (0.00351)  Time: 0.714s, 2867.21/s  (0.743s, 2755.55/s)  avg LR: 3.692e-03  iter ratio: 0.0000  Data: 0.041 (0.065)
INFO:Train: 158 [ 200/625 ( 32%)]  Loss: 0.004224 (0.00365)  Time: 0.716s, 2861.51/s  (0.736s, 2782.25/s)  avg LR: 3.692e-03  iter ratio: 0.0000  Data: 0.041 (0.057)
INFO:Train: 158 [ 250/625 ( 40%)]  Loss: 0.004717 (0.00383)  Time: 0.717s, 2857.12/s  (0.733s, 2795.52/s)  avg LR: 3.692e-03  iter ratio: 0.0000  Data: 0.040 (0.054)
INFO:Train: 158 [ 300/625 ( 48%)]  Loss: 0.004417 (0.00391)  Time: 0.702s, 2915.78/s  (0.729s, 2810.56/s)  avg LR: 3.692e-03  iter ratio: 0.0000  Data: 0.026 (0.051)
INFO:Train: 158 [ 350/625 ( 56%)]  Loss: 0.003694 (0.00389)  Time: 0.705s, 2904.19/s  (0.725s, 2823.51/s)  avg LR: 3.692e-03  iter ratio: 0.0000  Data: 0.029 (0.048)
INFO:Train: 158 [ 400/625 ( 64%)]  Loss: 0.003999 (0.00390)  Time: 0.701s, 2921.58/s  (0.723s, 2834.20/s)  avg LR: 3.692e-03  iter ratio: 0.0000  Data: 0.022 (0.045)
INFO:Train: 158 [ 450/625 ( 72%)]  Loss: 0.004028 (0.00391)  Time: 0.716s, 2859.40/s  (0.722s, 2837.17/s)  avg LR: 3.692e-03  iter ratio: 0.0000  Data: 0.041 (0.044)
INFO:Train: 158 [ 500/625 ( 80%)]  Loss: 0.004171 (0.00394)  Time: 0.702s, 2917.35/s  (0.720s, 2844.50/s)  avg LR: 3.692e-03  iter ratio: 0.0000  Data: 0.024 (0.043)
INFO:Train: 158 [ 550/625 ( 88%)]  Loss: 0.003741 (0.00392)  Time: 0.701s, 2920.67/s  (0.719s, 2849.58/s)  avg LR: 3.692e-03  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 158 [ 600/625 ( 96%)]  Loss: 0.003381 (0.00388)  Time: 0.700s, 2927.37/s  (0.717s, 2854.61/s)  avg LR: 3.692e-03  iter ratio: 0.0000  Data: 0.020 (0.040)
INFO:Train: 158 [ 624/625 (100%)]  Loss: 0.004184 (0.00390)  Time: 0.679s, 3015.04/s  (0.717s, 2856.37/s)  avg LR: 3.692e-03  iter ratio: 0.0000  Data: 0.000 (0.039)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.368 (4.368)  Loss:  0.8081 (0.8081)  Acc@1: 81.5430 (81.5430)  Acc@5: 94.4824 (94.4824)
INFO:Test: [  24/24]  Time: 0.080 (0.509)  Loss:  0.8008 (1.2624)  Acc@1: 81.0141 (70.8140)  Acc@5: 94.2217 (90.0520)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-156.pth.tar', 71.02000001953125)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-158.pth.tar', 70.81399989746093)

INFO:158-epoch: remaining time 19.56 h
INFO:Train: 159 [   0/625 (  0%)]  Loss: 0.003586 (0.00359)  Time: 4.414s,  464.01/s  (4.414s,  464.01/s)  avg LR: 3.651e-03  iter ratio: 0.0000  Data: 3.726 (3.726)
INFO:Train: 159 [  50/625 (  8%)]  Loss: 0.004629 (0.00411)  Time: 0.699s, 2931.61/s  (0.777s, 2637.21/s)  avg LR: 3.651e-03  iter ratio: 0.0000  Data: 0.024 (0.101)
INFO:Train: 159 [ 100/625 ( 16%)]  Loss: 0.004052 (0.00409)  Time: 0.698s, 2934.29/s  (0.740s, 2769.32/s)  avg LR: 3.651e-03  iter ratio: 0.0000  Data: 0.022 (0.065)
INFO:Train: 159 [ 150/625 ( 24%)]  Loss: 0.003570 (0.00396)  Time: 0.702s, 2916.10/s  (0.727s, 2816.18/s)  avg LR: 3.651e-03  iter ratio: 0.0000  Data: 0.028 (0.052)
INFO:Train: 159 [ 200/625 ( 32%)]  Loss: 0.004887 (0.00414)  Time: 0.700s, 2924.01/s  (0.721s, 2840.05/s)  avg LR: 3.651e-03  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 159 [ 250/625 ( 40%)]  Loss: 0.004024 (0.00412)  Time: 0.698s, 2932.63/s  (0.717s, 2854.53/s)  avg LR: 3.651e-03  iter ratio: 0.0000  Data: 0.024 (0.042)
INFO:Train: 159 [ 300/625 ( 48%)]  Loss: 0.004378 (0.00416)  Time: 0.699s, 2928.67/s  (0.715s, 2865.11/s)  avg LR: 3.651e-03  iter ratio: 0.0000  Data: 0.024 (0.040)
INFO:Train: 159 [ 350/625 ( 56%)]  Loss: 0.003879 (0.00413)  Time: 0.701s, 2922.42/s  (0.713s, 2872.71/s)  avg LR: 3.651e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 159 [ 400/625 ( 64%)]  Loss: 0.003528 (0.00406)  Time: 0.697s, 2936.94/s  (0.712s, 2877.15/s)  avg LR: 3.651e-03  iter ratio: 0.0000  Data: 0.022 (0.037)
INFO:Train: 159 [ 450/625 ( 72%)]  Loss: 0.004516 (0.00410)  Time: 0.703s, 2911.63/s  (0.711s, 2881.54/s)  avg LR: 3.651e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 159 [ 500/625 ( 80%)]  Loss: 0.003592 (0.00406)  Time: 0.699s, 2930.46/s  (0.710s, 2884.11/s)  avg LR: 3.651e-03  iter ratio: 0.0000  Data: 0.022 (0.035)
INFO:Train: 159 [ 550/625 ( 88%)]  Loss: 0.004435 (0.00409)  Time: 0.700s, 2924.64/s  (0.710s, 2886.41/s)  avg LR: 3.651e-03  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 159 [ 600/625 ( 96%)]  Loss: 0.003862 (0.00407)  Time: 0.701s, 2922.24/s  (0.709s, 2887.95/s)  avg LR: 3.651e-03  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 159 [ 624/625 (100%)]  Loss: 0.003141 (0.00401)  Time: 0.673s, 3043.38/s  (0.709s, 2889.24/s)  avg LR: 3.651e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.375 (4.375)  Loss:  0.8320 (0.8320)  Acc@1: 81.4453 (81.4453)  Acc@5: 94.4336 (94.4336)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.7905 (1.2538)  Acc@1: 82.3113 (71.2760)  Acc@5: 95.2830 (90.4000)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-159.pth.tar', 71.27599994384765)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-156.pth.tar', 71.02000001953125)

INFO:159-epoch: remaining time 19.24 h
INFO:Train: 160 [   0/625 (  0%)]  Loss: 0.003757 (0.00376)  Time: 4.290s,  477.36/s  (4.290s,  477.36/s)  avg LR: 3.609e-03  iter ratio: 0.0000  Data: 3.602 (3.602)
INFO:Train: 160 [  50/625 (  8%)]  Loss: 0.004815 (0.00429)  Time: 0.701s, 2920.28/s  (0.773s, 2648.32/s)  avg LR: 3.609e-03  iter ratio: 0.0000  Data: 0.026 (0.097)
INFO:Train: 160 [ 100/625 ( 16%)]  Loss: 0.004412 (0.00433)  Time: 0.713s, 2873.46/s  (0.741s, 2764.82/s)  avg LR: 3.609e-03  iter ratio: 0.0000  Data: 0.039 (0.065)
INFO:Train: 160 [ 150/625 ( 24%)]  Loss: 0.003639 (0.00416)  Time: 0.699s, 2930.13/s  (0.732s, 2797.95/s)  avg LR: 3.609e-03  iter ratio: 0.0000  Data: 0.024 (0.056)
INFO:Train: 160 [ 200/625 ( 32%)]  Loss: 0.004704 (0.00427)  Time: 0.701s, 2921.42/s  (0.725s, 2825.08/s)  avg LR: 3.609e-03  iter ratio: 0.0000  Data: 0.025 (0.049)
INFO:Train: 160 [ 250/625 ( 40%)]  Loss: 0.003984 (0.00422)  Time: 0.700s, 2924.29/s  (0.721s, 2842.04/s)  avg LR: 3.609e-03  iter ratio: 0.0000  Data: 0.022 (0.045)
INFO:Train: 160 [ 300/625 ( 48%)]  Loss: 0.003718 (0.00415)  Time: 0.697s, 2937.17/s  (0.718s, 2850.39/s)  avg LR: 3.609e-03  iter ratio: 0.0000  Data: 0.023 (0.042)
INFO:Train: 160 [ 350/625 ( 56%)]  Loss: 0.003564 (0.00407)  Time: 0.703s, 2913.22/s  (0.716s, 2859.32/s)  avg LR: 3.609e-03  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 160 [ 400/625 ( 64%)]  Loss: 0.003846 (0.00405)  Time: 0.703s, 2912.28/s  (0.715s, 2865.42/s)  avg LR: 3.609e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 160 [ 450/625 ( 72%)]  Loss: 0.003753 (0.00402)  Time: 0.703s, 2914.55/s  (0.714s, 2870.22/s)  avg LR: 3.609e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 160 [ 500/625 ( 80%)]  Loss: 0.004744 (0.00409)  Time: 0.716s, 2860.47/s  (0.713s, 2872.11/s)  avg LR: 3.609e-03  iter ratio: 0.0000  Data: 0.041 (0.037)
INFO:Train: 160 [ 550/625 ( 88%)]  Loss: 0.004338 (0.00411)  Time: 0.718s, 2852.81/s  (0.713s, 2870.81/s)  avg LR: 3.609e-03  iter ratio: 0.0000  Data: 0.041 (0.037)
INFO:Train: 160 [ 600/625 ( 96%)]  Loss: 0.003361 (0.00405)  Time: 0.701s, 2919.50/s  (0.713s, 2871.12/s)  avg LR: 3.609e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 160 [ 624/625 (100%)]  Loss: 0.003762 (0.00403)  Time: 0.672s, 3049.06/s  (0.713s, 2873.59/s)  avg LR: 3.609e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.357 (4.357)  Loss:  0.9092 (0.9092)  Acc@1: 79.2480 (79.2480)  Acc@5: 93.5059 (93.5059)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.7417 (1.3156)  Acc@1: 82.3113 (69.6840)  Acc@5: 95.1651 (89.5760)
INFO:160-epoch: remaining time 19.17 h
INFO:Train: 161 [   0/625 (  0%)]  Loss: 0.003464 (0.00346)  Time: 4.137s,  494.99/s  (4.137s,  494.99/s)  avg LR: 3.568e-03  iter ratio: 0.0000  Data: 3.453 (3.453)
INFO:Train: 161 [  50/625 (  8%)]  Loss: 0.003509 (0.00349)  Time: 0.698s, 2932.37/s  (0.776s, 2638.61/s)  avg LR: 3.568e-03  iter ratio: 0.0000  Data: 0.024 (0.099)
INFO:Train: 161 [ 100/625 ( 16%)]  Loss: 0.004113 (0.00370)  Time: 0.704s, 2908.99/s  (0.743s, 2755.07/s)  avg LR: 3.568e-03  iter ratio: 0.0000  Data: 0.029 (0.067)
INFO:Train: 161 [ 150/625 ( 24%)]  Loss: 0.004244 (0.00383)  Time: 0.702s, 2917.11/s  (0.730s, 2806.79/s)  avg LR: 3.568e-03  iter ratio: 0.0000  Data: 0.027 (0.054)
INFO:Train: 161 [ 200/625 ( 32%)]  Loss: 0.004878 (0.00404)  Time: 0.709s, 2887.19/s  (0.723s, 2831.98/s)  avg LR: 3.568e-03  iter ratio: 0.0000  Data: 0.034 (0.047)
INFO:Train: 161 [ 250/625 ( 40%)]  Loss: 0.004323 (0.00409)  Time: 0.700s, 2926.84/s  (0.719s, 2847.26/s)  avg LR: 3.568e-03  iter ratio: 0.0000  Data: 0.024 (0.043)
INFO:Train: 161 [ 300/625 ( 48%)]  Loss: 0.004014 (0.00408)  Time: 0.697s, 2936.34/s  (0.716s, 2859.09/s)  avg LR: 3.568e-03  iter ratio: 0.0000  Data: 0.023 (0.040)
INFO:Train: 161 [ 350/625 ( 56%)]  Loss: 0.003621 (0.00402)  Time: 0.701s, 2919.64/s  (0.714s, 2866.77/s)  avg LR: 3.568e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 161 [ 400/625 ( 64%)]  Loss: 0.004540 (0.00408)  Time: 0.707s, 2898.16/s  (0.713s, 2872.70/s)  avg LR: 3.568e-03  iter ratio: 0.0000  Data: 0.021 (0.037)
INFO:Train: 161 [ 450/625 ( 72%)]  Loss: 0.003860 (0.00406)  Time: 0.701s, 2920.10/s  (0.712s, 2876.74/s)  avg LR: 3.568e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 161 [ 500/625 ( 80%)]  Loss: 0.004592 (0.00411)  Time: 0.702s, 2916.87/s  (0.711s, 2879.39/s)  avg LR: 3.568e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 161 [ 550/625 ( 88%)]  Loss: 0.003929 (0.00409)  Time: 0.714s, 2868.34/s  (0.711s, 2881.85/s)  avg LR: 3.568e-03  iter ratio: 0.0000  Data: 0.039 (0.034)
INFO:Train: 161 [ 600/625 ( 96%)]  Loss: 0.004407 (0.00411)  Time: 0.704s, 2909.31/s  (0.710s, 2883.61/s)  avg LR: 3.568e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 161 [ 624/625 (100%)]  Loss: 0.003942 (0.00410)  Time: 0.676s, 3031.67/s  (0.710s, 2885.24/s)  avg LR: 3.568e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.346 (4.346)  Loss:  0.7827 (0.7827)  Acc@1: 82.4219 (82.4219)  Acc@5: 94.7754 (94.7754)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.7344 (1.2512)  Acc@1: 82.6651 (71.4920)  Acc@5: 95.2830 (90.7300)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-161.pth.tar', 71.49200009765624)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-159.pth.tar', 71.27599994384765)

INFO:161-epoch: remaining time 19.01 h
INFO:Train: 162 [   0/625 (  0%)]  Loss: 0.004265 (0.00427)  Time: 4.606s,  444.62/s  (4.606s,  444.62/s)  avg LR: 3.527e-03  iter ratio: 0.0000  Data: 3.904 (3.904)
INFO:Train: 162 [  50/625 (  8%)]  Loss: 0.004022 (0.00414)  Time: 0.701s, 2921.46/s  (0.779s, 2629.08/s)  avg LR: 3.527e-03  iter ratio: 0.0000  Data: 0.026 (0.102)
INFO:Train: 162 [ 100/625 ( 16%)]  Loss: 0.004261 (0.00418)  Time: 0.701s, 2920.16/s  (0.741s, 2761.99/s)  avg LR: 3.527e-03  iter ratio: 0.0000  Data: 0.026 (0.065)
INFO:Train: 162 [ 150/625 ( 24%)]  Loss: 0.003630 (0.00404)  Time: 0.716s, 2861.76/s  (0.731s, 2802.93/s)  avg LR: 3.527e-03  iter ratio: 0.0000  Data: 0.041 (0.054)
INFO:Train: 162 [ 200/625 ( 32%)]  Loss: 0.003957 (0.00403)  Time: 0.716s, 2859.24/s  (0.727s, 2815.84/s)  avg LR: 3.527e-03  iter ratio: 0.0000  Data: 0.042 (0.051)
INFO:Train: 162 [ 250/625 ( 40%)]  Loss: 0.003877 (0.00400)  Time: 0.714s, 2868.85/s  (0.725s, 2823.26/s)  avg LR: 3.527e-03  iter ratio: 0.0000  Data: 0.039 (0.050)
INFO:Train: 162 [ 300/625 ( 48%)]  Loss: 0.003966 (0.00400)  Time: 0.707s, 2894.93/s  (0.723s, 2831.95/s)  avg LR: 3.527e-03  iter ratio: 0.0000  Data: 0.028 (0.048)
INFO:Train: 162 [ 350/625 ( 56%)]  Loss: 0.003589 (0.00395)  Time: 0.711s, 2879.35/s  (0.721s, 2841.47/s)  avg LR: 3.527e-03  iter ratio: 0.0000  Data: 0.036 (0.045)
INFO:Train: 162 [ 400/625 ( 64%)]  Loss: 0.003837 (0.00393)  Time: 0.702s, 2916.58/s  (0.719s, 2849.53/s)  avg LR: 3.527e-03  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 162 [ 450/625 ( 72%)]  Loss: 0.003503 (0.00389)  Time: 0.702s, 2916.25/s  (0.717s, 2856.92/s)  avg LR: 3.527e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 162 [ 500/625 ( 80%)]  Loss: 0.003945 (0.00390)  Time: 0.705s, 2903.00/s  (0.716s, 2861.65/s)  avg LR: 3.527e-03  iter ratio: 0.0000  Data: 0.030 (0.040)
INFO:Train: 162 [ 550/625 ( 88%)]  Loss: 0.004165 (0.00392)  Time: 0.703s, 2914.71/s  (0.715s, 2865.71/s)  avg LR: 3.527e-03  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 162 [ 600/625 ( 96%)]  Loss: 0.004797 (0.00399)  Time: 0.702s, 2919.20/s  (0.714s, 2869.71/s)  avg LR: 3.527e-03  iter ratio: 0.0000  Data: 0.023 (0.038)
INFO:Train: 162 [ 624/625 (100%)]  Loss: 0.004029 (0.00399)  Time: 0.673s, 3041.01/s  (0.713s, 2871.36/s)  avg LR: 3.527e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.364 (4.364)  Loss:  0.9111 (0.9111)  Acc@1: 80.2246 (80.2246)  Acc@5: 93.7012 (93.7012)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.7397 (1.3294)  Acc@1: 82.3113 (70.1520)  Acc@5: 94.5755 (89.8160)
INFO:162-epoch: remaining time 18.95 h
INFO:Train: 163 [   0/625 (  0%)]  Loss: 0.003902 (0.00390)  Time: 4.349s,  470.92/s  (4.349s,  470.92/s)  avg LR: 3.486e-03  iter ratio: 0.0000  Data: 3.665 (3.665)
INFO:Train: 163 [  50/625 (  8%)]  Loss: 0.003416 (0.00366)  Time: 0.714s, 2866.61/s  (0.778s, 2632.96/s)  avg LR: 3.486e-03  iter ratio: 0.0000  Data: 0.040 (0.101)
INFO:Train: 163 [ 100/625 ( 16%)]  Loss: 0.003731 (0.00368)  Time: 0.709s, 2889.80/s  (0.748s, 2739.66/s)  avg LR: 3.486e-03  iter ratio: 0.0000  Data: 0.031 (0.071)
INFO:Train: 163 [ 150/625 ( 24%)]  Loss: 0.004342 (0.00385)  Time: 0.713s, 2873.88/s  (0.737s, 2777.79/s)  avg LR: 3.486e-03  iter ratio: 0.0000  Data: 0.038 (0.061)
INFO:Train: 163 [ 200/625 ( 32%)]  Loss: 0.003758 (0.00383)  Time: 0.717s, 2855.92/s  (0.732s, 2797.19/s)  avg LR: 3.486e-03  iter ratio: 0.0000  Data: 0.042 (0.056)
INFO:Train: 163 [ 250/625 ( 40%)]  Loss: 0.004397 (0.00392)  Time: 0.714s, 2869.20/s  (0.729s, 2809.27/s)  avg LR: 3.486e-03  iter ratio: 0.0000  Data: 0.039 (0.053)
INFO:Train: 163 [ 300/625 ( 48%)]  Loss: 0.004473 (0.00400)  Time: 0.709s, 2889.21/s  (0.726s, 2822.45/s)  avg LR: 3.486e-03  iter ratio: 0.0000  Data: 0.030 (0.050)
INFO:Train: 163 [ 350/625 ( 56%)]  Loss: 0.004319 (0.00404)  Time: 0.703s, 2913.80/s  (0.722s, 2835.80/s)  avg LR: 3.486e-03  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 163 [ 400/625 ( 64%)]  Loss: 0.003980 (0.00404)  Time: 0.702s, 2916.84/s  (0.720s, 2845.60/s)  avg LR: 3.486e-03  iter ratio: 0.0000  Data: 0.023 (0.044)
INFO:Train: 163 [ 450/625 ( 72%)]  Loss: 0.004350 (0.00407)  Time: 0.697s, 2937.64/s  (0.719s, 2849.83/s)  avg LR: 3.486e-03  iter ratio: 0.0000  Data: 0.022 (0.043)
INFO:Train: 163 [ 500/625 ( 80%)]  Loss: 0.003901 (0.00405)  Time: 0.707s, 2897.10/s  (0.717s, 2856.29/s)  avg LR: 3.486e-03  iter ratio: 0.0000  Data: 0.029 (0.041)
INFO:Train: 163 [ 550/625 ( 88%)]  Loss: 0.004069 (0.00405)  Time: 0.707s, 2897.55/s  (0.716s, 2861.34/s)  avg LR: 3.486e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 163 [ 600/625 ( 96%)]  Loss: 0.003408 (0.00400)  Time: 0.699s, 2931.12/s  (0.715s, 2864.91/s)  avg LR: 3.486e-03  iter ratio: 0.0000  Data: 0.018 (0.038)
INFO:Train: 163 [ 624/625 (100%)]  Loss: 0.004026 (0.00401)  Time: 0.673s, 3044.79/s  (0.714s, 2867.21/s)  avg LR: 3.486e-03  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.334 (4.334)  Loss:  0.8281 (0.8281)  Acc@1: 81.0059 (81.0059)  Acc@5: 95.0195 (95.0195)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.7163 (1.2185)  Acc@1: 84.1981 (72.3340)  Acc@5: 95.4009 (91.1400)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-163.pth.tar', 72.33399998779296)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-161.pth.tar', 71.49200009765624)

INFO:163-epoch: remaining time 18.86 h
INFO:Train: 164 [   0/625 (  0%)]  Loss: 0.003558 (0.00356)  Time: 4.330s,  472.99/s  (4.330s,  472.99/s)  avg LR: 3.444e-03  iter ratio: 0.0000  Data: 3.633 (3.633)
INFO:Train: 164 [  50/625 (  8%)]  Loss: 0.003261 (0.00341)  Time: 0.700s, 2925.42/s  (0.782s, 2619.47/s)  avg LR: 3.444e-03  iter ratio: 0.0000  Data: 0.025 (0.105)
INFO:Train: 164 [ 100/625 ( 16%)]  Loss: 0.003693 (0.00350)  Time: 0.703s, 2911.24/s  (0.744s, 2753.70/s)  avg LR: 3.444e-03  iter ratio: 0.0000  Data: 0.029 (0.067)
INFO:Train: 164 [ 150/625 ( 24%)]  Loss: 0.003845 (0.00359)  Time: 0.710s, 2884.49/s  (0.731s, 2803.31/s)  avg LR: 3.444e-03  iter ratio: 0.0000  Data: 0.036 (0.054)
INFO:Train: 164 [ 200/625 ( 32%)]  Loss: 0.003555 (0.00358)  Time: 0.702s, 2918.91/s  (0.724s, 2830.47/s)  avg LR: 3.444e-03  iter ratio: 0.0000  Data: 0.028 (0.047)
INFO:Train: 164 [ 250/625 ( 40%)]  Loss: 0.003853 (0.00363)  Time: 0.703s, 2913.32/s  (0.720s, 2846.17/s)  avg LR: 3.444e-03  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 164 [ 300/625 ( 48%)]  Loss: 0.004372 (0.00373)  Time: 0.703s, 2914.35/s  (0.717s, 2858.13/s)  avg LR: 3.444e-03  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 164 [ 350/625 ( 56%)]  Loss: 0.003699 (0.00373)  Time: 0.703s, 2911.83/s  (0.715s, 2865.59/s)  avg LR: 3.444e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 164 [ 400/625 ( 64%)]  Loss: 0.003775 (0.00373)  Time: 0.702s, 2917.37/s  (0.713s, 2871.82/s)  avg LR: 3.444e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 164 [ 450/625 ( 72%)]  Loss: 0.004045 (0.00377)  Time: 0.704s, 2907.19/s  (0.712s, 2876.59/s)  avg LR: 3.444e-03  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 164 [ 500/625 ( 80%)]  Loss: 0.003497 (0.00374)  Time: 0.702s, 2917.39/s  (0.711s, 2880.05/s)  avg LR: 3.444e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 164 [ 550/625 ( 88%)]  Loss: 0.004303 (0.00379)  Time: 0.703s, 2911.21/s  (0.710s, 2883.37/s)  avg LR: 3.444e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 164 [ 600/625 ( 96%)]  Loss: 0.004149 (0.00382)  Time: 0.701s, 2919.86/s  (0.710s, 2885.67/s)  avg LR: 3.444e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 164 [ 624/625 (100%)]  Loss: 0.003747 (0.00381)  Time: 0.674s, 3039.94/s  (0.709s, 2887.48/s)  avg LR: 3.444e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.369 (4.369)  Loss:  0.8149 (0.8149)  Acc@1: 80.9570 (80.9570)  Acc@5: 94.9707 (94.9707)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.7070 (1.2221)  Acc@1: 83.1368 (72.1960)  Acc@5: 95.9906 (91.1380)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-163.pth.tar', 72.33399998779296)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-164.pth.tar', 72.19600004394532)

INFO:164-epoch: remaining time 18.59 h
INFO:Train: 165 [   0/625 (  0%)]  Loss: 0.004069 (0.00407)  Time: 4.249s,  482.05/s  (4.249s,  482.05/s)  avg LR: 3.403e-03  iter ratio: 0.0000  Data: 3.552 (3.552)
INFO:Train: 165 [  50/625 (  8%)]  Loss: 0.003363 (0.00372)  Time: 0.707s, 2894.76/s  (0.773s, 2648.89/s)  avg LR: 3.403e-03  iter ratio: 0.0000  Data: 0.032 (0.096)
INFO:Train: 165 [ 100/625 ( 16%)]  Loss: 0.004383 (0.00394)  Time: 0.717s, 2858.10/s  (0.739s, 2772.78/s)  avg LR: 3.403e-03  iter ratio: 0.0000  Data: 0.042 (0.062)
INFO:Train: 165 [ 150/625 ( 24%)]  Loss: 0.003690 (0.00388)  Time: 0.702s, 2917.22/s  (0.729s, 2810.35/s)  avg LR: 3.403e-03  iter ratio: 0.0000  Data: 0.027 (0.053)
INFO:Train: 165 [ 200/625 ( 32%)]  Loss: 0.003844 (0.00387)  Time: 0.701s, 2919.63/s  (0.722s, 2834.87/s)  avg LR: 3.403e-03  iter ratio: 0.0000  Data: 0.027 (0.047)
INFO:Train: 165 [ 250/625 ( 40%)]  Loss: 0.005068 (0.00407)  Time: 0.720s, 2845.81/s  (0.719s, 2849.08/s)  avg LR: 3.403e-03  iter ratio: 0.0000  Data: 0.045 (0.042)
INFO:Train: 165 [ 300/625 ( 48%)]  Loss: 0.004216 (0.00409)  Time: 0.698s, 2935.29/s  (0.717s, 2855.50/s)  avg LR: 3.403e-03  iter ratio: 0.0000  Data: 0.024 (0.041)
INFO:Train: 165 [ 350/625 ( 56%)]  Loss: 0.003509 (0.00402)  Time: 0.708s, 2893.67/s  (0.715s, 2862.83/s)  avg LR: 3.403e-03  iter ratio: 0.0000  Data: 0.032 (0.039)
INFO:Train: 165 [ 400/625 ( 64%)]  Loss: 0.004283 (0.00405)  Time: 0.710s, 2886.23/s  (0.714s, 2868.21/s)  avg LR: 3.403e-03  iter ratio: 0.0000  Data: 0.033 (0.038)
INFO:Train: 165 [ 450/625 ( 72%)]  Loss: 0.003428 (0.00399)  Time: 0.703s, 2915.11/s  (0.713s, 2872.80/s)  avg LR: 3.403e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 165 [ 500/625 ( 80%)]  Loss: 0.004287 (0.00401)  Time: 0.719s, 2849.33/s  (0.713s, 2873.11/s)  avg LR: 3.403e-03  iter ratio: 0.0000  Data: 0.044 (0.036)
INFO:Train: 165 [ 550/625 ( 88%)]  Loss: 0.004701 (0.00407)  Time: 0.716s, 2861.03/s  (0.713s, 2871.69/s)  avg LR: 3.403e-03  iter ratio: 0.0000  Data: 0.040 (0.037)
INFO:Train: 165 [ 600/625 ( 96%)]  Loss: 0.003619 (0.00404)  Time: 0.713s, 2870.74/s  (0.713s, 2870.62/s)  avg LR: 3.403e-03  iter ratio: 0.0000  Data: 0.039 (0.037)
INFO:Train: 165 [ 624/625 (100%)]  Loss: 0.004258 (0.00405)  Time: 0.676s, 3030.60/s  (0.713s, 2870.73/s)  avg LR: 3.403e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.351 (4.351)  Loss:  0.8701 (0.8701)  Acc@1: 78.5645 (78.5645)  Acc@5: 94.7754 (94.7754)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.7505 (1.2738)  Acc@1: 81.6038 (70.7740)  Acc@5: 95.5189 (90.2380)
INFO:165-epoch: remaining time 18.56 h
INFO:Train: 166 [   0/625 (  0%)]  Loss: 0.004215 (0.00421)  Time: 4.106s,  498.76/s  (4.106s,  498.76/s)  avg LR: 3.362e-03  iter ratio: 0.0000  Data: 3.399 (3.399)
INFO:Train: 166 [  50/625 (  8%)]  Loss: 0.004065 (0.00414)  Time: 0.704s, 2910.10/s  (0.774s, 2645.34/s)  avg LR: 3.362e-03  iter ratio: 0.0000  Data: 0.029 (0.096)
INFO:Train: 166 [ 100/625 ( 16%)]  Loss: 0.004264 (0.00418)  Time: 0.701s, 2923.27/s  (0.740s, 2767.00/s)  avg LR: 3.362e-03  iter ratio: 0.0000  Data: 0.023 (0.063)
INFO:Train: 166 [ 150/625 ( 24%)]  Loss: 0.003379 (0.00398)  Time: 0.719s, 2849.81/s  (0.730s, 2807.33/s)  avg LR: 3.362e-03  iter ratio: 0.0000  Data: 0.044 (0.052)
INFO:Train: 166 [ 200/625 ( 32%)]  Loss: 0.002998 (0.00378)  Time: 0.713s, 2871.53/s  (0.727s, 2817.85/s)  avg LR: 3.362e-03  iter ratio: 0.0000  Data: 0.039 (0.050)
INFO:Train: 166 [ 250/625 ( 40%)]  Loss: 0.003777 (0.00378)  Time: 0.720s, 2843.99/s  (0.725s, 2824.01/s)  avg LR: 3.362e-03  iter ratio: 0.0000  Data: 0.042 (0.048)
INFO:Train: 166 [ 300/625 ( 48%)]  Loss: 0.004144 (0.00383)  Time: 0.704s, 2907.85/s  (0.724s, 2830.52/s)  avg LR: 3.362e-03  iter ratio: 0.0000  Data: 0.030 (0.047)
INFO:Train: 166 [ 350/625 ( 56%)]  Loss: 0.003553 (0.00380)  Time: 0.708s, 2893.21/s  (0.721s, 2841.11/s)  avg LR: 3.362e-03  iter ratio: 0.0000  Data: 0.028 (0.044)
INFO:Train: 166 [ 400/625 ( 64%)]  Loss: 0.003523 (0.00377)  Time: 0.708s, 2891.77/s  (0.720s, 2846.41/s)  avg LR: 3.362e-03  iter ratio: 0.0000  Data: 0.034 (0.043)
INFO:Train: 166 [ 450/625 ( 72%)]  Loss: 0.004153 (0.00381)  Time: 0.714s, 2869.72/s  (0.719s, 2847.28/s)  avg LR: 3.362e-03  iter ratio: 0.0000  Data: 0.039 (0.043)
INFO:Train: 166 [ 500/625 ( 80%)]  Loss: 0.004153 (0.00384)  Time: 0.715s, 2864.90/s  (0.719s, 2847.81/s)  avg LR: 3.362e-03  iter ratio: 0.0000  Data: 0.041 (0.043)
INFO:Train: 166 [ 550/625 ( 88%)]  Loss: 0.004507 (0.00389)  Time: 0.715s, 2865.15/s  (0.719s, 2848.59/s)  avg LR: 3.362e-03  iter ratio: 0.0000  Data: 0.040 (0.043)
INFO:Train: 166 [ 600/625 ( 96%)]  Loss: 0.004200 (0.00392)  Time: 0.718s, 2851.83/s  (0.719s, 2848.91/s)  avg LR: 3.362e-03  iter ratio: 0.0000  Data: 0.044 (0.043)
INFO:Train: 166 [ 624/625 (100%)]  Loss: 0.003936 (0.00392)  Time: 0.672s, 3046.48/s  (0.718s, 2851.25/s)  avg LR: 3.362e-03  iter ratio: 0.0000  Data: 0.000 (0.042)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.380 (4.380)  Loss:  0.7964 (0.7964)  Acc@1: 81.3477 (81.3477)  Acc@5: 94.7266 (94.7266)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.7109 (1.2226)  Acc@1: 83.3727 (71.4400)  Acc@5: 95.4009 (90.4120)
INFO:166-epoch: remaining time 18.56 h
INFO:Train: 167 [   0/625 (  0%)]  Loss: 0.004088 (0.00409)  Time: 4.537s,  451.37/s  (4.537s,  451.37/s)  avg LR: 3.321e-03  iter ratio: 0.0000  Data: 3.844 (3.844)
INFO:Train: 167 [  50/625 (  8%)]  Loss: 0.004192 (0.00414)  Time: 0.709s, 2888.52/s  (0.789s, 2594.31/s)  avg LR: 3.321e-03  iter ratio: 0.0000  Data: 0.029 (0.107)
INFO:Train: 167 [ 100/625 ( 16%)]  Loss: 0.004328 (0.00420)  Time: 0.708s, 2891.85/s  (0.749s, 2735.43/s)  avg LR: 3.321e-03  iter ratio: 0.0000  Data: 0.029 (0.068)
INFO:Train: 167 [ 150/625 ( 24%)]  Loss: 0.003381 (0.00400)  Time: 0.709s, 2887.44/s  (0.735s, 2786.59/s)  avg LR: 3.321e-03  iter ratio: 0.0000  Data: 0.029 (0.054)
INFO:Train: 167 [ 200/625 ( 32%)]  Loss: 0.003440 (0.00389)  Time: 0.707s, 2897.15/s  (0.728s, 2813.33/s)  avg LR: 3.321e-03  iter ratio: 0.0000  Data: 0.025 (0.047)
INFO:Train: 167 [ 250/625 ( 40%)]  Loss: 0.004206 (0.00394)  Time: 0.708s, 2891.42/s  (0.724s, 2829.64/s)  avg LR: 3.321e-03  iter ratio: 0.0000  Data: 0.030 (0.043)
INFO:Train: 167 [ 300/625 ( 48%)]  Loss: 0.004546 (0.00403)  Time: 0.702s, 2919.17/s  (0.721s, 2841.52/s)  avg LR: 3.321e-03  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 167 [ 350/625 ( 56%)]  Loss: 0.004340 (0.00406)  Time: 0.707s, 2897.93/s  (0.719s, 2848.47/s)  avg LR: 3.321e-03  iter ratio: 0.0000  Data: 0.021 (0.038)
INFO:Train: 167 [ 400/625 ( 64%)]  Loss: 0.003983 (0.00406)  Time: 0.704s, 2907.71/s  (0.717s, 2855.12/s)  avg LR: 3.321e-03  iter ratio: 0.0000  Data: 0.020 (0.037)
INFO:Train: 167 [ 450/625 ( 72%)]  Loss: 0.003185 (0.00397)  Time: 0.703s, 2913.62/s  (0.716s, 2860.55/s)  avg LR: 3.321e-03  iter ratio: 0.0000  Data: 0.020 (0.035)
INFO:Train: 167 [ 500/625 ( 80%)]  Loss: 0.003591 (0.00393)  Time: 0.707s, 2898.64/s  (0.715s, 2864.83/s)  avg LR: 3.321e-03  iter ratio: 0.0000  Data: 0.030 (0.034)
INFO:Train: 167 [ 550/625 ( 88%)]  Loss: 0.003406 (0.00389)  Time: 0.709s, 2887.40/s  (0.714s, 2867.87/s)  avg LR: 3.321e-03  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 167 [ 600/625 ( 96%)]  Loss: 0.003768 (0.00388)  Time: 0.705s, 2904.45/s  (0.713s, 2870.87/s)  avg LR: 3.321e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 167 [ 624/625 (100%)]  Loss: 0.003003 (0.00382)  Time: 0.680s, 3012.47/s  (0.713s, 2872.57/s)  avg LR: 3.321e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.302 (4.302)  Loss:  0.8516 (0.8516)  Acc@1: 80.1270 (80.1270)  Acc@5: 94.7266 (94.7266)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.7261 (1.2133)  Acc@1: 82.0755 (72.1700)  Acc@5: 95.1651 (90.8560)
INFO:167-epoch: remaining time 18.32 h
INFO:Train: 168 [   0/625 (  0%)]  Loss: 0.003842 (0.00384)  Time: 4.040s,  506.90/s  (4.040s,  506.90/s)  avg LR: 3.280e-03  iter ratio: 0.0000  Data: 3.347 (3.347)
INFO:Train: 168 [  50/625 (  8%)]  Loss: 0.004823 (0.00433)  Time: 0.704s, 2907.43/s  (0.772s, 2653.56/s)  avg LR: 3.280e-03  iter ratio: 0.0000  Data: 0.029 (0.095)
INFO:Train: 168 [ 100/625 ( 16%)]  Loss: 0.003963 (0.00421)  Time: 0.702s, 2915.98/s  (0.739s, 2773.05/s)  avg LR: 3.280e-03  iter ratio: 0.0000  Data: 0.020 (0.061)
INFO:Train: 168 [ 150/625 ( 24%)]  Loss: 0.003207 (0.00396)  Time: 0.711s, 2882.26/s  (0.728s, 2813.38/s)  avg LR: 3.280e-03  iter ratio: 0.0000  Data: 0.036 (0.050)
INFO:Train: 168 [ 200/625 ( 32%)]  Loss: 0.002970 (0.00376)  Time: 0.718s, 2853.37/s  (0.726s, 2822.60/s)  avg LR: 3.280e-03  iter ratio: 0.0000  Data: 0.044 (0.048)
INFO:Train: 168 [ 250/625 ( 40%)]  Loss: 0.003232 (0.00367)  Time: 0.707s, 2897.83/s  (0.724s, 2828.84/s)  avg LR: 3.280e-03  iter ratio: 0.0000  Data: 0.033 (0.047)
INFO:Train: 168 [ 300/625 ( 48%)]  Loss: 0.003870 (0.00370)  Time: 0.700s, 2926.38/s  (0.722s, 2837.03/s)  avg LR: 3.280e-03  iter ratio: 0.0000  Data: 0.026 (0.045)
INFO:Train: 168 [ 350/625 ( 56%)]  Loss: 0.003879 (0.00372)  Time: 0.703s, 2912.97/s  (0.719s, 2847.56/s)  avg LR: 3.280e-03  iter ratio: 0.0000  Data: 0.029 (0.042)
INFO:Train: 168 [ 400/625 ( 64%)]  Loss: 0.004464 (0.00381)  Time: 0.703s, 2912.14/s  (0.717s, 2854.45/s)  avg LR: 3.280e-03  iter ratio: 0.0000  Data: 0.024 (0.040)
INFO:Train: 168 [ 450/625 ( 72%)]  Loss: 0.003649 (0.00379)  Time: 0.702s, 2917.84/s  (0.716s, 2859.48/s)  avg LR: 3.280e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 168 [ 500/625 ( 80%)]  Loss: 0.003619 (0.00377)  Time: 0.712s, 2875.67/s  (0.716s, 2859.47/s)  avg LR: 3.280e-03  iter ratio: 0.0000  Data: 0.038 (0.038)
INFO:Train: 168 [ 550/625 ( 88%)]  Loss: 0.003603 (0.00376)  Time: 0.719s, 2850.16/s  (0.716s, 2858.86/s)  avg LR: 3.280e-03  iter ratio: 0.0000  Data: 0.044 (0.038)
INFO:Train: 168 [ 600/625 ( 96%)]  Loss: 0.004162 (0.00379)  Time: 0.722s, 2837.56/s  (0.717s, 2858.17/s)  avg LR: 3.280e-03  iter ratio: 0.0000  Data: 0.045 (0.039)
INFO:Train: 168 [ 624/625 (100%)]  Loss: 0.004532 (0.00384)  Time: 0.675s, 3033.27/s  (0.716s, 2858.84/s)  avg LR: 3.280e-03  iter ratio: 0.0000  Data: 0.000 (0.039)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.327 (4.327)  Loss:  0.8594 (0.8594)  Acc@1: 80.4688 (80.4688)  Acc@5: 94.0918 (94.0918)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.7773 (1.2326)  Acc@1: 81.4858 (71.5680)  Acc@5: 95.0472 (90.6820)
INFO:168-epoch: remaining time 18.25 h
INFO:Train: 169 [   0/625 (  0%)]  Loss: 0.003039 (0.00304)  Time: 4.480s,  457.11/s  (4.480s,  457.11/s)  avg LR: 3.239e-03  iter ratio: 0.0000  Data: 3.795 (3.795)
INFO:Train: 169 [  50/625 (  8%)]  Loss: 0.003894 (0.00347)  Time: 0.706s, 2901.80/s  (0.778s, 2630.90/s)  avg LR: 3.239e-03  iter ratio: 0.0000  Data: 0.031 (0.102)
INFO:Train: 169 [ 100/625 ( 16%)]  Loss: 0.003930 (0.00362)  Time: 0.704s, 2909.48/s  (0.742s, 2759.10/s)  avg LR: 3.239e-03  iter ratio: 0.0000  Data: 0.029 (0.066)
INFO:Train: 169 [ 150/625 ( 24%)]  Loss: 0.003231 (0.00352)  Time: 0.709s, 2890.22/s  (0.730s, 2805.86/s)  avg LR: 3.239e-03  iter ratio: 0.0000  Data: 0.034 (0.054)
INFO:Train: 169 [ 200/625 ( 32%)]  Loss: 0.004222 (0.00366)  Time: 0.711s, 2880.82/s  (0.724s, 2830.00/s)  avg LR: 3.239e-03  iter ratio: 0.0000  Data: 0.036 (0.048)
INFO:Train: 169 [ 250/625 ( 40%)]  Loss: 0.004230 (0.00376)  Time: 0.712s, 2878.36/s  (0.720s, 2843.33/s)  avg LR: 3.239e-03  iter ratio: 0.0000  Data: 0.037 (0.045)
INFO:Train: 169 [ 300/625 ( 48%)]  Loss: 0.003959 (0.00379)  Time: 0.706s, 2899.54/s  (0.718s, 2854.15/s)  avg LR: 3.239e-03  iter ratio: 0.0000  Data: 0.031 (0.042)
INFO:Train: 169 [ 350/625 ( 56%)]  Loss: 0.003174 (0.00371)  Time: 0.708s, 2891.20/s  (0.716s, 2860.07/s)  avg LR: 3.239e-03  iter ratio: 0.0000  Data: 0.033 (0.040)
INFO:Train: 169 [ 400/625 ( 64%)]  Loss: 0.003988 (0.00374)  Time: 0.705s, 2904.17/s  (0.715s, 2864.39/s)  avg LR: 3.239e-03  iter ratio: 0.0000  Data: 0.032 (0.039)
INFO:Train: 169 [ 450/625 ( 72%)]  Loss: 0.004320 (0.00380)  Time: 0.710s, 2883.61/s  (0.714s, 2868.82/s)  avg LR: 3.239e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 169 [ 500/625 ( 80%)]  Loss: 0.003848 (0.00380)  Time: 0.721s, 2842.01/s  (0.714s, 2869.24/s)  avg LR: 3.239e-03  iter ratio: 0.0000  Data: 0.043 (0.037)
INFO:Train: 169 [ 550/625 ( 88%)]  Loss: 0.003403 (0.00377)  Time: 0.720s, 2845.81/s  (0.714s, 2867.89/s)  avg LR: 3.239e-03  iter ratio: 0.0000  Data: 0.040 (0.037)
INFO:Train: 169 [ 600/625 ( 96%)]  Loss: 0.003856 (0.00378)  Time: 0.731s, 2799.82/s  (0.714s, 2866.68/s)  avg LR: 3.239e-03  iter ratio: 0.0000  Data: 0.047 (0.037)
INFO:Train: 169 [ 624/625 (100%)]  Loss: 0.003834 (0.00378)  Time: 0.678s, 3021.14/s  (0.714s, 2867.30/s)  avg LR: 3.239e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.289 (4.289)  Loss:  0.9976 (0.9976)  Acc@1: 77.2949 (77.2949)  Acc@5: 93.1641 (93.1641)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.7969 (1.2941)  Acc@1: 81.3679 (70.7900)  Acc@5: 94.5755 (90.1440)
INFO:169-epoch: remaining time 18.08 h
INFO:Train: 170 [   0/625 (  0%)]  Loss: 0.003594 (0.00359)  Time: 4.333s,  472.60/s  (4.333s,  472.60/s)  avg LR: 3.199e-03  iter ratio: 0.0000  Data: 3.631 (3.631)
INFO:Train: 170 [  50/625 (  8%)]  Loss: 0.004560 (0.00408)  Time: 0.709s, 2888.47/s  (0.789s, 2596.06/s)  avg LR: 3.199e-03  iter ratio: 0.0000  Data: 0.026 (0.106)
INFO:Train: 170 [ 100/625 ( 16%)]  Loss: 0.004006 (0.00405)  Time: 0.710s, 2884.87/s  (0.750s, 2729.35/s)  avg LR: 3.199e-03  iter ratio: 0.0000  Data: 0.030 (0.069)
INFO:Train: 170 [ 150/625 ( 24%)]  Loss: 0.003567 (0.00393)  Time: 0.714s, 2866.97/s  (0.737s, 2778.02/s)  avg LR: 3.199e-03  iter ratio: 0.0000  Data: 0.028 (0.056)
INFO:Train: 170 [ 200/625 ( 32%)]  Loss: 0.004518 (0.00405)  Time: 0.708s, 2891.63/s  (0.730s, 2803.82/s)  avg LR: 3.199e-03  iter ratio: 0.0000  Data: 0.027 (0.050)
INFO:Train: 170 [ 250/625 ( 40%)]  Loss: 0.004090 (0.00406)  Time: 0.712s, 2876.47/s  (0.726s, 2819.21/s)  avg LR: 3.199e-03  iter ratio: 0.0000  Data: 0.027 (0.046)
INFO:Train: 170 [ 300/625 ( 48%)]  Loss: 0.003656 (0.00400)  Time: 0.704s, 2908.96/s  (0.723s, 2830.95/s)  avg LR: 3.199e-03  iter ratio: 0.0000  Data: 0.026 (0.043)
INFO:Train: 170 [ 350/625 ( 56%)]  Loss: 0.003633 (0.00395)  Time: 0.709s, 2886.68/s  (0.721s, 2839.20/s)  avg LR: 3.199e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 170 [ 400/625 ( 64%)]  Loss: 0.003090 (0.00386)  Time: 0.711s, 2879.29/s  (0.720s, 2844.75/s)  avg LR: 3.199e-03  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 170 [ 450/625 ( 72%)]  Loss: 0.004378 (0.00391)  Time: 0.713s, 2872.24/s  (0.719s, 2848.97/s)  avg LR: 3.199e-03  iter ratio: 0.0000  Data: 0.034 (0.039)
INFO:Train: 170 [ 500/625 ( 80%)]  Loss: 0.004645 (0.00398)  Time: 0.708s, 2894.11/s  (0.718s, 2852.58/s)  avg LR: 3.199e-03  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 170 [ 550/625 ( 88%)]  Loss: 0.004148 (0.00399)  Time: 0.720s, 2843.22/s  (0.717s, 2855.47/s)  avg LR: 3.199e-03  iter ratio: 0.0000  Data: 0.029 (0.037)
INFO:Train: 170 [ 600/625 ( 96%)]  Loss: 0.003995 (0.00399)  Time: 0.706s, 2900.98/s  (0.716s, 2858.35/s)  avg LR: 3.199e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 170 [ 624/625 (100%)]  Loss: 0.004274 (0.00401)  Time: 0.675s, 3034.11/s  (0.716s, 2860.94/s)  avg LR: 3.199e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.356 (4.356)  Loss:  0.7959 (0.7959)  Acc@1: 82.5684 (82.5684)  Acc@5: 95.1172 (95.1172)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.7944 (1.2443)  Acc@1: 80.7783 (72.2520)  Acc@5: 95.5189 (90.9480)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-163.pth.tar', 72.33399998779296)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-170.pth.tar', 72.25200005371094)

INFO:170-epoch: remaining time 17.99 h
INFO:Train: 171 [   0/625 (  0%)]  Loss: 0.004453 (0.00445)  Time: 4.209s,  486.58/s  (4.209s,  486.58/s)  avg LR: 3.158e-03  iter ratio: 0.0000  Data: 3.507 (3.507)
INFO:Train: 171 [  50/625 (  8%)]  Loss: 0.003784 (0.00412)  Time: 0.706s, 2901.67/s  (0.773s, 2649.94/s)  avg LR: 3.158e-03  iter ratio: 0.0000  Data: 0.031 (0.097)
INFO:Train: 171 [ 100/625 ( 16%)]  Loss: 0.003320 (0.00385)  Time: 0.708s, 2892.64/s  (0.741s, 2762.11/s)  avg LR: 3.158e-03  iter ratio: 0.0000  Data: 0.034 (0.066)
INFO:Train: 171 [ 150/625 ( 24%)]  Loss: 0.004620 (0.00404)  Time: 0.719s, 2849.97/s  (0.729s, 2809.80/s)  avg LR: 3.158e-03  iter ratio: 0.0000  Data: 0.042 (0.054)
INFO:Train: 171 [ 200/625 ( 32%)]  Loss: 0.004470 (0.00413)  Time: 0.704s, 2907.03/s  (0.723s, 2834.54/s)  avg LR: 3.158e-03  iter ratio: 0.0000  Data: 0.031 (0.047)
INFO:Train: 171 [ 250/625 ( 40%)]  Loss: 0.003664 (0.00405)  Time: 0.703s, 2911.99/s  (0.719s, 2849.61/s)  avg LR: 3.158e-03  iter ratio: 0.0000  Data: 0.030 (0.044)
INFO:Train: 171 [ 300/625 ( 48%)]  Loss: 0.003594 (0.00399)  Time: 0.705s, 2906.20/s  (0.716s, 2859.62/s)  avg LR: 3.158e-03  iter ratio: 0.0000  Data: 0.030 (0.041)
INFO:Train: 171 [ 350/625 ( 56%)]  Loss: 0.003760 (0.00396)  Time: 0.712s, 2874.73/s  (0.714s, 2866.82/s)  avg LR: 3.158e-03  iter ratio: 0.0000  Data: 0.038 (0.039)
INFO:Train: 171 [ 400/625 ( 64%)]  Loss: 0.003884 (0.00395)  Time: 0.709s, 2887.76/s  (0.713s, 2871.95/s)  avg LR: 3.158e-03  iter ratio: 0.0000  Data: 0.034 (0.038)
INFO:Train: 171 [ 450/625 ( 72%)]  Loss: 0.004010 (0.00396)  Time: 0.706s, 2902.11/s  (0.712s, 2876.42/s)  avg LR: 3.158e-03  iter ratio: 0.0000  Data: 0.032 (0.037)
INFO:Train: 171 [ 500/625 ( 80%)]  Loss: 0.004372 (0.00399)  Time: 0.715s, 2865.06/s  (0.711s, 2879.90/s)  avg LR: 3.158e-03  iter ratio: 0.0000  Data: 0.034 (0.036)
INFO:Train: 171 [ 550/625 ( 88%)]  Loss: 0.003827 (0.00398)  Time: 0.712s, 2877.84/s  (0.710s, 2882.61/s)  avg LR: 3.158e-03  iter ratio: 0.0000  Data: 0.030 (0.035)
INFO:Train: 171 [ 600/625 ( 96%)]  Loss: 0.004176 (0.00399)  Time: 0.723s, 2834.01/s  (0.711s, 2881.59/s)  avg LR: 3.158e-03  iter ratio: 0.0000  Data: 0.042 (0.035)
INFO:Train: 171 [ 624/625 (100%)]  Loss: 0.003606 (0.00397)  Time: 0.675s, 3031.93/s  (0.711s, 2881.50/s)  avg LR: 3.158e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.399 (4.399)  Loss:  0.7900 (0.7900)  Acc@1: 82.3242 (82.3242)  Acc@5: 95.1660 (95.1660)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.7246 (1.2153)  Acc@1: 83.9623 (72.4440)  Acc@5: 96.1085 (91.0680)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-171.pth.tar', 72.44400001464844)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-163.pth.tar', 72.33399998779296)

INFO:171-epoch: remaining time 17.73 h
INFO:Train: 172 [   0/625 (  0%)]  Loss: 0.003783 (0.00378)  Time: 4.212s,  486.27/s  (4.212s,  486.27/s)  avg LR: 3.117e-03  iter ratio: 0.0000  Data: 3.511 (3.511)
INFO:Train: 172 [  50/625 (  8%)]  Loss: 0.003267 (0.00353)  Time: 0.701s, 2920.24/s  (0.776s, 2638.86/s)  avg LR: 3.117e-03  iter ratio: 0.0000  Data: 0.026 (0.097)
INFO:Train: 172 [ 100/625 ( 16%)]  Loss: 0.003913 (0.00365)  Time: 0.701s, 2919.68/s  (0.740s, 2766.20/s)  avg LR: 3.117e-03  iter ratio: 0.0000  Data: 0.024 (0.063)
INFO:Train: 172 [ 150/625 ( 24%)]  Loss: 0.004299 (0.00382)  Time: 0.701s, 2921.88/s  (0.732s, 2798.99/s)  avg LR: 3.117e-03  iter ratio: 0.0000  Data: 0.024 (0.055)
INFO:Train: 172 [ 200/625 ( 32%)]  Loss: 0.003706 (0.00379)  Time: 0.701s, 2922.60/s  (0.725s, 2823.84/s)  avg LR: 3.117e-03  iter ratio: 0.0000  Data: 0.026 (0.048)
INFO:Train: 172 [ 250/625 ( 40%)]  Loss: 0.003518 (0.00375)  Time: 0.702s, 2916.08/s  (0.721s, 2839.84/s)  avg LR: 3.117e-03  iter ratio: 0.0000  Data: 0.028 (0.045)
INFO:Train: 172 [ 300/625 ( 48%)]  Loss: 0.003839 (0.00376)  Time: 0.702s, 2917.05/s  (0.718s, 2850.72/s)  avg LR: 3.117e-03  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 172 [ 350/625 ( 56%)]  Loss: 0.003776 (0.00376)  Time: 0.716s, 2861.77/s  (0.716s, 2859.42/s)  avg LR: 3.117e-03  iter ratio: 0.0000  Data: 0.034 (0.040)
INFO:Train: 172 [ 400/625 ( 64%)]  Loss: 0.003000 (0.00368)  Time: 0.704s, 2907.33/s  (0.715s, 2866.09/s)  avg LR: 3.117e-03  iter ratio: 0.0000  Data: 0.030 (0.038)
INFO:Train: 172 [ 450/625 ( 72%)]  Loss: 0.003853 (0.00370)  Time: 0.700s, 2926.55/s  (0.713s, 2871.18/s)  avg LR: 3.117e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 172 [ 500/625 ( 80%)]  Loss: 0.004062 (0.00373)  Time: 0.703s, 2911.28/s  (0.712s, 2875.15/s)  avg LR: 3.117e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 172 [ 550/625 ( 88%)]  Loss: 0.003409 (0.00370)  Time: 0.719s, 2849.41/s  (0.712s, 2877.17/s)  avg LR: 3.117e-03  iter ratio: 0.0000  Data: 0.043 (0.036)
INFO:Train: 172 [ 600/625 ( 96%)]  Loss: 0.003892 (0.00372)  Time: 0.719s, 2846.96/s  (0.712s, 2875.47/s)  avg LR: 3.117e-03  iter ratio: 0.0000  Data: 0.045 (0.036)
INFO:Train: 172 [ 624/625 (100%)]  Loss: 0.003263 (0.00368)  Time: 0.674s, 3037.29/s  (0.712s, 2876.96/s)  avg LR: 3.117e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.342 (4.342)  Loss:  0.8281 (0.8281)  Acc@1: 82.4219 (82.4219)  Acc@5: 94.4824 (94.4824)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.7080 (1.2181)  Acc@1: 83.3726 (72.0460)  Acc@5: 94.9292 (91.0920)
INFO:172-epoch: remaining time 17.61 h
INFO:Train: 173 [   0/625 (  0%)]  Loss: 0.003619 (0.00362)  Time: 4.187s,  489.17/s  (4.187s,  489.17/s)  avg LR: 3.077e-03  iter ratio: 0.0000  Data: 3.499 (3.499)
INFO:Train: 173 [  50/625 (  8%)]  Loss: 0.004133 (0.00388)  Time: 0.702s, 2916.66/s  (0.778s, 2632.29/s)  avg LR: 3.077e-03  iter ratio: 0.0000  Data: 0.029 (0.101)
INFO:Train: 173 [ 100/625 ( 16%)]  Loss: 0.003780 (0.00384)  Time: 0.716s, 2860.32/s  (0.744s, 2751.51/s)  avg LR: 3.077e-03  iter ratio: 0.0000  Data: 0.042 (0.068)
INFO:Train: 173 [ 150/625 ( 24%)]  Loss: 0.004229 (0.00394)  Time: 0.714s, 2868.06/s  (0.735s, 2785.21/s)  avg LR: 3.077e-03  iter ratio: 0.0000  Data: 0.039 (0.059)
INFO:Train: 173 [ 200/625 ( 32%)]  Loss: 0.004308 (0.00401)  Time: 0.717s, 2857.52/s  (0.731s, 2803.38/s)  avg LR: 3.077e-03  iter ratio: 0.0000  Data: 0.043 (0.055)
INFO:Train: 173 [ 250/625 ( 40%)]  Loss: 0.004406 (0.00408)  Time: 0.702s, 2916.10/s  (0.725s, 2823.26/s)  avg LR: 3.077e-03  iter ratio: 0.0000  Data: 0.027 (0.050)
INFO:Train: 173 [ 300/625 ( 48%)]  Loss: 0.003868 (0.00405)  Time: 0.700s, 2924.10/s  (0.722s, 2837.85/s)  avg LR: 3.077e-03  iter ratio: 0.0000  Data: 0.024 (0.046)
INFO:Train: 173 [ 350/625 ( 56%)]  Loss: 0.003862 (0.00403)  Time: 0.705s, 2904.67/s  (0.719s, 2847.80/s)  avg LR: 3.077e-03  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 173 [ 400/625 ( 64%)]  Loss: 0.003838 (0.00400)  Time: 0.723s, 2832.56/s  (0.718s, 2851.12/s)  avg LR: 3.077e-03  iter ratio: 0.0000  Data: 0.032 (0.042)
INFO:Train: 173 [ 450/625 ( 72%)]  Loss: 0.003847 (0.00399)  Time: 0.718s, 2850.81/s  (0.718s, 2851.47/s)  avg LR: 3.077e-03  iter ratio: 0.0000  Data: 0.040 (0.041)
INFO:Train: 173 [ 500/625 ( 80%)]  Loss: 0.004009 (0.00399)  Time: 0.721s, 2840.39/s  (0.718s, 2851.09/s)  avg LR: 3.077e-03  iter ratio: 0.0000  Data: 0.041 (0.041)
INFO:Train: 173 [ 550/625 ( 88%)]  Loss: 0.003553 (0.00395)  Time: 0.721s, 2838.90/s  (0.718s, 2851.62/s)  avg LR: 3.077e-03  iter ratio: 0.0000  Data: 0.042 (0.040)
INFO:Train: 173 [ 600/625 ( 96%)]  Loss: 0.004295 (0.00398)  Time: 0.706s, 2901.35/s  (0.718s, 2853.33/s)  avg LR: 3.077e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 173 [ 624/625 (100%)]  Loss: 0.003673 (0.00396)  Time: 0.675s, 3034.10/s  (0.717s, 2855.90/s)  avg LR: 3.077e-03  iter ratio: 0.0000  Data: 0.000 (0.039)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.300 (4.300)  Loss:  0.8525 (0.8525)  Acc@1: 81.7871 (81.7871)  Acc@5: 94.5312 (94.5312)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.6899 (1.2026)  Acc@1: 84.1981 (72.8900)  Acc@5: 95.8726 (91.4320)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-173.pth.tar', 72.8900001171875)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-171.pth.tar', 72.44400001464844)

INFO:173-epoch: remaining time 17.62 h
INFO:Train: 174 [   0/625 (  0%)]  Loss: 0.003767 (0.00377)  Time: 4.225s,  484.76/s  (4.225s,  484.76/s)  avg LR: 3.036e-03  iter ratio: 0.0000  Data: 3.532 (3.532)
INFO:Train: 174 [  50/625 (  8%)]  Loss: 0.004321 (0.00404)  Time: 0.702s, 2919.23/s  (0.775s, 2641.75/s)  avg LR: 3.036e-03  iter ratio: 0.0000  Data: 0.026 (0.099)
INFO:Train: 174 [ 100/625 ( 16%)]  Loss: 0.004083 (0.00406)  Time: 0.704s, 2907.72/s  (0.740s, 2766.72/s)  avg LR: 3.036e-03  iter ratio: 0.0000  Data: 0.029 (0.064)
INFO:Train: 174 [ 150/625 ( 24%)]  Loss: 0.004108 (0.00407)  Time: 0.706s, 2900.94/s  (0.729s, 2809.42/s)  avg LR: 3.036e-03  iter ratio: 0.0000  Data: 0.031 (0.053)
INFO:Train: 174 [ 200/625 ( 32%)]  Loss: 0.003748 (0.00401)  Time: 0.703s, 2912.12/s  (0.723s, 2831.87/s)  avg LR: 3.036e-03  iter ratio: 0.0000  Data: 0.029 (0.047)
INFO:Train: 174 [ 250/625 ( 40%)]  Loss: 0.004138 (0.00403)  Time: 0.703s, 2912.23/s  (0.720s, 2846.02/s)  avg LR: 3.036e-03  iter ratio: 0.0000  Data: 0.027 (0.044)
INFO:Train: 174 [ 300/625 ( 48%)]  Loss: 0.003656 (0.00397)  Time: 0.699s, 2928.81/s  (0.717s, 2855.19/s)  avg LR: 3.036e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 174 [ 350/625 ( 56%)]  Loss: 0.003905 (0.00397)  Time: 0.703s, 2912.03/s  (0.715s, 2862.59/s)  avg LR: 3.036e-03  iter ratio: 0.0000  Data: 0.025 (0.040)
INFO:Train: 174 [ 400/625 ( 64%)]  Loss: 0.004210 (0.00399)  Time: 0.701s, 2919.87/s  (0.714s, 2867.68/s)  avg LR: 3.036e-03  iter ratio: 0.0000  Data: 0.024 (0.038)
INFO:Train: 174 [ 450/625 ( 72%)]  Loss: 0.003692 (0.00396)  Time: 0.705s, 2906.41/s  (0.713s, 2872.08/s)  avg LR: 3.036e-03  iter ratio: 0.0000  Data: 0.029 (0.037)
INFO:Train: 174 [ 500/625 ( 80%)]  Loss: 0.004406 (0.00400)  Time: 0.703s, 2912.98/s  (0.712s, 2875.83/s)  avg LR: 3.036e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 174 [ 550/625 ( 88%)]  Loss: 0.003564 (0.00397)  Time: 0.707s, 2897.27/s  (0.711s, 2879.38/s)  avg LR: 3.036e-03  iter ratio: 0.0000  Data: 0.031 (0.035)
INFO:Train: 174 [ 600/625 ( 96%)]  Loss: 0.003710 (0.00395)  Time: 0.705s, 2904.04/s  (0.711s, 2882.05/s)  avg LR: 3.036e-03  iter ratio: 0.0000  Data: 0.029 (0.034)
INFO:Train: 174 [ 624/625 (100%)]  Loss: 0.004206 (0.00397)  Time: 0.676s, 3031.46/s  (0.710s, 2883.80/s)  avg LR: 3.036e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.310 (4.310)  Loss:  0.8340 (0.8340)  Acc@1: 81.0059 (81.0059)  Acc@5: 94.8242 (94.8242)
INFO:Test: [  24/24]  Time: 0.080 (0.502)  Loss:  0.6807 (1.1847)  Acc@1: 84.7877 (73.2340)  Acc@5: 95.2830 (91.3000)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-174.pth.tar', 73.23399998535156)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-173.pth.tar', 72.8900001171875)

INFO:174-epoch: remaining time 17.33 h
INFO:Train: 175 [   0/625 (  0%)]  Loss: 0.002969 (0.00297)  Time: 4.447s,  460.51/s  (4.447s,  460.51/s)  avg LR: 2.996e-03  iter ratio: 0.0000  Data: 3.759 (3.759)
INFO:Train: 175 [  50/625 (  8%)]  Loss: 0.004309 (0.00364)  Time: 0.709s, 2888.74/s  (0.780s, 2624.02/s)  avg LR: 2.996e-03  iter ratio: 0.0000  Data: 0.022 (0.101)
INFO:Train: 175 [ 100/625 ( 16%)]  Loss: 0.004390 (0.00389)  Time: 0.722s, 2834.92/s  (0.746s, 2746.48/s)  avg LR: 2.996e-03  iter ratio: 0.0000  Data: 0.041 (0.066)
INFO:Train: 175 [ 150/625 ( 24%)]  Loss: 0.003510 (0.00379)  Time: 0.718s, 2853.36/s  (0.736s, 2784.28/s)  avg LR: 2.996e-03  iter ratio: 0.0000  Data: 0.035 (0.057)
INFO:Train: 175 [ 200/625 ( 32%)]  Loss: 0.004009 (0.00384)  Time: 0.719s, 2848.48/s  (0.730s, 2803.68/s)  avg LR: 2.996e-03  iter ratio: 0.0000  Data: 0.039 (0.052)
INFO:Train: 175 [ 250/625 ( 40%)]  Loss: 0.004266 (0.00391)  Time: 0.717s, 2856.82/s  (0.728s, 2814.64/s)  avg LR: 2.996e-03  iter ratio: 0.0000  Data: 0.036 (0.049)
INFO:Train: 175 [ 300/625 ( 48%)]  Loss: 0.003496 (0.00385)  Time: 0.718s, 2850.47/s  (0.726s, 2822.69/s)  avg LR: 2.996e-03  iter ratio: 0.0000  Data: 0.038 (0.047)
INFO:Train: 175 [ 350/625 ( 56%)]  Loss: 0.003599 (0.00382)  Time: 0.704s, 2910.41/s  (0.723s, 2832.43/s)  avg LR: 2.996e-03  iter ratio: 0.0000  Data: 0.026 (0.045)
INFO:Train: 175 [ 400/625 ( 64%)]  Loss: 0.004474 (0.00389)  Time: 0.700s, 2925.69/s  (0.721s, 2841.53/s)  avg LR: 2.996e-03  iter ratio: 0.0000  Data: 0.023 (0.043)
INFO:Train: 175 [ 450/625 ( 72%)]  Loss: 0.004134 (0.00392)  Time: 0.697s, 2936.82/s  (0.719s, 2848.30/s)  avg LR: 2.996e-03  iter ratio: 0.0000  Data: 0.024 (0.041)
INFO:Train: 175 [ 500/625 ( 80%)]  Loss: 0.004002 (0.00392)  Time: 0.712s, 2876.16/s  (0.718s, 2851.08/s)  avg LR: 2.996e-03  iter ratio: 0.0000  Data: 0.037 (0.040)
INFO:Train: 175 [ 550/625 ( 88%)]  Loss: 0.004625 (0.00398)  Time: 0.718s, 2853.00/s  (0.718s, 2851.35/s)  avg LR: 2.996e-03  iter ratio: 0.0000  Data: 0.032 (0.040)
INFO:Train: 175 [ 600/625 ( 96%)]  Loss: 0.003677 (0.00396)  Time: 0.719s, 2849.72/s  (0.718s, 2851.70/s)  avg LR: 2.996e-03  iter ratio: 0.0000  Data: 0.034 (0.040)
INFO:Train: 175 [ 624/625 (100%)]  Loss: 0.003860 (0.00395)  Time: 0.676s, 3031.82/s  (0.718s, 2852.55/s)  avg LR: 2.996e-03  iter ratio: 0.0000  Data: 0.000 (0.039)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.334 (4.334)  Loss:  0.7622 (0.7622)  Acc@1: 82.2266 (82.2266)  Acc@5: 95.9961 (95.9961)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.7290 (1.1776)  Acc@1: 82.7830 (73.0560)  Acc@5: 95.6368 (91.4340)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-174.pth.tar', 73.23399998535156)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-175.pth.tar', 73.05600001953125)

INFO:175-epoch: remaining time 17.37 h
INFO:Train: 176 [   0/625 (  0%)]  Loss: 0.003305 (0.00331)  Time: 4.364s,  469.25/s  (4.364s,  469.25/s)  avg LR: 2.956e-03  iter ratio: 0.0000  Data: 3.674 (3.674)
INFO:Train: 176 [  50/625 (  8%)]  Loss: 0.003273 (0.00329)  Time: 0.701s, 2919.94/s  (0.781s, 2623.14/s)  avg LR: 2.956e-03  iter ratio: 0.0000  Data: 0.025 (0.102)
INFO:Train: 176 [ 100/625 ( 16%)]  Loss: 0.004001 (0.00353)  Time: 0.702s, 2918.44/s  (0.743s, 2757.33/s)  avg LR: 2.956e-03  iter ratio: 0.0000  Data: 0.026 (0.065)
INFO:Train: 176 [ 150/625 ( 24%)]  Loss: 0.004034 (0.00365)  Time: 0.716s, 2858.80/s  (0.734s, 2790.61/s)  avg LR: 2.956e-03  iter ratio: 0.0000  Data: 0.042 (0.057)
INFO:Train: 176 [ 200/625 ( 32%)]  Loss: 0.003601 (0.00364)  Time: 0.702s, 2916.77/s  (0.729s, 2811.24/s)  avg LR: 2.956e-03  iter ratio: 0.0000  Data: 0.028 (0.052)
INFO:Train: 176 [ 250/625 ( 40%)]  Loss: 0.003533 (0.00362)  Time: 0.705s, 2903.33/s  (0.724s, 2829.64/s)  avg LR: 2.956e-03  iter ratio: 0.0000  Data: 0.029 (0.048)
INFO:Train: 176 [ 300/625 ( 48%)]  Loss: 0.003507 (0.00361)  Time: 0.701s, 2919.49/s  (0.721s, 2842.18/s)  avg LR: 2.956e-03  iter ratio: 0.0000  Data: 0.026 (0.044)
INFO:Train: 176 [ 350/625 ( 56%)]  Loss: 0.004146 (0.00367)  Time: 0.704s, 2909.34/s  (0.718s, 2851.83/s)  avg LR: 2.956e-03  iter ratio: 0.0000  Data: 0.030 (0.042)
INFO:Train: 176 [ 400/625 ( 64%)]  Loss: 0.004622 (0.00378)  Time: 0.700s, 2924.27/s  (0.716s, 2858.48/s)  avg LR: 2.956e-03  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 176 [ 450/625 ( 72%)]  Loss: 0.004110 (0.00381)  Time: 0.704s, 2907.29/s  (0.715s, 2864.14/s)  avg LR: 2.956e-03  iter ratio: 0.0000  Data: 0.029 (0.039)
INFO:Train: 176 [ 500/625 ( 80%)]  Loss: 0.004382 (0.00386)  Time: 0.707s, 2897.52/s  (0.714s, 2868.81/s)  avg LR: 2.956e-03  iter ratio: 0.0000  Data: 0.032 (0.038)
INFO:Train: 176 [ 550/625 ( 88%)]  Loss: 0.004069 (0.00388)  Time: 0.705s, 2904.51/s  (0.713s, 2872.52/s)  avg LR: 2.956e-03  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 176 [ 600/625 ( 96%)]  Loss: 0.003417 (0.00385)  Time: 0.706s, 2900.78/s  (0.712s, 2875.36/s)  avg LR: 2.956e-03  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 176 [ 624/625 (100%)]  Loss: 0.004692 (0.00391)  Time: 0.677s, 3025.99/s  (0.712s, 2876.93/s)  avg LR: 2.956e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.310 (4.310)  Loss:  0.7925 (0.7925)  Acc@1: 81.4453 (81.4453)  Acc@5: 95.2148 (95.2148)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.6748 (1.1920)  Acc@1: 83.8443 (72.6940)  Acc@5: 95.6368 (91.2780)
INFO:176-epoch: remaining time 17.12 h
INFO:Train: 177 [   0/625 (  0%)]  Loss: 0.003492 (0.00349)  Time: 4.415s,  463.91/s  (4.415s,  463.91/s)  avg LR: 2.916e-03  iter ratio: 0.0000  Data: 3.720 (3.720)
INFO:Train: 177 [  50/625 (  8%)]  Loss: 0.004152 (0.00382)  Time: 0.704s, 2910.73/s  (0.777s, 2635.38/s)  avg LR: 2.916e-03  iter ratio: 0.0000  Data: 0.027 (0.101)
INFO:Train: 177 [ 100/625 ( 16%)]  Loss: 0.004131 (0.00392)  Time: 0.704s, 2907.43/s  (0.741s, 2763.45/s)  avg LR: 2.916e-03  iter ratio: 0.0000  Data: 0.020 (0.064)
INFO:Train: 177 [ 150/625 ( 24%)]  Loss: 0.003754 (0.00388)  Time: 0.701s, 2923.11/s  (0.729s, 2808.71/s)  avg LR: 2.916e-03  iter ratio: 0.0000  Data: 0.021 (0.051)
INFO:Train: 177 [ 200/625 ( 32%)]  Loss: 0.003458 (0.00380)  Time: 0.702s, 2915.33/s  (0.723s, 2831.89/s)  avg LR: 2.916e-03  iter ratio: 0.0000  Data: 0.021 (0.045)
INFO:Train: 177 [ 250/625 ( 40%)]  Loss: 0.003069 (0.00368)  Time: 0.707s, 2897.59/s  (0.720s, 2845.84/s)  avg LR: 2.916e-03  iter ratio: 0.0000  Data: 0.021 (0.041)
INFO:Train: 177 [ 300/625 ( 48%)]  Loss: 0.003527 (0.00365)  Time: 0.703s, 2913.24/s  (0.717s, 2855.47/s)  avg LR: 2.916e-03  iter ratio: 0.0000  Data: 0.022 (0.038)
INFO:Train: 177 [ 350/625 ( 56%)]  Loss: 0.003298 (0.00361)  Time: 0.699s, 2931.35/s  (0.716s, 2861.84/s)  avg LR: 2.916e-03  iter ratio: 0.0000  Data: 0.024 (0.037)
INFO:Train: 177 [ 400/625 ( 64%)]  Loss: 0.003567 (0.00361)  Time: 0.701s, 2920.82/s  (0.714s, 2867.11/s)  avg LR: 2.916e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 177 [ 450/625 ( 72%)]  Loss: 0.003466 (0.00359)  Time: 0.701s, 2921.61/s  (0.713s, 2872.16/s)  avg LR: 2.916e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 177 [ 500/625 ( 80%)]  Loss: 0.004187 (0.00365)  Time: 0.701s, 2920.68/s  (0.712s, 2875.79/s)  avg LR: 2.916e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 177 [ 550/625 ( 88%)]  Loss: 0.003492 (0.00363)  Time: 0.700s, 2926.40/s  (0.711s, 2878.81/s)  avg LR: 2.916e-03  iter ratio: 0.0000  Data: 0.023 (0.034)
INFO:Train: 177 [ 600/625 ( 96%)]  Loss: 0.003174 (0.00360)  Time: 0.701s, 2920.41/s  (0.711s, 2881.31/s)  avg LR: 2.916e-03  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 177 [ 624/625 (100%)]  Loss: 0.004195 (0.00364)  Time: 0.673s, 3041.59/s  (0.710s, 2882.88/s)  avg LR: 2.916e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.299 (4.299)  Loss:  0.8257 (0.8257)  Acc@1: 81.6406 (81.6406)  Acc@5: 95.0684 (95.0684)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.6646 (1.2006)  Acc@1: 84.4340 (72.8960)  Acc@5: 96.8160 (91.4200)
INFO:177-epoch: remaining time 16.95 h
INFO:Train: 178 [   0/625 (  0%)]  Loss: 0.002971 (0.00297)  Time: 4.263s,  480.47/s  (4.263s,  480.47/s)  avg LR: 2.876e-03  iter ratio: 0.0000  Data: 3.562 (3.562)
INFO:Train: 178 [  50/625 (  8%)]  Loss: 0.003927 (0.00345)  Time: 0.705s, 2905.01/s  (0.775s, 2642.37/s)  avg LR: 2.876e-03  iter ratio: 0.0000  Data: 0.031 (0.095)
INFO:Train: 178 [ 100/625 ( 16%)]  Loss: 0.004049 (0.00365)  Time: 0.706s, 2899.19/s  (0.740s, 2769.25/s)  avg LR: 2.876e-03  iter ratio: 0.0000  Data: 0.032 (0.061)
INFO:Train: 178 [ 150/625 ( 24%)]  Loss: 0.004785 (0.00393)  Time: 0.704s, 2910.45/s  (0.728s, 2814.54/s)  avg LR: 2.876e-03  iter ratio: 0.0000  Data: 0.030 (0.050)
INFO:Train: 178 [ 200/625 ( 32%)]  Loss: 0.003139 (0.00377)  Time: 0.702s, 2915.45/s  (0.721s, 2838.71/s)  avg LR: 2.876e-03  iter ratio: 0.0000  Data: 0.025 (0.044)
INFO:Train: 178 [ 250/625 ( 40%)]  Loss: 0.004485 (0.00389)  Time: 0.705s, 2905.92/s  (0.718s, 2852.67/s)  avg LR: 2.876e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 178 [ 300/625 ( 48%)]  Loss: 0.003597 (0.00385)  Time: 0.721s, 2842.34/s  (0.717s, 2856.28/s)  avg LR: 2.876e-03  iter ratio: 0.0000  Data: 0.040 (0.040)
INFO:Train: 178 [ 350/625 ( 56%)]  Loss: 0.003887 (0.00386)  Time: 0.714s, 2870.05/s  (0.716s, 2861.75/s)  avg LR: 2.876e-03  iter ratio: 0.0000  Data: 0.034 (0.038)
INFO:Train: 178 [ 400/625 ( 64%)]  Loss: 0.003920 (0.00386)  Time: 0.704s, 2908.31/s  (0.714s, 2867.42/s)  avg LR: 2.876e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 178 [ 450/625 ( 72%)]  Loss: 0.003612 (0.00384)  Time: 0.705s, 2903.30/s  (0.713s, 2872.07/s)  avg LR: 2.876e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 178 [ 500/625 ( 80%)]  Loss: 0.003858 (0.00384)  Time: 0.707s, 2894.84/s  (0.712s, 2875.51/s)  avg LR: 2.876e-03  iter ratio: 0.0000  Data: 0.030 (0.035)
INFO:Train: 178 [ 550/625 ( 88%)]  Loss: 0.003931 (0.00385)  Time: 0.717s, 2855.89/s  (0.712s, 2877.60/s)  avg LR: 2.876e-03  iter ratio: 0.0000  Data: 0.042 (0.035)
INFO:Train: 178 [ 600/625 ( 96%)]  Loss: 0.003539 (0.00382)  Time: 0.709s, 2888.27/s  (0.712s, 2876.55/s)  avg LR: 2.876e-03  iter ratio: 0.0000  Data: 0.033 (0.035)
INFO:Train: 178 [ 624/625 (100%)]  Loss: 0.003829 (0.00382)  Time: 0.674s, 3038.00/s  (0.711s, 2878.56/s)  avg LR: 2.876e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.303 (4.303)  Loss:  0.8486 (0.8486)  Acc@1: 80.9082 (80.9082)  Acc@5: 94.2383 (94.2383)
INFO:Test: [  24/24]  Time: 0.080 (0.502)  Loss:  0.7217 (1.2269)  Acc@1: 83.4906 (71.6940)  Acc@5: 94.8113 (90.7160)
INFO:178-epoch: remaining time 16.85 h
INFO:Train: 179 [   0/625 (  0%)]  Loss: 0.003648 (0.00365)  Time: 4.514s,  453.73/s  (4.514s,  453.73/s)  avg LR: 2.836e-03  iter ratio: 0.0000  Data: 3.819 (3.819)
INFO:Train: 179 [  50/625 (  8%)]  Loss: 0.004479 (0.00406)  Time: 0.700s, 2924.34/s  (0.788s, 2599.91/s)  avg LR: 2.836e-03  iter ratio: 0.0000  Data: 0.024 (0.109)
INFO:Train: 179 [ 100/625 ( 16%)]  Loss: 0.003864 (0.00400)  Time: 0.702s, 2915.59/s  (0.746s, 2743.83/s)  avg LR: 2.836e-03  iter ratio: 0.0000  Data: 0.026 (0.069)
INFO:Train: 179 [ 150/625 ( 24%)]  Loss: 0.003744 (0.00393)  Time: 0.716s, 2861.25/s  (0.736s, 2782.74/s)  avg LR: 2.836e-03  iter ratio: 0.0000  Data: 0.040 (0.060)
INFO:Train: 179 [ 200/625 ( 32%)]  Loss: 0.003647 (0.00388)  Time: 0.714s, 2869.32/s  (0.731s, 2801.54/s)  avg LR: 2.836e-03  iter ratio: 0.0000  Data: 0.039 (0.055)
INFO:Train: 179 [ 250/625 ( 40%)]  Loss: 0.002958 (0.00372)  Time: 0.714s, 2869.20/s  (0.728s, 2814.29/s)  avg LR: 2.836e-03  iter ratio: 0.0000  Data: 0.039 (0.052)
INFO:Train: 179 [ 300/625 ( 48%)]  Loss: 0.002929 (0.00361)  Time: 0.713s, 2870.95/s  (0.726s, 2822.18/s)  avg LR: 2.836e-03  iter ratio: 0.0000  Data: 0.039 (0.050)
INFO:Train: 179 [ 350/625 ( 56%)]  Loss: 0.004204 (0.00368)  Time: 0.703s, 2912.05/s  (0.724s, 2830.11/s)  avg LR: 2.836e-03  iter ratio: 0.0000  Data: 0.024 (0.048)
INFO:Train: 179 [ 400/625 ( 64%)]  Loss: 0.003356 (0.00365)  Time: 0.706s, 2900.49/s  (0.721s, 2838.86/s)  avg LR: 2.836e-03  iter ratio: 0.0000  Data: 0.023 (0.046)
INFO:Train: 179 [ 450/625 ( 72%)]  Loss: 0.004499 (0.00373)  Time: 0.703s, 2912.86/s  (0.720s, 2845.86/s)  avg LR: 2.836e-03  iter ratio: 0.0000  Data: 0.024 (0.044)
INFO:Train: 179 [ 500/625 ( 80%)]  Loss: 0.003759 (0.00374)  Time: 0.700s, 2925.63/s  (0.718s, 2851.43/s)  avg LR: 2.836e-03  iter ratio: 0.0000  Data: 0.022 (0.042)
INFO:Train: 179 [ 550/625 ( 88%)]  Loss: 0.003532 (0.00372)  Time: 0.700s, 2925.96/s  (0.717s, 2855.85/s)  avg LR: 2.836e-03  iter ratio: 0.0000  Data: 0.022 (0.040)
INFO:Train: 179 [ 600/625 ( 96%)]  Loss: 0.003679 (0.00372)  Time: 0.706s, 2899.04/s  (0.717s, 2856.90/s)  avg LR: 2.836e-03  iter ratio: 0.0000  Data: 0.032 (0.040)
INFO:Train: 179 [ 624/625 (100%)]  Loss: 0.003600 (0.00371)  Time: 0.673s, 3042.52/s  (0.717s, 2858.14/s)  avg LR: 2.836e-03  iter ratio: 0.0000  Data: 0.000 (0.040)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.360 (4.360)  Loss:  0.7568 (0.7568)  Acc@1: 82.1289 (82.1289)  Acc@5: 95.1172 (95.1172)
INFO:Test: [  24/24]  Time: 0.080 (0.502)  Loss:  0.7192 (1.1425)  Acc@1: 83.9623 (73.4580)  Acc@5: 94.4576 (91.5580)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-179.pth.tar', 73.45800001464843)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-174.pth.tar', 73.23399998535156)

INFO:179-epoch: remaining time 16.84 h
INFO:Train: 180 [   0/625 (  0%)]  Loss: 0.003429 (0.00343)  Time: 4.165s,  491.70/s  (4.165s,  491.70/s)  avg LR: 2.797e-03  iter ratio: 0.0000  Data: 3.475 (3.475)
INFO:Train: 180 [  50/625 (  8%)]  Loss: 0.003280 (0.00335)  Time: 0.699s, 2929.94/s  (0.774s, 2644.39/s)  avg LR: 2.797e-03  iter ratio: 0.0000  Data: 0.025 (0.097)
INFO:Train: 180 [ 100/625 ( 16%)]  Loss: 0.004829 (0.00385)  Time: 0.700s, 2925.66/s  (0.740s, 2768.52/s)  avg LR: 2.797e-03  iter ratio: 0.0000  Data: 0.021 (0.063)
INFO:Train: 180 [ 150/625 ( 24%)]  Loss: 0.003791 (0.00383)  Time: 0.698s, 2933.14/s  (0.731s, 2800.01/s)  avg LR: 2.797e-03  iter ratio: 0.0000  Data: 0.025 (0.054)
INFO:Train: 180 [ 200/625 ( 32%)]  Loss: 0.003960 (0.00386)  Time: 0.703s, 2914.87/s  (0.728s, 2814.63/s)  avg LR: 2.797e-03  iter ratio: 0.0000  Data: 0.026 (0.050)
INFO:Train: 180 [ 250/625 ( 40%)]  Loss: 0.004198 (0.00391)  Time: 0.718s, 2850.61/s  (0.725s, 2823.13/s)  avg LR: 2.797e-03  iter ratio: 0.0000  Data: 0.044 (0.047)
INFO:Train: 180 [ 300/625 ( 48%)]  Loss: 0.003715 (0.00389)  Time: 0.700s, 2924.37/s  (0.724s, 2829.21/s)  avg LR: 2.797e-03  iter ratio: 0.0000  Data: 0.024 (0.046)
INFO:Train: 180 [ 350/625 ( 56%)]  Loss: 0.003413 (0.00383)  Time: 0.701s, 2919.99/s  (0.722s, 2836.73/s)  avg LR: 2.797e-03  iter ratio: 0.0000  Data: 0.026 (0.044)
INFO:Train: 180 [ 400/625 ( 64%)]  Loss: 0.004202 (0.00387)  Time: 0.701s, 2920.36/s  (0.720s, 2843.80/s)  avg LR: 2.797e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 180 [ 450/625 ( 72%)]  Loss: 0.004568 (0.00394)  Time: 0.703s, 2913.48/s  (0.719s, 2849.89/s)  avg LR: 2.797e-03  iter ratio: 0.0000  Data: 0.023 (0.041)
INFO:Train: 180 [ 500/625 ( 80%)]  Loss: 0.003807 (0.00393)  Time: 0.706s, 2901.71/s  (0.717s, 2854.43/s)  avg LR: 2.797e-03  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 180 [ 550/625 ( 88%)]  Loss: 0.003596 (0.00390)  Time: 0.703s, 2913.87/s  (0.717s, 2855.45/s)  avg LR: 2.797e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 180 [ 600/625 ( 96%)]  Loss: 0.004565 (0.00395)  Time: 0.701s, 2920.21/s  (0.717s, 2856.68/s)  avg LR: 2.797e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 180 [ 624/625 (100%)]  Loss: 0.003405 (0.00391)  Time: 0.680s, 3010.19/s  (0.717s, 2857.85/s)  avg LR: 2.797e-03  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.283 (4.283)  Loss:  0.7471 (0.7471)  Acc@1: 82.5684 (82.5684)  Acc@5: 95.8008 (95.8008)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.7231 (1.1501)  Acc@1: 83.3726 (73.8100)  Acc@5: 95.0472 (91.8600)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-180.pth.tar', 73.81000001708985)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-179.pth.tar', 73.45800001464843)

INFO:180-epoch: remaining time 16.72 h
INFO:Train: 181 [   0/625 (  0%)]  Loss: 0.003506 (0.00351)  Time: 4.272s,  479.35/s  (4.272s,  479.35/s)  avg LR: 2.757e-03  iter ratio: 0.0000  Data: 3.568 (3.568)
INFO:Train: 181 [  50/625 (  8%)]  Loss: 0.003346 (0.00343)  Time: 0.704s, 2910.12/s  (0.775s, 2644.10/s)  avg LR: 2.757e-03  iter ratio: 0.0000  Data: 0.027 (0.098)
INFO:Train: 181 [ 100/625 ( 16%)]  Loss: 0.003085 (0.00331)  Time: 0.704s, 2910.14/s  (0.740s, 2766.46/s)  avg LR: 2.757e-03  iter ratio: 0.0000  Data: 0.029 (0.064)
INFO:Train: 181 [ 150/625 ( 24%)]  Loss: 0.003747 (0.00342)  Time: 0.719s, 2846.44/s  (0.730s, 2803.91/s)  avg LR: 2.757e-03  iter ratio: 0.0000  Data: 0.045 (0.054)
INFO:Train: 181 [ 200/625 ( 32%)]  Loss: 0.004043 (0.00355)  Time: 0.721s, 2840.59/s  (0.727s, 2816.02/s)  avg LR: 2.757e-03  iter ratio: 0.0000  Data: 0.046 (0.051)
INFO:Train: 181 [ 250/625 ( 40%)]  Loss: 0.003642 (0.00356)  Time: 0.723s, 2833.27/s  (0.726s, 2822.56/s)  avg LR: 2.757e-03  iter ratio: 0.0000  Data: 0.048 (0.049)
INFO:Train: 181 [ 300/625 ( 48%)]  Loss: 0.003691 (0.00358)  Time: 0.720s, 2844.63/s  (0.724s, 2827.27/s)  avg LR: 2.757e-03  iter ratio: 0.0000  Data: 0.045 (0.048)
INFO:Train: 181 [ 350/625 ( 56%)]  Loss: 0.004245 (0.00366)  Time: 0.704s, 2908.72/s  (0.723s, 2833.82/s)  avg LR: 2.757e-03  iter ratio: 0.0000  Data: 0.028 (0.046)
INFO:Train: 181 [ 400/625 ( 64%)]  Loss: 0.003755 (0.00367)  Time: 0.706s, 2900.77/s  (0.720s, 2842.96/s)  avg LR: 2.757e-03  iter ratio: 0.0000  Data: 0.029 (0.044)
INFO:Train: 181 [ 450/625 ( 72%)]  Loss: 0.003394 (0.00365)  Time: 0.710s, 2886.24/s  (0.719s, 2849.55/s)  avg LR: 2.757e-03  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 181 [ 500/625 ( 80%)]  Loss: 0.003631 (0.00364)  Time: 0.712s, 2874.40/s  (0.718s, 2853.46/s)  avg LR: 2.757e-03  iter ratio: 0.0000  Data: 0.032 (0.041)
INFO:Train: 181 [ 550/625 ( 88%)]  Loss: 0.003995 (0.00367)  Time: 0.713s, 2874.05/s  (0.717s, 2856.92/s)  avg LR: 2.757e-03  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 181 [ 600/625 ( 96%)]  Loss: 0.004397 (0.00373)  Time: 0.709s, 2887.55/s  (0.716s, 2859.87/s)  avg LR: 2.757e-03  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 181 [ 624/625 (100%)]  Loss: 0.004352 (0.00377)  Time: 0.675s, 3032.89/s  (0.716s, 2861.81/s)  avg LR: 2.757e-03  iter ratio: 0.0000  Data: 0.000 (0.039)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.370 (4.370)  Loss:  0.7520 (0.7520)  Acc@1: 81.2988 (81.2988)  Acc@5: 95.8008 (95.8008)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.6997 (1.1231)  Acc@1: 82.1934 (73.8380)  Acc@5: 95.5189 (92.0440)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-181.pth.tar', 73.83800015136718)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-180.pth.tar', 73.81000001708985)

INFO:181-epoch: remaining time 16.55 h
INFO:Train: 182 [   0/625 (  0%)]  Loss: 0.003914 (0.00391)  Time: 4.252s,  481.68/s  (4.252s,  481.68/s)  avg LR: 2.718e-03  iter ratio: 0.0000  Data: 3.549 (3.549)
INFO:Train: 182 [  50/625 (  8%)]  Loss: 0.004401 (0.00416)  Time: 0.704s, 2910.71/s  (0.779s, 2629.10/s)  avg LR: 2.718e-03  iter ratio: 0.0000  Data: 0.027 (0.099)
INFO:Train: 182 [ 100/625 ( 16%)]  Loss: 0.003705 (0.00401)  Time: 0.714s, 2870.11/s  (0.746s, 2745.82/s)  avg LR: 2.718e-03  iter ratio: 0.0000  Data: 0.037 (0.067)
INFO:Train: 182 [ 150/625 ( 24%)]  Loss: 0.003665 (0.00392)  Time: 0.708s, 2893.02/s  (0.734s, 2788.82/s)  avg LR: 2.718e-03  iter ratio: 0.0000  Data: 0.032 (0.056)
INFO:Train: 182 [ 200/625 ( 32%)]  Loss: 0.003788 (0.00389)  Time: 0.711s, 2881.92/s  (0.729s, 2809.13/s)  avg LR: 2.718e-03  iter ratio: 0.0000  Data: 0.032 (0.050)
INFO:Train: 182 [ 250/625 ( 40%)]  Loss: 0.003937 (0.00390)  Time: 0.716s, 2862.22/s  (0.726s, 2821.14/s)  avg LR: 2.718e-03  iter ratio: 0.0000  Data: 0.038 (0.047)
INFO:Train: 182 [ 300/625 ( 48%)]  Loss: 0.003429 (0.00383)  Time: 0.712s, 2877.55/s  (0.724s, 2830.15/s)  avg LR: 2.718e-03  iter ratio: 0.0000  Data: 0.037 (0.045)
INFO:Train: 182 [ 350/625 ( 56%)]  Loss: 0.003493 (0.00379)  Time: 0.711s, 2880.11/s  (0.721s, 2839.52/s)  avg LR: 2.718e-03  iter ratio: 0.0000  Data: 0.031 (0.043)
INFO:Train: 182 [ 400/625 ( 64%)]  Loss: 0.004021 (0.00382)  Time: 0.706s, 2901.39/s  (0.720s, 2846.21/s)  avg LR: 2.718e-03  iter ratio: 0.0000  Data: 0.030 (0.041)
INFO:Train: 182 [ 450/625 ( 72%)]  Loss: 0.003439 (0.00378)  Time: 0.704s, 2911.01/s  (0.718s, 2852.24/s)  avg LR: 2.718e-03  iter ratio: 0.0000  Data: 0.029 (0.039)
INFO:Train: 182 [ 500/625 ( 80%)]  Loss: 0.003908 (0.00379)  Time: 0.705s, 2905.10/s  (0.717s, 2856.66/s)  avg LR: 2.718e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 182 [ 550/625 ( 88%)]  Loss: 0.004472 (0.00385)  Time: 0.706s, 2900.69/s  (0.716s, 2860.57/s)  avg LR: 2.718e-03  iter ratio: 0.0000  Data: 0.031 (0.037)
INFO:Train: 182 [ 600/625 ( 96%)]  Loss: 0.004062 (0.00386)  Time: 0.705s, 2905.31/s  (0.715s, 2862.64/s)  avg LR: 2.718e-03  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 182 [ 624/625 (100%)]  Loss: 0.003799 (0.00386)  Time: 0.675s, 3036.25/s  (0.715s, 2864.91/s)  avg LR: 2.718e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.310 (4.310)  Loss:  0.7085 (0.7085)  Acc@1: 82.2266 (82.2266)  Acc@5: 95.8496 (95.8496)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.6460 (1.1121)  Acc@1: 83.7264 (74.0200)  Acc@5: 96.3443 (92.2060)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-182.pth.tar', 74.01999991210937)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-181.pth.tar', 73.83800015136718)

INFO:182-epoch: remaining time 16.43 h
INFO:Train: 183 [   0/625 (  0%)]  Loss: 0.003330 (0.00333)  Time: 4.652s,  440.29/s  (4.652s,  440.29/s)  avg LR: 2.679e-03  iter ratio: 0.0000  Data: 3.947 (3.947)
INFO:Train: 183 [  50/625 (  8%)]  Loss: 0.003950 (0.00364)  Time: 0.702s, 2916.32/s  (0.783s, 2614.99/s)  avg LR: 2.679e-03  iter ratio: 0.0000  Data: 0.027 (0.106)
INFO:Train: 183 [ 100/625 ( 16%)]  Loss: 0.003473 (0.00358)  Time: 0.704s, 2908.39/s  (0.745s, 2748.28/s)  avg LR: 2.679e-03  iter ratio: 0.0000  Data: 0.027 (0.068)
INFO:Train: 183 [ 150/625 ( 24%)]  Loss: 0.003056 (0.00345)  Time: 0.705s, 2905.83/s  (0.732s, 2797.27/s)  avg LR: 2.679e-03  iter ratio: 0.0000  Data: 0.029 (0.055)
INFO:Train: 183 [ 200/625 ( 32%)]  Loss: 0.003653 (0.00349)  Time: 0.707s, 2895.98/s  (0.725s, 2823.11/s)  avg LR: 2.679e-03  iter ratio: 0.0000  Data: 0.032 (0.048)
INFO:Train: 183 [ 250/625 ( 40%)]  Loss: 0.003712 (0.00353)  Time: 0.707s, 2896.78/s  (0.722s, 2838.12/s)  avg LR: 2.679e-03  iter ratio: 0.0000  Data: 0.032 (0.045)
INFO:Train: 183 [ 300/625 ( 48%)]  Loss: 0.004190 (0.00362)  Time: 0.710s, 2886.31/s  (0.719s, 2848.59/s)  avg LR: 2.679e-03  iter ratio: 0.0000  Data: 0.033 (0.042)
INFO:Train: 183 [ 350/625 ( 56%)]  Loss: 0.003560 (0.00362)  Time: 0.706s, 2900.56/s  (0.717s, 2856.54/s)  avg LR: 2.679e-03  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 183 [ 400/625 ( 64%)]  Loss: 0.003089 (0.00356)  Time: 0.708s, 2891.21/s  (0.715s, 2862.58/s)  avg LR: 2.679e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 183 [ 450/625 ( 72%)]  Loss: 0.003661 (0.00357)  Time: 0.708s, 2891.01/s  (0.714s, 2867.33/s)  avg LR: 2.679e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 183 [ 500/625 ( 80%)]  Loss: 0.004021 (0.00361)  Time: 0.708s, 2891.55/s  (0.714s, 2869.62/s)  avg LR: 2.679e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 183 [ 550/625 ( 88%)]  Loss: 0.003407 (0.00359)  Time: 0.707s, 2895.66/s  (0.713s, 2872.02/s)  avg LR: 2.679e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 183 [ 600/625 ( 96%)]  Loss: 0.003827 (0.00361)  Time: 0.705s, 2903.94/s  (0.713s, 2873.83/s)  avg LR: 2.679e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 183 [ 624/625 (100%)]  Loss: 0.003773 (0.00362)  Time: 0.676s, 3027.71/s  (0.712s, 2875.28/s)  avg LR: 2.679e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.363 (4.363)  Loss:  0.7573 (0.7573)  Acc@1: 83.2520 (83.2520)  Acc@5: 95.0684 (95.0684)
INFO:Test: [  24/24]  Time: 0.080 (0.500)  Loss:  0.7793 (1.1384)  Acc@1: 82.0755 (73.8040)  Acc@5: 94.1038 (91.6220)
INFO:183-epoch: remaining time 16.21 h
INFO:Train: 184 [   0/625 (  0%)]  Loss: 0.003741 (0.00374)  Time: 4.078s,  502.27/s  (4.078s,  502.27/s)  avg LR: 2.639e-03  iter ratio: 0.0000  Data: 3.376 (3.376)
INFO:Train: 184 [  50/625 (  8%)]  Loss: 0.003276 (0.00351)  Time: 0.704s, 2910.73/s  (0.776s, 2640.79/s)  avg LR: 2.639e-03  iter ratio: 0.0000  Data: 0.026 (0.096)
INFO:Train: 184 [ 100/625 ( 16%)]  Loss: 0.004330 (0.00378)  Time: 0.703s, 2912.79/s  (0.742s, 2758.35/s)  avg LR: 2.639e-03  iter ratio: 0.0000  Data: 0.026 (0.064)
INFO:Train: 184 [ 150/625 ( 24%)]  Loss: 0.004025 (0.00384)  Time: 0.702s, 2915.39/s  (0.731s, 2801.99/s)  avg LR: 2.639e-03  iter ratio: 0.0000  Data: 0.025 (0.052)
INFO:Train: 184 [ 200/625 ( 32%)]  Loss: 0.003441 (0.00376)  Time: 0.701s, 2919.78/s  (0.725s, 2825.58/s)  avg LR: 2.639e-03  iter ratio: 0.0000  Data: 0.025 (0.046)
INFO:Train: 184 [ 250/625 ( 40%)]  Loss: 0.003696 (0.00375)  Time: 0.701s, 2920.01/s  (0.721s, 2841.65/s)  avg LR: 2.639e-03  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 184 [ 300/625 ( 48%)]  Loss: 0.003403 (0.00370)  Time: 0.709s, 2890.42/s  (0.719s, 2848.91/s)  avg LR: 2.639e-03  iter ratio: 0.0000  Data: 0.034 (0.041)
INFO:Train: 184 [ 350/625 ( 56%)]  Loss: 0.003626 (0.00369)  Time: 0.705s, 2905.63/s  (0.718s, 2852.26/s)  avg LR: 2.639e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 184 [ 400/625 ( 64%)]  Loss: 0.002979 (0.00361)  Time: 0.703s, 2912.28/s  (0.717s, 2858.03/s)  avg LR: 2.639e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 184 [ 450/625 ( 72%)]  Loss: 0.003524 (0.00360)  Time: 0.701s, 2923.04/s  (0.715s, 2862.87/s)  avg LR: 2.639e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 184 [ 500/625 ( 80%)]  Loss: 0.004377 (0.00367)  Time: 0.699s, 2929.57/s  (0.714s, 2866.80/s)  avg LR: 2.639e-03  iter ratio: 0.0000  Data: 0.024 (0.037)
INFO:Train: 184 [ 550/625 ( 88%)]  Loss: 0.003064 (0.00362)  Time: 0.703s, 2913.17/s  (0.713s, 2870.84/s)  avg LR: 2.639e-03  iter ratio: 0.0000  Data: 0.022 (0.035)
INFO:Train: 184 [ 600/625 ( 96%)]  Loss: 0.003710 (0.00363)  Time: 0.717s, 2857.10/s  (0.713s, 2872.97/s)  avg LR: 2.639e-03  iter ratio: 0.0000  Data: 0.042 (0.035)
INFO:Train: 184 [ 624/625 (100%)]  Loss: 0.004682 (0.00371)  Time: 0.679s, 3018.08/s  (0.713s, 2873.36/s)  avg LR: 2.639e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.301 (4.301)  Loss:  0.7915 (0.7915)  Acc@1: 82.7148 (82.7148)  Acc@5: 95.9961 (95.9961)
INFO:Test: [  24/24]  Time: 0.080 (0.502)  Loss:  0.6943 (1.1674)  Acc@1: 84.6698 (74.3280)  Acc@5: 96.2264 (92.1280)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-184.pth.tar', 74.32800006347657)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-182.pth.tar', 74.01999991210937)

INFO:184-epoch: remaining time 16.14 h
INFO:Train: 185 [   0/625 (  0%)]  Loss: 0.004408 (0.00441)  Time: 4.328s,  473.19/s  (4.328s,  473.19/s)  avg LR: 2.600e-03  iter ratio: 0.0000  Data: 3.641 (3.641)
INFO:Train: 185 [  50/625 (  8%)]  Loss: 0.003164 (0.00379)  Time: 0.699s, 2930.36/s  (0.781s, 2621.45/s)  avg LR: 2.600e-03  iter ratio: 0.0000  Data: 0.022 (0.099)
INFO:Train: 185 [ 100/625 ( 16%)]  Loss: 0.003487 (0.00369)  Time: 0.715s, 2865.53/s  (0.744s, 2751.52/s)  avg LR: 2.600e-03  iter ratio: 0.0000  Data: 0.041 (0.064)
INFO:Train: 185 [ 150/625 ( 24%)]  Loss: 0.003757 (0.00370)  Time: 0.719s, 2848.90/s  (0.735s, 2786.54/s)  avg LR: 2.600e-03  iter ratio: 0.0000  Data: 0.040 (0.055)
INFO:Train: 185 [ 200/625 ( 32%)]  Loss: 0.004021 (0.00377)  Time: 0.714s, 2870.27/s  (0.730s, 2803.94/s)  avg LR: 2.600e-03  iter ratio: 0.0000  Data: 0.039 (0.051)
INFO:Train: 185 [ 250/625 ( 40%)]  Loss: 0.004035 (0.00381)  Time: 0.697s, 2937.10/s  (0.726s, 2822.63/s)  avg LR: 2.600e-03  iter ratio: 0.0000  Data: 0.022 (0.047)
INFO:Train: 185 [ 300/625 ( 48%)]  Loss: 0.003954 (0.00383)  Time: 0.699s, 2929.57/s  (0.722s, 2837.41/s)  avg LR: 2.600e-03  iter ratio: 0.0000  Data: 0.023 (0.043)
INFO:Train: 185 [ 350/625 ( 56%)]  Loss: 0.004135 (0.00387)  Time: 0.714s, 2868.05/s  (0.719s, 2848.03/s)  avg LR: 2.600e-03  iter ratio: 0.0000  Data: 0.030 (0.041)
INFO:Train: 185 [ 400/625 ( 64%)]  Loss: 0.003642 (0.00384)  Time: 0.698s, 2933.59/s  (0.717s, 2855.39/s)  avg LR: 2.600e-03  iter ratio: 0.0000  Data: 0.023 (0.039)
INFO:Train: 185 [ 450/625 ( 72%)]  Loss: 0.003165 (0.00378)  Time: 0.717s, 2857.97/s  (0.717s, 2857.84/s)  avg LR: 2.600e-03  iter ratio: 0.0000  Data: 0.043 (0.038)
INFO:Train: 185 [ 500/625 ( 80%)]  Loss: 0.004182 (0.00381)  Time: 0.698s, 2932.80/s  (0.716s, 2858.99/s)  avg LR: 2.600e-03  iter ratio: 0.0000  Data: 0.022 (0.038)
INFO:Train: 185 [ 550/625 ( 88%)]  Loss: 0.003190 (0.00376)  Time: 0.704s, 2909.31/s  (0.715s, 2863.78/s)  avg LR: 2.600e-03  iter ratio: 0.0000  Data: 0.023 (0.037)
INFO:Train: 185 [ 600/625 ( 96%)]  Loss: 0.003222 (0.00372)  Time: 0.701s, 2923.48/s  (0.714s, 2867.21/s)  avg LR: 2.600e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 185 [ 624/625 (100%)]  Loss: 0.003657 (0.00372)  Time: 0.674s, 3038.05/s  (0.714s, 2869.33/s)  avg LR: 2.600e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.298 (4.298)  Loss:  0.7231 (0.7231)  Acc@1: 83.5449 (83.5449)  Acc@5: 95.8008 (95.8008)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.7114 (1.1361)  Acc@1: 83.4906 (73.7720)  Acc@5: 95.8726 (92.0740)
INFO:185-epoch: remaining time 16.00 h
INFO:Train: 186 [   0/625 (  0%)]  Loss: 0.003865 (0.00386)  Time: 4.313s,  474.84/s  (4.313s,  474.84/s)  avg LR: 2.562e-03  iter ratio: 0.0000  Data: 3.630 (3.630)
INFO:Train: 186 [  50/625 (  8%)]  Loss: 0.003828 (0.00385)  Time: 0.700s, 2924.18/s  (0.776s, 2640.80/s)  avg LR: 2.562e-03  iter ratio: 0.0000  Data: 0.022 (0.098)
INFO:Train: 186 [ 100/625 ( 16%)]  Loss: 0.004054 (0.00392)  Time: 0.712s, 2875.97/s  (0.741s, 2764.07/s)  avg LR: 2.562e-03  iter ratio: 0.0000  Data: 0.039 (0.064)
INFO:Train: 186 [ 150/625 ( 24%)]  Loss: 0.003045 (0.00370)  Time: 0.712s, 2874.54/s  (0.733s, 2793.85/s)  avg LR: 2.562e-03  iter ratio: 0.0000  Data: 0.039 (0.056)
INFO:Train: 186 [ 200/625 ( 32%)]  Loss: 0.003871 (0.00373)  Time: 0.699s, 2928.32/s  (0.726s, 2819.08/s)  avg LR: 2.562e-03  iter ratio: 0.0000  Data: 0.020 (0.049)
INFO:Train: 186 [ 250/625 ( 40%)]  Loss: 0.003366 (0.00367)  Time: 0.700s, 2927.16/s  (0.722s, 2836.58/s)  avg LR: 2.562e-03  iter ratio: 0.0000  Data: 0.022 (0.045)
INFO:Train: 186 [ 300/625 ( 48%)]  Loss: 0.003618 (0.00366)  Time: 0.700s, 2924.44/s  (0.719s, 2847.11/s)  avg LR: 2.562e-03  iter ratio: 0.0000  Data: 0.021 (0.041)
INFO:Train: 186 [ 350/625 ( 56%)]  Loss: 0.003859 (0.00369)  Time: 0.700s, 2925.16/s  (0.717s, 2855.41/s)  avg LR: 2.562e-03  iter ratio: 0.0000  Data: 0.017 (0.039)
INFO:Train: 186 [ 400/625 ( 64%)]  Loss: 0.003448 (0.00366)  Time: 0.716s, 2859.74/s  (0.716s, 2859.79/s)  avg LR: 2.562e-03  iter ratio: 0.0000  Data: 0.042 (0.038)
INFO:Train: 186 [ 450/625 ( 72%)]  Loss: 0.004051 (0.00370)  Time: 0.717s, 2858.11/s  (0.716s, 2858.90/s)  avg LR: 2.562e-03  iter ratio: 0.0000  Data: 0.042 (0.039)
INFO:Train: 186 [ 500/625 ( 80%)]  Loss: 0.003385 (0.00367)  Time: 0.712s, 2875.67/s  (0.716s, 2858.49/s)  avg LR: 2.562e-03  iter ratio: 0.0000  Data: 0.039 (0.039)
INFO:Train: 186 [ 550/625 ( 88%)]  Loss: 0.004003 (0.00370)  Time: 0.717s, 2858.21/s  (0.717s, 2857.80/s)  avg LR: 2.562e-03  iter ratio: 0.0000  Data: 0.043 (0.040)
INFO:Train: 186 [ 600/625 ( 96%)]  Loss: 0.003420 (0.00368)  Time: 0.714s, 2868.56/s  (0.717s, 2857.43/s)  avg LR: 2.562e-03  iter ratio: 0.0000  Data: 0.037 (0.040)
INFO:Train: 186 [ 624/625 (100%)]  Loss: 0.003567 (0.00367)  Time: 0.674s, 3038.73/s  (0.716s, 2858.47/s)  avg LR: 2.562e-03  iter ratio: 0.0000  Data: 0.000 (0.040)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.346 (4.346)  Loss:  0.7598 (0.7598)  Acc@1: 82.6660 (82.6660)  Acc@5: 95.3125 (95.3125)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.6123 (1.1319)  Acc@1: 85.7311 (74.0620)  Acc@5: 96.9340 (92.0180)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-184.pth.tar', 74.32800006347657)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-186.pth.tar', 74.06200000732422)

INFO:186-epoch: remaining time 15.95 h
INFO:Train: 187 [   0/625 (  0%)]  Loss: 0.003557 (0.00356)  Time: 4.501s,  455.02/s  (4.501s,  455.02/s)  avg LR: 2.523e-03  iter ratio: 0.0000  Data: 3.794 (3.794)
INFO:Train: 187 [  50/625 (  8%)]  Loss: 0.004064 (0.00381)  Time: 0.708s, 2894.20/s  (0.781s, 2620.97/s)  avg LR: 2.523e-03  iter ratio: 0.0000  Data: 0.028 (0.104)
INFO:Train: 187 [ 100/625 ( 16%)]  Loss: 0.003966 (0.00386)  Time: 0.706s, 2900.87/s  (0.746s, 2746.56/s)  avg LR: 2.523e-03  iter ratio: 0.0000  Data: 0.025 (0.068)
INFO:Train: 187 [ 150/625 ( 24%)]  Loss: 0.003754 (0.00384)  Time: 0.708s, 2892.10/s  (0.734s, 2791.32/s)  avg LR: 2.523e-03  iter ratio: 0.0000  Data: 0.028 (0.056)
INFO:Train: 187 [ 200/625 ( 32%)]  Loss: 0.003428 (0.00375)  Time: 0.707s, 2898.58/s  (0.728s, 2814.07/s)  avg LR: 2.523e-03  iter ratio: 0.0000  Data: 0.029 (0.049)
INFO:Train: 187 [ 250/625 ( 40%)]  Loss: 0.003577 (0.00372)  Time: 0.710s, 2883.87/s  (0.724s, 2828.07/s)  avg LR: 2.523e-03  iter ratio: 0.0000  Data: 0.032 (0.046)
INFO:Train: 187 [ 300/625 ( 48%)]  Loss: 0.004222 (0.00380)  Time: 0.711s, 2881.15/s  (0.722s, 2837.22/s)  avg LR: 2.523e-03  iter ratio: 0.0000  Data: 0.029 (0.043)
INFO:Train: 187 [ 350/625 ( 56%)]  Loss: 0.003997 (0.00382)  Time: 0.716s, 2861.11/s  (0.720s, 2844.94/s)  avg LR: 2.523e-03  iter ratio: 0.0000  Data: 0.039 (0.041)
INFO:Train: 187 [ 400/625 ( 64%)]  Loss: 0.003981 (0.00384)  Time: 0.709s, 2888.92/s  (0.719s, 2850.10/s)  avg LR: 2.523e-03  iter ratio: 0.0000  Data: 0.033 (0.040)
INFO:Train: 187 [ 450/625 ( 72%)]  Loss: 0.004310 (0.00389)  Time: 0.708s, 2892.66/s  (0.718s, 2854.21/s)  avg LR: 2.523e-03  iter ratio: 0.0000  Data: 0.031 (0.039)
INFO:Train: 187 [ 500/625 ( 80%)]  Loss: 0.003582 (0.00386)  Time: 0.705s, 2903.67/s  (0.717s, 2857.29/s)  avg LR: 2.523e-03  iter ratio: 0.0000  Data: 0.030 (0.039)
INFO:Train: 187 [ 550/625 ( 88%)]  Loss: 0.004248 (0.00389)  Time: 0.705s, 2905.59/s  (0.716s, 2859.94/s)  avg LR: 2.523e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 187 [ 600/625 ( 96%)]  Loss: 0.003900 (0.00389)  Time: 0.706s, 2900.44/s  (0.715s, 2862.73/s)  avg LR: 2.523e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 187 [ 624/625 (100%)]  Loss: 0.004190 (0.00391)  Time: 0.676s, 3030.58/s  (0.715s, 2864.46/s)  avg LR: 2.523e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.299 (4.299)  Loss:  0.7485 (0.7485)  Acc@1: 82.7148 (82.7148)  Acc@5: 96.1426 (96.1426)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.7236 (1.1396)  Acc@1: 83.1368 (73.9960)  Acc@5: 96.3443 (92.1340)
INFO:187-epoch: remaining time 15.77 h
INFO:Train: 188 [   0/625 (  0%)]  Loss: 0.004377 (0.00438)  Time: 4.255s,  481.26/s  (4.255s,  481.26/s)  avg LR: 2.485e-03  iter ratio: 0.0000  Data: 3.552 (3.552)
INFO:Train: 188 [  50/625 (  8%)]  Loss: 0.003125 (0.00375)  Time: 0.706s, 2898.82/s  (0.781s, 2620.78/s)  avg LR: 2.485e-03  iter ratio: 0.0000  Data: 0.030 (0.102)
INFO:Train: 188 [ 100/625 ( 16%)]  Loss: 0.003222 (0.00357)  Time: 0.706s, 2901.54/s  (0.745s, 2749.61/s)  avg LR: 2.485e-03  iter ratio: 0.0000  Data: 0.030 (0.067)
INFO:Train: 188 [ 150/625 ( 24%)]  Loss: 0.003734 (0.00361)  Time: 0.709s, 2890.35/s  (0.732s, 2796.89/s)  avg LR: 2.485e-03  iter ratio: 0.0000  Data: 0.032 (0.055)
INFO:Train: 188 [ 200/625 ( 32%)]  Loss: 0.004477 (0.00379)  Time: 0.702s, 2917.03/s  (0.725s, 2824.48/s)  avg LR: 2.485e-03  iter ratio: 0.0000  Data: 0.023 (0.048)
INFO:Train: 188 [ 250/625 ( 40%)]  Loss: 0.003959 (0.00382)  Time: 0.703s, 2914.11/s  (0.721s, 2840.90/s)  avg LR: 2.485e-03  iter ratio: 0.0000  Data: 0.024 (0.044)
INFO:Train: 188 [ 300/625 ( 48%)]  Loss: 0.004104 (0.00386)  Time: 0.701s, 2919.80/s  (0.718s, 2852.29/s)  avg LR: 2.485e-03  iter ratio: 0.0000  Data: 0.021 (0.041)
INFO:Train: 188 [ 350/625 ( 56%)]  Loss: 0.003601 (0.00382)  Time: 0.714s, 2867.30/s  (0.716s, 2860.35/s)  avg LR: 2.485e-03  iter ratio: 0.0000  Data: 0.033 (0.038)
INFO:Train: 188 [ 400/625 ( 64%)]  Loss: 0.003933 (0.00384)  Time: 0.705s, 2903.44/s  (0.715s, 2862.50/s)  avg LR: 2.485e-03  iter ratio: 0.0000  Data: 0.031 (0.038)
INFO:Train: 188 [ 450/625 ( 72%)]  Loss: 0.002851 (0.00374)  Time: 0.711s, 2878.48/s  (0.716s, 2861.48/s)  avg LR: 2.485e-03  iter ratio: 0.0000  Data: 0.035 (0.038)
INFO:Train: 188 [ 500/625 ( 80%)]  Loss: 0.003550 (0.00372)  Time: 0.709s, 2889.43/s  (0.715s, 2862.95/s)  avg LR: 2.485e-03  iter ratio: 0.0000  Data: 0.030 (0.038)
INFO:Train: 188 [ 550/625 ( 88%)]  Loss: 0.003302 (0.00369)  Time: 0.707s, 2897.03/s  (0.715s, 2865.72/s)  avg LR: 2.485e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 188 [ 600/625 ( 96%)]  Loss: 0.003855 (0.00370)  Time: 0.701s, 2921.24/s  (0.714s, 2868.42/s)  avg LR: 2.485e-03  iter ratio: 0.0000  Data: 0.023 (0.036)
INFO:Train: 188 [ 624/625 (100%)]  Loss: 0.003073 (0.00365)  Time: 0.677s, 3027.01/s  (0.713s, 2870.50/s)  avg LR: 2.485e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.281 (4.281)  Loss:  0.7812 (0.7812)  Acc@1: 81.8848 (81.8848)  Acc@5: 95.5078 (95.5078)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.6880 (1.1542)  Acc@1: 83.9623 (73.3160)  Acc@5: 95.4009 (91.5600)
INFO:188-epoch: remaining time 15.62 h
INFO:Train: 189 [   0/625 (  0%)]  Loss: 0.004371 (0.00437)  Time: 4.365s,  469.17/s  (4.365s,  469.17/s)  avg LR: 2.446e-03  iter ratio: 0.0000  Data: 3.662 (3.662)
INFO:Train: 189 [  50/625 (  8%)]  Loss: 0.004046 (0.00421)  Time: 0.718s, 2850.84/s  (0.778s, 2632.08/s)  avg LR: 2.446e-03  iter ratio: 0.0000  Data: 0.044 (0.099)
INFO:Train: 189 [ 100/625 ( 16%)]  Loss: 0.003600 (0.00401)  Time: 0.703s, 2911.63/s  (0.742s, 2760.78/s)  avg LR: 2.446e-03  iter ratio: 0.0000  Data: 0.026 (0.064)
INFO:Train: 189 [ 150/625 ( 24%)]  Loss: 0.003702 (0.00393)  Time: 0.704s, 2907.59/s  (0.730s, 2807.34/s)  avg LR: 2.446e-03  iter ratio: 0.0000  Data: 0.025 (0.051)
INFO:Train: 189 [ 200/625 ( 32%)]  Loss: 0.003700 (0.00388)  Time: 0.703s, 2914.84/s  (0.723s, 2831.39/s)  avg LR: 2.446e-03  iter ratio: 0.0000  Data: 0.024 (0.045)
INFO:Train: 189 [ 250/625 ( 40%)]  Loss: 0.003721 (0.00386)  Time: 0.706s, 2902.67/s  (0.720s, 2846.11/s)  avg LR: 2.446e-03  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 189 [ 300/625 ( 48%)]  Loss: 0.003333 (0.00378)  Time: 0.709s, 2889.15/s  (0.717s, 2855.14/s)  avg LR: 2.446e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 189 [ 350/625 ( 56%)]  Loss: 0.003789 (0.00378)  Time: 0.701s, 2923.11/s  (0.715s, 2862.86/s)  avg LR: 2.446e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 189 [ 400/625 ( 64%)]  Loss: 0.003460 (0.00375)  Time: 0.705s, 2903.91/s  (0.714s, 2867.42/s)  avg LR: 2.446e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 189 [ 450/625 ( 72%)]  Loss: 0.003802 (0.00375)  Time: 0.703s, 2914.05/s  (0.713s, 2871.26/s)  avg LR: 2.446e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 189 [ 500/625 ( 80%)]  Loss: 0.003941 (0.00377)  Time: 0.708s, 2891.75/s  (0.713s, 2872.48/s)  avg LR: 2.446e-03  iter ratio: 0.0000  Data: 0.034 (0.034)
INFO:Train: 189 [ 550/625 ( 88%)]  Loss: 0.003763 (0.00377)  Time: 0.701s, 2923.43/s  (0.713s, 2870.68/s)  avg LR: 2.446e-03  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 189 [ 600/625 ( 96%)]  Loss: 0.004562 (0.00383)  Time: 0.704s, 2908.74/s  (0.714s, 2869.10/s)  avg LR: 2.446e-03  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 189 [ 624/625 (100%)]  Loss: 0.003401 (0.00380)  Time: 0.681s, 3006.21/s  (0.714s, 2869.36/s)  avg LR: 2.446e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.290 (4.290)  Loss:  0.7217 (0.7217)  Acc@1: 83.6426 (83.6426)  Acc@5: 95.8984 (95.8984)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.6309 (1.1076)  Acc@1: 83.8443 (74.4740)  Acc@5: 96.6981 (92.2100)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-189.pth.tar', 74.47400009277344)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-184.pth.tar', 74.32800006347657)

INFO:189-epoch: remaining time 15.50 h
INFO:Train: 190 [   0/625 (  0%)]  Loss: 0.004545 (0.00455)  Time: 4.201s,  487.48/s  (4.201s,  487.48/s)  avg LR: 2.408e-03  iter ratio: 0.0000  Data: 3.515 (3.515)
INFO:Train: 190 [  50/625 (  8%)]  Loss: 0.003564 (0.00405)  Time: 0.717s, 2854.90/s  (0.778s, 2631.95/s)  avg LR: 2.408e-03  iter ratio: 0.0000  Data: 0.044 (0.102)
INFO:Train: 190 [ 100/625 ( 16%)]  Loss: 0.004308 (0.00414)  Time: 0.709s, 2886.56/s  (0.747s, 2741.60/s)  avg LR: 2.408e-03  iter ratio: 0.0000  Data: 0.035 (0.071)
INFO:Train: 190 [ 150/625 ( 24%)]  Loss: 0.004447 (0.00422)  Time: 0.705s, 2905.69/s  (0.736s, 2781.87/s)  avg LR: 2.408e-03  iter ratio: 0.0000  Data: 0.030 (0.060)
INFO:Train: 190 [ 200/625 ( 32%)]  Loss: 0.003914 (0.00416)  Time: 0.715s, 2865.71/s  (0.731s, 2802.21/s)  avg LR: 2.408e-03  iter ratio: 0.0000  Data: 0.040 (0.054)
INFO:Train: 190 [ 250/625 ( 40%)]  Loss: 0.003979 (0.00413)  Time: 0.702s, 2916.57/s  (0.727s, 2815.78/s)  avg LR: 2.408e-03  iter ratio: 0.0000  Data: 0.026 (0.051)
INFO:Train: 190 [ 300/625 ( 48%)]  Loss: 0.003005 (0.00397)  Time: 0.708s, 2894.65/s  (0.724s, 2829.70/s)  avg LR: 2.408e-03  iter ratio: 0.0000  Data: 0.030 (0.048)
INFO:Train: 190 [ 350/625 ( 56%)]  Loss: 0.003909 (0.00396)  Time: 0.701s, 2922.57/s  (0.721s, 2840.62/s)  avg LR: 2.408e-03  iter ratio: 0.0000  Data: 0.020 (0.045)
INFO:Train: 190 [ 400/625 ( 64%)]  Loss: 0.003300 (0.00389)  Time: 0.701s, 2919.63/s  (0.719s, 2849.01/s)  avg LR: 2.408e-03  iter ratio: 0.0000  Data: 0.025 (0.042)
INFO:Train: 190 [ 450/625 ( 72%)]  Loss: 0.002797 (0.00378)  Time: 0.704s, 2907.34/s  (0.717s, 2855.10/s)  avg LR: 2.408e-03  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 190 [ 500/625 ( 80%)]  Loss: 0.003723 (0.00377)  Time: 0.719s, 2849.20/s  (0.716s, 2858.90/s)  avg LR: 2.408e-03  iter ratio: 0.0000  Data: 0.035 (0.039)
INFO:Train: 190 [ 550/625 ( 88%)]  Loss: 0.003286 (0.00373)  Time: 0.700s, 2925.26/s  (0.715s, 2862.63/s)  avg LR: 2.408e-03  iter ratio: 0.0000  Data: 0.024 (0.038)
INFO:Train: 190 [ 600/625 ( 96%)]  Loss: 0.003853 (0.00374)  Time: 0.706s, 2902.78/s  (0.715s, 2866.32/s)  avg LR: 2.408e-03  iter ratio: 0.0000  Data: 0.022 (0.037)
INFO:Train: 190 [ 624/625 (100%)]  Loss: 0.003520 (0.00372)  Time: 0.678s, 3022.30/s  (0.714s, 2868.54/s)  avg LR: 2.408e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.324 (4.324)  Loss:  0.7573 (0.7573)  Acc@1: 82.3242 (82.3242)  Acc@5: 95.8984 (95.8984)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.7236 (1.1333)  Acc@1: 83.0189 (74.3620)  Acc@5: 95.1651 (92.1700)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-189.pth.tar', 74.47400009277344)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-190.pth.tar', 74.36199999267578)

INFO:190-epoch: remaining time 15.37 h
INFO:Train: 191 [   0/625 (  0%)]  Loss: 0.004043 (0.00404)  Time: 4.170s,  491.12/s  (4.170s,  491.12/s)  avg LR: 2.370e-03  iter ratio: 0.0000  Data: 3.472 (3.472)
INFO:Train: 191 [  50/625 (  8%)]  Loss: 0.003686 (0.00386)  Time: 0.702s, 2918.55/s  (0.780s, 2626.04/s)  avg LR: 2.370e-03  iter ratio: 0.0000  Data: 0.026 (0.100)
INFO:Train: 191 [ 100/625 ( 16%)]  Loss: 0.003927 (0.00389)  Time: 0.704s, 2907.88/s  (0.743s, 2756.95/s)  avg LR: 2.370e-03  iter ratio: 0.0000  Data: 0.025 (0.063)
INFO:Train: 191 [ 150/625 ( 24%)]  Loss: 0.004055 (0.00393)  Time: 0.702s, 2916.82/s  (0.731s, 2802.69/s)  avg LR: 2.370e-03  iter ratio: 0.0000  Data: 0.025 (0.051)
INFO:Train: 191 [ 200/625 ( 32%)]  Loss: 0.003649 (0.00387)  Time: 0.715s, 2864.56/s  (0.725s, 2824.94/s)  avg LR: 2.370e-03  iter ratio: 0.0000  Data: 0.040 (0.046)
INFO:Train: 191 [ 250/625 ( 40%)]  Loss: 0.004158 (0.00392)  Time: 0.718s, 2854.12/s  (0.724s, 2828.82/s)  avg LR: 2.370e-03  iter ratio: 0.0000  Data: 0.043 (0.046)
INFO:Train: 191 [ 300/625 ( 48%)]  Loss: 0.002818 (0.00376)  Time: 0.719s, 2847.84/s  (0.723s, 2830.91/s)  avg LR: 2.370e-03  iter ratio: 0.0000  Data: 0.045 (0.046)
INFO:Train: 191 [ 350/625 ( 56%)]  Loss: 0.003667 (0.00375)  Time: 0.700s, 2925.38/s  (0.722s, 2835.81/s)  avg LR: 2.370e-03  iter ratio: 0.0000  Data: 0.025 (0.045)
INFO:Train: 191 [ 400/625 ( 64%)]  Loss: 0.003654 (0.00374)  Time: 0.711s, 2881.75/s  (0.720s, 2843.45/s)  avg LR: 2.370e-03  iter ratio: 0.0000  Data: 0.033 (0.043)
INFO:Train: 191 [ 450/625 ( 72%)]  Loss: 0.003217 (0.00369)  Time: 0.706s, 2899.88/s  (0.719s, 2849.65/s)  avg LR: 2.370e-03  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 191 [ 500/625 ( 80%)]  Loss: 0.004316 (0.00374)  Time: 0.704s, 2909.28/s  (0.717s, 2855.35/s)  avg LR: 2.370e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 191 [ 550/625 ( 88%)]  Loss: 0.003176 (0.00370)  Time: 0.703s, 2915.12/s  (0.716s, 2859.06/s)  avg LR: 2.370e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 191 [ 600/625 ( 96%)]  Loss: 0.003488 (0.00368)  Time: 0.704s, 2909.72/s  (0.715s, 2862.96/s)  avg LR: 2.370e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 191 [ 624/625 (100%)]  Loss: 0.003755 (0.00369)  Time: 0.675s, 3035.42/s  (0.715s, 2865.16/s)  avg LR: 2.370e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.296 (4.296)  Loss:  0.7021 (0.7021)  Acc@1: 83.8379 (83.8379)  Acc@5: 96.3379 (96.3379)
INFO:Test: [  24/24]  Time: 0.081 (0.506)  Loss:  0.6816 (1.0797)  Acc@1: 84.5519 (74.9360)  Acc@5: 96.3443 (92.6100)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-191.pth.tar', 74.93600001220703)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-189.pth.tar', 74.47400009277344)

INFO:191-epoch: remaining time 15.26 h
INFO:Train: 192 [   0/625 (  0%)]  Loss: 0.003371 (0.00337)  Time: 4.848s,  422.48/s  (4.848s,  422.48/s)  avg LR: 2.333e-03  iter ratio: 0.0000  Data: 4.160 (4.160)
INFO:Train: 192 [  50/625 (  8%)]  Loss: 0.004056 (0.00371)  Time: 0.705s, 2906.84/s  (0.788s, 2597.86/s)  avg LR: 2.333e-03  iter ratio: 0.0000  Data: 0.028 (0.109)
INFO:Train: 192 [ 100/625 ( 16%)]  Loss: 0.004113 (0.00385)  Time: 0.706s, 2899.14/s  (0.748s, 2736.57/s)  avg LR: 2.333e-03  iter ratio: 0.0000  Data: 0.030 (0.070)
INFO:Train: 192 [ 150/625 ( 24%)]  Loss: 0.003555 (0.00377)  Time: 0.706s, 2900.30/s  (0.734s, 2789.16/s)  avg LR: 2.333e-03  iter ratio: 0.0000  Data: 0.026 (0.056)
INFO:Train: 192 [ 200/625 ( 32%)]  Loss: 0.003684 (0.00376)  Time: 0.711s, 2880.12/s  (0.728s, 2815.03/s)  avg LR: 2.333e-03  iter ratio: 0.0000  Data: 0.035 (0.049)
INFO:Train: 192 [ 250/625 ( 40%)]  Loss: 0.003831 (0.00377)  Time: 0.707s, 2894.99/s  (0.725s, 2826.54/s)  avg LR: 2.333e-03  iter ratio: 0.0000  Data: 0.030 (0.047)
INFO:Train: 192 [ 300/625 ( 48%)]  Loss: 0.003580 (0.00374)  Time: 0.706s, 2900.85/s  (0.723s, 2834.50/s)  avg LR: 2.333e-03  iter ratio: 0.0000  Data: 0.029 (0.045)
INFO:Train: 192 [ 350/625 ( 56%)]  Loss: 0.003279 (0.00368)  Time: 0.701s, 2921.49/s  (0.721s, 2841.69/s)  avg LR: 2.333e-03  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 192 [ 400/625 ( 64%)]  Loss: 0.004082 (0.00373)  Time: 0.704s, 2909.15/s  (0.719s, 2848.60/s)  avg LR: 2.333e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 192 [ 450/625 ( 72%)]  Loss: 0.004018 (0.00376)  Time: 0.706s, 2900.69/s  (0.717s, 2854.91/s)  avg LR: 2.333e-03  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 192 [ 500/625 ( 80%)]  Loss: 0.004442 (0.00382)  Time: 0.713s, 2870.83/s  (0.716s, 2859.58/s)  avg LR: 2.333e-03  iter ratio: 0.0000  Data: 0.038 (0.038)
INFO:Train: 192 [ 550/625 ( 88%)]  Loss: 0.003416 (0.00379)  Time: 0.713s, 2873.82/s  (0.716s, 2858.68/s)  avg LR: 2.333e-03  iter ratio: 0.0000  Data: 0.038 (0.039)
INFO:Train: 192 [ 600/625 ( 96%)]  Loss: 0.003748 (0.00378)  Time: 0.712s, 2878.19/s  (0.717s, 2858.00/s)  avg LR: 2.333e-03  iter ratio: 0.0000  Data: 0.037 (0.039)
INFO:Train: 192 [ 624/625 (100%)]  Loss: 0.003909 (0.00379)  Time: 0.672s, 3045.68/s  (0.716s, 2858.58/s)  avg LR: 2.333e-03  iter ratio: 0.0000  Data: 0.000 (0.039)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.308 (4.308)  Loss:  0.7280 (0.7280)  Acc@1: 83.0566 (83.0566)  Acc@5: 95.6055 (95.6055)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.6533 (1.0961)  Acc@1: 84.7877 (74.7000)  Acc@5: 96.4623 (92.3620)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-191.pth.tar', 74.93600001220703)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-192.pth.tar', 74.69999998535157)

INFO:192-epoch: remaining time 15.16 h
INFO:Train: 193 [   0/625 (  0%)]  Loss: 0.003777 (0.00378)  Time: 4.515s,  453.61/s  (4.515s,  453.61/s)  avg LR: 2.295e-03  iter ratio: 0.0000  Data: 3.832 (3.832)
INFO:Train: 193 [  50/625 (  8%)]  Loss: 0.003754 (0.00377)  Time: 0.716s, 2858.80/s  (0.793s, 2582.97/s)  avg LR: 2.295e-03  iter ratio: 0.0000  Data: 0.037 (0.115)
INFO:Train: 193 [ 100/625 ( 16%)]  Loss: 0.004481 (0.00400)  Time: 0.712s, 2877.53/s  (0.754s, 2715.08/s)  avg LR: 2.295e-03  iter ratio: 0.0000  Data: 0.034 (0.076)
INFO:Train: 193 [ 150/625 ( 24%)]  Loss: 0.002886 (0.00372)  Time: 0.703s, 2913.01/s  (0.740s, 2767.74/s)  avg LR: 2.295e-03  iter ratio: 0.0000  Data: 0.026 (0.062)
INFO:Train: 193 [ 200/625 ( 32%)]  Loss: 0.003654 (0.00371)  Time: 0.706s, 2899.45/s  (0.731s, 2799.99/s)  avg LR: 2.295e-03  iter ratio: 0.0000  Data: 0.029 (0.053)
INFO:Train: 193 [ 250/625 ( 40%)]  Loss: 0.004172 (0.00379)  Time: 0.707s, 2898.21/s  (0.727s, 2818.57/s)  avg LR: 2.295e-03  iter ratio: 0.0000  Data: 0.030 (0.049)
INFO:Train: 193 [ 300/625 ( 48%)]  Loss: 0.004054 (0.00383)  Time: 0.706s, 2900.41/s  (0.723s, 2831.92/s)  avg LR: 2.295e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 193 [ 350/625 ( 56%)]  Loss: 0.003471 (0.00378)  Time: 0.722s, 2837.36/s  (0.721s, 2838.63/s)  avg LR: 2.295e-03  iter ratio: 0.0000  Data: 0.047 (0.044)
INFO:Train: 193 [ 400/625 ( 64%)]  Loss: 0.004115 (0.00382)  Time: 0.707s, 2897.55/s  (0.720s, 2844.96/s)  avg LR: 2.295e-03  iter ratio: 0.0000  Data: 0.029 (0.042)
INFO:Train: 193 [ 450/625 ( 72%)]  Loss: 0.004284 (0.00386)  Time: 0.706s, 2899.24/s  (0.719s, 2850.37/s)  avg LR: 2.295e-03  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 193 [ 500/625 ( 80%)]  Loss: 0.004028 (0.00388)  Time: 0.710s, 2883.50/s  (0.717s, 2854.84/s)  avg LR: 2.295e-03  iter ratio: 0.0000  Data: 0.035 (0.039)
INFO:Train: 193 [ 550/625 ( 88%)]  Loss: 0.003800 (0.00387)  Time: 0.704s, 2907.79/s  (0.716s, 2859.43/s)  avg LR: 2.295e-03  iter ratio: 0.0000  Data: 0.022 (0.038)
INFO:Train: 193 [ 600/625 ( 96%)]  Loss: 0.003212 (0.00382)  Time: 0.714s, 2870.05/s  (0.716s, 2860.45/s)  avg LR: 2.295e-03  iter ratio: 0.0000  Data: 0.038 (0.038)
INFO:Train: 193 [ 624/625 (100%)]  Loss: 0.003190 (0.00378)  Time: 0.674s, 3040.80/s  (0.716s, 2861.43/s)  avg LR: 2.295e-03  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.332 (4.332)  Loss:  0.7681 (0.7681)  Acc@1: 82.5684 (82.5684)  Acc@5: 95.1660 (95.1660)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.6963 (1.1127)  Acc@1: 83.6085 (74.4640)  Acc@5: 95.6368 (92.2020)
INFO:193-epoch: remaining time 15.03 h
INFO:Train: 194 [   0/625 (  0%)]  Loss: 0.003693 (0.00369)  Time: 4.326s,  473.39/s  (4.326s,  473.39/s)  avg LR: 2.258e-03  iter ratio: 0.0000  Data: 3.613 (3.613)
INFO:Train: 194 [  50/625 (  8%)]  Loss: 0.003887 (0.00379)  Time: 0.708s, 2891.82/s  (0.781s, 2623.89/s)  avg LR: 2.258e-03  iter ratio: 0.0000  Data: 0.024 (0.101)
INFO:Train: 194 [ 100/625 ( 16%)]  Loss: 0.003983 (0.00385)  Time: 0.716s, 2862.14/s  (0.748s, 2739.06/s)  avg LR: 2.258e-03  iter ratio: 0.0000  Data: 0.042 (0.070)
INFO:Train: 194 [ 150/625 ( 24%)]  Loss: 0.003701 (0.00382)  Time: 0.718s, 2852.14/s  (0.738s, 2774.33/s)  avg LR: 2.258e-03  iter ratio: 0.0000  Data: 0.043 (0.062)
INFO:Train: 194 [ 200/625 ( 32%)]  Loss: 0.004096 (0.00387)  Time: 0.722s, 2837.18/s  (0.733s, 2792.57/s)  avg LR: 2.258e-03  iter ratio: 0.0000  Data: 0.048 (0.057)
INFO:Train: 194 [ 250/625 ( 40%)]  Loss: 0.004009 (0.00389)  Time: 0.717s, 2856.49/s  (0.731s, 2803.54/s)  avg LR: 2.258e-03  iter ratio: 0.0000  Data: 0.043 (0.055)
INFO:Train: 194 [ 300/625 ( 48%)]  Loss: 0.003425 (0.00383)  Time: 0.715s, 2865.56/s  (0.728s, 2811.37/s)  avg LR: 2.258e-03  iter ratio: 0.0000  Data: 0.041 (0.053)
INFO:Train: 194 [ 350/625 ( 56%)]  Loss: 0.003678 (0.00381)  Time: 0.713s, 2873.37/s  (0.727s, 2817.93/s)  avg LR: 2.258e-03  iter ratio: 0.0000  Data: 0.039 (0.052)
INFO:Train: 194 [ 400/625 ( 64%)]  Loss: 0.002836 (0.00370)  Time: 0.702s, 2918.39/s  (0.724s, 2828.45/s)  avg LR: 2.258e-03  iter ratio: 0.0000  Data: 0.026 (0.049)
INFO:Train: 194 [ 450/625 ( 72%)]  Loss: 0.002926 (0.00362)  Time: 0.704s, 2908.72/s  (0.722s, 2836.16/s)  avg LR: 2.258e-03  iter ratio: 0.0000  Data: 0.029 (0.047)
INFO:Train: 194 [ 500/625 ( 80%)]  Loss: 0.004190 (0.00367)  Time: 0.706s, 2901.19/s  (0.720s, 2842.51/s)  avg LR: 2.258e-03  iter ratio: 0.0000  Data: 0.031 (0.045)
INFO:Train: 194 [ 550/625 ( 88%)]  Loss: 0.003530 (0.00366)  Time: 0.702s, 2917.61/s  (0.719s, 2848.51/s)  avg LR: 2.258e-03  iter ratio: 0.0000  Data: 0.024 (0.043)
INFO:Train: 194 [ 600/625 ( 96%)]  Loss: 0.003669 (0.00366)  Time: 0.715s, 2864.58/s  (0.718s, 2850.51/s)  avg LR: 2.258e-03  iter ratio: 0.0000  Data: 0.041 (0.043)
INFO:Train: 194 [ 624/625 (100%)]  Loss: 0.004019 (0.00369)  Time: 0.674s, 3036.58/s  (0.718s, 2852.22/s)  avg LR: 2.258e-03  iter ratio: 0.0000  Data: 0.000 (0.042)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.321 (4.321)  Loss:  0.6865 (0.6865)  Acc@1: 84.4238 (84.4238)  Acc@5: 96.6797 (96.6797)
INFO:Test: [  24/24]  Time: 0.080 (0.507)  Loss:  0.6333 (1.0411)  Acc@1: 85.1415 (75.8220)  Acc@5: 96.2264 (93.0020)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-194.pth.tar', 75.82200000976563)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-191.pth.tar', 74.93600001220703)

INFO:194-epoch: remaining time 14.94 h
INFO:Train: 195 [   0/625 (  0%)]  Loss: 0.003740 (0.00374)  Time: 4.350s,  470.79/s  (4.350s,  470.79/s)  avg LR: 2.220e-03  iter ratio: 0.0000  Data: 3.667 (3.667)
INFO:Train: 195 [  50/625 (  8%)]  Loss: 0.004013 (0.00388)  Time: 0.709s, 2889.82/s  (0.777s, 2637.44/s)  avg LR: 2.220e-03  iter ratio: 0.0000  Data: 0.034 (0.100)
INFO:Train: 195 [ 100/625 ( 16%)]  Loss: 0.003209 (0.00365)  Time: 0.718s, 2853.47/s  (0.742s, 2761.92/s)  avg LR: 2.220e-03  iter ratio: 0.0000  Data: 0.043 (0.065)
INFO:Train: 195 [ 150/625 ( 24%)]  Loss: 0.003441 (0.00360)  Time: 0.703s, 2912.40/s  (0.731s, 2801.47/s)  avg LR: 2.220e-03  iter ratio: 0.0000  Data: 0.029 (0.055)
INFO:Train: 195 [ 200/625 ( 32%)]  Loss: 0.003867 (0.00365)  Time: 0.709s, 2887.52/s  (0.724s, 2827.14/s)  avg LR: 2.220e-03  iter ratio: 0.0000  Data: 0.033 (0.048)
INFO:Train: 195 [ 250/625 ( 40%)]  Loss: 0.003913 (0.00370)  Time: 0.703s, 2914.46/s  (0.721s, 2841.65/s)  avg LR: 2.220e-03  iter ratio: 0.0000  Data: 0.028 (0.044)
INFO:Train: 195 [ 300/625 ( 48%)]  Loss: 0.003557 (0.00368)  Time: 0.716s, 2859.30/s  (0.718s, 2850.81/s)  avg LR: 2.220e-03  iter ratio: 0.0000  Data: 0.041 (0.042)
INFO:Train: 195 [ 350/625 ( 56%)]  Loss: 0.003270 (0.00363)  Time: 0.703s, 2912.43/s  (0.718s, 2852.84/s)  avg LR: 2.220e-03  iter ratio: 0.0000  Data: 0.029 (0.042)
INFO:Train: 195 [ 400/625 ( 64%)]  Loss: 0.004242 (0.00369)  Time: 0.706s, 2902.46/s  (0.716s, 2858.44/s)  avg LR: 2.220e-03  iter ratio: 0.0000  Data: 0.030 (0.040)
INFO:Train: 195 [ 450/625 ( 72%)]  Loss: 0.004041 (0.00373)  Time: 0.701s, 2921.84/s  (0.715s, 2864.26/s)  avg LR: 2.220e-03  iter ratio: 0.0000  Data: 0.023 (0.039)
INFO:Train: 195 [ 500/625 ( 80%)]  Loss: 0.004148 (0.00377)  Time: 0.719s, 2848.69/s  (0.714s, 2866.39/s)  avg LR: 2.220e-03  iter ratio: 0.0000  Data: 0.043 (0.038)
INFO:Train: 195 [ 550/625 ( 88%)]  Loss: 0.003767 (0.00377)  Time: 0.720s, 2846.36/s  (0.715s, 2865.07/s)  avg LR: 2.220e-03  iter ratio: 0.0000  Data: 0.045 (0.039)
INFO:Train: 195 [ 600/625 ( 96%)]  Loss: 0.003924 (0.00378)  Time: 0.701s, 2922.82/s  (0.715s, 2864.48/s)  avg LR: 2.220e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 195 [ 624/625 (100%)]  Loss: 0.003194 (0.00374)  Time: 0.674s, 3039.94/s  (0.714s, 2867.10/s)  avg LR: 2.220e-03  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.337 (4.337)  Loss:  0.7217 (0.7217)  Acc@1: 82.3730 (82.3730)  Acc@5: 96.1426 (96.1426)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.5957 (1.0710)  Acc@1: 85.4953 (75.4280)  Acc@5: 96.6981 (92.7660)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-194.pth.tar', 75.82200000976563)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-195.pth.tar', 75.42800003417969)

INFO:195-epoch: remaining time 14.73 h
INFO:Train: 196 [   0/625 (  0%)]  Loss: 0.003884 (0.00388)  Time: 4.395s,  465.99/s  (4.395s,  465.99/s)  avg LR: 2.183e-03  iter ratio: 0.0000  Data: 3.692 (3.692)
INFO:Train: 196 [  50/625 (  8%)]  Loss: 0.003065 (0.00347)  Time: 0.701s, 2923.38/s  (0.778s, 2633.11/s)  avg LR: 2.183e-03  iter ratio: 0.0000  Data: 0.025 (0.101)
INFO:Train: 196 [ 100/625 ( 16%)]  Loss: 0.003728 (0.00356)  Time: 0.704s, 2908.71/s  (0.741s, 2764.42/s)  avg LR: 2.183e-03  iter ratio: 0.0000  Data: 0.028 (0.064)
INFO:Train: 196 [ 150/625 ( 24%)]  Loss: 0.003769 (0.00361)  Time: 0.712s, 2877.93/s  (0.733s, 2793.90/s)  avg LR: 2.183e-03  iter ratio: 0.0000  Data: 0.037 (0.057)
INFO:Train: 196 [ 200/625 ( 32%)]  Loss: 0.003916 (0.00367)  Time: 0.713s, 2870.91/s  (0.729s, 2808.47/s)  avg LR: 2.183e-03  iter ratio: 0.0000  Data: 0.040 (0.054)
INFO:Train: 196 [ 250/625 ( 40%)]  Loss: 0.004038 (0.00373)  Time: 0.706s, 2900.70/s  (0.724s, 2828.60/s)  avg LR: 2.183e-03  iter ratio: 0.0000  Data: 0.032 (0.049)
INFO:Train: 196 [ 300/625 ( 48%)]  Loss: 0.003168 (0.00365)  Time: 0.707s, 2896.86/s  (0.721s, 2842.47/s)  avg LR: 2.183e-03  iter ratio: 0.0000  Data: 0.029 (0.045)
INFO:Train: 196 [ 350/625 ( 56%)]  Loss: 0.003808 (0.00367)  Time: 0.710s, 2883.36/s  (0.720s, 2846.28/s)  avg LR: 2.183e-03  iter ratio: 0.0000  Data: 0.036 (0.044)
INFO:Train: 196 [ 400/625 ( 64%)]  Loss: 0.004033 (0.00371)  Time: 0.704s, 2908.06/s  (0.718s, 2853.32/s)  avg LR: 2.183e-03  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 196 [ 450/625 ( 72%)]  Loss: 0.004062 (0.00375)  Time: 0.698s, 2932.05/s  (0.716s, 2859.20/s)  avg LR: 2.183e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 196 [ 500/625 ( 80%)]  Loss: 0.003401 (0.00372)  Time: 0.713s, 2871.28/s  (0.716s, 2861.74/s)  avg LR: 2.183e-03  iter ratio: 0.0000  Data: 0.039 (0.040)
INFO:Train: 196 [ 550/625 ( 88%)]  Loss: 0.003545 (0.00370)  Time: 0.715s, 2863.29/s  (0.716s, 2860.91/s)  avg LR: 2.183e-03  iter ratio: 0.0000  Data: 0.041 (0.040)
INFO:Train: 196 [ 600/625 ( 96%)]  Loss: 0.003626 (0.00370)  Time: 0.714s, 2870.14/s  (0.716s, 2860.10/s)  avg LR: 2.183e-03  iter ratio: 0.0000  Data: 0.040 (0.041)
INFO:Train: 196 [ 624/625 (100%)]  Loss: 0.003413 (0.00368)  Time: 0.674s, 3039.05/s  (0.715s, 2862.43/s)  avg LR: 2.183e-03  iter ratio: 0.0000  Data: 0.000 (0.040)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.299 (4.299)  Loss:  0.6992 (0.6992)  Acc@1: 83.7891 (83.7891)  Acc@5: 96.5332 (96.5332)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.6260 (1.0407)  Acc@1: 84.5519 (76.0180)  Acc@5: 96.8160 (93.0180)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-196.pth.tar', 76.0179998828125)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-194.pth.tar', 75.82200000976563)

INFO:196-epoch: remaining time 14.62 h
INFO:Train: 197 [   0/625 (  0%)]  Loss: 0.003803 (0.00380)  Time: 4.205s,  487.10/s  (4.205s,  487.10/s)  avg LR: 2.147e-03  iter ratio: 0.0000  Data: 3.515 (3.515)
INFO:Train: 197 [  50/625 (  8%)]  Loss: 0.003793 (0.00380)  Time: 0.700s, 2924.01/s  (0.778s, 2633.59/s)  avg LR: 2.147e-03  iter ratio: 0.0000  Data: 0.026 (0.099)
INFO:Train: 197 [ 100/625 ( 16%)]  Loss: 0.003596 (0.00373)  Time: 0.717s, 2855.42/s  (0.743s, 2757.60/s)  avg LR: 2.147e-03  iter ratio: 0.0000  Data: 0.042 (0.065)
INFO:Train: 197 [ 150/625 ( 24%)]  Loss: 0.003560 (0.00369)  Time: 0.715s, 2863.69/s  (0.734s, 2788.86/s)  avg LR: 2.147e-03  iter ratio: 0.0000  Data: 0.041 (0.058)
INFO:Train: 197 [ 200/625 ( 32%)]  Loss: 0.002935 (0.00354)  Time: 0.725s, 2826.17/s  (0.730s, 2804.69/s)  avg LR: 2.147e-03  iter ratio: 0.0000  Data: 0.046 (0.054)
INFO:Train: 197 [ 250/625 ( 40%)]  Loss: 0.003150 (0.00347)  Time: 0.717s, 2857.96/s  (0.728s, 2814.95/s)  avg LR: 2.147e-03  iter ratio: 0.0000  Data: 0.042 (0.052)
INFO:Train: 197 [ 300/625 ( 48%)]  Loss: 0.003637 (0.00350)  Time: 0.716s, 2860.50/s  (0.726s, 2821.85/s)  avg LR: 2.147e-03  iter ratio: 0.0000  Data: 0.041 (0.050)
INFO:Train: 197 [ 350/625 ( 56%)]  Loss: 0.004174 (0.00358)  Time: 0.711s, 2879.56/s  (0.724s, 2827.59/s)  avg LR: 2.147e-03  iter ratio: 0.0000  Data: 0.037 (0.049)
INFO:Train: 197 [ 400/625 ( 64%)]  Loss: 0.003968 (0.00362)  Time: 0.700s, 2923.93/s  (0.722s, 2837.91/s)  avg LR: 2.147e-03  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 197 [ 450/625 ( 72%)]  Loss: 0.004086 (0.00367)  Time: 0.701s, 2919.59/s  (0.719s, 2846.75/s)  avg LR: 2.147e-03  iter ratio: 0.0000  Data: 0.027 (0.044)
INFO:Train: 197 [ 500/625 ( 80%)]  Loss: 0.004382 (0.00373)  Time: 0.706s, 2901.92/s  (0.718s, 2853.55/s)  avg LR: 2.147e-03  iter ratio: 0.0000  Data: 0.031 (0.042)
INFO:Train: 197 [ 550/625 ( 88%)]  Loss: 0.003440 (0.00371)  Time: 0.702s, 2917.02/s  (0.716s, 2859.53/s)  avg LR: 2.147e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 197 [ 600/625 ( 96%)]  Loss: 0.003628 (0.00370)  Time: 0.704s, 2908.44/s  (0.715s, 2864.20/s)  avg LR: 2.147e-03  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 197 [ 624/625 (100%)]  Loss: 0.003680 (0.00370)  Time: 0.676s, 3031.55/s  (0.714s, 2866.84/s)  avg LR: 2.147e-03  iter ratio: 0.0000  Data: 0.000 (0.039)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.308 (4.308)  Loss:  0.7246 (0.7246)  Acc@1: 82.5684 (82.5684)  Acc@5: 96.1426 (96.1426)
INFO:Test: [  24/24]  Time: 0.081 (0.508)  Loss:  0.6040 (1.0561)  Acc@1: 85.3774 (75.6880)  Acc@5: 96.3443 (92.8760)
INFO:197-epoch: remaining time 14.48 h
INFO:Train: 198 [   0/625 (  0%)]  Loss: 0.004078 (0.00408)  Time: 4.269s,  479.79/s  (4.269s,  479.79/s)  avg LR: 2.110e-03  iter ratio: 0.0000  Data: 3.569 (3.569)
INFO:Train: 198 [  50/625 (  8%)]  Loss: 0.003682 (0.00388)  Time: 0.718s, 2853.03/s  (0.779s, 2627.92/s)  avg LR: 2.110e-03  iter ratio: 0.0000  Data: 0.039 (0.099)
INFO:Train: 198 [ 100/625 ( 16%)]  Loss: 0.003684 (0.00381)  Time: 0.707s, 2895.16/s  (0.746s, 2744.04/s)  avg LR: 2.110e-03  iter ratio: 0.0000  Data: 0.026 (0.066)
INFO:Train: 198 [ 150/625 ( 24%)]  Loss: 0.003085 (0.00363)  Time: 0.714s, 2867.50/s  (0.735s, 2786.54/s)  avg LR: 2.110e-03  iter ratio: 0.0000  Data: 0.040 (0.056)
INFO:Train: 198 [ 200/625 ( 32%)]  Loss: 0.004023 (0.00371)  Time: 0.714s, 2870.20/s  (0.730s, 2804.25/s)  avg LR: 2.110e-03  iter ratio: 0.0000  Data: 0.038 (0.052)
INFO:Train: 198 [ 250/625 ( 40%)]  Loss: 0.003626 (0.00370)  Time: 0.714s, 2868.85/s  (0.728s, 2814.82/s)  avg LR: 2.110e-03  iter ratio: 0.0000  Data: 0.039 (0.050)
INFO:Train: 198 [ 300/625 ( 48%)]  Loss: 0.003570 (0.00368)  Time: 0.714s, 2867.47/s  (0.726s, 2822.08/s)  avg LR: 2.110e-03  iter ratio: 0.0000  Data: 0.039 (0.049)
INFO:Train: 198 [ 350/625 ( 56%)]  Loss: 0.004672 (0.00380)  Time: 0.697s, 2940.30/s  (0.722s, 2835.57/s)  avg LR: 2.110e-03  iter ratio: 0.0000  Data: 0.022 (0.045)
INFO:Train: 198 [ 400/625 ( 64%)]  Loss: 0.003833 (0.00381)  Time: 0.700s, 2923.90/s  (0.720s, 2845.72/s)  avg LR: 2.110e-03  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 198 [ 450/625 ( 72%)]  Loss: 0.004345 (0.00386)  Time: 0.700s, 2926.96/s  (0.718s, 2853.48/s)  avg LR: 2.110e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 198 [ 500/625 ( 80%)]  Loss: 0.003757 (0.00385)  Time: 0.696s, 2941.50/s  (0.716s, 2859.07/s)  avg LR: 2.110e-03  iter ratio: 0.0000  Data: 0.022 (0.040)
INFO:Train: 198 [ 550/625 ( 88%)]  Loss: 0.003569 (0.00383)  Time: 0.701s, 2922.33/s  (0.715s, 2864.41/s)  avg LR: 2.110e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 198 [ 600/625 ( 96%)]  Loss: 0.003762 (0.00382)  Time: 0.703s, 2911.16/s  (0.714s, 2868.67/s)  avg LR: 2.110e-03  iter ratio: 0.0000  Data: 0.021 (0.037)
INFO:Train: 198 [ 624/625 (100%)]  Loss: 0.004059 (0.00384)  Time: 0.671s, 3050.00/s  (0.713s, 2870.98/s)  avg LR: 2.110e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.313 (4.313)  Loss:  0.7891 (0.7891)  Acc@1: 82.6660 (82.6660)  Acc@5: 95.1660 (95.1660)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.6362 (1.0996)  Acc@1: 84.4340 (75.4960)  Acc@5: 97.1698 (92.7400)
INFO:198-epoch: remaining time 14.33 h
INFO:Train: 199 [   0/625 (  0%)]  Loss: 0.003252 (0.00325)  Time: 4.234s,  483.65/s  (4.234s,  483.65/s)  avg LR: 2.074e-03  iter ratio: 0.0000  Data: 3.550 (3.550)
INFO:Train: 199 [  50/625 (  8%)]  Loss: 0.004202 (0.00373)  Time: 0.720s, 2843.94/s  (0.777s, 2635.80/s)  avg LR: 2.074e-03  iter ratio: 0.0000  Data: 0.046 (0.098)
INFO:Train: 199 [ 100/625 ( 16%)]  Loss: 0.003651 (0.00370)  Time: 0.701s, 2920.03/s  (0.744s, 2751.57/s)  avg LR: 2.074e-03  iter ratio: 0.0000  Data: 0.027 (0.068)
INFO:Train: 199 [ 150/625 ( 24%)]  Loss: 0.003921 (0.00376)  Time: 0.703s, 2914.26/s  (0.731s, 2803.37/s)  avg LR: 2.074e-03  iter ratio: 0.0000  Data: 0.028 (0.054)
INFO:Train: 199 [ 200/625 ( 32%)]  Loss: 0.002953 (0.00360)  Time: 0.701s, 2920.23/s  (0.724s, 2830.12/s)  avg LR: 2.074e-03  iter ratio: 0.0000  Data: 0.026 (0.047)
INFO:Train: 199 [ 250/625 ( 40%)]  Loss: 0.002778 (0.00346)  Time: 0.710s, 2885.38/s  (0.719s, 2846.80/s)  avg LR: 2.074e-03  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 199 [ 300/625 ( 48%)]  Loss: 0.003653 (0.00349)  Time: 0.710s, 2884.84/s  (0.717s, 2857.39/s)  avg LR: 2.074e-03  iter ratio: 0.0000  Data: 0.035 (0.040)
INFO:Train: 199 [ 350/625 ( 56%)]  Loss: 0.003704 (0.00351)  Time: 0.698s, 2932.14/s  (0.716s, 2859.59/s)  avg LR: 2.074e-03  iter ratio: 0.0000  Data: 0.022 (0.040)
INFO:Train: 199 [ 400/625 ( 64%)]  Loss: 0.003942 (0.00356)  Time: 0.700s, 2927.16/s  (0.714s, 2867.25/s)  avg LR: 2.074e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 199 [ 450/625 ( 72%)]  Loss: 0.003647 (0.00357)  Time: 0.700s, 2924.06/s  (0.713s, 2872.80/s)  avg LR: 2.074e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 199 [ 500/625 ( 80%)]  Loss: 0.004316 (0.00364)  Time: 0.717s, 2856.64/s  (0.712s, 2876.73/s)  avg LR: 2.074e-03  iter ratio: 0.0000  Data: 0.043 (0.036)
INFO:Train: 199 [ 550/625 ( 88%)]  Loss: 0.003621 (0.00364)  Time: 0.742s, 2758.99/s  (0.712s, 2874.48/s)  avg LR: 2.074e-03  iter ratio: 0.0000  Data: 0.044 (0.036)
INFO:Train: 199 [ 600/625 ( 96%)]  Loss: 0.003249 (0.00361)  Time: 0.720s, 2845.69/s  (0.713s, 2873.21/s)  avg LR: 2.074e-03  iter ratio: 0.0000  Data: 0.045 (0.037)
INFO:Train: 199 [ 624/625 (100%)]  Loss: 0.002802 (0.00355)  Time: 0.673s, 3041.69/s  (0.713s, 2873.55/s)  avg LR: 2.074e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.341 (4.341)  Loss:  0.7422 (0.7422)  Acc@1: 82.5195 (82.5195)  Acc@5: 95.9961 (95.9961)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.5898 (1.0550)  Acc@1: 85.9670 (75.6700)  Acc@5: 96.2264 (92.7520)
INFO:199-epoch: remaining time 14.19 h
INFO:Train: 200 [   0/625 (  0%)]  Loss: 0.003293 (0.00329)  Time: 4.456s,  459.56/s  (4.456s,  459.56/s)  avg LR: 2.037e-03  iter ratio: 0.0000  Data: 3.771 (3.771)
INFO:Train: 200 [  50/625 (  8%)]  Loss: 0.003558 (0.00343)  Time: 0.700s, 2925.95/s  (0.783s, 2615.04/s)  avg LR: 2.037e-03  iter ratio: 0.0000  Data: 0.025 (0.105)
INFO:Train: 200 [ 100/625 ( 16%)]  Loss: 0.003974 (0.00361)  Time: 0.717s, 2857.24/s  (0.746s, 2746.15/s)  avg LR: 2.037e-03  iter ratio: 0.0000  Data: 0.042 (0.068)
INFO:Train: 200 [ 150/625 ( 24%)]  Loss: 0.003086 (0.00348)  Time: 0.716s, 2859.60/s  (0.735s, 2784.93/s)  avg LR: 2.037e-03  iter ratio: 0.0000  Data: 0.039 (0.058)
INFO:Train: 200 [ 200/625 ( 32%)]  Loss: 0.003737 (0.00353)  Time: 0.717s, 2857.90/s  (0.730s, 2804.30/s)  avg LR: 2.037e-03  iter ratio: 0.0000  Data: 0.040 (0.053)
INFO:Train: 200 [ 250/625 ( 40%)]  Loss: 0.003669 (0.00355)  Time: 0.716s, 2860.22/s  (0.727s, 2815.88/s)  avg LR: 2.037e-03  iter ratio: 0.0000  Data: 0.041 (0.050)
INFO:Train: 200 [ 300/625 ( 48%)]  Loss: 0.003301 (0.00352)  Time: 0.713s, 2872.24/s  (0.725s, 2823.10/s)  avg LR: 2.037e-03  iter ratio: 0.0000  Data: 0.039 (0.048)
INFO:Train: 200 [ 350/625 ( 56%)]  Loss: 0.003775 (0.00355)  Time: 0.715s, 2865.88/s  (0.724s, 2828.11/s)  avg LR: 2.037e-03  iter ratio: 0.0000  Data: 0.039 (0.047)
INFO:Train: 200 [ 400/625 ( 64%)]  Loss: 0.003443 (0.00354)  Time: 0.704s, 2910.81/s  (0.722s, 2836.83/s)  avg LR: 2.037e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 200 [ 450/625 ( 72%)]  Loss: 0.003184 (0.00350)  Time: 0.716s, 2861.88/s  (0.720s, 2844.84/s)  avg LR: 2.037e-03  iter ratio: 0.0000  Data: 0.041 (0.043)
INFO:Train: 200 [ 500/625 ( 80%)]  Loss: 0.004242 (0.00357)  Time: 0.704s, 2907.16/s  (0.720s, 2846.13/s)  avg LR: 2.037e-03  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 200 [ 550/625 ( 88%)]  Loss: 0.003526 (0.00357)  Time: 0.702s, 2916.02/s  (0.718s, 2852.06/s)  avg LR: 2.037e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 200 [ 600/625 ( 96%)]  Loss: 0.003129 (0.00353)  Time: 0.704s, 2909.66/s  (0.717s, 2856.70/s)  avg LR: 2.037e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 200 [ 624/625 (100%)]  Loss: 0.003151 (0.00350)  Time: 0.673s, 3041.12/s  (0.716s, 2859.00/s)  avg LR: 2.037e-03  iter ratio: 0.0000  Data: 0.000 (0.039)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.336 (4.336)  Loss:  0.6816 (0.6816)  Acc@1: 84.1797 (84.1797)  Acc@5: 96.3867 (96.3867)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.6123 (1.0352)  Acc@1: 84.0802 (76.0360)  Acc@5: 96.3443 (92.9680)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-200.pth.tar', 76.03600006591797)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-196.pth.tar', 76.0179998828125)

INFO:200-epoch: remaining time 14.13 h
INFO:Train: 201 [   0/625 (  0%)]  Loss: 0.003473 (0.00347)  Time: 4.534s,  451.69/s  (4.534s,  451.69/s)  avg LR: 2.002e-03  iter ratio: 0.0000  Data: 3.837 (3.837)
INFO:Train: 201 [  50/625 (  8%)]  Loss: 0.002841 (0.00316)  Time: 0.700s, 2925.77/s  (0.779s, 2629.23/s)  avg LR: 2.002e-03  iter ratio: 0.0000  Data: 0.026 (0.101)
INFO:Train: 201 [ 100/625 ( 16%)]  Loss: 0.003210 (0.00317)  Time: 0.698s, 2936.08/s  (0.741s, 2762.57/s)  avg LR: 2.002e-03  iter ratio: 0.0000  Data: 0.023 (0.065)
INFO:Train: 201 [ 150/625 ( 24%)]  Loss: 0.004025 (0.00339)  Time: 0.703s, 2914.21/s  (0.728s, 2811.42/s)  avg LR: 2.002e-03  iter ratio: 0.0000  Data: 0.028 (0.052)
INFO:Train: 201 [ 200/625 ( 32%)]  Loss: 0.003376 (0.00339)  Time: 0.700s, 2924.37/s  (0.722s, 2837.68/s)  avg LR: 2.002e-03  iter ratio: 0.0000  Data: 0.025 (0.045)
INFO:Train: 201 [ 250/625 ( 40%)]  Loss: 0.004059 (0.00350)  Time: 0.701s, 2920.86/s  (0.718s, 2852.82/s)  avg LR: 2.002e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 201 [ 300/625 ( 48%)]  Loss: 0.003402 (0.00348)  Time: 0.701s, 2921.32/s  (0.715s, 2863.63/s)  avg LR: 2.002e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 201 [ 350/625 ( 56%)]  Loss: 0.002988 (0.00342)  Time: 0.703s, 2914.42/s  (0.713s, 2871.29/s)  avg LR: 2.002e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 201 [ 400/625 ( 64%)]  Loss: 0.004220 (0.00351)  Time: 0.711s, 2880.73/s  (0.712s, 2876.45/s)  avg LR: 2.002e-03  iter ratio: 0.0000  Data: 0.032 (0.036)
INFO:Train: 201 [ 450/625 ( 72%)]  Loss: 0.003503 (0.00351)  Time: 0.723s, 2830.71/s  (0.711s, 2879.71/s)  avg LR: 2.002e-03  iter ratio: 0.0000  Data: 0.048 (0.035)
INFO:Train: 201 [ 500/625 ( 80%)]  Loss: 0.003395 (0.00350)  Time: 0.707s, 2898.71/s  (0.711s, 2880.35/s)  avg LR: 2.002e-03  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 201 [ 550/625 ( 88%)]  Loss: 0.004069 (0.00355)  Time: 0.700s, 2926.17/s  (0.710s, 2882.89/s)  avg LR: 2.002e-03  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 201 [ 600/625 ( 96%)]  Loss: 0.003912 (0.00357)  Time: 0.700s, 2924.52/s  (0.711s, 2882.06/s)  avg LR: 2.002e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 201 [ 624/625 (100%)]  Loss: 0.004205 (0.00362)  Time: 0.676s, 3029.84/s  (0.710s, 2883.78/s)  avg LR: 2.002e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.339 (4.339)  Loss:  0.6621 (0.6621)  Acc@1: 84.0332 (84.0332)  Acc@5: 96.7773 (96.7773)
INFO:Test: [  24/24]  Time: 0.080 (0.510)  Loss:  0.5586 (1.0154)  Acc@1: 86.7924 (76.4240)  Acc@5: 97.0519 (93.1800)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-201.pth.tar', 76.42399995117188)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-200.pth.tar', 76.03600006591797)

INFO:201-epoch: remaining time 13.89 h
INFO:Train: 202 [   0/625 (  0%)]  Loss: 0.003130 (0.00313)  Time: 4.102s,  499.22/s  (4.102s,  499.22/s)  avg LR: 1.966e-03  iter ratio: 0.0000  Data: 3.404 (3.404)
INFO:Train: 202 [  50/625 (  8%)]  Loss: 0.003396 (0.00326)  Time: 0.702s, 2919.33/s  (0.773s, 2649.98/s)  avg LR: 1.966e-03  iter ratio: 0.0000  Data: 0.026 (0.093)
INFO:Train: 202 [ 100/625 ( 16%)]  Loss: 0.004232 (0.00359)  Time: 0.702s, 2917.38/s  (0.745s, 2749.10/s)  avg LR: 1.966e-03  iter ratio: 0.0000  Data: 0.022 (0.064)
INFO:Train: 202 [ 150/625 ( 24%)]  Loss: 0.003512 (0.00357)  Time: 0.702s, 2917.86/s  (0.731s, 2799.93/s)  avg LR: 1.966e-03  iter ratio: 0.0000  Data: 0.026 (0.052)
INFO:Train: 202 [ 200/625 ( 32%)]  Loss: 0.003877 (0.00363)  Time: 0.698s, 2933.01/s  (0.725s, 2825.06/s)  avg LR: 1.966e-03  iter ratio: 0.0000  Data: 0.022 (0.045)
INFO:Train: 202 [ 250/625 ( 40%)]  Loss: 0.003723 (0.00364)  Time: 0.702s, 2918.77/s  (0.722s, 2837.47/s)  avg LR: 1.966e-03  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 202 [ 300/625 ( 48%)]  Loss: 0.003894 (0.00368)  Time: 0.701s, 2920.88/s  (0.719s, 2848.90/s)  avg LR: 1.966e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 202 [ 350/625 ( 56%)]  Loss: 0.003213 (0.00362)  Time: 0.723s, 2834.47/s  (0.717s, 2855.59/s)  avg LR: 1.966e-03  iter ratio: 0.0000  Data: 0.045 (0.039)
INFO:Train: 202 [ 400/625 ( 64%)]  Loss: 0.003339 (0.00359)  Time: 0.706s, 2900.86/s  (0.715s, 2862.69/s)  avg LR: 1.966e-03  iter ratio: 0.0000  Data: 0.029 (0.037)
INFO:Train: 202 [ 450/625 ( 72%)]  Loss: 0.003934 (0.00362)  Time: 0.700s, 2926.48/s  (0.714s, 2867.36/s)  avg LR: 1.966e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 202 [ 500/625 ( 80%)]  Loss: 0.004014 (0.00366)  Time: 0.701s, 2920.63/s  (0.713s, 2871.39/s)  avg LR: 1.966e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 202 [ 550/625 ( 88%)]  Loss: 0.003385 (0.00364)  Time: 0.713s, 2871.20/s  (0.712s, 2874.67/s)  avg LR: 1.966e-03  iter ratio: 0.0000  Data: 0.039 (0.035)
INFO:Train: 202 [ 600/625 ( 96%)]  Loss: 0.004092 (0.00367)  Time: 0.707s, 2895.05/s  (0.713s, 2873.38/s)  avg LR: 1.966e-03  iter ratio: 0.0000  Data: 0.033 (0.035)
INFO:Train: 202 [ 624/625 (100%)]  Loss: 0.004254 (0.00371)  Time: 0.672s, 3046.71/s  (0.712s, 2874.59/s)  avg LR: 1.966e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.311 (4.311)  Loss:  0.7134 (0.7134)  Acc@1: 82.5684 (82.5684)  Acc@5: 96.1914 (96.1914)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.5869 (1.0367)  Acc@1: 85.2594 (76.0360)  Acc@5: 96.9340 (93.0560)
INFO:202-epoch: remaining time 13.79 h
INFO:Train: 203 [   0/625 (  0%)]  Loss: 0.003587 (0.00359)  Time: 4.279s,  478.57/s  (4.279s,  478.57/s)  avg LR: 1.930e-03  iter ratio: 0.0000  Data: 3.592 (3.592)
INFO:Train: 203 [  50/625 (  8%)]  Loss: 0.003224 (0.00341)  Time: 0.700s, 2925.22/s  (0.781s, 2621.59/s)  avg LR: 1.930e-03  iter ratio: 0.0000  Data: 0.025 (0.101)
INFO:Train: 203 [ 100/625 ( 16%)]  Loss: 0.003103 (0.00330)  Time: 0.710s, 2885.49/s  (0.743s, 2755.70/s)  avg LR: 1.930e-03  iter ratio: 0.0000  Data: 0.035 (0.064)
INFO:Train: 203 [ 150/625 ( 24%)]  Loss: 0.003447 (0.00334)  Time: 0.717s, 2856.73/s  (0.734s, 2789.48/s)  avg LR: 1.930e-03  iter ratio: 0.0000  Data: 0.041 (0.056)
INFO:Train: 203 [ 200/625 ( 32%)]  Loss: 0.003963 (0.00346)  Time: 0.701s, 2923.06/s  (0.729s, 2810.99/s)  avg LR: 1.930e-03  iter ratio: 0.0000  Data: 0.023 (0.050)
INFO:Train: 203 [ 250/625 ( 40%)]  Loss: 0.003981 (0.00355)  Time: 0.717s, 2856.31/s  (0.725s, 2824.42/s)  avg LR: 1.930e-03  iter ratio: 0.0000  Data: 0.041 (0.047)
INFO:Train: 203 [ 300/625 ( 48%)]  Loss: 0.003728 (0.00358)  Time: 0.717s, 2857.56/s  (0.724s, 2829.54/s)  avg LR: 1.930e-03  iter ratio: 0.0000  Data: 0.042 (0.046)
INFO:Train: 203 [ 350/625 ( 56%)]  Loss: 0.003884 (0.00361)  Time: 0.716s, 2862.24/s  (0.723s, 2834.09/s)  avg LR: 1.930e-03  iter ratio: 0.0000  Data: 0.040 (0.045)
INFO:Train: 203 [ 400/625 ( 64%)]  Loss: 0.003968 (0.00365)  Time: 0.707s, 2895.69/s  (0.721s, 2840.58/s)  avg LR: 1.930e-03  iter ratio: 0.0000  Data: 0.026 (0.043)
INFO:Train: 203 [ 450/625 ( 72%)]  Loss: 0.003115 (0.00360)  Time: 0.705s, 2906.81/s  (0.719s, 2847.01/s)  avg LR: 1.930e-03  iter ratio: 0.0000  Data: 0.024 (0.041)
INFO:Train: 203 [ 500/625 ( 80%)]  Loss: 0.003699 (0.00361)  Time: 0.703s, 2914.08/s  (0.718s, 2852.35/s)  avg LR: 1.930e-03  iter ratio: 0.0000  Data: 0.022 (0.040)
INFO:Train: 203 [ 550/625 ( 88%)]  Loss: 0.003343 (0.00359)  Time: 0.706s, 2898.85/s  (0.717s, 2856.64/s)  avg LR: 1.930e-03  iter ratio: 0.0000  Data: 0.022 (0.038)
INFO:Train: 203 [ 600/625 ( 96%)]  Loss: 0.004412 (0.00365)  Time: 0.706s, 2902.65/s  (0.716s, 2859.99/s)  avg LR: 1.930e-03  iter ratio: 0.0000  Data: 0.024 (0.037)
INFO:Train: 203 [ 624/625 (100%)]  Loss: 0.003590 (0.00365)  Time: 0.679s, 3017.95/s  (0.716s, 2861.74/s)  avg LR: 1.930e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.311 (4.311)  Loss:  0.6709 (0.6709)  Acc@1: 83.7402 (83.7402)  Acc@5: 96.7773 (96.7773)
INFO:Test: [  24/24]  Time: 0.080 (0.505)  Loss:  0.5903 (1.0299)  Acc@1: 84.9057 (76.2160)  Acc@5: 96.5802 (93.0600)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-201.pth.tar', 76.42399995117188)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-203.pth.tar', 76.2160000366211)

INFO:203-epoch: remaining time 13.76 h
INFO:Train: 204 [   0/625 (  0%)]  Loss: 0.003824 (0.00382)  Time: 4.252s,  481.61/s  (4.252s,  481.61/s)  avg LR: 1.895e-03  iter ratio: 0.0000  Data: 3.558 (3.558)
INFO:Train: 204 [  50/625 (  8%)]  Loss: 0.003295 (0.00356)  Time: 0.705s, 2906.46/s  (0.775s, 2642.15/s)  avg LR: 1.895e-03  iter ratio: 0.0000  Data: 0.029 (0.096)
INFO:Train: 204 [ 100/625 ( 16%)]  Loss: 0.003430 (0.00352)  Time: 0.701s, 2923.28/s  (0.740s, 2767.63/s)  avg LR: 1.895e-03  iter ratio: 0.0000  Data: 0.021 (0.061)
INFO:Train: 204 [ 150/625 ( 24%)]  Loss: 0.002823 (0.00334)  Time: 0.716s, 2861.65/s  (0.730s, 2805.06/s)  avg LR: 1.895e-03  iter ratio: 0.0000  Data: 0.041 (0.051)
INFO:Train: 204 [ 200/625 ( 32%)]  Loss: 0.003633 (0.00340)  Time: 0.715s, 2863.83/s  (0.726s, 2820.43/s)  avg LR: 1.895e-03  iter ratio: 0.0000  Data: 0.039 (0.047)
INFO:Train: 204 [ 250/625 ( 40%)]  Loss: 0.003359 (0.00339)  Time: 0.718s, 2852.25/s  (0.724s, 2830.17/s)  avg LR: 1.895e-03  iter ratio: 0.0000  Data: 0.043 (0.044)
INFO:Train: 204 [ 300/625 ( 48%)]  Loss: 0.003791 (0.00345)  Time: 0.710s, 2885.39/s  (0.722s, 2836.60/s)  avg LR: 1.895e-03  iter ratio: 0.0000  Data: 0.033 (0.043)
INFO:Train: 204 [ 350/625 ( 56%)]  Loss: 0.003490 (0.00346)  Time: 0.713s, 2871.47/s  (0.721s, 2841.49/s)  avg LR: 1.895e-03  iter ratio: 0.0000  Data: 0.037 (0.041)
INFO:Train: 204 [ 400/625 ( 64%)]  Loss: 0.003633 (0.00348)  Time: 0.710s, 2882.84/s  (0.719s, 2848.27/s)  avg LR: 1.895e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 204 [ 450/625 ( 72%)]  Loss: 0.003708 (0.00350)  Time: 0.709s, 2887.79/s  (0.718s, 2852.06/s)  avg LR: 1.895e-03  iter ratio: 0.0000  Data: 0.021 (0.038)
INFO:Train: 204 [ 500/625 ( 80%)]  Loss: 0.003389 (0.00349)  Time: 0.711s, 2881.04/s  (0.717s, 2854.81/s)  avg LR: 1.895e-03  iter ratio: 0.0000  Data: 0.024 (0.037)
INFO:Train: 204 [ 550/625 ( 88%)]  Loss: 0.003858 (0.00352)  Time: 0.708s, 2894.65/s  (0.717s, 2856.91/s)  avg LR: 1.895e-03  iter ratio: 0.0000  Data: 0.029 (0.037)
INFO:Train: 204 [ 600/625 ( 96%)]  Loss: 0.003316 (0.00350)  Time: 0.707s, 2896.95/s  (0.716s, 2859.55/s)  avg LR: 1.895e-03  iter ratio: 0.0000  Data: 0.031 (0.036)
INFO:Train: 204 [ 624/625 (100%)]  Loss: 0.003149 (0.00348)  Time: 0.675s, 3032.20/s  (0.716s, 2861.31/s)  avg LR: 1.895e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.308 (4.308)  Loss:  0.6836 (0.6836)  Acc@1: 83.3008 (83.3008)  Acc@5: 96.4355 (96.4355)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.6572 (1.0416)  Acc@1: 83.3726 (75.6200)  Acc@5: 95.9906 (92.9520)
INFO:204-epoch: remaining time 13.60 h
INFO:Train: 205 [   0/625 (  0%)]  Loss: 0.003662 (0.00366)  Time: 4.549s,  450.22/s  (4.549s,  450.22/s)  avg LR: 1.860e-03  iter ratio: 0.0000  Data: 3.857 (3.857)
INFO:Train: 205 [  50/625 (  8%)]  Loss: 0.004079 (0.00387)  Time: 0.702s, 2918.60/s  (0.779s, 2630.11/s)  avg LR: 1.860e-03  iter ratio: 0.0000  Data: 0.026 (0.102)
INFO:Train: 205 [ 100/625 ( 16%)]  Loss: 0.003114 (0.00362)  Time: 0.717s, 2856.21/s  (0.742s, 2761.43/s)  avg LR: 1.860e-03  iter ratio: 0.0000  Data: 0.042 (0.065)
INFO:Train: 205 [ 150/625 ( 24%)]  Loss: 0.003833 (0.00367)  Time: 0.703s, 2911.35/s  (0.730s, 2805.62/s)  avg LR: 1.860e-03  iter ratio: 0.0000  Data: 0.028 (0.054)
INFO:Train: 205 [ 200/625 ( 32%)]  Loss: 0.002991 (0.00354)  Time: 0.703s, 2915.03/s  (0.723s, 2831.13/s)  avg LR: 1.860e-03  iter ratio: 0.0000  Data: 0.028 (0.048)
INFO:Train: 205 [ 250/625 ( 40%)]  Loss: 0.003904 (0.00360)  Time: 0.707s, 2897.61/s  (0.720s, 2844.84/s)  avg LR: 1.860e-03  iter ratio: 0.0000  Data: 0.032 (0.044)
INFO:Train: 205 [ 300/625 ( 48%)]  Loss: 0.003447 (0.00358)  Time: 0.702s, 2917.20/s  (0.717s, 2855.61/s)  avg LR: 1.860e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 205 [ 350/625 ( 56%)]  Loss: 0.003330 (0.00355)  Time: 0.701s, 2921.60/s  (0.715s, 2863.36/s)  avg LR: 1.860e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 205 [ 400/625 ( 64%)]  Loss: 0.003511 (0.00354)  Time: 0.699s, 2931.45/s  (0.714s, 2868.78/s)  avg LR: 1.860e-03  iter ratio: 0.0000  Data: 0.023 (0.038)
INFO:Train: 205 [ 450/625 ( 72%)]  Loss: 0.003324 (0.00352)  Time: 0.700s, 2926.99/s  (0.713s, 2873.55/s)  avg LR: 1.860e-03  iter ratio: 0.0000  Data: 0.022 (0.037)
INFO:Train: 205 [ 500/625 ( 80%)]  Loss: 0.003736 (0.00354)  Time: 0.714s, 2869.23/s  (0.713s, 2872.29/s)  avg LR: 1.860e-03  iter ratio: 0.0000  Data: 0.039 (0.037)
INFO:Train: 205 [ 550/625 ( 88%)]  Loss: 0.003625 (0.00355)  Time: 0.712s, 2875.34/s  (0.713s, 2871.02/s)  avg LR: 1.860e-03  iter ratio: 0.0000  Data: 0.037 (0.038)
INFO:Train: 205 [ 600/625 ( 96%)]  Loss: 0.003232 (0.00352)  Time: 0.703s, 2912.70/s  (0.713s, 2873.46/s)  avg LR: 1.860e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 205 [ 624/625 (100%)]  Loss: 0.003737 (0.00354)  Time: 0.674s, 3040.51/s  (0.712s, 2875.56/s)  avg LR: 1.860e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.310 (4.310)  Loss:  0.6855 (0.6855)  Acc@1: 84.7168 (84.7168)  Acc@5: 96.2402 (96.2402)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.6470 (1.0261)  Acc@1: 84.6698 (76.4580)  Acc@5: 96.3443 (93.2860)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-205.pth.tar', 76.45799993408203)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-201.pth.tar', 76.42399995117188)

INFO:205-epoch: remaining time 13.43 h
INFO:Train: 206 [   0/625 (  0%)]  Loss: 0.003694 (0.00369)  Time: 4.319s,  474.14/s  (4.319s,  474.14/s)  avg LR: 1.825e-03  iter ratio: 0.0000  Data: 3.624 (3.624)
INFO:Train: 206 [  50/625 (  8%)]  Loss: 0.004278 (0.00399)  Time: 0.700s, 2924.20/s  (0.782s, 2617.85/s)  avg LR: 1.825e-03  iter ratio: 0.0000  Data: 0.021 (0.099)
INFO:Train: 206 [ 100/625 ( 16%)]  Loss: 0.003256 (0.00374)  Time: 0.716s, 2859.92/s  (0.749s, 2734.34/s)  avg LR: 1.825e-03  iter ratio: 0.0000  Data: 0.040 (0.068)
INFO:Train: 206 [ 150/625 ( 24%)]  Loss: 0.003694 (0.00373)  Time: 0.718s, 2852.98/s  (0.738s, 2774.81/s)  avg LR: 1.825e-03  iter ratio: 0.0000  Data: 0.043 (0.058)
INFO:Train: 206 [ 200/625 ( 32%)]  Loss: 0.003768 (0.00374)  Time: 0.699s, 2931.76/s  (0.733s, 2795.87/s)  avg LR: 1.825e-03  iter ratio: 0.0000  Data: 0.023 (0.053)
INFO:Train: 206 [ 250/625 ( 40%)]  Loss: 0.003673 (0.00373)  Time: 0.699s, 2930.01/s  (0.727s, 2818.80/s)  avg LR: 1.825e-03  iter ratio: 0.0000  Data: 0.023 (0.048)
INFO:Train: 206 [ 300/625 ( 48%)]  Loss: 0.003660 (0.00372)  Time: 0.706s, 2899.96/s  (0.723s, 2831.72/s)  avg LR: 1.825e-03  iter ratio: 0.0000  Data: 0.032 (0.044)
INFO:Train: 206 [ 350/625 ( 56%)]  Loss: 0.003904 (0.00374)  Time: 0.699s, 2931.38/s  (0.720s, 2843.01/s)  avg LR: 1.825e-03  iter ratio: 0.0000  Data: 0.023 (0.042)
INFO:Train: 206 [ 400/625 ( 64%)]  Loss: 0.003471 (0.00371)  Time: 0.702s, 2917.72/s  (0.718s, 2851.10/s)  avg LR: 1.825e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 206 [ 450/625 ( 72%)]  Loss: 0.003736 (0.00371)  Time: 0.699s, 2929.50/s  (0.717s, 2857.74/s)  avg LR: 1.825e-03  iter ratio: 0.0000  Data: 0.023 (0.038)
INFO:Train: 206 [ 500/625 ( 80%)]  Loss: 0.003746 (0.00372)  Time: 0.701s, 2922.89/s  (0.715s, 2862.67/s)  avg LR: 1.825e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 206 [ 550/625 ( 88%)]  Loss: 0.004030 (0.00374)  Time: 0.716s, 2859.04/s  (0.715s, 2864.72/s)  avg LR: 1.825e-03  iter ratio: 0.0000  Data: 0.042 (0.036)
INFO:Train: 206 [ 600/625 ( 96%)]  Loss: 0.003611 (0.00373)  Time: 0.720s, 2844.32/s  (0.715s, 2864.02/s)  avg LR: 1.825e-03  iter ratio: 0.0000  Data: 0.043 (0.037)
INFO:Train: 206 [ 624/625 (100%)]  Loss: 0.003150 (0.00369)  Time: 0.678s, 3022.28/s  (0.715s, 2864.56/s)  avg LR: 1.825e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.317 (4.317)  Loss:  0.6611 (0.6611)  Acc@1: 84.4238 (84.4238)  Acc@5: 96.8262 (96.8262)
INFO:Test: [  24/24]  Time: 0.080 (0.502)  Loss:  0.5410 (1.0052)  Acc@1: 87.2641 (76.8060)  Acc@5: 97.1698 (93.4280)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-206.pth.tar', 76.80599989746094)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-205.pth.tar', 76.45799993408203)

INFO:206-epoch: remaining time 13.36 h
INFO:Train: 207 [   0/625 (  0%)]  Loss: 0.003355 (0.00336)  Time: 4.213s,  486.16/s  (4.213s,  486.16/s)  avg LR: 1.791e-03  iter ratio: 0.0000  Data: 3.520 (3.520)
INFO:Train: 207 [  50/625 (  8%)]  Loss: 0.003516 (0.00344)  Time: 0.703s, 2912.08/s  (0.772s, 2653.51/s)  avg LR: 1.791e-03  iter ratio: 0.0000  Data: 0.028 (0.095)
INFO:Train: 207 [ 100/625 ( 16%)]  Loss: 0.003426 (0.00343)  Time: 0.707s, 2897.27/s  (0.738s, 2775.34/s)  avg LR: 1.791e-03  iter ratio: 0.0000  Data: 0.027 (0.060)
INFO:Train: 207 [ 150/625 ( 24%)]  Loss: 0.003911 (0.00355)  Time: 0.725s, 2824.21/s  (0.730s, 2804.19/s)  avg LR: 1.791e-03  iter ratio: 0.0000  Data: 0.050 (0.053)
INFO:Train: 207 [ 200/625 ( 32%)]  Loss: 0.004299 (0.00370)  Time: 0.720s, 2846.30/s  (0.727s, 2816.33/s)  avg LR: 1.791e-03  iter ratio: 0.0000  Data: 0.045 (0.050)
INFO:Train: 207 [ 250/625 ( 40%)]  Loss: 0.004070 (0.00376)  Time: 0.721s, 2840.80/s  (0.725s, 2823.62/s)  avg LR: 1.791e-03  iter ratio: 0.0000  Data: 0.046 (0.048)
INFO:Train: 207 [ 300/625 ( 48%)]  Loss: 0.002957 (0.00365)  Time: 0.724s, 2827.89/s  (0.724s, 2828.75/s)  avg LR: 1.791e-03  iter ratio: 0.0000  Data: 0.050 (0.047)
INFO:Train: 207 [ 350/625 ( 56%)]  Loss: 0.003244 (0.00360)  Time: 0.718s, 2851.60/s  (0.723s, 2832.02/s)  avg LR: 1.791e-03  iter ratio: 0.0000  Data: 0.044 (0.046)
INFO:Train: 207 [ 400/625 ( 64%)]  Loss: 0.003789 (0.00362)  Time: 0.699s, 2929.98/s  (0.721s, 2838.65/s)  avg LR: 1.791e-03  iter ratio: 0.0000  Data: 0.024 (0.044)
INFO:Train: 207 [ 450/625 ( 72%)]  Loss: 0.003166 (0.00357)  Time: 0.700s, 2925.25/s  (0.720s, 2845.89/s)  avg LR: 1.791e-03  iter ratio: 0.0000  Data: 0.023 (0.042)
INFO:Train: 207 [ 500/625 ( 80%)]  Loss: 0.004343 (0.00364)  Time: 0.701s, 2919.64/s  (0.718s, 2851.53/s)  avg LR: 1.791e-03  iter ratio: 0.0000  Data: 0.023 (0.040)
INFO:Train: 207 [ 550/625 ( 88%)]  Loss: 0.003141 (0.00360)  Time: 0.701s, 2919.55/s  (0.717s, 2856.06/s)  avg LR: 1.791e-03  iter ratio: 0.0000  Data: 0.023 (0.039)
INFO:Train: 207 [ 600/625 ( 96%)]  Loss: 0.003639 (0.00360)  Time: 0.701s, 2919.56/s  (0.716s, 2860.04/s)  avg LR: 1.791e-03  iter ratio: 0.0000  Data: 0.022 (0.037)
INFO:Train: 207 [ 624/625 (100%)]  Loss: 0.002706 (0.00354)  Time: 0.675s, 3034.01/s  (0.716s, 2862.20/s)  avg LR: 1.791e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.332 (4.332)  Loss:  0.6699 (0.6699)  Acc@1: 84.5215 (84.5215)  Acc@5: 96.5332 (96.5332)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.6167 (1.0070)  Acc@1: 84.7877 (76.6440)  Acc@5: 96.8160 (93.2600)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-206.pth.tar', 76.80599989746094)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-207.pth.tar', 76.64399998535156)

INFO:207-epoch: remaining time 13.22 h
INFO:Train: 208 [   0/625 (  0%)]  Loss: 0.003521 (0.00352)  Time: 4.282s,  478.33/s  (4.282s,  478.33/s)  avg LR: 1.756e-03  iter ratio: 0.0000  Data: 3.583 (3.583)
INFO:Train: 208 [  50/625 (  8%)]  Loss: 0.003887 (0.00370)  Time: 0.706s, 2902.90/s  (0.773s, 2648.97/s)  avg LR: 1.756e-03  iter ratio: 0.0000  Data: 0.030 (0.097)
INFO:Train: 208 [ 100/625 ( 16%)]  Loss: 0.003549 (0.00365)  Time: 0.698s, 2936.15/s  (0.738s, 2774.71/s)  avg LR: 1.756e-03  iter ratio: 0.0000  Data: 0.022 (0.062)
INFO:Train: 208 [ 150/625 ( 24%)]  Loss: 0.004094 (0.00376)  Time: 0.702s, 2918.89/s  (0.729s, 2808.24/s)  avg LR: 1.756e-03  iter ratio: 0.0000  Data: 0.027 (0.053)
INFO:Train: 208 [ 200/625 ( 32%)]  Loss: 0.003165 (0.00364)  Time: 0.706s, 2901.15/s  (0.723s, 2833.84/s)  avg LR: 1.756e-03  iter ratio: 0.0000  Data: 0.031 (0.047)
INFO:Train: 208 [ 250/625 ( 40%)]  Loss: 0.004070 (0.00371)  Time: 0.718s, 2853.54/s  (0.719s, 2848.45/s)  avg LR: 1.756e-03  iter ratio: 0.0000  Data: 0.044 (0.043)
INFO:Train: 208 [ 300/625 ( 48%)]  Loss: 0.003564 (0.00369)  Time: 0.704s, 2910.36/s  (0.718s, 2850.52/s)  avg LR: 1.756e-03  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 208 [ 350/625 ( 56%)]  Loss: 0.003762 (0.00370)  Time: 0.701s, 2922.94/s  (0.716s, 2859.60/s)  avg LR: 1.756e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 208 [ 400/625 ( 64%)]  Loss: 0.003119 (0.00364)  Time: 0.703s, 2914.15/s  (0.714s, 2866.55/s)  avg LR: 1.756e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 208 [ 450/625 ( 72%)]  Loss: 0.003399 (0.00361)  Time: 0.701s, 2922.62/s  (0.713s, 2871.92/s)  avg LR: 1.756e-03  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 208 [ 500/625 ( 80%)]  Loss: 0.002956 (0.00355)  Time: 0.708s, 2891.41/s  (0.712s, 2875.97/s)  avg LR: 1.756e-03  iter ratio: 0.0000  Data: 0.034 (0.036)
INFO:Train: 208 [ 550/625 ( 88%)]  Loss: 0.003894 (0.00358)  Time: 0.709s, 2886.84/s  (0.711s, 2879.50/s)  avg LR: 1.756e-03  iter ratio: 0.0000  Data: 0.018 (0.035)
INFO:Train: 208 [ 600/625 ( 96%)]  Loss: 0.003592 (0.00358)  Time: 0.700s, 2926.09/s  (0.710s, 2882.75/s)  avg LR: 1.756e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 208 [ 624/625 (100%)]  Loss: 0.004024 (0.00361)  Time: 0.676s, 3027.55/s  (0.710s, 2884.20/s)  avg LR: 1.756e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.327 (4.327)  Loss:  0.6641 (0.6641)  Acc@1: 84.9609 (84.9609)  Acc@5: 97.0215 (97.0215)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.5898 (0.9868)  Acc@1: 86.0849 (77.2000)  Acc@5: 96.6981 (93.6640)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-208.pth.tar', 77.20000003173828)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-206.pth.tar', 76.80599989746094)

INFO:208-epoch: remaining time 12.99 h
INFO:Train: 209 [   0/625 (  0%)]  Loss: 0.003197 (0.00320)  Time: 4.164s,  491.79/s  (4.164s,  491.79/s)  avg LR: 1.722e-03  iter ratio: 0.0000  Data: 3.481 (3.481)
INFO:Train: 209 [  50/625 (  8%)]  Loss: 0.003230 (0.00321)  Time: 0.721s, 2839.63/s  (0.786s, 2607.01/s)  avg LR: 1.722e-03  iter ratio: 0.0000  Data: 0.036 (0.102)
INFO:Train: 209 [ 100/625 ( 16%)]  Loss: 0.003481 (0.00330)  Time: 0.706s, 2899.96/s  (0.752s, 2723.21/s)  avg LR: 1.722e-03  iter ratio: 0.0000  Data: 0.028 (0.066)
INFO:Train: 209 [ 150/625 ( 24%)]  Loss: 0.003088 (0.00325)  Time: 0.707s, 2894.98/s  (0.740s, 2768.40/s)  avg LR: 1.722e-03  iter ratio: 0.0000  Data: 0.023 (0.053)
INFO:Train: 209 [ 200/625 ( 32%)]  Loss: 0.004581 (0.00352)  Time: 0.710s, 2885.16/s  (0.734s, 2789.23/s)  avg LR: 1.722e-03  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 209 [ 250/625 ( 40%)]  Loss: 0.004109 (0.00361)  Time: 0.707s, 2896.73/s  (0.730s, 2803.72/s)  avg LR: 1.722e-03  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 209 [ 300/625 ( 48%)]  Loss: 0.003913 (0.00366)  Time: 0.714s, 2867.27/s  (0.728s, 2813.06/s)  avg LR: 1.722e-03  iter ratio: 0.0000  Data: 0.024 (0.040)
INFO:Train: 209 [ 350/625 ( 56%)]  Loss: 0.004439 (0.00375)  Time: 0.712s, 2876.37/s  (0.726s, 2819.01/s)  avg LR: 1.722e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 209 [ 400/625 ( 64%)]  Loss: 0.003684 (0.00375)  Time: 0.702s, 2915.41/s  (0.725s, 2825.73/s)  avg LR: 1.722e-03  iter ratio: 0.0000  Data: 0.022 (0.037)
INFO:Train: 209 [ 450/625 ( 72%)]  Loss: 0.004025 (0.00377)  Time: 0.704s, 2910.23/s  (0.723s, 2834.32/s)  avg LR: 1.722e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 209 [ 500/625 ( 80%)]  Loss: 0.003520 (0.00375)  Time: 0.710s, 2884.31/s  (0.721s, 2841.64/s)  avg LR: 1.722e-03  iter ratio: 0.0000  Data: 0.023 (0.035)
INFO:Train: 209 [ 550/625 ( 88%)]  Loss: 0.003566 (0.00374)  Time: 0.725s, 2824.41/s  (0.720s, 2843.67/s)  avg LR: 1.722e-03  iter ratio: 0.0000  Data: 0.042 (0.035)
INFO:Train: 209 [ 600/625 ( 96%)]  Loss: 0.003903 (0.00375)  Time: 0.715s, 2863.91/s  (0.720s, 2844.50/s)  avg LR: 1.722e-03  iter ratio: 0.0000  Data: 0.032 (0.035)
INFO:Train: 209 [ 624/625 (100%)]  Loss: 0.003507 (0.00373)  Time: 0.677s, 3024.88/s  (0.720s, 2845.69/s)  avg LR: 1.722e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.378 (4.378)  Loss:  0.6587 (0.6587)  Acc@1: 84.6680 (84.6680)  Acc@5: 96.6797 (96.6797)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.5581 (0.9848)  Acc@1: 86.2028 (77.2660)  Acc@5: 96.8160 (93.7120)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-209.pth.tar', 77.26599995361327)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-208.pth.tar', 77.20000003173828)

INFO:209-epoch: remaining time 13.03 h
INFO:Train: 210 [   0/625 (  0%)]  Loss: 0.002708 (0.00271)  Time: 4.276s,  478.91/s  (4.276s,  478.91/s)  avg LR: 1.689e-03  iter ratio: 0.0000  Data: 3.583 (3.583)
INFO:Train: 210 [  50/625 (  8%)]  Loss: 0.003717 (0.00321)  Time: 0.701s, 2923.41/s  (0.774s, 2645.73/s)  avg LR: 1.689e-03  iter ratio: 0.0000  Data: 0.023 (0.098)
INFO:Train: 210 [ 100/625 ( 16%)]  Loss: 0.003601 (0.00334)  Time: 0.704s, 2908.97/s  (0.739s, 2770.41/s)  avg LR: 1.689e-03  iter ratio: 0.0000  Data: 0.023 (0.063)
INFO:Train: 210 [ 150/625 ( 24%)]  Loss: 0.003429 (0.00336)  Time: 0.703s, 2912.55/s  (0.728s, 2813.16/s)  avg LR: 1.689e-03  iter ratio: 0.0000  Data: 0.024 (0.051)
INFO:Train: 210 [ 200/625 ( 32%)]  Loss: 0.003627 (0.00342)  Time: 0.705s, 2903.44/s  (0.722s, 2835.72/s)  avg LR: 1.689e-03  iter ratio: 0.0000  Data: 0.020 (0.044)
INFO:Train: 210 [ 250/625 ( 40%)]  Loss: 0.003393 (0.00341)  Time: 0.719s, 2848.13/s  (0.721s, 2841.17/s)  avg LR: 1.689e-03  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 210 [ 300/625 ( 48%)]  Loss: 0.002906 (0.00334)  Time: 0.705s, 2903.23/s  (0.721s, 2840.41/s)  avg LR: 1.689e-03  iter ratio: 0.0000  Data: 0.030 (0.039)
INFO:Train: 210 [ 350/625 ( 56%)]  Loss: 0.003768 (0.00339)  Time: 0.714s, 2869.85/s  (0.719s, 2849.84/s)  avg LR: 1.689e-03  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 210 [ 400/625 ( 64%)]  Loss: 0.003574 (0.00341)  Time: 0.707s, 2894.73/s  (0.717s, 2857.18/s)  avg LR: 1.689e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 210 [ 450/625 ( 72%)]  Loss: 0.003021 (0.00337)  Time: 0.704s, 2908.72/s  (0.716s, 2862.17/s)  avg LR: 1.689e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 210 [ 500/625 ( 80%)]  Loss: 0.003301 (0.00337)  Time: 0.700s, 2923.89/s  (0.715s, 2865.99/s)  avg LR: 1.689e-03  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 210 [ 550/625 ( 88%)]  Loss: 0.003345 (0.00337)  Time: 0.708s, 2893.16/s  (0.714s, 2870.02/s)  avg LR: 1.689e-03  iter ratio: 0.0000  Data: 0.032 (0.033)
INFO:Train: 210 [ 600/625 ( 96%)]  Loss: 0.003496 (0.00338)  Time: 0.712s, 2875.81/s  (0.713s, 2870.83/s)  avg LR: 1.689e-03  iter ratio: 0.0000  Data: 0.019 (0.032)
INFO:Train: 210 [ 624/625 (100%)]  Loss: 0.003554 (0.00339)  Time: 0.677s, 3024.91/s  (0.713s, 2872.40/s)  avg LR: 1.689e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.320 (4.320)  Loss:  0.6738 (0.6738)  Acc@1: 84.4727 (84.4727)  Acc@5: 96.2402 (96.2402)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.5840 (0.9938)  Acc@1: 85.1415 (76.9220)  Acc@5: 97.0519 (93.4800)
INFO:210-epoch: remaining time 12.78 h
INFO:Train: 211 [   0/625 (  0%)]  Loss: 0.003689 (0.00369)  Time: 4.491s,  456.02/s  (4.491s,  456.02/s)  avg LR: 1.655e-03  iter ratio: 0.0000  Data: 3.802 (3.802)
INFO:Train: 211 [  50/625 (  8%)]  Loss: 0.003478 (0.00358)  Time: 0.705s, 2906.14/s  (0.779s, 2628.89/s)  avg LR: 1.655e-03  iter ratio: 0.0000  Data: 0.030 (0.102)
INFO:Train: 211 [ 100/625 ( 16%)]  Loss: 0.003012 (0.00339)  Time: 0.720s, 2845.76/s  (0.745s, 2749.89/s)  avg LR: 1.655e-03  iter ratio: 0.0000  Data: 0.046 (0.069)
INFO:Train: 211 [ 150/625 ( 24%)]  Loss: 0.003452 (0.00341)  Time: 0.723s, 2832.54/s  (0.735s, 2784.84/s)  avg LR: 1.655e-03  iter ratio: 0.0000  Data: 0.047 (0.060)
INFO:Train: 211 [ 200/625 ( 32%)]  Loss: 0.004008 (0.00353)  Time: 0.707s, 2894.71/s  (0.728s, 2813.81/s)  avg LR: 1.655e-03  iter ratio: 0.0000  Data: 0.032 (0.052)
INFO:Train: 211 [ 250/625 ( 40%)]  Loss: 0.003871 (0.00359)  Time: 0.702s, 2915.85/s  (0.723s, 2834.12/s)  avg LR: 1.655e-03  iter ratio: 0.0000  Data: 0.027 (0.047)
INFO:Train: 211 [ 300/625 ( 48%)]  Loss: 0.003600 (0.00359)  Time: 0.720s, 2843.29/s  (0.722s, 2838.20/s)  avg LR: 1.655e-03  iter ratio: 0.0000  Data: 0.047 (0.046)
INFO:Train: 211 [ 350/625 ( 56%)]  Loss: 0.003837 (0.00362)  Time: 0.700s, 2927.47/s  (0.720s, 2842.54/s)  avg LR: 1.655e-03  iter ratio: 0.0000  Data: 0.025 (0.045)
INFO:Train: 211 [ 400/625 ( 64%)]  Loss: 0.003140 (0.00357)  Time: 0.700s, 2924.77/s  (0.718s, 2852.39/s)  avg LR: 1.655e-03  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 211 [ 450/625 ( 72%)]  Loss: 0.004198 (0.00363)  Time: 0.708s, 2891.02/s  (0.717s, 2857.99/s)  avg LR: 1.655e-03  iter ratio: 0.0000  Data: 0.033 (0.041)
INFO:Train: 211 [ 500/625 ( 80%)]  Loss: 0.004327 (0.00369)  Time: 0.707s, 2896.75/s  (0.716s, 2861.99/s)  avg LR: 1.655e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 211 [ 550/625 ( 88%)]  Loss: 0.003726 (0.00369)  Time: 0.708s, 2891.55/s  (0.715s, 2866.11/s)  avg LR: 1.655e-03  iter ratio: 0.0000  Data: 0.029 (0.039)
INFO:Train: 211 [ 600/625 ( 96%)]  Loss: 0.003483 (0.00368)  Time: 0.721s, 2839.76/s  (0.715s, 2865.83/s)  avg LR: 1.655e-03  iter ratio: 0.0000  Data: 0.036 (0.038)
INFO:Train: 211 [ 624/625 (100%)]  Loss: 0.003438 (0.00366)  Time: 0.677s, 3023.91/s  (0.714s, 2866.45/s)  avg LR: 1.655e-03  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.342 (4.342)  Loss:  0.6650 (0.6650)  Acc@1: 84.8145 (84.8145)  Acc@5: 96.9727 (96.9727)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.5850 (1.0201)  Acc@1: 86.0849 (76.7740)  Acc@5: 97.0519 (93.4120)
INFO:211-epoch: remaining time 12.69 h
INFO:Train: 212 [   0/625 (  0%)]  Loss: 0.003598 (0.00360)  Time: 4.340s,  471.86/s  (4.340s,  471.86/s)  avg LR: 1.622e-03  iter ratio: 0.0000  Data: 3.653 (3.653)
INFO:Train: 212 [  50/625 (  8%)]  Loss: 0.003274 (0.00344)  Time: 0.712s, 2875.44/s  (0.789s, 2596.74/s)  avg LR: 1.622e-03  iter ratio: 0.0000  Data: 0.038 (0.110)
INFO:Train: 212 [ 100/625 ( 16%)]  Loss: 0.003069 (0.00331)  Time: 0.718s, 2854.23/s  (0.753s, 2719.48/s)  avg LR: 1.622e-03  iter ratio: 0.0000  Data: 0.043 (0.076)
INFO:Train: 212 [ 150/625 ( 24%)]  Loss: 0.003085 (0.00326)  Time: 0.713s, 2871.26/s  (0.740s, 2766.09/s)  avg LR: 1.622e-03  iter ratio: 0.0000  Data: 0.039 (0.064)
INFO:Train: 212 [ 200/625 ( 32%)]  Loss: 0.003653 (0.00334)  Time: 0.718s, 2853.82/s  (0.734s, 2788.31/s)  avg LR: 1.622e-03  iter ratio: 0.0000  Data: 0.043 (0.059)
INFO:Train: 212 [ 250/625 ( 40%)]  Loss: 0.003597 (0.00338)  Time: 0.716s, 2860.27/s  (0.731s, 2801.85/s)  avg LR: 1.622e-03  iter ratio: 0.0000  Data: 0.042 (0.055)
INFO:Train: 212 [ 300/625 ( 48%)]  Loss: 0.003156 (0.00335)  Time: 0.716s, 2861.54/s  (0.729s, 2810.62/s)  avg LR: 1.622e-03  iter ratio: 0.0000  Data: 0.041 (0.053)
INFO:Train: 212 [ 350/625 ( 56%)]  Loss: 0.003505 (0.00337)  Time: 0.716s, 2862.05/s  (0.727s, 2817.15/s)  avg LR: 1.622e-03  iter ratio: 0.0000  Data: 0.042 (0.051)
INFO:Train: 212 [ 400/625 ( 64%)]  Loss: 0.003527 (0.00338)  Time: 0.699s, 2931.82/s  (0.724s, 2828.42/s)  avg LR: 1.622e-03  iter ratio: 0.0000  Data: 0.022 (0.048)
INFO:Train: 212 [ 450/625 ( 72%)]  Loss: 0.002877 (0.00333)  Time: 0.702s, 2918.98/s  (0.722s, 2837.12/s)  avg LR: 1.622e-03  iter ratio: 0.0000  Data: 0.025 (0.046)
INFO:Train: 212 [ 500/625 ( 80%)]  Loss: 0.003777 (0.00337)  Time: 0.709s, 2888.29/s  (0.720s, 2843.75/s)  avg LR: 1.622e-03  iter ratio: 0.0000  Data: 0.032 (0.044)
INFO:Train: 212 [ 550/625 ( 88%)]  Loss: 0.003509 (0.00339)  Time: 0.707s, 2895.62/s  (0.719s, 2848.87/s)  avg LR: 1.622e-03  iter ratio: 0.0000  Data: 0.030 (0.043)
INFO:Train: 212 [ 600/625 ( 96%)]  Loss: 0.004134 (0.00344)  Time: 0.715s, 2863.54/s  (0.718s, 2853.05/s)  avg LR: 1.622e-03  iter ratio: 0.0000  Data: 0.039 (0.041)
INFO:Train: 212 [ 624/625 (100%)]  Loss: 0.004327 (0.00351)  Time: 0.676s, 3029.43/s  (0.718s, 2853.66/s)  avg LR: 1.622e-03  iter ratio: 0.0000  Data: 0.000 (0.041)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.307 (4.307)  Loss:  0.6694 (0.6694)  Acc@1: 85.1074 (85.1074)  Acc@5: 96.6309 (96.6309)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.6440 (1.0264)  Acc@1: 85.3774 (76.8780)  Acc@5: 95.7547 (93.3220)
INFO:212-epoch: remaining time 12.62 h
INFO:Train: 213 [   0/625 (  0%)]  Loss: 0.003473 (0.00347)  Time: 4.199s,  487.70/s  (4.199s,  487.70/s)  avg LR: 1.589e-03  iter ratio: 0.0000  Data: 3.492 (3.492)
INFO:Train: 213 [  50/625 (  8%)]  Loss: 0.003478 (0.00348)  Time: 0.702s, 2915.59/s  (0.775s, 2641.70/s)  avg LR: 1.589e-03  iter ratio: 0.0000  Data: 0.025 (0.093)
INFO:Train: 213 [ 100/625 ( 16%)]  Loss: 0.003087 (0.00335)  Time: 0.707s, 2897.01/s  (0.742s, 2758.49/s)  avg LR: 1.589e-03  iter ratio: 0.0000  Data: 0.029 (0.061)
INFO:Train: 213 [ 150/625 ( 24%)]  Loss: 0.003655 (0.00342)  Time: 0.710s, 2883.37/s  (0.731s, 2803.17/s)  avg LR: 1.589e-03  iter ratio: 0.0000  Data: 0.031 (0.049)
INFO:Train: 213 [ 200/625 ( 32%)]  Loss: 0.002979 (0.00333)  Time: 0.706s, 2899.10/s  (0.724s, 2826.89/s)  avg LR: 1.589e-03  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 213 [ 250/625 ( 40%)]  Loss: 0.003776 (0.00341)  Time: 0.707s, 2898.32/s  (0.721s, 2841.33/s)  avg LR: 1.589e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 213 [ 300/625 ( 48%)]  Loss: 0.002945 (0.00334)  Time: 0.713s, 2872.62/s  (0.718s, 2850.75/s)  avg LR: 1.589e-03  iter ratio: 0.0000  Data: 0.036 (0.037)
INFO:Train: 213 [ 350/625 ( 56%)]  Loss: 0.003458 (0.00336)  Time: 0.709s, 2890.20/s  (0.717s, 2856.64/s)  avg LR: 1.589e-03  iter ratio: 0.0000  Data: 0.030 (0.035)
INFO:Train: 213 [ 400/625 ( 64%)]  Loss: 0.003268 (0.00335)  Time: 0.710s, 2883.96/s  (0.715s, 2862.45/s)  avg LR: 1.589e-03  iter ratio: 0.0000  Data: 0.035 (0.034)
INFO:Train: 213 [ 450/625 ( 72%)]  Loss: 0.003446 (0.00336)  Time: 0.710s, 2886.06/s  (0.715s, 2866.07/s)  avg LR: 1.589e-03  iter ratio: 0.0000  Data: 0.034 (0.033)
INFO:Train: 213 [ 500/625 ( 80%)]  Loss: 0.003418 (0.00336)  Time: 0.707s, 2896.45/s  (0.714s, 2868.34/s)  avg LR: 1.589e-03  iter ratio: 0.0000  Data: 0.031 (0.033)
INFO:Train: 213 [ 550/625 ( 88%)]  Loss: 0.003291 (0.00336)  Time: 0.709s, 2890.21/s  (0.713s, 2871.31/s)  avg LR: 1.589e-03  iter ratio: 0.0000  Data: 0.029 (0.032)
INFO:Train: 213 [ 600/625 ( 96%)]  Loss: 0.003148 (0.00334)  Time: 0.710s, 2885.07/s  (0.713s, 2872.44/s)  avg LR: 1.589e-03  iter ratio: 0.0000  Data: 0.030 (0.032)
INFO:Train: 213 [ 624/625 (100%)]  Loss: 0.003073 (0.00332)  Time: 0.674s, 3037.65/s  (0.713s, 2873.78/s)  avg LR: 1.589e-03  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.360 (4.360)  Loss:  0.6343 (0.6343)  Acc@1: 84.8145 (84.8145)  Acc@5: 96.8262 (96.8262)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.5679 (0.9501)  Acc@1: 84.5519 (77.8820)  Acc@5: 97.7594 (94.1680)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-213.pth.tar', 77.88200001220703)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-209.pth.tar', 77.26599995361327)

INFO:213-epoch: remaining time 12.41 h
INFO:Train: 214 [   0/625 (  0%)]  Loss: 0.003390 (0.00339)  Time: 4.148s,  493.72/s  (4.148s,  493.72/s)  avg LR: 1.556e-03  iter ratio: 0.0000  Data: 3.463 (3.463)
INFO:Train: 214 [  50/625 (  8%)]  Loss: 0.003136 (0.00326)  Time: 0.703s, 2912.72/s  (0.772s, 2652.66/s)  avg LR: 1.556e-03  iter ratio: 0.0000  Data: 0.027 (0.095)
INFO:Train: 214 [ 100/625 ( 16%)]  Loss: 0.003227 (0.00325)  Time: 0.707s, 2895.13/s  (0.738s, 2775.95/s)  avg LR: 1.556e-03  iter ratio: 0.0000  Data: 0.033 (0.062)
INFO:Train: 214 [ 150/625 ( 24%)]  Loss: 0.003465 (0.00330)  Time: 0.707s, 2897.40/s  (0.727s, 2818.08/s)  avg LR: 1.556e-03  iter ratio: 0.0000  Data: 0.032 (0.051)
INFO:Train: 214 [ 200/625 ( 32%)]  Loss: 0.003755 (0.00339)  Time: 0.708s, 2891.77/s  (0.721s, 2840.04/s)  avg LR: 1.556e-03  iter ratio: 0.0000  Data: 0.032 (0.045)
INFO:Train: 214 [ 250/625 ( 40%)]  Loss: 0.003672 (0.00344)  Time: 0.701s, 2920.18/s  (0.718s, 2853.74/s)  avg LR: 1.556e-03  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 214 [ 300/625 ( 48%)]  Loss: 0.003031 (0.00338)  Time: 0.704s, 2910.44/s  (0.715s, 2863.57/s)  avg LR: 1.556e-03  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 214 [ 350/625 ( 56%)]  Loss: 0.003978 (0.00346)  Time: 0.704s, 2908.55/s  (0.713s, 2871.05/s)  avg LR: 1.556e-03  iter ratio: 0.0000  Data: 0.030 (0.038)
INFO:Train: 214 [ 400/625 ( 64%)]  Loss: 0.003794 (0.00349)  Time: 0.704s, 2910.74/s  (0.712s, 2876.48/s)  avg LR: 1.556e-03  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 214 [ 450/625 ( 72%)]  Loss: 0.003635 (0.00351)  Time: 0.707s, 2895.45/s  (0.711s, 2879.36/s)  avg LR: 1.556e-03  iter ratio: 0.0000  Data: 0.031 (0.036)
INFO:Train: 214 [ 500/625 ( 80%)]  Loss: 0.003082 (0.00347)  Time: 0.706s, 2900.53/s  (0.711s, 2881.99/s)  avg LR: 1.556e-03  iter ratio: 0.0000  Data: 0.031 (0.035)
INFO:Train: 214 [ 550/625 ( 88%)]  Loss: 0.003826 (0.00350)  Time: 0.706s, 2902.66/s  (0.710s, 2884.14/s)  avg LR: 1.556e-03  iter ratio: 0.0000  Data: 0.031 (0.034)
INFO:Train: 214 [ 600/625 ( 96%)]  Loss: 0.002750 (0.00344)  Time: 0.716s, 2859.15/s  (0.710s, 2885.76/s)  avg LR: 1.556e-03  iter ratio: 0.0000  Data: 0.039 (0.033)
INFO:Train: 214 [ 624/625 (100%)]  Loss: 0.003780 (0.00347)  Time: 0.674s, 3038.64/s  (0.709s, 2887.14/s)  avg LR: 1.556e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.309 (4.309)  Loss:  0.6626 (0.6626)  Acc@1: 84.5215 (84.5215)  Acc@5: 96.0938 (96.0938)
INFO:Test: [  24/24]  Time: 0.080 (0.510)  Loss:  0.5830 (1.0154)  Acc@1: 84.7877 (76.6580)  Acc@5: 96.8160 (93.2280)
INFO:214-epoch: remaining time 12.23 h
INFO:Train: 215 [   0/625 (  0%)]  Loss: 0.003326 (0.00333)  Time: 4.257s,  481.04/s  (4.257s,  481.04/s)  avg LR: 1.523e-03  iter ratio: 0.0000  Data: 3.572 (3.572)
INFO:Train: 215 [  50/625 (  8%)]  Loss: 0.003543 (0.00343)  Time: 0.707s, 2898.00/s  (0.780s, 2627.22/s)  avg LR: 1.523e-03  iter ratio: 0.0000  Data: 0.032 (0.101)
INFO:Train: 215 [ 100/625 ( 16%)]  Loss: 0.003251 (0.00337)  Time: 0.702s, 2916.60/s  (0.742s, 2759.54/s)  avg LR: 1.523e-03  iter ratio: 0.0000  Data: 0.027 (0.065)
INFO:Train: 215 [ 150/625 ( 24%)]  Loss: 0.003031 (0.00329)  Time: 0.701s, 2921.50/s  (0.730s, 2807.34/s)  avg LR: 1.523e-03  iter ratio: 0.0000  Data: 0.026 (0.052)
INFO:Train: 215 [ 200/625 ( 32%)]  Loss: 0.002967 (0.00322)  Time: 0.704s, 2908.38/s  (0.723s, 2833.86/s)  avg LR: 1.523e-03  iter ratio: 0.0000  Data: 0.029 (0.046)
INFO:Train: 215 [ 250/625 ( 40%)]  Loss: 0.004184 (0.00338)  Time: 0.700s, 2924.43/s  (0.719s, 2849.53/s)  avg LR: 1.523e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 215 [ 300/625 ( 48%)]  Loss: 0.003376 (0.00338)  Time: 0.702s, 2916.55/s  (0.716s, 2860.09/s)  avg LR: 1.523e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 215 [ 350/625 ( 56%)]  Loss: 0.003235 (0.00336)  Time: 0.703s, 2914.15/s  (0.714s, 2867.78/s)  avg LR: 1.523e-03  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 215 [ 400/625 ( 64%)]  Loss: 0.003383 (0.00337)  Time: 0.697s, 2938.34/s  (0.713s, 2873.75/s)  avg LR: 1.523e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 215 [ 450/625 ( 72%)]  Loss: 0.003382 (0.00337)  Time: 0.703s, 2913.94/s  (0.712s, 2878.18/s)  avg LR: 1.523e-03  iter ratio: 0.0000  Data: 0.026 (0.035)
INFO:Train: 215 [ 500/625 ( 80%)]  Loss: 0.003749 (0.00340)  Time: 0.706s, 2901.02/s  (0.711s, 2880.65/s)  avg LR: 1.523e-03  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 215 [ 550/625 ( 88%)]  Loss: 0.003561 (0.00342)  Time: 0.702s, 2918.29/s  (0.710s, 2883.31/s)  avg LR: 1.523e-03  iter ratio: 0.0000  Data: 0.022 (0.033)
INFO:Train: 215 [ 600/625 ( 96%)]  Loss: 0.003553 (0.00343)  Time: 0.721s, 2840.54/s  (0.710s, 2883.17/s)  avg LR: 1.523e-03  iter ratio: 0.0000  Data: 0.042 (0.033)
INFO:Train: 215 [ 624/625 (100%)]  Loss: 0.003510 (0.00343)  Time: 0.674s, 3038.38/s  (0.710s, 2883.08/s)  avg LR: 1.523e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.326 (4.326)  Loss:  0.6221 (0.6221)  Acc@1: 85.5469 (85.5469)  Acc@5: 96.8262 (96.8262)
INFO:Test: [  24/24]  Time: 0.080 (0.507)  Loss:  0.5518 (0.9705)  Acc@1: 85.7311 (77.3380)  Acc@5: 96.4623 (93.7600)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-213.pth.tar', 77.88200001220703)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-215.pth.tar', 77.33800013671875)

INFO:215-epoch: remaining time 12.10 h
INFO:Train: 216 [   0/625 (  0%)]  Loss: 0.003524 (0.00352)  Time: 4.256s,  481.16/s  (4.256s,  481.16/s)  avg LR: 1.491e-03  iter ratio: 0.0000  Data: 3.550 (3.550)
INFO:Train: 216 [  50/625 (  8%)]  Loss: 0.003018 (0.00327)  Time: 0.704s, 2911.04/s  (0.774s, 2644.33/s)  avg LR: 1.491e-03  iter ratio: 0.0000  Data: 0.026 (0.096)
INFO:Train: 216 [ 100/625 ( 16%)]  Loss: 0.003090 (0.00321)  Time: 0.710s, 2882.53/s  (0.740s, 2765.90/s)  avg LR: 1.491e-03  iter ratio: 0.0000  Data: 0.035 (0.061)
INFO:Train: 216 [ 150/625 ( 24%)]  Loss: 0.003303 (0.00323)  Time: 0.718s, 2852.41/s  (0.733s, 2794.70/s)  avg LR: 1.491e-03  iter ratio: 0.0000  Data: 0.042 (0.053)
INFO:Train: 216 [ 200/625 ( 32%)]  Loss: 0.003429 (0.00327)  Time: 0.715s, 2864.18/s  (0.729s, 2810.15/s)  avg LR: 1.491e-03  iter ratio: 0.0000  Data: 0.037 (0.049)
INFO:Train: 216 [ 250/625 ( 40%)]  Loss: 0.003802 (0.00336)  Time: 0.714s, 2867.50/s  (0.726s, 2819.74/s)  avg LR: 1.491e-03  iter ratio: 0.0000  Data: 0.036 (0.046)
INFO:Train: 216 [ 300/625 ( 48%)]  Loss: 0.003773 (0.00342)  Time: 0.715s, 2863.89/s  (0.725s, 2825.77/s)  avg LR: 1.491e-03  iter ratio: 0.0000  Data: 0.037 (0.045)
INFO:Train: 216 [ 350/625 ( 56%)]  Loss: 0.003864 (0.00348)  Time: 0.709s, 2886.66/s  (0.724s, 2830.43/s)  avg LR: 1.491e-03  iter ratio: 0.0000  Data: 0.031 (0.044)
INFO:Train: 216 [ 400/625 ( 64%)]  Loss: 0.003652 (0.00350)  Time: 0.704s, 2907.52/s  (0.723s, 2834.36/s)  avg LR: 1.491e-03  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 216 [ 450/625 ( 72%)]  Loss: 0.003082 (0.00345)  Time: 0.703s, 2914.12/s  (0.721s, 2841.06/s)  avg LR: 1.491e-03  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 216 [ 500/625 ( 80%)]  Loss: 0.002722 (0.00339)  Time: 0.700s, 2924.12/s  (0.719s, 2847.22/s)  avg LR: 1.491e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 216 [ 550/625 ( 88%)]  Loss: 0.002808 (0.00334)  Time: 0.710s, 2885.85/s  (0.719s, 2848.34/s)  avg LR: 1.491e-03  iter ratio: 0.0000  Data: 0.036 (0.039)
INFO:Train: 216 [ 600/625 ( 96%)]  Loss: 0.003157 (0.00332)  Time: 0.715s, 2865.96/s  (0.719s, 2849.39/s)  avg LR: 1.491e-03  iter ratio: 0.0000  Data: 0.039 (0.039)
INFO:Train: 216 [ 624/625 (100%)]  Loss: 0.003754 (0.00336)  Time: 0.673s, 3044.74/s  (0.718s, 2851.38/s)  avg LR: 1.491e-03  iter ratio: 0.0000  Data: 0.000 (0.039)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.319 (4.319)  Loss:  0.6416 (0.6416)  Acc@1: 86.2793 (86.2793)  Acc@5: 96.9238 (96.9238)
INFO:Test: [  24/24]  Time: 0.080 (0.512)  Loss:  0.6362 (0.9882)  Acc@1: 84.7877 (77.4680)  Acc@5: 96.8160 (94.0940)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-213.pth.tar', 77.88200001220703)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-216.pth.tar', 77.46799998535157)

INFO:216-epoch: remaining time 12.11 h
INFO:Train: 217 [   0/625 (  0%)]  Loss: 0.003764 (0.00376)  Time: 4.301s,  476.11/s  (4.301s,  476.11/s)  avg LR: 1.459e-03  iter ratio: 0.0000  Data: 3.607 (3.607)
INFO:Train: 217 [  50/625 (  8%)]  Loss: 0.003673 (0.00372)  Time: 0.701s, 2919.78/s  (0.776s, 2637.56/s)  avg LR: 1.459e-03  iter ratio: 0.0000  Data: 0.025 (0.097)
INFO:Train: 217 [ 100/625 ( 16%)]  Loss: 0.003519 (0.00365)  Time: 0.702s, 2916.47/s  (0.740s, 2767.13/s)  avg LR: 1.459e-03  iter ratio: 0.0000  Data: 0.024 (0.061)
INFO:Train: 217 [ 150/625 ( 24%)]  Loss: 0.003411 (0.00359)  Time: 0.703s, 2911.30/s  (0.729s, 2808.12/s)  avg LR: 1.459e-03  iter ratio: 0.0000  Data: 0.028 (0.050)
INFO:Train: 217 [ 200/625 ( 32%)]  Loss: 0.003998 (0.00367)  Time: 0.705s, 2904.62/s  (0.723s, 2832.07/s)  avg LR: 1.459e-03  iter ratio: 0.0000  Data: 0.030 (0.044)
INFO:Train: 217 [ 250/625 ( 40%)]  Loss: 0.003982 (0.00372)  Time: 0.714s, 2869.54/s  (0.721s, 2841.04/s)  avg LR: 1.459e-03  iter ratio: 0.0000  Data: 0.038 (0.041)
INFO:Train: 217 [ 300/625 ( 48%)]  Loss: 0.003623 (0.00371)  Time: 0.701s, 2921.46/s  (0.720s, 2844.27/s)  avg LR: 1.459e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 217 [ 350/625 ( 56%)]  Loss: 0.003236 (0.00365)  Time: 0.704s, 2909.81/s  (0.718s, 2853.80/s)  avg LR: 1.459e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 217 [ 400/625 ( 64%)]  Loss: 0.003474 (0.00363)  Time: 0.700s, 2927.29/s  (0.716s, 2860.12/s)  avg LR: 1.459e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 217 [ 450/625 ( 72%)]  Loss: 0.003334 (0.00360)  Time: 0.705s, 2905.80/s  (0.715s, 2865.38/s)  avg LR: 1.459e-03  iter ratio: 0.0000  Data: 0.030 (0.035)
INFO:Train: 217 [ 500/625 ( 80%)]  Loss: 0.002732 (0.00352)  Time: 0.710s, 2883.54/s  (0.714s, 2869.51/s)  avg LR: 1.459e-03  iter ratio: 0.0000  Data: 0.033 (0.034)
INFO:Train: 217 [ 550/625 ( 88%)]  Loss: 0.003480 (0.00352)  Time: 0.703s, 2913.57/s  (0.713s, 2872.74/s)  avg LR: 1.459e-03  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 217 [ 600/625 ( 96%)]  Loss: 0.003482 (0.00352)  Time: 0.704s, 2910.70/s  (0.712s, 2875.46/s)  avg LR: 1.459e-03  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 217 [ 624/625 (100%)]  Loss: 0.003397 (0.00351)  Time: 0.675s, 3033.77/s  (0.712s, 2877.32/s)  avg LR: 1.459e-03  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.356 (4.356)  Loss:  0.6348 (0.6348)  Acc@1: 84.5215 (84.5215)  Acc@5: 97.2656 (97.2656)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.5801 (0.9454)  Acc@1: 85.6132 (78.2700)  Acc@5: 97.1698 (94.1300)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-217.pth.tar', 78.27000008544921)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-213.pth.tar', 77.88200001220703)

INFO:217-epoch: remaining time 11.87 h
INFO:Train: 218 [   0/625 (  0%)]  Loss: 0.003617 (0.00362)  Time: 4.575s,  447.68/s  (4.575s,  447.68/s)  avg LR: 1.428e-03  iter ratio: 0.0000  Data: 3.869 (3.869)
INFO:Train: 218 [  50/625 (  8%)]  Loss: 0.004194 (0.00391)  Time: 0.702s, 2916.32/s  (0.787s, 2600.73/s)  avg LR: 1.428e-03  iter ratio: 0.0000  Data: 0.025 (0.107)
INFO:Train: 218 [ 100/625 ( 16%)]  Loss: 0.003065 (0.00363)  Time: 0.715s, 2866.17/s  (0.751s, 2727.65/s)  avg LR: 1.428e-03  iter ratio: 0.0000  Data: 0.040 (0.073)
INFO:Train: 218 [ 150/625 ( 24%)]  Loss: 0.003168 (0.00351)  Time: 0.723s, 2832.00/s  (0.739s, 2769.51/s)  avg LR: 1.428e-03  iter ratio: 0.0000  Data: 0.046 (0.062)
INFO:Train: 218 [ 200/625 ( 32%)]  Loss: 0.003032 (0.00342)  Time: 0.699s, 2930.75/s  (0.732s, 2795.96/s)  avg LR: 1.428e-03  iter ratio: 0.0000  Data: 0.024 (0.055)
INFO:Train: 218 [ 250/625 ( 40%)]  Loss: 0.003437 (0.00342)  Time: 0.704s, 2908.16/s  (0.727s, 2817.24/s)  avg LR: 1.428e-03  iter ratio: 0.0000  Data: 0.027 (0.050)
INFO:Train: 218 [ 300/625 ( 48%)]  Loss: 0.003779 (0.00347)  Time: 0.704s, 2909.90/s  (0.724s, 2830.62/s)  avg LR: 1.428e-03  iter ratio: 0.0000  Data: 0.030 (0.046)
INFO:Train: 218 [ 350/625 ( 56%)]  Loss: 0.002968 (0.00341)  Time: 0.725s, 2825.08/s  (0.721s, 2838.92/s)  avg LR: 1.428e-03  iter ratio: 0.0000  Data: 0.050 (0.044)
INFO:Train: 218 [ 400/625 ( 64%)]  Loss: 0.003440 (0.00341)  Time: 0.703s, 2911.76/s  (0.720s, 2846.20/s)  avg LR: 1.428e-03  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 218 [ 450/625 ( 72%)]  Loss: 0.003486 (0.00342)  Time: 0.705s, 2904.51/s  (0.718s, 2852.68/s)  avg LR: 1.428e-03  iter ratio: 0.0000  Data: 0.030 (0.041)
INFO:Train: 218 [ 500/625 ( 80%)]  Loss: 0.004335 (0.00350)  Time: 0.705s, 2904.42/s  (0.717s, 2858.28/s)  avg LR: 1.428e-03  iter ratio: 0.0000  Data: 0.031 (0.040)
INFO:Train: 218 [ 550/625 ( 88%)]  Loss: 0.002930 (0.00345)  Time: 0.705s, 2905.86/s  (0.715s, 2863.20/s)  avg LR: 1.428e-03  iter ratio: 0.0000  Data: 0.030 (0.039)
INFO:Train: 218 [ 600/625 ( 96%)]  Loss: 0.003402 (0.00345)  Time: 0.709s, 2889.56/s  (0.714s, 2867.06/s)  avg LR: 1.428e-03  iter ratio: 0.0000  Data: 0.032 (0.038)
INFO:Train: 218 [ 624/625 (100%)]  Loss: 0.003644 (0.00346)  Time: 0.675s, 3034.84/s  (0.714s, 2869.35/s)  avg LR: 1.428e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.345 (4.345)  Loss:  0.5908 (0.5908)  Acc@1: 86.7676 (86.7676)  Acc@5: 96.9727 (96.9727)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.5645 (0.9517)  Acc@1: 85.7311 (78.5000)  Acc@5: 97.4057 (94.1240)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-218.pth.tar', 78.50000013671875)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-217.pth.tar', 78.27000008544921)

INFO:218-epoch: remaining time 11.78 h
INFO:Train: 219 [   0/625 (  0%)]  Loss: 0.003706 (0.00371)  Time: 4.209s,  486.54/s  (4.209s,  486.54/s)  avg LR: 1.396e-03  iter ratio: 0.0000  Data: 3.523 (3.523)
INFO:Train: 219 [  50/625 (  8%)]  Loss: 0.003360 (0.00353)  Time: 0.703s, 2911.59/s  (0.773s, 2650.81/s)  avg LR: 1.396e-03  iter ratio: 0.0000  Data: 0.026 (0.097)
INFO:Train: 219 [ 100/625 ( 16%)]  Loss: 0.003381 (0.00348)  Time: 0.703s, 2913.11/s  (0.739s, 2772.85/s)  avg LR: 1.396e-03  iter ratio: 0.0000  Data: 0.024 (0.063)
INFO:Train: 219 [ 150/625 ( 24%)]  Loss: 0.004151 (0.00365)  Time: 0.706s, 2902.01/s  (0.727s, 2818.06/s)  avg LR: 1.396e-03  iter ratio: 0.0000  Data: 0.028 (0.051)
INFO:Train: 219 [ 200/625 ( 32%)]  Loss: 0.003634 (0.00365)  Time: 0.705s, 2905.93/s  (0.721s, 2840.14/s)  avg LR: 1.396e-03  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 219 [ 250/625 ( 40%)]  Loss: 0.003114 (0.00356)  Time: 0.701s, 2922.87/s  (0.718s, 2853.81/s)  avg LR: 1.396e-03  iter ratio: 0.0000  Data: 0.024 (0.042)
INFO:Train: 219 [ 300/625 ( 48%)]  Loss: 0.003006 (0.00348)  Time: 0.708s, 2892.03/s  (0.715s, 2862.96/s)  avg LR: 1.396e-03  iter ratio: 0.0000  Data: 0.031 (0.040)
INFO:Train: 219 [ 350/625 ( 56%)]  Loss: 0.003512 (0.00348)  Time: 0.703s, 2911.20/s  (0.714s, 2869.86/s)  avg LR: 1.396e-03  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 219 [ 400/625 ( 64%)]  Loss: 0.003239 (0.00346)  Time: 0.702s, 2917.52/s  (0.712s, 2875.10/s)  avg LR: 1.396e-03  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 219 [ 450/625 ( 72%)]  Loss: 0.003915 (0.00350)  Time: 0.706s, 2899.65/s  (0.711s, 2878.66/s)  avg LR: 1.396e-03  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 219 [ 500/625 ( 80%)]  Loss: 0.002858 (0.00344)  Time: 0.696s, 2942.98/s  (0.711s, 2880.31/s)  avg LR: 1.396e-03  iter ratio: 0.0000  Data: 0.020 (0.035)
INFO:Train: 219 [ 550/625 ( 88%)]  Loss: 0.003338 (0.00343)  Time: 0.703s, 2912.92/s  (0.711s, 2880.74/s)  avg LR: 1.396e-03  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 219 [ 600/625 ( 96%)]  Loss: 0.003367 (0.00343)  Time: 0.706s, 2899.52/s  (0.710s, 2883.35/s)  avg LR: 1.396e-03  iter ratio: 0.0000  Data: 0.030 (0.034)
INFO:Train: 219 [ 624/625 (100%)]  Loss: 0.002987 (0.00340)  Time: 0.674s, 3037.51/s  (0.710s, 2885.03/s)  avg LR: 1.396e-03  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.331 (4.331)  Loss:  0.6367 (0.6367)  Acc@1: 85.7910 (85.7910)  Acc@5: 96.7285 (96.7285)
INFO:Test: [  24/24]  Time: 0.081 (0.508)  Loss:  0.5933 (0.9733)  Acc@1: 85.7311 (77.8240)  Acc@5: 97.2877 (93.9160)
INFO:219-epoch: remaining time 11.58 h
INFO:Train: 220 [   0/625 (  0%)]  Loss: 0.003373 (0.00337)  Time: 4.113s,  497.96/s  (4.113s,  497.96/s)  avg LR: 1.365e-03  iter ratio: 0.0000  Data: 3.407 (3.407)
INFO:Train: 220 [  50/625 (  8%)]  Loss: 0.003194 (0.00328)  Time: 0.706s, 2902.75/s  (0.772s, 2652.90/s)  avg LR: 1.365e-03  iter ratio: 0.0000  Data: 0.024 (0.092)
INFO:Train: 220 [ 100/625 ( 16%)]  Loss: 0.004258 (0.00361)  Time: 0.715s, 2865.63/s  (0.744s, 2752.36/s)  avg LR: 1.365e-03  iter ratio: 0.0000  Data: 0.038 (0.065)
INFO:Train: 220 [ 150/625 ( 24%)]  Loss: 0.003052 (0.00347)  Time: 0.716s, 2860.62/s  (0.736s, 2784.25/s)  avg LR: 1.365e-03  iter ratio: 0.0000  Data: 0.041 (0.057)
INFO:Train: 220 [ 200/625 ( 32%)]  Loss: 0.003830 (0.00354)  Time: 0.707s, 2897.68/s  (0.731s, 2802.02/s)  avg LR: 1.365e-03  iter ratio: 0.0000  Data: 0.028 (0.053)
INFO:Train: 220 [ 250/625 ( 40%)]  Loss: 0.003049 (0.00346)  Time: 0.705s, 2905.19/s  (0.725s, 2823.46/s)  avg LR: 1.365e-03  iter ratio: 0.0000  Data: 0.029 (0.048)
INFO:Train: 220 [ 300/625 ( 48%)]  Loss: 0.003124 (0.00341)  Time: 0.705s, 2906.66/s  (0.722s, 2837.56/s)  avg LR: 1.365e-03  iter ratio: 0.0000  Data: 0.026 (0.044)
INFO:Train: 220 [ 350/625 ( 56%)]  Loss: 0.003235 (0.00339)  Time: 0.722s, 2837.52/s  (0.721s, 2841.90/s)  avg LR: 1.365e-03  iter ratio: 0.0000  Data: 0.046 (0.043)
INFO:Train: 220 [ 400/625 ( 64%)]  Loss: 0.003225 (0.00337)  Time: 0.711s, 2878.79/s  (0.720s, 2843.42/s)  avg LR: 1.365e-03  iter ratio: 0.0000  Data: 0.037 (0.043)
INFO:Train: 220 [ 450/625 ( 72%)]  Loss: 0.003446 (0.00338)  Time: 0.703s, 2912.26/s  (0.719s, 2848.47/s)  avg LR: 1.365e-03  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 220 [ 500/625 ( 80%)]  Loss: 0.004015 (0.00344)  Time: 0.705s, 2905.97/s  (0.718s, 2853.97/s)  avg LR: 1.365e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 220 [ 550/625 ( 88%)]  Loss: 0.004068 (0.00349)  Time: 0.706s, 2900.03/s  (0.716s, 2858.47/s)  avg LR: 1.365e-03  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 220 [ 600/625 ( 96%)]  Loss: 0.003994 (0.00353)  Time: 0.719s, 2848.49/s  (0.716s, 2859.58/s)  avg LR: 1.365e-03  iter ratio: 0.0000  Data: 0.044 (0.038)
INFO:Train: 220 [ 624/625 (100%)]  Loss: 0.003393 (0.00352)  Time: 0.672s, 3046.30/s  (0.716s, 2859.82/s)  avg LR: 1.365e-03  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.362 (4.362)  Loss:  0.6147 (0.6147)  Acc@1: 85.8887 (85.8887)  Acc@5: 96.7773 (96.7773)
INFO:Test: [  24/24]  Time: 0.080 (0.502)  Loss:  0.5850 (0.9628)  Acc@1: 85.8491 (77.7720)  Acc@5: 97.1698 (94.1080)
INFO:220-epoch: remaining time 11.56 h
INFO:Train: 221 [   0/625 (  0%)]  Loss: 0.003897 (0.00390)  Time: 4.407s,  464.72/s  (4.407s,  464.72/s)  avg LR: 1.334e-03  iter ratio: 0.0000  Data: 3.717 (3.717)
INFO:Train: 221 [  50/625 (  8%)]  Loss: 0.003056 (0.00348)  Time: 0.706s, 2902.78/s  (0.783s, 2614.70/s)  avg LR: 1.334e-03  iter ratio: 0.0000  Data: 0.031 (0.106)
INFO:Train: 221 [ 100/625 ( 16%)]  Loss: 0.002705 (0.00322)  Time: 0.705s, 2904.33/s  (0.744s, 2752.76/s)  avg LR: 1.334e-03  iter ratio: 0.0000  Data: 0.030 (0.067)
INFO:Train: 221 [ 150/625 ( 24%)]  Loss: 0.003329 (0.00325)  Time: 0.702s, 2916.13/s  (0.731s, 2803.44/s)  avg LR: 1.334e-03  iter ratio: 0.0000  Data: 0.024 (0.054)
INFO:Train: 221 [ 200/625 ( 32%)]  Loss: 0.003167 (0.00323)  Time: 0.704s, 2907.54/s  (0.724s, 2827.06/s)  avg LR: 1.334e-03  iter ratio: 0.0000  Data: 0.029 (0.048)
INFO:Train: 221 [ 250/625 ( 40%)]  Loss: 0.003257 (0.00324)  Time: 0.708s, 2893.30/s  (0.720s, 2842.99/s)  avg LR: 1.334e-03  iter ratio: 0.0000  Data: 0.032 (0.044)
INFO:Train: 221 [ 300/625 ( 48%)]  Loss: 0.003580 (0.00328)  Time: 0.719s, 2846.90/s  (0.718s, 2852.51/s)  avg LR: 1.334e-03  iter ratio: 0.0000  Data: 0.044 (0.042)
INFO:Train: 221 [ 350/625 ( 56%)]  Loss: 0.003434 (0.00330)  Time: 0.706s, 2902.65/s  (0.716s, 2860.39/s)  avg LR: 1.334e-03  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 221 [ 400/625 ( 64%)]  Loss: 0.002674 (0.00323)  Time: 0.700s, 2924.76/s  (0.714s, 2866.59/s)  avg LR: 1.334e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 221 [ 450/625 ( 72%)]  Loss: 0.004007 (0.00331)  Time: 0.706s, 2899.75/s  (0.713s, 2871.95/s)  avg LR: 1.334e-03  iter ratio: 0.0000  Data: 0.031 (0.037)
INFO:Train: 221 [ 500/625 ( 80%)]  Loss: 0.003014 (0.00328)  Time: 0.702s, 2916.66/s  (0.712s, 2875.60/s)  avg LR: 1.334e-03  iter ratio: 0.0000  Data: 0.022 (0.036)
INFO:Train: 221 [ 550/625 ( 88%)]  Loss: 0.003215 (0.00328)  Time: 0.704s, 2908.55/s  (0.711s, 2879.59/s)  avg LR: 1.334e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 221 [ 600/625 ( 96%)]  Loss: 0.004313 (0.00336)  Time: 0.703s, 2912.88/s  (0.711s, 2882.01/s)  avg LR: 1.334e-03  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 221 [ 624/625 (100%)]  Loss: 0.003449 (0.00336)  Time: 0.674s, 3037.92/s  (0.710s, 2883.89/s)  avg LR: 1.334e-03  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.296 (4.296)  Loss:  0.6250 (0.6250)  Acc@1: 84.2285 (84.2285)  Acc@5: 97.1680 (97.1680)
INFO:Test: [  24/24]  Time: 0.081 (0.509)  Loss:  0.6230 (0.9420)  Acc@1: 85.0236 (78.0660)  Acc@5: 96.2264 (94.0500)
INFO:221-epoch: remaining time 11.34 h
INFO:Train: 222 [   0/625 (  0%)]  Loss: 0.003318 (0.00332)  Time: 4.246s,  482.33/s  (4.246s,  482.33/s)  avg LR: 1.304e-03  iter ratio: 0.0000  Data: 3.553 (3.553)
INFO:Train: 222 [  50/625 (  8%)]  Loss: 0.003171 (0.00324)  Time: 0.704s, 2909.49/s  (0.777s, 2635.72/s)  avg LR: 1.304e-03  iter ratio: 0.0000  Data: 0.028 (0.097)
INFO:Train: 222 [ 100/625 ( 16%)]  Loss: 0.003011 (0.00317)  Time: 0.700s, 2924.47/s  (0.742s, 2759.59/s)  avg LR: 1.304e-03  iter ratio: 0.0000  Data: 0.026 (0.063)
INFO:Train: 222 [ 150/625 ( 24%)]  Loss: 0.002671 (0.00304)  Time: 0.702s, 2915.80/s  (0.730s, 2807.03/s)  avg LR: 1.304e-03  iter ratio: 0.0000  Data: 0.023 (0.050)
INFO:Train: 222 [ 200/625 ( 32%)]  Loss: 0.003588 (0.00315)  Time: 0.703s, 2914.61/s  (0.723s, 2831.13/s)  avg LR: 1.304e-03  iter ratio: 0.0000  Data: 0.024 (0.044)
INFO:Train: 222 [ 250/625 ( 40%)]  Loss: 0.003692 (0.00324)  Time: 0.705s, 2906.01/s  (0.720s, 2845.24/s)  avg LR: 1.304e-03  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 222 [ 300/625 ( 48%)]  Loss: 0.003691 (0.00331)  Time: 0.705s, 2903.31/s  (0.717s, 2855.01/s)  avg LR: 1.304e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 222 [ 350/625 ( 56%)]  Loss: 0.003293 (0.00330)  Time: 0.703s, 2912.48/s  (0.716s, 2862.27/s)  avg LR: 1.304e-03  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 222 [ 400/625 ( 64%)]  Loss: 0.003313 (0.00331)  Time: 0.718s, 2851.80/s  (0.715s, 2862.92/s)  avg LR: 1.304e-03  iter ratio: 0.0000  Data: 0.032 (0.037)
INFO:Train: 222 [ 450/625 ( 72%)]  Loss: 0.004005 (0.00338)  Time: 0.709s, 2888.53/s  (0.715s, 2864.84/s)  avg LR: 1.304e-03  iter ratio: 0.0000  Data: 0.033 (0.036)
INFO:Train: 222 [ 500/625 ( 80%)]  Loss: 0.003387 (0.00338)  Time: 0.708s, 2891.45/s  (0.714s, 2867.53/s)  avg LR: 1.304e-03  iter ratio: 0.0000  Data: 0.034 (0.036)
INFO:Train: 222 [ 550/625 ( 88%)]  Loss: 0.003682 (0.00340)  Time: 0.718s, 2851.44/s  (0.714s, 2869.58/s)  avg LR: 1.304e-03  iter ratio: 0.0000  Data: 0.044 (0.035)
INFO:Train: 222 [ 600/625 ( 96%)]  Loss: 0.003189 (0.00339)  Time: 0.722s, 2837.82/s  (0.714s, 2867.86/s)  avg LR: 1.304e-03  iter ratio: 0.0000  Data: 0.046 (0.036)
INFO:Train: 222 [ 624/625 (100%)]  Loss: 0.003943 (0.00343)  Time: 0.674s, 3039.97/s  (0.714s, 2868.14/s)  avg LR: 1.304e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.327 (4.327)  Loss:  0.6401 (0.6401)  Acc@1: 85.6445 (85.6445)  Acc@5: 97.1191 (97.1191)
INFO:Test: [  24/24]  Time: 0.080 (0.502)  Loss:  0.5713 (0.9615)  Acc@1: 85.7311 (78.0940)  Acc@5: 97.1698 (94.0420)
INFO:222-epoch: remaining time 11.27 h
INFO:Train: 223 [   0/625 (  0%)]  Loss: 0.003573 (0.00357)  Time: 4.304s,  475.82/s  (4.304s,  475.82/s)  avg LR: 1.274e-03  iter ratio: 0.0000  Data: 3.621 (3.621)
INFO:Train: 223 [  50/625 (  8%)]  Loss: 0.003310 (0.00344)  Time: 0.723s, 2834.41/s  (0.780s, 2623.98/s)  avg LR: 1.274e-03  iter ratio: 0.0000  Data: 0.025 (0.099)
INFO:Train: 223 [ 100/625 ( 16%)]  Loss: 0.004359 (0.00375)  Time: 0.700s, 2926.45/s  (0.744s, 2753.85/s)  avg LR: 1.274e-03  iter ratio: 0.0000  Data: 0.025 (0.063)
INFO:Train: 223 [ 150/625 ( 24%)]  Loss: 0.004101 (0.00384)  Time: 0.705s, 2903.55/s  (0.732s, 2796.77/s)  avg LR: 1.274e-03  iter ratio: 0.0000  Data: 0.026 (0.052)
INFO:Train: 223 [ 200/625 ( 32%)]  Loss: 0.003923 (0.00385)  Time: 0.702s, 2916.14/s  (0.725s, 2824.41/s)  avg LR: 1.274e-03  iter ratio: 0.0000  Data: 0.027 (0.046)
INFO:Train: 223 [ 250/625 ( 40%)]  Loss: 0.003081 (0.00372)  Time: 0.701s, 2920.86/s  (0.721s, 2839.72/s)  avg LR: 1.274e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 223 [ 300/625 ( 48%)]  Loss: 0.003465 (0.00369)  Time: 0.703s, 2913.75/s  (0.718s, 2851.77/s)  avg LR: 1.274e-03  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 223 [ 350/625 ( 56%)]  Loss: 0.003470 (0.00366)  Time: 0.702s, 2916.06/s  (0.716s, 2858.77/s)  avg LR: 1.274e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 223 [ 400/625 ( 64%)]  Loss: 0.004412 (0.00374)  Time: 0.705s, 2905.17/s  (0.715s, 2865.21/s)  avg LR: 1.274e-03  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 223 [ 450/625 ( 72%)]  Loss: 0.003396 (0.00371)  Time: 0.704s, 2908.26/s  (0.714s, 2870.28/s)  avg LR: 1.274e-03  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 223 [ 500/625 ( 80%)]  Loss: 0.002663 (0.00361)  Time: 0.702s, 2918.75/s  (0.713s, 2873.69/s)  avg LR: 1.274e-03  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 223 [ 550/625 ( 88%)]  Loss: 0.003432 (0.00360)  Time: 0.720s, 2843.06/s  (0.713s, 2872.09/s)  avg LR: 1.274e-03  iter ratio: 0.0000  Data: 0.045 (0.035)
INFO:Train: 223 [ 600/625 ( 96%)]  Loss: 0.003446 (0.00359)  Time: 0.721s, 2839.86/s  (0.714s, 2870.15/s)  avg LR: 1.274e-03  iter ratio: 0.0000  Data: 0.046 (0.036)
INFO:Train: 223 [ 624/625 (100%)]  Loss: 0.003404 (0.00357)  Time: 0.678s, 3020.25/s  (0.714s, 2869.94/s)  avg LR: 1.274e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.354 (4.354)  Loss:  0.6001 (0.6001)  Acc@1: 86.1328 (86.1328)  Acc@5: 96.9238 (96.9238)
INFO:Test: [  24/24]  Time: 0.080 (0.507)  Loss:  0.5303 (0.9313)  Acc@1: 86.9104 (78.7340)  Acc@5: 97.9953 (94.2680)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-223.pth.tar', 78.7340000024414)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-218.pth.tar', 78.50000013671875)

INFO:223-epoch: remaining time 11.14 h
INFO:Train: 224 [   0/625 (  0%)]  Loss: 0.002947 (0.00295)  Time: 4.488s,  456.33/s  (4.488s,  456.33/s)  avg LR: 1.244e-03  iter ratio: 0.0000  Data: 3.802 (3.802)
INFO:Train: 224 [  50/625 (  8%)]  Loss: 0.003690 (0.00332)  Time: 0.705s, 2903.50/s  (0.785s, 2609.38/s)  avg LR: 1.244e-03  iter ratio: 0.0000  Data: 0.030 (0.106)
INFO:Train: 224 [ 100/625 ( 16%)]  Loss: 0.002992 (0.00321)  Time: 0.720s, 2844.74/s  (0.749s, 2736.06/s)  avg LR: 1.244e-03  iter ratio: 0.0000  Data: 0.045 (0.071)
INFO:Train: 224 [ 150/625 ( 24%)]  Loss: 0.003644 (0.00332)  Time: 0.719s, 2847.43/s  (0.739s, 2772.61/s)  avg LR: 1.244e-03  iter ratio: 0.0000  Data: 0.044 (0.062)
INFO:Train: 224 [ 200/625 ( 32%)]  Loss: 0.003464 (0.00335)  Time: 0.712s, 2875.14/s  (0.730s, 2803.70/s)  avg LR: 1.244e-03  iter ratio: 0.0000  Data: 0.034 (0.054)
INFO:Train: 224 [ 250/625 ( 40%)]  Loss: 0.003452 (0.00336)  Time: 0.704s, 2908.57/s  (0.726s, 2821.73/s)  avg LR: 1.244e-03  iter ratio: 0.0000  Data: 0.029 (0.049)
INFO:Train: 224 [ 300/625 ( 48%)]  Loss: 0.003634 (0.00340)  Time: 0.712s, 2875.45/s  (0.723s, 2834.26/s)  avg LR: 1.244e-03  iter ratio: 0.0000  Data: 0.036 (0.046)
INFO:Train: 224 [ 350/625 ( 56%)]  Loss: 0.003056 (0.00336)  Time: 0.705s, 2906.66/s  (0.720s, 2844.45/s)  avg LR: 1.244e-03  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 224 [ 400/625 ( 64%)]  Loss: 0.003208 (0.00334)  Time: 0.703s, 2913.67/s  (0.718s, 2852.22/s)  avg LR: 1.244e-03  iter ratio: 0.0000  Data: 0.029 (0.041)
INFO:Train: 224 [ 450/625 ( 72%)]  Loss: 0.003616 (0.00337)  Time: 0.698s, 2934.71/s  (0.716s, 2859.06/s)  avg LR: 1.244e-03  iter ratio: 0.0000  Data: 0.021 (0.040)
INFO:Train: 224 [ 500/625 ( 80%)]  Loss: 0.003260 (0.00336)  Time: 0.725s, 2825.73/s  (0.716s, 2862.27/s)  avg LR: 1.244e-03  iter ratio: 0.0000  Data: 0.050 (0.039)
INFO:Train: 224 [ 550/625 ( 88%)]  Loss: 0.002908 (0.00332)  Time: 0.722s, 2837.15/s  (0.716s, 2861.08/s)  avg LR: 1.244e-03  iter ratio: 0.0000  Data: 0.047 (0.039)
INFO:Train: 224 [ 600/625 ( 96%)]  Loss: 0.003259 (0.00332)  Time: 0.702s, 2916.60/s  (0.715s, 2862.84/s)  avg LR: 1.244e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 224 [ 624/625 (100%)]  Loss: 0.003433 (0.00333)  Time: 0.674s, 3039.06/s  (0.715s, 2865.19/s)  avg LR: 1.244e-03  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.351 (4.351)  Loss:  0.5967 (0.5967)  Acc@1: 85.6934 (85.6934)  Acc@5: 97.3633 (97.3633)
INFO:Test: [  24/24]  Time: 0.080 (0.509)  Loss:  0.5234 (0.9059)  Acc@1: 86.7925 (78.7520)  Acc@5: 97.8774 (94.4280)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-224.pth.tar', 78.7520000805664)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-223.pth.tar', 78.7340000024414)

INFO:224-epoch: remaining time 11.04 h
INFO:Train: 225 [   0/625 (  0%)]  Loss: 0.003137 (0.00314)  Time: 4.243s,  482.70/s  (4.243s,  482.70/s)  avg LR: 1.214e-03  iter ratio: 0.0000  Data: 3.542 (3.542)
INFO:Train: 225 [  50/625 (  8%)]  Loss: 0.002931 (0.00303)  Time: 0.698s, 2934.78/s  (0.774s, 2647.50/s)  avg LR: 1.214e-03  iter ratio: 0.0000  Data: 0.023 (0.097)
INFO:Train: 225 [ 100/625 ( 16%)]  Loss: 0.003696 (0.00325)  Time: 0.703s, 2911.52/s  (0.740s, 2768.12/s)  avg LR: 1.214e-03  iter ratio: 0.0000  Data: 0.027 (0.063)
INFO:Train: 225 [ 150/625 ( 24%)]  Loss: 0.003847 (0.00340)  Time: 0.703s, 2914.89/s  (0.728s, 2813.37/s)  avg LR: 1.214e-03  iter ratio: 0.0000  Data: 0.025 (0.051)
INFO:Train: 225 [ 200/625 ( 32%)]  Loss: 0.003425 (0.00341)  Time: 0.706s, 2901.86/s  (0.722s, 2835.63/s)  avg LR: 1.214e-03  iter ratio: 0.0000  Data: 0.029 (0.046)
INFO:Train: 225 [ 250/625 ( 40%)]  Loss: 0.003224 (0.00338)  Time: 0.700s, 2924.62/s  (0.719s, 2848.91/s)  avg LR: 1.214e-03  iter ratio: 0.0000  Data: 0.025 (0.042)
INFO:Train: 225 [ 300/625 ( 48%)]  Loss: 0.003316 (0.00337)  Time: 0.700s, 2926.37/s  (0.716s, 2858.46/s)  avg LR: 1.214e-03  iter ratio: 0.0000  Data: 0.025 (0.040)
INFO:Train: 225 [ 350/625 ( 56%)]  Loss: 0.003417 (0.00337)  Time: 0.699s, 2929.66/s  (0.715s, 2865.33/s)  avg LR: 1.214e-03  iter ratio: 0.0000  Data: 0.023 (0.038)
INFO:Train: 225 [ 400/625 ( 64%)]  Loss: 0.003125 (0.00335)  Time: 0.712s, 2876.83/s  (0.713s, 2870.54/s)  avg LR: 1.214e-03  iter ratio: 0.0000  Data: 0.034 (0.037)
INFO:Train: 225 [ 450/625 ( 72%)]  Loss: 0.003256 (0.00334)  Time: 0.711s, 2880.83/s  (0.712s, 2875.31/s)  avg LR: 1.214e-03  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 225 [ 500/625 ( 80%)]  Loss: 0.002857 (0.00329)  Time: 0.716s, 2861.52/s  (0.712s, 2877.51/s)  avg LR: 1.214e-03  iter ratio: 0.0000  Data: 0.041 (0.035)
INFO:Train: 225 [ 550/625 ( 88%)]  Loss: 0.003338 (0.00330)  Time: 0.724s, 2830.38/s  (0.712s, 2876.82/s)  avg LR: 1.214e-03  iter ratio: 0.0000  Data: 0.045 (0.035)
INFO:Train: 225 [ 600/625 ( 96%)]  Loss: 0.003025 (0.00328)  Time: 0.715s, 2866.03/s  (0.712s, 2875.69/s)  avg LR: 1.214e-03  iter ratio: 0.0000  Data: 0.040 (0.035)
INFO:Train: 225 [ 624/625 (100%)]  Loss: 0.003081 (0.00326)  Time: 0.675s, 3033.26/s  (0.712s, 2875.72/s)  avg LR: 1.214e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.356 (4.356)  Loss:  0.5938 (0.5938)  Acc@1: 86.0352 (86.0352)  Acc@5: 97.2656 (97.2656)
INFO:Test: [  24/24]  Time: 0.082 (0.512)  Loss:  0.5327 (0.9231)  Acc@1: 86.9104 (78.4300)  Acc@5: 97.8774 (94.3880)
INFO:225-epoch: remaining time 10.85 h
INFO:Train: 226 [   0/625 (  0%)]  Loss: 0.003771 (0.00377)  Time: 4.412s,  464.20/s  (4.412s,  464.20/s)  avg LR: 1.185e-03  iter ratio: 0.0000  Data: 3.714 (3.714)
INFO:Train: 226 [  50/625 (  8%)]  Loss: 0.002795 (0.00328)  Time: 0.718s, 2851.22/s  (0.787s, 2602.82/s)  avg LR: 1.185e-03  iter ratio: 0.0000  Data: 0.043 (0.108)
INFO:Train: 226 [ 100/625 ( 16%)]  Loss: 0.003235 (0.00327)  Time: 0.718s, 2852.98/s  (0.753s, 2718.92/s)  avg LR: 1.185e-03  iter ratio: 0.0000  Data: 0.039 (0.075)
INFO:Train: 226 [ 150/625 ( 24%)]  Loss: 0.003221 (0.00326)  Time: 0.722s, 2838.07/s  (0.742s, 2760.99/s)  avg LR: 1.185e-03  iter ratio: 0.0000  Data: 0.043 (0.063)
INFO:Train: 226 [ 200/625 ( 32%)]  Loss: 0.002947 (0.00319)  Time: 0.715s, 2863.36/s  (0.736s, 2783.45/s)  avg LR: 1.185e-03  iter ratio: 0.0000  Data: 0.038 (0.057)
INFO:Train: 226 [ 250/625 ( 40%)]  Loss: 0.003451 (0.00324)  Time: 0.721s, 2839.25/s  (0.732s, 2796.90/s)  avg LR: 1.185e-03  iter ratio: 0.0000  Data: 0.043 (0.054)
INFO:Train: 226 [ 300/625 ( 48%)]  Loss: 0.003869 (0.00333)  Time: 0.706s, 2901.06/s  (0.728s, 2814.22/s)  avg LR: 1.185e-03  iter ratio: 0.0000  Data: 0.027 (0.050)
INFO:Train: 226 [ 350/625 ( 56%)]  Loss: 0.002735 (0.00325)  Time: 0.703s, 2912.66/s  (0.724s, 2827.18/s)  avg LR: 1.185e-03  iter ratio: 0.0000  Data: 0.021 (0.046)
INFO:Train: 226 [ 400/625 ( 64%)]  Loss: 0.003326 (0.00326)  Time: 0.714s, 2867.79/s  (0.723s, 2831.17/s)  avg LR: 1.185e-03  iter ratio: 0.0000  Data: 0.037 (0.045)
INFO:Train: 226 [ 450/625 ( 72%)]  Loss: 0.002898 (0.00322)  Time: 0.702s, 2916.93/s  (0.723s, 2834.60/s)  avg LR: 1.185e-03  iter ratio: 0.0000  Data: 0.026 (0.045)
INFO:Train: 226 [ 500/625 ( 80%)]  Loss: 0.002997 (0.00320)  Time: 0.697s, 2937.24/s  (0.721s, 2841.71/s)  avg LR: 1.185e-03  iter ratio: 0.0000  Data: 0.022 (0.043)
INFO:Train: 226 [ 550/625 ( 88%)]  Loss: 0.003369 (0.00322)  Time: 0.701s, 2922.52/s  (0.719s, 2847.15/s)  avg LR: 1.185e-03  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 226 [ 600/625 ( 96%)]  Loss: 0.003034 (0.00320)  Time: 0.698s, 2932.57/s  (0.718s, 2852.26/s)  avg LR: 1.185e-03  iter ratio: 0.0000  Data: 0.024 (0.040)
INFO:Train: 226 [ 624/625 (100%)]  Loss: 0.002989 (0.00319)  Time: 0.675s, 3032.78/s  (0.718s, 2854.02/s)  avg LR: 1.185e-03  iter ratio: 0.0000  Data: 0.000 (0.040)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.310 (4.310)  Loss:  0.6187 (0.6187)  Acc@1: 84.6680 (84.6680)  Acc@5: 97.1680 (97.1680)
INFO:Test: [  24/24]  Time: 0.080 (0.507)  Loss:  0.4995 (0.9203)  Acc@1: 88.0896 (78.6320)  Acc@5: 97.5236 (94.3380)
INFO:226-epoch: remaining time 10.81 h
INFO:Train: 227 [   0/625 (  0%)]  Loss: 0.003128 (0.00313)  Time: 4.601s,  445.12/s  (4.601s,  445.12/s)  avg LR: 1.156e-03  iter ratio: 0.0000  Data: 3.905 (3.905)
INFO:Train: 227 [  50/625 (  8%)]  Loss: 0.003511 (0.00332)  Time: 0.704s, 2907.73/s  (0.787s, 2603.77/s)  avg LR: 1.156e-03  iter ratio: 0.0000  Data: 0.020 (0.107)
INFO:Train: 227 [ 100/625 ( 16%)]  Loss: 0.003615 (0.00342)  Time: 0.722s, 2838.34/s  (0.753s, 2718.35/s)  avg LR: 1.156e-03  iter ratio: 0.0000  Data: 0.036 (0.071)
INFO:Train: 227 [ 150/625 ( 24%)]  Loss: 0.003584 (0.00346)  Time: 0.717s, 2856.45/s  (0.743s, 2756.68/s)  avg LR: 1.156e-03  iter ratio: 0.0000  Data: 0.034 (0.060)
INFO:Train: 227 [ 200/625 ( 32%)]  Loss: 0.002885 (0.00334)  Time: 0.718s, 2854.01/s  (0.737s, 2777.40/s)  avg LR: 1.156e-03  iter ratio: 0.0000  Data: 0.034 (0.054)
INFO:Train: 227 [ 250/625 ( 40%)]  Loss: 0.003635 (0.00339)  Time: 0.702s, 2915.34/s  (0.732s, 2797.63/s)  avg LR: 1.156e-03  iter ratio: 0.0000  Data: 0.021 (0.048)
INFO:Train: 227 [ 300/625 ( 48%)]  Loss: 0.002899 (0.00332)  Time: 0.706s, 2899.69/s  (0.728s, 2812.80/s)  avg LR: 1.156e-03  iter ratio: 0.0000  Data: 0.025 (0.044)
INFO:Train: 227 [ 350/625 ( 56%)]  Loss: 0.003531 (0.00335)  Time: 0.719s, 2849.75/s  (0.726s, 2821.45/s)  avg LR: 1.156e-03  iter ratio: 0.0000  Data: 0.034 (0.042)
INFO:Train: 227 [ 400/625 ( 64%)]  Loss: 0.003289 (0.00334)  Time: 0.725s, 2825.30/s  (0.725s, 2826.07/s)  avg LR: 1.156e-03  iter ratio: 0.0000  Data: 0.044 (0.041)
INFO:Train: 227 [ 450/625 ( 72%)]  Loss: 0.003721 (0.00338)  Time: 0.707s, 2898.50/s  (0.724s, 2829.95/s)  avg LR: 1.156e-03  iter ratio: 0.0000  Data: 0.025 (0.040)
INFO:Train: 227 [ 500/625 ( 80%)]  Loss: 0.003509 (0.00339)  Time: 0.707s, 2895.40/s  (0.722s, 2836.26/s)  avg LR: 1.156e-03  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 227 [ 550/625 ( 88%)]  Loss: 0.003591 (0.00341)  Time: 0.705s, 2905.35/s  (0.721s, 2841.39/s)  avg LR: 1.156e-03  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 227 [ 600/625 ( 96%)]  Loss: 0.003757 (0.00344)  Time: 0.705s, 2906.89/s  (0.720s, 2845.73/s)  avg LR: 1.156e-03  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 227 [ 624/625 (100%)]  Loss: 0.003361 (0.00343)  Time: 0.679s, 3017.67/s  (0.719s, 2848.11/s)  avg LR: 1.156e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.313 (4.313)  Loss:  0.5820 (0.5820)  Acc@1: 86.3770 (86.3770)  Acc@5: 97.2656 (97.2656)
INFO:Test: [  24/24]  Time: 0.080 (0.509)  Loss:  0.5376 (0.9414)  Acc@1: 86.2028 (78.4960)  Acc@5: 96.9340 (94.1200)
INFO:227-epoch: remaining time 10.71 h
INFO:Train: 228 [   0/625 (  0%)]  Loss: 0.003077 (0.00308)  Time: 4.326s,  473.45/s  (4.326s,  473.45/s)  avg LR: 1.127e-03  iter ratio: 0.0000  Data: 3.624 (3.624)
INFO:Train: 228 [  50/625 (  8%)]  Loss: 0.004025 (0.00355)  Time: 0.706s, 2902.58/s  (0.776s, 2639.36/s)  avg LR: 1.127e-03  iter ratio: 0.0000  Data: 0.029 (0.098)
INFO:Train: 228 [ 100/625 ( 16%)]  Loss: 0.003285 (0.00346)  Time: 0.704s, 2907.82/s  (0.741s, 2763.96/s)  avg LR: 1.127e-03  iter ratio: 0.0000  Data: 0.028 (0.063)
INFO:Train: 228 [ 150/625 ( 24%)]  Loss: 0.003387 (0.00344)  Time: 0.708s, 2894.63/s  (0.730s, 2807.16/s)  avg LR: 1.127e-03  iter ratio: 0.0000  Data: 0.030 (0.052)
INFO:Train: 228 [ 200/625 ( 32%)]  Loss: 0.004050 (0.00356)  Time: 0.703s, 2915.15/s  (0.723s, 2830.79/s)  avg LR: 1.127e-03  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 228 [ 250/625 ( 40%)]  Loss: 0.003520 (0.00356)  Time: 0.707s, 2897.08/s  (0.720s, 2844.27/s)  avg LR: 1.127e-03  iter ratio: 0.0000  Data: 0.031 (0.043)
INFO:Train: 228 [ 300/625 ( 48%)]  Loss: 0.003184 (0.00350)  Time: 0.706s, 2901.85/s  (0.718s, 2853.71/s)  avg LR: 1.127e-03  iter ratio: 0.0000  Data: 0.030 (0.041)
INFO:Train: 228 [ 350/625 ( 56%)]  Loss: 0.004124 (0.00358)  Time: 0.710s, 2885.12/s  (0.716s, 2861.09/s)  avg LR: 1.127e-03  iter ratio: 0.0000  Data: 0.034 (0.039)
INFO:Train: 228 [ 400/625 ( 64%)]  Loss: 0.003581 (0.00358)  Time: 0.711s, 2881.70/s  (0.715s, 2865.28/s)  avg LR: 1.127e-03  iter ratio: 0.0000  Data: 0.037 (0.038)
INFO:Train: 228 [ 450/625 ( 72%)]  Loss: 0.003989 (0.00362)  Time: 0.702s, 2919.17/s  (0.713s, 2870.41/s)  avg LR: 1.127e-03  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 228 [ 500/625 ( 80%)]  Loss: 0.003440 (0.00361)  Time: 0.722s, 2835.74/s  (0.713s, 2871.54/s)  avg LR: 1.127e-03  iter ratio: 0.0000  Data: 0.046 (0.036)
INFO:Train: 228 [ 550/625 ( 88%)]  Loss: 0.003477 (0.00359)  Time: 0.721s, 2839.42/s  (0.714s, 2870.20/s)  avg LR: 1.127e-03  iter ratio: 0.0000  Data: 0.046 (0.036)
INFO:Train: 228 [ 600/625 ( 96%)]  Loss: 0.003333 (0.00357)  Time: 0.706s, 2901.98/s  (0.714s, 2869.13/s)  avg LR: 1.127e-03  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 228 [ 624/625 (100%)]  Loss: 0.003258 (0.00355)  Time: 0.676s, 3028.51/s  (0.713s, 2871.13/s)  avg LR: 1.127e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.282 (4.282)  Loss:  0.5996 (0.5996)  Acc@1: 85.5469 (85.5469)  Acc@5: 97.6562 (97.6562)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.4866 (0.9201)  Acc@1: 87.1462 (78.8180)  Acc@5: 97.7594 (94.5900)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-228.pth.tar', 78.81799997558593)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-224.pth.tar', 78.7520000805664)

INFO:228-epoch: remaining time 10.49 h
INFO:Train: 229 [   0/625 (  0%)]  Loss: 0.003983 (0.00398)  Time: 4.124s,  496.61/s  (4.124s,  496.61/s)  avg LR: 1.099e-03  iter ratio: 0.0000  Data: 3.432 (3.432)
INFO:Train: 229 [  50/625 (  8%)]  Loss: 0.004088 (0.00404)  Time: 0.723s, 2834.20/s  (0.774s, 2646.69/s)  avg LR: 1.099e-03  iter ratio: 0.0000  Data: 0.048 (0.094)
INFO:Train: 229 [ 100/625 ( 16%)]  Loss: 0.004213 (0.00409)  Time: 0.704s, 2909.72/s  (0.743s, 2758.19/s)  avg LR: 1.099e-03  iter ratio: 0.0000  Data: 0.024 (0.064)
INFO:Train: 229 [ 150/625 ( 24%)]  Loss: 0.003444 (0.00393)  Time: 0.710s, 2883.98/s  (0.730s, 2804.91/s)  avg LR: 1.099e-03  iter ratio: 0.0000  Data: 0.028 (0.051)
INFO:Train: 229 [ 200/625 ( 32%)]  Loss: 0.003590 (0.00386)  Time: 0.709s, 2888.67/s  (0.725s, 2825.56/s)  avg LR: 1.099e-03  iter ratio: 0.0000  Data: 0.024 (0.045)
INFO:Train: 229 [ 250/625 ( 40%)]  Loss: 0.003116 (0.00374)  Time: 0.706s, 2901.82/s  (0.722s, 2837.92/s)  avg LR: 1.099e-03  iter ratio: 0.0000  Data: 0.023 (0.041)
INFO:Train: 229 [ 300/625 ( 48%)]  Loss: 0.003430 (0.00369)  Time: 0.702s, 2915.69/s  (0.719s, 2847.25/s)  avg LR: 1.099e-03  iter ratio: 0.0000  Data: 0.023 (0.038)
INFO:Train: 229 [ 350/625 ( 56%)]  Loss: 0.004025 (0.00374)  Time: 0.708s, 2894.12/s  (0.718s, 2854.22/s)  avg LR: 1.099e-03  iter ratio: 0.0000  Data: 0.023 (0.036)
INFO:Train: 229 [ 400/625 ( 64%)]  Loss: 0.003434 (0.00370)  Time: 0.707s, 2897.46/s  (0.716s, 2859.47/s)  avg LR: 1.099e-03  iter ratio: 0.0000  Data: 0.019 (0.034)
INFO:Train: 229 [ 450/625 ( 72%)]  Loss: 0.002950 (0.00363)  Time: 0.701s, 2919.93/s  (0.715s, 2864.18/s)  avg LR: 1.099e-03  iter ratio: 0.0000  Data: 0.024 (0.033)
INFO:Train: 229 [ 500/625 ( 80%)]  Loss: 0.003167 (0.00359)  Time: 0.706s, 2899.58/s  (0.714s, 2866.79/s)  avg LR: 1.099e-03  iter ratio: 0.0000  Data: 0.031 (0.032)
INFO:Train: 229 [ 550/625 ( 88%)]  Loss: 0.003572 (0.00358)  Time: 0.723s, 2834.41/s  (0.714s, 2869.65/s)  avg LR: 1.099e-03  iter ratio: 0.0000  Data: 0.046 (0.031)
INFO:Train: 229 [ 600/625 ( 96%)]  Loss: 0.003517 (0.00358)  Time: 0.703s, 2914.68/s  (0.714s, 2870.03/s)  avg LR: 1.099e-03  iter ratio: 0.0000  Data: 0.022 (0.031)
INFO:Train: 229 [ 624/625 (100%)]  Loss: 0.003003 (0.00354)  Time: 0.672s, 3046.41/s  (0.713s, 2871.84/s)  avg LR: 1.099e-03  iter ratio: 0.0000  Data: 0.000 (0.031)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.345 (4.345)  Loss:  0.6064 (0.6064)  Acc@1: 85.8887 (85.8887)  Acc@5: 97.3145 (97.3145)
INFO:Test: [  24/24]  Time: 0.080 (0.509)  Loss:  0.5454 (0.9186)  Acc@1: 85.7311 (78.9620)  Acc@5: 97.5236 (94.5140)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-229.pth.tar', 78.96200000732422)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-228.pth.tar', 78.81799997558593)

INFO:229-epoch: remaining time 10.37 h
INFO:Train: 230 [   0/625 (  0%)]  Loss: 0.003572 (0.00357)  Time: 4.216s,  485.76/s  (4.216s,  485.76/s)  avg LR: 1.071e-03  iter ratio: 0.0000  Data: 3.514 (3.514)
INFO:Train: 230 [  50/625 (  8%)]  Loss: 0.003174 (0.00337)  Time: 0.705s, 2903.83/s  (0.784s, 2612.70/s)  avg LR: 1.071e-03  iter ratio: 0.0000  Data: 0.025 (0.099)
INFO:Train: 230 [ 100/625 ( 16%)]  Loss: 0.002842 (0.00320)  Time: 0.709s, 2890.18/s  (0.747s, 2743.12/s)  avg LR: 1.071e-03  iter ratio: 0.0000  Data: 0.029 (0.062)
INFO:Train: 230 [ 150/625 ( 24%)]  Loss: 0.004070 (0.00341)  Time: 0.702s, 2918.72/s  (0.733s, 2793.93/s)  avg LR: 1.071e-03  iter ratio: 0.0000  Data: 0.024 (0.050)
INFO:Train: 230 [ 200/625 ( 32%)]  Loss: 0.002732 (0.00328)  Time: 0.715s, 2864.09/s  (0.727s, 2818.65/s)  avg LR: 1.071e-03  iter ratio: 0.0000  Data: 0.040 (0.044)
INFO:Train: 230 [ 250/625 ( 40%)]  Loss: 0.003205 (0.00327)  Time: 0.722s, 2837.14/s  (0.725s, 2825.07/s)  avg LR: 1.071e-03  iter ratio: 0.0000  Data: 0.046 (0.043)
INFO:Train: 230 [ 300/625 ( 48%)]  Loss: 0.002623 (0.00317)  Time: 0.721s, 2840.47/s  (0.724s, 2829.47/s)  avg LR: 1.071e-03  iter ratio: 0.0000  Data: 0.045 (0.042)
INFO:Train: 230 [ 350/625 ( 56%)]  Loss: 0.003139 (0.00317)  Time: 0.721s, 2839.41/s  (0.723s, 2832.21/s)  avg LR: 1.071e-03  iter ratio: 0.0000  Data: 0.046 (0.042)
INFO:Train: 230 [ 400/625 ( 64%)]  Loss: 0.004182 (0.00328)  Time: 0.724s, 2828.04/s  (0.722s, 2835.21/s)  avg LR: 1.071e-03  iter ratio: 0.0000  Data: 0.046 (0.042)
INFO:Train: 230 [ 450/625 ( 72%)]  Loss: 0.003392 (0.00329)  Time: 0.705s, 2906.68/s  (0.722s, 2838.46/s)  avg LR: 1.071e-03  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 230 [ 500/625 ( 80%)]  Loss: 0.004446 (0.00340)  Time: 0.704s, 2910.82/s  (0.720s, 2843.93/s)  avg LR: 1.071e-03  iter ratio: 0.0000  Data: 0.025 (0.040)
INFO:Train: 230 [ 550/625 ( 88%)]  Loss: 0.003365 (0.00340)  Time: 0.703s, 2912.53/s  (0.719s, 2848.56/s)  avg LR: 1.071e-03  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 230 [ 600/625 ( 96%)]  Loss: 0.003116 (0.00337)  Time: 0.705s, 2905.02/s  (0.718s, 2853.13/s)  avg LR: 1.071e-03  iter ratio: 0.0000  Data: 0.022 (0.038)
INFO:Train: 230 [ 624/625 (100%)]  Loss: 0.003102 (0.00335)  Time: 0.678s, 3020.65/s  (0.717s, 2855.41/s)  avg LR: 1.071e-03  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.308 (4.308)  Loss:  0.6226 (0.6226)  Acc@1: 84.7656 (84.7656)  Acc@5: 96.8750 (96.8750)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.5381 (0.9328)  Acc@1: 86.6745 (78.4400)  Acc@5: 96.9340 (94.2120)
INFO:230-epoch: remaining time 10.28 h
INFO:Train: 231 [   0/625 (  0%)]  Loss: 0.003759 (0.00376)  Time: 4.222s,  485.05/s  (4.222s,  485.05/s)  avg LR: 1.043e-03  iter ratio: 0.0000  Data: 3.522 (3.522)
INFO:Train: 231 [  50/625 (  8%)]  Loss: 0.003875 (0.00382)  Time: 0.717s, 2854.70/s  (0.781s, 2623.49/s)  avg LR: 1.043e-03  iter ratio: 0.0000  Data: 0.038 (0.101)
INFO:Train: 231 [ 100/625 ( 16%)]  Loss: 0.003833 (0.00382)  Time: 0.701s, 2919.47/s  (0.748s, 2738.65/s)  avg LR: 1.043e-03  iter ratio: 0.0000  Data: 0.027 (0.070)
INFO:Train: 231 [ 150/625 ( 24%)]  Loss: 0.004032 (0.00387)  Time: 0.713s, 2871.33/s  (0.734s, 2790.89/s)  avg LR: 1.043e-03  iter ratio: 0.0000  Data: 0.033 (0.056)
INFO:Train: 231 [ 200/625 ( 32%)]  Loss: 0.002828 (0.00367)  Time: 0.710s, 2886.04/s  (0.728s, 2813.62/s)  avg LR: 1.043e-03  iter ratio: 0.0000  Data: 0.033 (0.050)
INFO:Train: 231 [ 250/625 ( 40%)]  Loss: 0.002999 (0.00355)  Time: 0.708s, 2894.55/s  (0.724s, 2827.98/s)  avg LR: 1.043e-03  iter ratio: 0.0000  Data: 0.032 (0.046)
INFO:Train: 231 [ 300/625 ( 48%)]  Loss: 0.003379 (0.00353)  Time: 0.710s, 2884.92/s  (0.722s, 2837.86/s)  avg LR: 1.043e-03  iter ratio: 0.0000  Data: 0.031 (0.043)
INFO:Train: 231 [ 350/625 ( 56%)]  Loss: 0.004255 (0.00362)  Time: 0.703s, 2911.60/s  (0.720s, 2846.22/s)  avg LR: 1.043e-03  iter ratio: 0.0000  Data: 0.024 (0.041)
INFO:Train: 231 [ 400/625 ( 64%)]  Loss: 0.003692 (0.00363)  Time: 0.707s, 2897.82/s  (0.718s, 2851.82/s)  avg LR: 1.043e-03  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 231 [ 450/625 ( 72%)]  Loss: 0.003116 (0.00358)  Time: 0.721s, 2839.53/s  (0.718s, 2853.24/s)  avg LR: 1.043e-03  iter ratio: 0.0000  Data: 0.046 (0.039)
INFO:Train: 231 [ 500/625 ( 80%)]  Loss: 0.002957 (0.00352)  Time: 0.706s, 2899.80/s  (0.717s, 2857.27/s)  avg LR: 1.043e-03  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 231 [ 550/625 ( 88%)]  Loss: 0.004053 (0.00356)  Time: 0.709s, 2887.62/s  (0.716s, 2860.89/s)  avg LR: 1.043e-03  iter ratio: 0.0000  Data: 0.022 (0.037)
INFO:Train: 231 [ 600/625 ( 96%)]  Loss: 0.003079 (0.00353)  Time: 0.718s, 2853.58/s  (0.715s, 2862.78/s)  avg LR: 1.043e-03  iter ratio: 0.0000  Data: 0.041 (0.036)
INFO:Train: 231 [ 624/625 (100%)]  Loss: 0.003742 (0.00354)  Time: 0.675s, 3032.81/s  (0.715s, 2862.86/s)  avg LR: 1.043e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.369 (4.369)  Loss:  0.5918 (0.5918)  Acc@1: 86.5723 (86.5723)  Acc@5: 97.4609 (97.4609)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.5508 (0.9280)  Acc@1: 86.3208 (78.8920)  Acc@5: 97.6415 (94.4800)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-229.pth.tar', 78.96200000732422)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-231.pth.tar', 78.89200000488282)

INFO:231-epoch: remaining time 10.14 h
INFO:Train: 232 [   0/625 (  0%)]  Loss: 0.003293 (0.00329)  Time: 4.165s,  491.73/s  (4.165s,  491.73/s)  avg LR: 1.016e-03  iter ratio: 0.0000  Data: 3.474 (3.474)
INFO:Train: 232 [  50/625 (  8%)]  Loss: 0.003006 (0.00315)  Time: 0.705s, 2903.78/s  (0.772s, 2652.45/s)  avg LR: 1.016e-03  iter ratio: 0.0000  Data: 0.030 (0.096)
INFO:Train: 232 [ 100/625 ( 16%)]  Loss: 0.003483 (0.00326)  Time: 0.703s, 2913.58/s  (0.740s, 2768.80/s)  avg LR: 1.016e-03  iter ratio: 0.0000  Data: 0.028 (0.064)
INFO:Train: 232 [ 150/625 ( 24%)]  Loss: 0.003446 (0.00331)  Time: 0.716s, 2859.09/s  (0.729s, 2808.53/s)  avg LR: 1.016e-03  iter ratio: 0.0000  Data: 0.042 (0.053)
INFO:Train: 232 [ 200/625 ( 32%)]  Loss: 0.003539 (0.00335)  Time: 0.712s, 2876.54/s  (0.727s, 2818.54/s)  avg LR: 1.016e-03  iter ratio: 0.0000  Data: 0.036 (0.051)
INFO:Train: 232 [ 250/625 ( 40%)]  Loss: 0.003412 (0.00336)  Time: 0.719s, 2846.53/s  (0.724s, 2829.37/s)  avg LR: 1.016e-03  iter ratio: 0.0000  Data: 0.045 (0.048)
INFO:Train: 232 [ 300/625 ( 48%)]  Loss: 0.003132 (0.00333)  Time: 0.703s, 2911.25/s  (0.721s, 2838.63/s)  avg LR: 1.016e-03  iter ratio: 0.0000  Data: 0.029 (0.046)
INFO:Train: 232 [ 350/625 ( 56%)]  Loss: 0.003752 (0.00338)  Time: 0.707s, 2896.18/s  (0.719s, 2847.80/s)  avg LR: 1.016e-03  iter ratio: 0.0000  Data: 0.032 (0.043)
INFO:Train: 232 [ 400/625 ( 64%)]  Loss: 0.003847 (0.00343)  Time: 0.707s, 2895.54/s  (0.717s, 2854.85/s)  avg LR: 1.016e-03  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 232 [ 450/625 ( 72%)]  Loss: 0.003406 (0.00343)  Time: 0.702s, 2916.05/s  (0.716s, 2860.24/s)  avg LR: 1.016e-03  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 232 [ 500/625 ( 80%)]  Loss: 0.003919 (0.00348)  Time: 0.704s, 2908.19/s  (0.715s, 2863.68/s)  avg LR: 1.016e-03  iter ratio: 0.0000  Data: 0.030 (0.039)
INFO:Train: 232 [ 550/625 ( 88%)]  Loss: 0.003672 (0.00349)  Time: 0.702s, 2916.21/s  (0.714s, 2866.62/s)  avg LR: 1.016e-03  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 232 [ 600/625 ( 96%)]  Loss: 0.003132 (0.00346)  Time: 0.710s, 2883.98/s  (0.714s, 2869.43/s)  avg LR: 1.016e-03  iter ratio: 0.0000  Data: 0.032 (0.037)
INFO:Train: 232 [ 624/625 (100%)]  Loss: 0.003273 (0.00345)  Time: 0.675s, 3033.09/s  (0.713s, 2870.78/s)  avg LR: 1.016e-03  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.354 (4.354)  Loss:  0.5703 (0.5703)  Acc@1: 87.1582 (87.1582)  Acc@5: 97.4121 (97.4121)
INFO:Test: [  24/24]  Time: 0.083 (0.502)  Loss:  0.5195 (0.8899)  Acc@1: 85.9670 (79.2400)  Acc@5: 97.5236 (94.5720)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-232.pth.tar', 79.23999998046875)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-229.pth.tar', 78.96200000732422)

INFO:232-epoch: remaining time 9.97 h
INFO:Train: 233 [   0/625 (  0%)]  Loss: 0.003547 (0.00355)  Time: 4.281s,  478.38/s  (4.281s,  478.38/s)  avg LR: 9.889e-04  iter ratio: 0.0000  Data: 3.581 (3.581)
INFO:Train: 233 [  50/625 (  8%)]  Loss: 0.002881 (0.00321)  Time: 0.710s, 2885.82/s  (0.780s, 2625.55/s)  avg LR: 9.889e-04  iter ratio: 0.0000  Data: 0.028 (0.101)
INFO:Train: 233 [ 100/625 ( 16%)]  Loss: 0.003241 (0.00322)  Time: 0.703s, 2911.37/s  (0.743s, 2758.00/s)  avg LR: 9.889e-04  iter ratio: 0.0000  Data: 0.027 (0.065)
INFO:Train: 233 [ 150/625 ( 24%)]  Loss: 0.003568 (0.00331)  Time: 0.706s, 2901.34/s  (0.730s, 2806.90/s)  avg LR: 9.889e-04  iter ratio: 0.0000  Data: 0.029 (0.053)
INFO:Train: 233 [ 200/625 ( 32%)]  Loss: 0.003518 (0.00335)  Time: 0.700s, 2926.88/s  (0.723s, 2831.65/s)  avg LR: 9.889e-04  iter ratio: 0.0000  Data: 0.024 (0.046)
INFO:Train: 233 [ 250/625 ( 40%)]  Loss: 0.003698 (0.00341)  Time: 0.705s, 2906.46/s  (0.719s, 2847.17/s)  avg LR: 9.889e-04  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 233 [ 300/625 ( 48%)]  Loss: 0.004123 (0.00351)  Time: 0.699s, 2928.41/s  (0.717s, 2857.43/s)  avg LR: 9.889e-04  iter ratio: 0.0000  Data: 0.023 (0.040)
INFO:Train: 233 [ 350/625 ( 56%)]  Loss: 0.003265 (0.00348)  Time: 0.702s, 2917.30/s  (0.715s, 2864.98/s)  avg LR: 9.889e-04  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 233 [ 400/625 ( 64%)]  Loss: 0.004000 (0.00354)  Time: 0.701s, 2921.92/s  (0.713s, 2870.94/s)  avg LR: 9.889e-04  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 233 [ 450/625 ( 72%)]  Loss: 0.003549 (0.00354)  Time: 0.698s, 2934.64/s  (0.712s, 2876.28/s)  avg LR: 9.889e-04  iter ratio: 0.0000  Data: 0.022 (0.036)
INFO:Train: 233 [ 500/625 ( 80%)]  Loss: 0.003738 (0.00356)  Time: 0.705s, 2903.04/s  (0.711s, 2879.42/s)  avg LR: 9.889e-04  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 233 [ 550/625 ( 88%)]  Loss: 0.003269 (0.00353)  Time: 0.697s, 2937.62/s  (0.711s, 2880.69/s)  avg LR: 9.889e-04  iter ratio: 0.0000  Data: 0.023 (0.035)
INFO:Train: 233 [ 600/625 ( 96%)]  Loss: 0.003337 (0.00352)  Time: 0.701s, 2920.18/s  (0.710s, 2883.02/s)  avg LR: 9.889e-04  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 233 [ 624/625 (100%)]  Loss: 0.004212 (0.00357)  Time: 0.673s, 3041.81/s  (0.710s, 2884.74/s)  avg LR: 9.889e-04  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.341 (4.341)  Loss:  0.5879 (0.5879)  Acc@1: 85.8887 (85.8887)  Acc@5: 97.7051 (97.7051)
INFO:Test: [  24/24]  Time: 0.080 (0.509)  Loss:  0.5679 (0.9089)  Acc@1: 86.2028 (79.3040)  Acc@5: 97.6415 (94.5780)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-233.pth.tar', 79.30399995361329)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-232.pth.tar', 79.23999998046875)

INFO:233-epoch: remaining time 9.81 h
INFO:Train: 234 [   0/625 (  0%)]  Loss: 0.003268 (0.00327)  Time: 4.080s,  501.95/s  (4.080s,  501.95/s)  avg LR: 9.622e-04  iter ratio: 0.0000  Data: 3.393 (3.393)
INFO:Train: 234 [  50/625 (  8%)]  Loss: 0.003474 (0.00337)  Time: 0.707s, 2898.11/s  (0.775s, 2641.91/s)  avg LR: 9.622e-04  iter ratio: 0.0000  Data: 0.030 (0.097)
INFO:Train: 234 [ 100/625 ( 16%)]  Loss: 0.003682 (0.00347)  Time: 0.706s, 2898.96/s  (0.743s, 2757.73/s)  avg LR: 9.622e-04  iter ratio: 0.0000  Data: 0.030 (0.064)
INFO:Train: 234 [ 150/625 ( 24%)]  Loss: 0.003330 (0.00344)  Time: 0.707s, 2895.86/s  (0.731s, 2800.12/s)  avg LR: 9.622e-04  iter ratio: 0.0000  Data: 0.030 (0.053)
INFO:Train: 234 [ 200/625 ( 32%)]  Loss: 0.003612 (0.00347)  Time: 0.704s, 2909.13/s  (0.725s, 2824.36/s)  avg LR: 9.622e-04  iter ratio: 0.0000  Data: 0.027 (0.047)
INFO:Train: 234 [ 250/625 ( 40%)]  Loss: 0.002731 (0.00335)  Time: 0.715s, 2866.14/s  (0.724s, 2829.22/s)  avg LR: 9.622e-04  iter ratio: 0.0000  Data: 0.040 (0.045)
INFO:Train: 234 [ 300/625 ( 48%)]  Loss: 0.003870 (0.00342)  Time: 0.718s, 2853.50/s  (0.723s, 2831.67/s)  avg LR: 9.622e-04  iter ratio: 0.0000  Data: 0.043 (0.044)
INFO:Train: 234 [ 350/625 ( 56%)]  Loss: 0.003715 (0.00346)  Time: 0.717s, 2858.08/s  (0.723s, 2833.22/s)  avg LR: 9.622e-04  iter ratio: 0.0000  Data: 0.041 (0.044)
INFO:Train: 234 [ 400/625 ( 64%)]  Loss: 0.002942 (0.00340)  Time: 0.718s, 2850.64/s  (0.723s, 2834.51/s)  avg LR: 9.622e-04  iter ratio: 0.0000  Data: 0.041 (0.043)
INFO:Train: 234 [ 450/625 ( 72%)]  Loss: 0.003302 (0.00339)  Time: 0.711s, 2881.56/s  (0.722s, 2836.14/s)  avg LR: 9.622e-04  iter ratio: 0.0000  Data: 0.035 (0.043)
INFO:Train: 234 [ 500/625 ( 80%)]  Loss: 0.003016 (0.00336)  Time: 0.701s, 2919.54/s  (0.721s, 2841.26/s)  avg LR: 9.622e-04  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 234 [ 550/625 ( 88%)]  Loss: 0.003609 (0.00338)  Time: 0.704s, 2909.48/s  (0.719s, 2846.66/s)  avg LR: 9.622e-04  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 234 [ 600/625 ( 96%)]  Loss: 0.003531 (0.00339)  Time: 0.704s, 2910.15/s  (0.718s, 2851.29/s)  avg LR: 9.622e-04  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 234 [ 624/625 (100%)]  Loss: 0.003711 (0.00341)  Time: 0.675s, 3035.43/s  (0.718s, 2853.60/s)  avg LR: 9.622e-04  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.319 (4.319)  Loss:  0.5835 (0.5835)  Acc@1: 87.2559 (87.2559)  Acc@5: 97.6074 (97.6074)
INFO:Test: [  24/24]  Time: 0.080 (0.509)  Loss:  0.5601 (0.9176)  Acc@1: 87.0283 (79.2060)  Acc@5: 97.0519 (94.5560)
INFO:234-epoch: remaining time 9.78 h
INFO:Train: 235 [   0/625 (  0%)]  Loss: 0.003405 (0.00341)  Time: 4.346s,  471.20/s  (4.346s,  471.20/s)  avg LR: 9.358e-04  iter ratio: 0.0000  Data: 3.646 (3.646)
INFO:Train: 235 [  50/625 (  8%)]  Loss: 0.003748 (0.00358)  Time: 0.707s, 2896.38/s  (0.775s, 2641.44/s)  avg LR: 9.358e-04  iter ratio: 0.0000  Data: 0.025 (0.097)
INFO:Train: 235 [ 100/625 ( 16%)]  Loss: 0.003220 (0.00346)  Time: 0.698s, 2934.96/s  (0.739s, 2769.94/s)  avg LR: 9.358e-04  iter ratio: 0.0000  Data: 0.023 (0.061)
INFO:Train: 235 [ 150/625 ( 24%)]  Loss: 0.003821 (0.00355)  Time: 0.700s, 2927.73/s  (0.727s, 2815.26/s)  avg LR: 9.358e-04  iter ratio: 0.0000  Data: 0.023 (0.050)
INFO:Train: 235 [ 200/625 ( 32%)]  Loss: 0.003072 (0.00345)  Time: 0.698s, 2932.89/s  (0.721s, 2838.71/s)  avg LR: 9.358e-04  iter ratio: 0.0000  Data: 0.023 (0.044)
INFO:Train: 235 [ 250/625 ( 40%)]  Loss: 0.002598 (0.00331)  Time: 0.703s, 2913.30/s  (0.718s, 2852.98/s)  avg LR: 9.358e-04  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 235 [ 300/625 ( 48%)]  Loss: 0.003741 (0.00337)  Time: 0.710s, 2884.51/s  (0.716s, 2860.69/s)  avg LR: 9.358e-04  iter ratio: 0.0000  Data: 0.024 (0.038)
INFO:Train: 235 [ 350/625 ( 56%)]  Loss: 0.004395 (0.00350)  Time: 0.705s, 2903.56/s  (0.715s, 2865.51/s)  avg LR: 9.358e-04  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 235 [ 400/625 ( 64%)]  Loss: 0.003114 (0.00346)  Time: 0.713s, 2873.59/s  (0.715s, 2863.84/s)  avg LR: 9.358e-04  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 235 [ 450/625 ( 72%)]  Loss: 0.003648 (0.00348)  Time: 0.702s, 2915.76/s  (0.714s, 2869.33/s)  avg LR: 9.358e-04  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 235 [ 500/625 ( 80%)]  Loss: 0.003275 (0.00346)  Time: 0.707s, 2896.76/s  (0.713s, 2872.60/s)  avg LR: 9.358e-04  iter ratio: 0.0000  Data: 0.033 (0.033)
INFO:Train: 235 [ 550/625 ( 88%)]  Loss: 0.003749 (0.00348)  Time: 0.707s, 2897.99/s  (0.712s, 2874.99/s)  avg LR: 9.358e-04  iter ratio: 0.0000  Data: 0.030 (0.033)
INFO:Train: 235 [ 600/625 ( 96%)]  Loss: 0.003677 (0.00350)  Time: 0.711s, 2880.37/s  (0.712s, 2876.76/s)  avg LR: 9.358e-04  iter ratio: 0.0000  Data: 0.034 (0.032)
INFO:Train: 235 [ 624/625 (100%)]  Loss: 0.003241 (0.00348)  Time: 0.675s, 3034.03/s  (0.712s, 2878.30/s)  avg LR: 9.358e-04  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.339 (4.339)  Loss:  0.5986 (0.5986)  Acc@1: 85.8887 (85.8887)  Acc@5: 97.6562 (97.6562)
INFO:Test: [  24/24]  Time: 0.080 (0.510)  Loss:  0.5396 (0.8903)  Acc@1: 85.2594 (79.4500)  Acc@5: 97.4057 (94.7040)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-235.pth.tar', 79.44999993164062)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-233.pth.tar', 79.30399995361329)

INFO:235-epoch: remaining time 9.58 h
INFO:Train: 236 [   0/625 (  0%)]  Loss: 0.002864 (0.00286)  Time: 4.295s,  476.87/s  (4.295s,  476.87/s)  avg LR: 9.098e-04  iter ratio: 0.0000  Data: 3.596 (3.596)
INFO:Train: 236 [  50/625 (  8%)]  Loss: 0.004427 (0.00365)  Time: 0.700s, 2927.64/s  (0.781s, 2620.95/s)  avg LR: 9.098e-04  iter ratio: 0.0000  Data: 0.023 (0.099)
INFO:Train: 236 [ 100/625 ( 16%)]  Loss: 0.003030 (0.00344)  Time: 0.702s, 2916.59/s  (0.744s, 2753.70/s)  avg LR: 9.098e-04  iter ratio: 0.0000  Data: 0.021 (0.062)
INFO:Train: 236 [ 150/625 ( 24%)]  Loss: 0.003414 (0.00343)  Time: 0.700s, 2926.10/s  (0.732s, 2798.78/s)  avg LR: 9.098e-04  iter ratio: 0.0000  Data: 0.024 (0.050)
INFO:Train: 236 [ 200/625 ( 32%)]  Loss: 0.003122 (0.00337)  Time: 0.700s, 2924.90/s  (0.725s, 2824.41/s)  avg LR: 9.098e-04  iter ratio: 0.0000  Data: 0.025 (0.044)
INFO:Train: 236 [ 250/625 ( 40%)]  Loss: 0.003407 (0.00338)  Time: 0.706s, 2899.42/s  (0.721s, 2839.67/s)  avg LR: 9.098e-04  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 236 [ 300/625 ( 48%)]  Loss: 0.003352 (0.00337)  Time: 0.702s, 2919.36/s  (0.719s, 2849.02/s)  avg LR: 9.098e-04  iter ratio: 0.0000  Data: 0.024 (0.038)
INFO:Train: 236 [ 350/625 ( 56%)]  Loss: 0.003029 (0.00333)  Time: 0.700s, 2924.93/s  (0.717s, 2855.34/s)  avg LR: 9.098e-04  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 236 [ 400/625 ( 64%)]  Loss: 0.003320 (0.00333)  Time: 0.701s, 2920.45/s  (0.716s, 2861.04/s)  avg LR: 9.098e-04  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 236 [ 450/625 ( 72%)]  Loss: 0.003753 (0.00337)  Time: 0.709s, 2886.65/s  (0.715s, 2864.22/s)  avg LR: 9.098e-04  iter ratio: 0.0000  Data: 0.036 (0.035)
INFO:Train: 236 [ 500/625 ( 80%)]  Loss: 0.002951 (0.00333)  Time: 0.711s, 2879.79/s  (0.714s, 2867.10/s)  avg LR: 9.098e-04  iter ratio: 0.0000  Data: 0.036 (0.034)
INFO:Train: 236 [ 550/625 ( 88%)]  Loss: 0.003086 (0.00331)  Time: 0.718s, 2850.69/s  (0.715s, 2865.86/s)  avg LR: 9.098e-04  iter ratio: 0.0000  Data: 0.044 (0.035)
INFO:Train: 236 [ 600/625 ( 96%)]  Loss: 0.003640 (0.00334)  Time: 0.718s, 2850.60/s  (0.715s, 2864.57/s)  avg LR: 9.098e-04  iter ratio: 0.0000  Data: 0.043 (0.035)
INFO:Train: 236 [ 624/625 (100%)]  Loss: 0.002978 (0.00331)  Time: 0.675s, 3035.14/s  (0.715s, 2865.13/s)  avg LR: 9.098e-04  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.317 (4.317)  Loss:  0.5820 (0.5820)  Acc@1: 85.9375 (85.9375)  Acc@5: 97.5586 (97.5586)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.5205 (0.8798)  Acc@1: 87.3821 (79.4760)  Acc@5: 97.2877 (94.5840)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-236.pth.tar', 79.47599994873048)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-235.pth.tar', 79.44999993164062)

INFO:236-epoch: remaining time 9.49 h
INFO:Train: 237 [   0/625 (  0%)]  Loss: 0.003231 (0.00323)  Time: 4.544s,  450.72/s  (4.544s,  450.72/s)  avg LR: 8.841e-04  iter ratio: 0.0000  Data: 3.844 (3.844)
INFO:Train: 237 [  50/625 (  8%)]  Loss: 0.003399 (0.00332)  Time: 0.726s, 2822.14/s  (0.785s, 2610.48/s)  avg LR: 8.841e-04  iter ratio: 0.0000  Data: 0.040 (0.104)
INFO:Train: 237 [ 100/625 ( 16%)]  Loss: 0.002993 (0.00321)  Time: 0.728s, 2814.88/s  (0.750s, 2731.61/s)  avg LR: 8.841e-04  iter ratio: 0.0000  Data: 0.046 (0.070)
INFO:Train: 237 [ 150/625 ( 24%)]  Loss: 0.003494 (0.00328)  Time: 0.719s, 2847.82/s  (0.739s, 2770.55/s)  avg LR: 8.841e-04  iter ratio: 0.0000  Data: 0.043 (0.060)
INFO:Train: 237 [ 200/625 ( 32%)]  Loss: 0.003862 (0.00340)  Time: 0.722s, 2834.65/s  (0.734s, 2789.00/s)  avg LR: 8.841e-04  iter ratio: 0.0000  Data: 0.044 (0.056)
INFO:Train: 237 [ 250/625 ( 40%)]  Loss: 0.002676 (0.00328)  Time: 0.719s, 2848.68/s  (0.731s, 2801.62/s)  avg LR: 8.841e-04  iter ratio: 0.0000  Data: 0.044 (0.052)
INFO:Train: 237 [ 300/625 ( 48%)]  Loss: 0.002889 (0.00322)  Time: 0.718s, 2852.92/s  (0.729s, 2809.34/s)  avg LR: 8.841e-04  iter ratio: 0.0000  Data: 0.044 (0.050)
INFO:Train: 237 [ 350/625 ( 56%)]  Loss: 0.003136 (0.00321)  Time: 0.716s, 2858.65/s  (0.728s, 2814.87/s)  avg LR: 8.841e-04  iter ratio: 0.0000  Data: 0.042 (0.049)
INFO:Train: 237 [ 400/625 ( 64%)]  Loss: 0.003332 (0.00322)  Time: 0.716s, 2861.88/s  (0.727s, 2818.74/s)  avg LR: 8.841e-04  iter ratio: 0.0000  Data: 0.041 (0.048)
INFO:Train: 237 [ 450/625 ( 72%)]  Loss: 0.003470 (0.00325)  Time: 0.701s, 2919.91/s  (0.726s, 2822.63/s)  avg LR: 8.841e-04  iter ratio: 0.0000  Data: 0.026 (0.047)
INFO:Train: 237 [ 500/625 ( 80%)]  Loss: 0.004068 (0.00332)  Time: 0.702s, 2916.25/s  (0.724s, 2829.65/s)  avg LR: 8.841e-04  iter ratio: 0.0000  Data: 0.026 (0.045)
INFO:Train: 237 [ 550/625 ( 88%)]  Loss: 0.002880 (0.00329)  Time: 0.703s, 2914.78/s  (0.722s, 2835.85/s)  avg LR: 8.841e-04  iter ratio: 0.0000  Data: 0.021 (0.043)
INFO:Train: 237 [ 600/625 ( 96%)]  Loss: 0.003141 (0.00327)  Time: 0.705s, 2905.96/s  (0.721s, 2840.56/s)  avg LR: 8.841e-04  iter ratio: 0.0000  Data: 0.023 (0.041)
INFO:Train: 237 [ 624/625 (100%)]  Loss: 0.003799 (0.00331)  Time: 0.675s, 3036.21/s  (0.720s, 2843.12/s)  avg LR: 8.841e-04  iter ratio: 0.0000  Data: 0.000 (0.040)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.352 (4.352)  Loss:  0.6035 (0.6035)  Acc@1: 86.3281 (86.3281)  Acc@5: 97.8027 (97.8027)
INFO:Test: [  24/24]  Time: 0.080 (0.511)  Loss:  0.5664 (0.9103)  Acc@1: 86.0849 (79.5560)  Acc@5: 97.0519 (94.6960)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-237.pth.tar', 79.55600003173828)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-236.pth.tar', 79.47599994873048)

INFO:237-epoch: remaining time 9.44 h
INFO:Train: 238 [   0/625 (  0%)]  Loss: 0.003676 (0.00368)  Time: 4.356s,  470.19/s  (4.356s,  470.19/s)  avg LR: 8.588e-04  iter ratio: 0.0000  Data: 3.657 (3.657)
INFO:Train: 238 [  50/625 (  8%)]  Loss: 0.003496 (0.00359)  Time: 0.702s, 2918.49/s  (0.777s, 2636.55/s)  avg LR: 8.588e-04  iter ratio: 0.0000  Data: 0.023 (0.096)
INFO:Train: 238 [ 100/625 ( 16%)]  Loss: 0.003364 (0.00351)  Time: 0.704s, 2909.04/s  (0.741s, 2762.29/s)  avg LR: 8.588e-04  iter ratio: 0.0000  Data: 0.021 (0.060)
INFO:Train: 238 [ 150/625 ( 24%)]  Loss: 0.003151 (0.00342)  Time: 0.712s, 2877.12/s  (0.730s, 2806.92/s)  avg LR: 8.588e-04  iter ratio: 0.0000  Data: 0.034 (0.048)
INFO:Train: 238 [ 200/625 ( 32%)]  Loss: 0.002877 (0.00331)  Time: 0.710s, 2882.92/s  (0.726s, 2821.52/s)  avg LR: 8.588e-04  iter ratio: 0.0000  Data: 0.034 (0.045)
INFO:Train: 238 [ 250/625 ( 40%)]  Loss: 0.004264 (0.00347)  Time: 0.708s, 2892.46/s  (0.724s, 2829.03/s)  avg LR: 8.588e-04  iter ratio: 0.0000  Data: 0.031 (0.044)
INFO:Train: 238 [ 300/625 ( 48%)]  Loss: 0.004097 (0.00356)  Time: 0.706s, 2902.89/s  (0.722s, 2836.47/s)  avg LR: 8.588e-04  iter ratio: 0.0000  Data: 0.030 (0.041)
INFO:Train: 238 [ 350/625 ( 56%)]  Loss: 0.003865 (0.00360)  Time: 0.716s, 2858.98/s  (0.721s, 2840.08/s)  avg LR: 8.588e-04  iter ratio: 0.0000  Data: 0.043 (0.041)
INFO:Train: 238 [ 400/625 ( 64%)]  Loss: 0.002603 (0.00349)  Time: 0.718s, 2851.78/s  (0.721s, 2842.41/s)  avg LR: 8.588e-04  iter ratio: 0.0000  Data: 0.042 (0.040)
INFO:Train: 238 [ 450/625 ( 72%)]  Loss: 0.002710 (0.00341)  Time: 0.713s, 2873.29/s  (0.720s, 2844.25/s)  avg LR: 8.588e-04  iter ratio: 0.0000  Data: 0.039 (0.040)
INFO:Train: 238 [ 500/625 ( 80%)]  Loss: 0.003141 (0.00339)  Time: 0.706s, 2900.52/s  (0.719s, 2849.66/s)  avg LR: 8.588e-04  iter ratio: 0.0000  Data: 0.030 (0.039)
INFO:Train: 238 [ 550/625 ( 88%)]  Loss: 0.003001 (0.00335)  Time: 0.707s, 2897.74/s  (0.717s, 2854.62/s)  avg LR: 8.588e-04  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 238 [ 600/625 ( 96%)]  Loss: 0.003240 (0.00334)  Time: 0.706s, 2901.11/s  (0.716s, 2859.08/s)  avg LR: 8.588e-04  iter ratio: 0.0000  Data: 0.024 (0.037)
INFO:Train: 238 [ 624/625 (100%)]  Loss: 0.003481 (0.00335)  Time: 0.676s, 3028.47/s  (0.716s, 2861.33/s)  avg LR: 8.588e-04  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.306 (4.306)  Loss:  0.5972 (0.5972)  Acc@1: 86.3281 (86.3281)  Acc@5: 97.3633 (97.3633)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.5449 (0.8937)  Acc@1: 86.4387 (79.7120)  Acc@5: 97.4057 (94.7740)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-238.pth.tar', 79.71200005615235)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-237.pth.tar', 79.55600003173828)

INFO:238-epoch: remaining time 9.24 h
INFO:Train: 239 [   0/625 (  0%)]  Loss: 0.003096 (0.00310)  Time: 4.234s,  483.75/s  (4.234s,  483.75/s)  avg LR: 8.338e-04  iter ratio: 0.0000  Data: 3.540 (3.540)
INFO:Train: 239 [  50/625 (  8%)]  Loss: 0.003264 (0.00318)  Time: 0.703s, 2914.93/s  (0.780s, 2624.31/s)  avg LR: 8.338e-04  iter ratio: 0.0000  Data: 0.023 (0.097)
INFO:Train: 239 [ 100/625 ( 16%)]  Loss: 0.003691 (0.00335)  Time: 0.707s, 2898.28/s  (0.743s, 2756.04/s)  avg LR: 8.338e-04  iter ratio: 0.0000  Data: 0.030 (0.064)
INFO:Train: 239 [ 150/625 ( 24%)]  Loss: 0.002636 (0.00317)  Time: 0.705s, 2903.40/s  (0.731s, 2802.88/s)  avg LR: 8.338e-04  iter ratio: 0.0000  Data: 0.030 (0.052)
INFO:Train: 239 [ 200/625 ( 32%)]  Loss: 0.002765 (0.00309)  Time: 0.710s, 2884.25/s  (0.724s, 2827.98/s)  avg LR: 8.338e-04  iter ratio: 0.0000  Data: 0.031 (0.046)
INFO:Train: 239 [ 250/625 ( 40%)]  Loss: 0.003332 (0.00313)  Time: 0.721s, 2840.34/s  (0.722s, 2837.62/s)  avg LR: 8.338e-04  iter ratio: 0.0000  Data: 0.046 (0.044)
INFO:Train: 239 [ 300/625 ( 48%)]  Loss: 0.003479 (0.00318)  Time: 0.719s, 2848.60/s  (0.721s, 2840.05/s)  avg LR: 8.338e-04  iter ratio: 0.0000  Data: 0.044 (0.044)
INFO:Train: 239 [ 350/625 ( 56%)]  Loss: 0.003233 (0.00319)  Time: 0.706s, 2901.77/s  (0.721s, 2842.02/s)  avg LR: 8.338e-04  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 239 [ 400/625 ( 64%)]  Loss: 0.003585 (0.00323)  Time: 0.720s, 2843.89/s  (0.720s, 2844.40/s)  avg LR: 8.338e-04  iter ratio: 0.0000  Data: 0.044 (0.043)
INFO:Train: 239 [ 450/625 ( 72%)]  Loss: 0.003692 (0.00328)  Time: 0.721s, 2842.37/s  (0.720s, 2845.95/s)  avg LR: 8.338e-04  iter ratio: 0.0000  Data: 0.046 (0.042)
INFO:Train: 239 [ 500/625 ( 80%)]  Loss: 0.003341 (0.00328)  Time: 0.705s, 2904.27/s  (0.718s, 2850.43/s)  avg LR: 8.338e-04  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 239 [ 550/625 ( 88%)]  Loss: 0.003163 (0.00327)  Time: 0.711s, 2881.27/s  (0.717s, 2855.86/s)  avg LR: 8.338e-04  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 239 [ 600/625 ( 96%)]  Loss: 0.003032 (0.00325)  Time: 0.704s, 2907.67/s  (0.716s, 2860.45/s)  avg LR: 8.338e-04  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 239 [ 624/625 (100%)]  Loss: 0.003168 (0.00325)  Time: 0.676s, 3030.63/s  (0.715s, 2862.95/s)  avg LR: 8.338e-04  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.352 (4.352)  Loss:  0.5864 (0.5864)  Acc@1: 86.2305 (86.2305)  Acc@5: 97.6562 (97.6562)
INFO:Test: [  24/24]  Time: 0.080 (0.500)  Loss:  0.5352 (0.8687)  Acc@1: 85.7311 (79.9040)  Acc@5: 97.4057 (94.8940)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-239.pth.tar', 79.90400000732421)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-238.pth.tar', 79.71200005615235)

INFO:239-epoch: remaining time 9.11 h
INFO:Train: 240 [   0/625 (  0%)]  Loss: 0.003010 (0.00301)  Time: 4.192s,  488.51/s  (4.192s,  488.51/s)  avg LR: 8.092e-04  iter ratio: 0.0000  Data: 3.503 (3.503)
INFO:Train: 240 [  50/625 (  8%)]  Loss: 0.003589 (0.00330)  Time: 0.707s, 2894.78/s  (0.775s, 2641.49/s)  avg LR: 8.092e-04  iter ratio: 0.0000  Data: 0.027 (0.096)
INFO:Train: 240 [ 100/625 ( 16%)]  Loss: 0.002380 (0.00299)  Time: 0.706s, 2899.64/s  (0.741s, 2765.12/s)  avg LR: 8.092e-04  iter ratio: 0.0000  Data: 0.024 (0.062)
INFO:Train: 240 [ 150/625 ( 24%)]  Loss: 0.002912 (0.00297)  Time: 0.696s, 2941.72/s  (0.729s, 2810.57/s)  avg LR: 8.092e-04  iter ratio: 0.0000  Data: 0.021 (0.049)
INFO:Train: 240 [ 200/625 ( 32%)]  Loss: 0.003451 (0.00307)  Time: 0.715s, 2865.35/s  (0.723s, 2831.92/s)  avg LR: 8.092e-04  iter ratio: 0.0000  Data: 0.041 (0.044)
INFO:Train: 240 [ 250/625 ( 40%)]  Loss: 0.003616 (0.00316)  Time: 0.719s, 2846.70/s  (0.722s, 2838.50/s)  avg LR: 8.092e-04  iter ratio: 0.0000  Data: 0.038 (0.043)
INFO:Train: 240 [ 300/625 ( 48%)]  Loss: 0.003319 (0.00318)  Time: 0.722s, 2835.47/s  (0.720s, 2842.65/s)  avg LR: 8.092e-04  iter ratio: 0.0000  Data: 0.044 (0.042)
INFO:Train: 240 [ 350/625 ( 56%)]  Loss: 0.003537 (0.00323)  Time: 0.719s, 2848.82/s  (0.720s, 2846.02/s)  avg LR: 8.092e-04  iter ratio: 0.0000  Data: 0.042 (0.041)
INFO:Train: 240 [ 400/625 ( 64%)]  Loss: 0.003193 (0.00322)  Time: 0.713s, 2873.94/s  (0.719s, 2847.84/s)  avg LR: 8.092e-04  iter ratio: 0.0000  Data: 0.036 (0.041)
INFO:Train: 240 [ 450/625 ( 72%)]  Loss: 0.004120 (0.00331)  Time: 0.714s, 2868.49/s  (0.719s, 2849.25/s)  avg LR: 8.092e-04  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 240 [ 500/625 ( 80%)]  Loss: 0.003191 (0.00330)  Time: 0.709s, 2888.04/s  (0.718s, 2853.78/s)  avg LR: 8.092e-04  iter ratio: 0.0000  Data: 0.030 (0.040)
INFO:Train: 240 [ 550/625 ( 88%)]  Loss: 0.003824 (0.00335)  Time: 0.710s, 2883.33/s  (0.716s, 2858.66/s)  avg LR: 8.092e-04  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 240 [ 600/625 ( 96%)]  Loss: 0.003123 (0.00333)  Time: 0.706s, 2899.58/s  (0.715s, 2862.57/s)  avg LR: 8.092e-04  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 240 [ 624/625 (100%)]  Loss: 0.002799 (0.00329)  Time: 0.674s, 3038.74/s  (0.715s, 2864.92/s)  avg LR: 8.092e-04  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.344 (4.344)  Loss:  0.5635 (0.5635)  Acc@1: 86.7188 (86.7188)  Acc@5: 97.9492 (97.9492)
INFO:Test: [  24/24]  Time: 0.080 (0.511)  Loss:  0.4946 (0.8586)  Acc@1: 87.2641 (80.0060)  Acc@5: 97.9953 (95.0100)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-240.pth.tar', 80.00599989746094)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-239.pth.tar', 79.90400000732421)

INFO:240-epoch: remaining time 8.98 h
INFO:Train: 241 [   0/625 (  0%)]  Loss: 0.003130 (0.00313)  Time: 4.673s,  438.24/s  (4.673s,  438.24/s)  avg LR: 7.849e-04  iter ratio: 0.0000  Data: 3.978 (3.978)
INFO:Train: 241 [  50/625 (  8%)]  Loss: 0.003756 (0.00344)  Time: 0.705s, 2904.75/s  (0.783s, 2616.39/s)  avg LR: 7.849e-04  iter ratio: 0.0000  Data: 0.019 (0.100)
INFO:Train: 241 [ 100/625 ( 16%)]  Loss: 0.003256 (0.00338)  Time: 0.709s, 2890.46/s  (0.745s, 2750.53/s)  avg LR: 7.849e-04  iter ratio: 0.0000  Data: 0.020 (0.061)
INFO:Train: 241 [ 150/625 ( 24%)]  Loss: 0.002896 (0.00326)  Time: 0.708s, 2893.92/s  (0.731s, 2799.88/s)  avg LR: 7.849e-04  iter ratio: 0.0000  Data: 0.025 (0.049)
INFO:Train: 241 [ 200/625 ( 32%)]  Loss: 0.003747 (0.00336)  Time: 0.706s, 2899.14/s  (0.725s, 2825.35/s)  avg LR: 7.849e-04  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 241 [ 250/625 ( 40%)]  Loss: 0.003741 (0.00342)  Time: 0.706s, 2901.96/s  (0.721s, 2841.38/s)  avg LR: 7.849e-04  iter ratio: 0.0000  Data: 0.022 (0.040)
INFO:Train: 241 [ 300/625 ( 48%)]  Loss: 0.002858 (0.00334)  Time: 0.706s, 2902.49/s  (0.718s, 2851.91/s)  avg LR: 7.849e-04  iter ratio: 0.0000  Data: 0.024 (0.038)
INFO:Train: 241 [ 350/625 ( 56%)]  Loss: 0.003377 (0.00335)  Time: 0.710s, 2885.61/s  (0.716s, 2859.50/s)  avg LR: 7.849e-04  iter ratio: 0.0000  Data: 0.022 (0.036)
INFO:Train: 241 [ 400/625 ( 64%)]  Loss: 0.003044 (0.00331)  Time: 0.706s, 2900.41/s  (0.715s, 2865.04/s)  avg LR: 7.849e-04  iter ratio: 0.0000  Data: 0.021 (0.034)
INFO:Train: 241 [ 450/625 ( 72%)]  Loss: 0.002835 (0.00326)  Time: 0.701s, 2923.47/s  (0.714s, 2869.91/s)  avg LR: 7.849e-04  iter ratio: 0.0000  Data: 0.023 (0.033)
INFO:Train: 241 [ 500/625 ( 80%)]  Loss: 0.003367 (0.00327)  Time: 0.704s, 2908.42/s  (0.713s, 2873.35/s)  avg LR: 7.849e-04  iter ratio: 0.0000  Data: 0.029 (0.032)
INFO:Train: 241 [ 550/625 ( 88%)]  Loss: 0.003325 (0.00328)  Time: 0.704s, 2907.55/s  (0.712s, 2876.11/s)  avg LR: 7.849e-04  iter ratio: 0.0000  Data: 0.030 (0.032)
INFO:Train: 241 [ 600/625 ( 96%)]  Loss: 0.003739 (0.00331)  Time: 0.721s, 2841.94/s  (0.712s, 2878.00/s)  avg LR: 7.849e-04  iter ratio: 0.0000  Data: 0.046 (0.032)
INFO:Train: 241 [ 624/625 (100%)]  Loss: 0.003418 (0.00332)  Time: 0.673s, 3044.23/s  (0.712s, 2877.87/s)  avg LR: 7.849e-04  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.360 (4.360)  Loss:  0.5928 (0.5928)  Acc@1: 86.0840 (86.0840)  Acc@5: 97.7051 (97.7051)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.5542 (0.8791)  Acc@1: 86.5566 (79.9680)  Acc@5: 97.2877 (94.9140)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-240.pth.tar', 80.00599989746094)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-241.pth.tar', 79.96799997802735)

INFO:241-epoch: remaining time 8.81 h
INFO:Train: 242 [   0/625 (  0%)]  Loss: 0.002848 (0.00285)  Time: 4.089s,  500.83/s  (4.089s,  500.83/s)  avg LR: 7.609e-04  iter ratio: 0.0000  Data: 3.404 (3.404)
INFO:Train: 242 [  50/625 (  8%)]  Loss: 0.003563 (0.00321)  Time: 0.704s, 2908.15/s  (0.777s, 2634.32/s)  avg LR: 7.609e-04  iter ratio: 0.0000  Data: 0.022 (0.098)
INFO:Train: 242 [ 100/625 ( 16%)]  Loss: 0.003324 (0.00325)  Time: 0.705s, 2903.03/s  (0.742s, 2760.71/s)  avg LR: 7.609e-04  iter ratio: 0.0000  Data: 0.023 (0.061)
INFO:Train: 242 [ 150/625 ( 24%)]  Loss: 0.003667 (0.00335)  Time: 0.705s, 2903.15/s  (0.730s, 2807.03/s)  avg LR: 7.609e-04  iter ratio: 0.0000  Data: 0.019 (0.048)
INFO:Train: 242 [ 200/625 ( 32%)]  Loss: 0.002847 (0.00325)  Time: 0.705s, 2904.09/s  (0.724s, 2830.66/s)  avg LR: 7.609e-04  iter ratio: 0.0000  Data: 0.020 (0.041)
INFO:Train: 242 [ 250/625 ( 40%)]  Loss: 0.003603 (0.00331)  Time: 0.705s, 2906.57/s  (0.720s, 2844.96/s)  avg LR: 7.609e-04  iter ratio: 0.0000  Data: 0.020 (0.037)
INFO:Train: 242 [ 300/625 ( 48%)]  Loss: 0.002992 (0.00326)  Time: 0.708s, 2891.55/s  (0.718s, 2854.08/s)  avg LR: 7.609e-04  iter ratio: 0.0000  Data: 0.021 (0.034)
INFO:Train: 242 [ 350/625 ( 56%)]  Loss: 0.003801 (0.00333)  Time: 0.704s, 2908.36/s  (0.716s, 2860.95/s)  avg LR: 7.609e-04  iter ratio: 0.0000  Data: 0.020 (0.032)
INFO:Train: 242 [ 400/625 ( 64%)]  Loss: 0.002294 (0.00322)  Time: 0.709s, 2887.02/s  (0.715s, 2865.95/s)  avg LR: 7.609e-04  iter ratio: 0.0000  Data: 0.033 (0.031)
INFO:Train: 242 [ 450/625 ( 72%)]  Loss: 0.003180 (0.00321)  Time: 0.714s, 2866.95/s  (0.715s, 2864.74/s)  avg LR: 7.609e-04  iter ratio: 0.0000  Data: 0.040 (0.032)
INFO:Train: 242 [ 500/625 ( 80%)]  Loss: 0.003395 (0.00323)  Time: 0.703s, 2913.89/s  (0.714s, 2867.85/s)  avg LR: 7.609e-04  iter ratio: 0.0000  Data: 0.027 (0.032)
INFO:Train: 242 [ 550/625 ( 88%)]  Loss: 0.003364 (0.00324)  Time: 0.700s, 2925.06/s  (0.713s, 2871.63/s)  avg LR: 7.609e-04  iter ratio: 0.0000  Data: 0.027 (0.032)
INFO:Train: 242 [ 600/625 ( 96%)]  Loss: 0.003170 (0.00323)  Time: 0.700s, 2927.64/s  (0.712s, 2875.20/s)  avg LR: 7.609e-04  iter ratio: 0.0000  Data: 0.023 (0.031)
INFO:Train: 242 [ 624/625 (100%)]  Loss: 0.003451 (0.00325)  Time: 0.675s, 3035.94/s  (0.712s, 2877.37/s)  avg LR: 7.609e-04  iter ratio: 0.0000  Data: 0.000 (0.031)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.304 (4.304)  Loss:  0.5547 (0.5547)  Acc@1: 87.9883 (87.9883)  Acc@5: 97.5098 (97.5098)
INFO:Test: [  24/24]  Time: 0.080 (0.511)  Loss:  0.4966 (0.8585)  Acc@1: 86.4387 (80.1060)  Acc@5: 97.4057 (94.9320)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-242.pth.tar', 80.10600005615234)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-240.pth.tar', 80.00599989746094)

INFO:242-epoch: remaining time 8.69 h
INFO:Train: 243 [   0/625 (  0%)]  Loss: 0.003029 (0.00303)  Time: 4.312s,  474.91/s  (4.312s,  474.91/s)  avg LR: 7.374e-04  iter ratio: 0.0000  Data: 3.617 (3.617)
INFO:Train: 243 [  50/625 (  8%)]  Loss: 0.003487 (0.00326)  Time: 0.702s, 2915.68/s  (0.775s, 2642.30/s)  avg LR: 7.374e-04  iter ratio: 0.0000  Data: 0.024 (0.097)
INFO:Train: 243 [ 100/625 ( 16%)]  Loss: 0.004379 (0.00363)  Time: 0.702s, 2917.82/s  (0.740s, 2768.01/s)  avg LR: 7.374e-04  iter ratio: 0.0000  Data: 0.025 (0.062)
INFO:Train: 243 [ 150/625 ( 24%)]  Loss: 0.003257 (0.00354)  Time: 0.702s, 2916.84/s  (0.728s, 2813.15/s)  avg LR: 7.374e-04  iter ratio: 0.0000  Data: 0.026 (0.050)
INFO:Train: 243 [ 200/625 ( 32%)]  Loss: 0.002927 (0.00342)  Time: 0.703s, 2913.80/s  (0.722s, 2835.73/s)  avg LR: 7.374e-04  iter ratio: 0.0000  Data: 0.021 (0.043)
INFO:Train: 243 [ 250/625 ( 40%)]  Loss: 0.003021 (0.00335)  Time: 0.703s, 2914.85/s  (0.719s, 2849.63/s)  avg LR: 7.374e-04  iter ratio: 0.0000  Data: 0.022 (0.039)
INFO:Train: 243 [ 300/625 ( 48%)]  Loss: 0.002759 (0.00327)  Time: 0.712s, 2877.01/s  (0.716s, 2858.40/s)  avg LR: 7.374e-04  iter ratio: 0.0000  Data: 0.020 (0.036)
INFO:Train: 243 [ 350/625 ( 56%)]  Loss: 0.003460 (0.00329)  Time: 0.705s, 2904.59/s  (0.715s, 2862.50/s)  avg LR: 7.374e-04  iter ratio: 0.0000  Data: 0.021 (0.035)
INFO:Train: 243 [ 400/625 ( 64%)]  Loss: 0.003042 (0.00326)  Time: 0.711s, 2879.69/s  (0.714s, 2867.56/s)  avg LR: 7.374e-04  iter ratio: 0.0000  Data: 0.021 (0.033)
INFO:Train: 243 [ 450/625 ( 72%)]  Loss: 0.003128 (0.00325)  Time: 0.703s, 2912.49/s  (0.713s, 2871.83/s)  avg LR: 7.374e-04  iter ratio: 0.0000  Data: 0.021 (0.032)
INFO:Train: 243 [ 500/625 ( 80%)]  Loss: 0.004121 (0.00333)  Time: 0.714s, 2866.88/s  (0.712s, 2874.60/s)  avg LR: 7.374e-04  iter ratio: 0.0000  Data: 0.024 (0.031)
INFO:Train: 243 [ 550/625 ( 88%)]  Loss: 0.003911 (0.00338)  Time: 0.717s, 2856.96/s  (0.713s, 2873.95/s)  avg LR: 7.374e-04  iter ratio: 0.0000  Data: 0.035 (0.031)
INFO:Train: 243 [ 600/625 ( 96%)]  Loss: 0.002939 (0.00334)  Time: 0.714s, 2870.06/s  (0.712s, 2875.66/s)  avg LR: 7.374e-04  iter ratio: 0.0000  Data: 0.025 (0.031)
INFO:Train: 243 [ 624/625 (100%)]  Loss: 0.002607 (0.00329)  Time: 0.676s, 3030.48/s  (0.712s, 2877.35/s)  avg LR: 7.374e-04  iter ratio: 0.0000  Data: 0.000 (0.030)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.342 (4.342)  Loss:  0.5679 (0.5679)  Acc@1: 86.9629 (86.9629)  Acc@5: 97.3633 (97.3633)
INFO:Test: [  24/24]  Time: 0.080 (0.500)  Loss:  0.5439 (0.8783)  Acc@1: 85.2594 (79.7520)  Acc@5: 97.1698 (94.7700)
INFO:243-epoch: remaining time 8.55 h
INFO:Train: 244 [   0/625 (  0%)]  Loss: 0.002993 (0.00299)  Time: 4.258s,  481.00/s  (4.258s,  481.00/s)  avg LR: 7.141e-04  iter ratio: 0.0000  Data: 3.567 (3.567)
INFO:Train: 244 [  50/625 (  8%)]  Loss: 0.003734 (0.00336)  Time: 0.706s, 2900.01/s  (0.777s, 2636.89/s)  avg LR: 7.141e-04  iter ratio: 0.0000  Data: 0.027 (0.098)
INFO:Train: 244 [ 100/625 ( 16%)]  Loss: 0.003564 (0.00343)  Time: 0.707s, 2894.82/s  (0.743s, 2757.45/s)  avg LR: 7.141e-04  iter ratio: 0.0000  Data: 0.028 (0.064)
INFO:Train: 244 [ 150/625 ( 24%)]  Loss: 0.003148 (0.00336)  Time: 0.704s, 2910.79/s  (0.731s, 2801.46/s)  avg LR: 7.141e-04  iter ratio: 0.0000  Data: 0.026 (0.052)
INFO:Train: 244 [ 200/625 ( 32%)]  Loss: 0.003608 (0.00341)  Time: 0.708s, 2893.33/s  (0.725s, 2825.48/s)  avg LR: 7.141e-04  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 244 [ 250/625 ( 40%)]  Loss: 0.003565 (0.00344)  Time: 0.707s, 2894.85/s  (0.721s, 2839.83/s)  avg LR: 7.141e-04  iter ratio: 0.0000  Data: 0.025 (0.042)
INFO:Train: 244 [ 300/625 ( 48%)]  Loss: 0.002846 (0.00335)  Time: 0.711s, 2881.61/s  (0.719s, 2849.30/s)  avg LR: 7.141e-04  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 244 [ 350/625 ( 56%)]  Loss: 0.002994 (0.00331)  Time: 0.709s, 2890.00/s  (0.717s, 2856.36/s)  avg LR: 7.141e-04  iter ratio: 0.0000  Data: 0.024 (0.038)
INFO:Train: 244 [ 400/625 ( 64%)]  Loss: 0.003163 (0.00329)  Time: 0.706s, 2900.21/s  (0.716s, 2861.56/s)  avg LR: 7.141e-04  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 244 [ 450/625 ( 72%)]  Loss: 0.002966 (0.00326)  Time: 0.710s, 2884.83/s  (0.715s, 2865.60/s)  avg LR: 7.141e-04  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 244 [ 500/625 ( 80%)]  Loss: 0.003120 (0.00325)  Time: 0.703s, 2914.85/s  (0.714s, 2869.54/s)  avg LR: 7.141e-04  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 244 [ 550/625 ( 88%)]  Loss: 0.003087 (0.00323)  Time: 0.702s, 2916.66/s  (0.713s, 2873.41/s)  avg LR: 7.141e-04  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 244 [ 600/625 ( 96%)]  Loss: 0.003851 (0.00328)  Time: 0.702s, 2915.75/s  (0.712s, 2876.30/s)  avg LR: 7.141e-04  iter ratio: 0.0000  Data: 0.023 (0.033)
INFO:Train: 244 [ 624/625 (100%)]  Loss: 0.003221 (0.00328)  Time: 0.672s, 3046.38/s  (0.712s, 2878.40/s)  avg LR: 7.141e-04  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.300 (4.300)  Loss:  0.6094 (0.6094)  Acc@1: 86.3281 (86.3281)  Acc@5: 97.7539 (97.7539)
INFO:Test: [  24/24]  Time: 0.080 (0.510)  Loss:  0.5864 (0.9112)  Acc@1: 86.2028 (79.8400)  Acc@5: 97.5236 (94.9900)
INFO:244-epoch: remaining time 8.43 h
INFO:Train: 245 [   0/625 (  0%)]  Loss: 0.004400 (0.00440)  Time: 4.222s,  485.12/s  (4.222s,  485.12/s)  avg LR: 6.913e-04  iter ratio: 0.0000  Data: 3.522 (3.522)
INFO:Train: 245 [  50/625 (  8%)]  Loss: 0.003352 (0.00388)  Time: 0.712s, 2878.08/s  (0.784s, 2613.21/s)  avg LR: 6.913e-04  iter ratio: 0.0000  Data: 0.026 (0.104)
INFO:Train: 245 [ 100/625 ( 16%)]  Loss: 0.003385 (0.00371)  Time: 0.711s, 2881.72/s  (0.746s, 2743.75/s)  avg LR: 6.913e-04  iter ratio: 0.0000  Data: 0.034 (0.067)
INFO:Train: 245 [ 150/625 ( 24%)]  Loss: 0.003237 (0.00359)  Time: 0.708s, 2890.87/s  (0.734s, 2790.18/s)  avg LR: 6.913e-04  iter ratio: 0.0000  Data: 0.029 (0.055)
INFO:Train: 245 [ 200/625 ( 32%)]  Loss: 0.003296 (0.00353)  Time: 0.711s, 2881.73/s  (0.728s, 2814.05/s)  avg LR: 6.913e-04  iter ratio: 0.0000  Data: 0.034 (0.049)
INFO:Train: 245 [ 250/625 ( 40%)]  Loss: 0.003038 (0.00345)  Time: 0.710s, 2886.07/s  (0.724s, 2828.88/s)  avg LR: 6.913e-04  iter ratio: 0.0000  Data: 0.032 (0.045)
INFO:Train: 245 [ 300/625 ( 48%)]  Loss: 0.003231 (0.00342)  Time: 0.711s, 2878.85/s  (0.722s, 2838.38/s)  avg LR: 6.913e-04  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 245 [ 350/625 ( 56%)]  Loss: 0.003805 (0.00347)  Time: 0.707s, 2895.76/s  (0.720s, 2845.06/s)  avg LR: 6.913e-04  iter ratio: 0.0000  Data: 0.030 (0.041)
INFO:Train: 245 [ 400/625 ( 64%)]  Loss: 0.004151 (0.00354)  Time: 0.707s, 2897.88/s  (0.719s, 2849.92/s)  avg LR: 6.913e-04  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 245 [ 450/625 ( 72%)]  Loss: 0.003072 (0.00350)  Time: 0.717s, 2857.14/s  (0.718s, 2853.82/s)  avg LR: 6.913e-04  iter ratio: 0.0000  Data: 0.039 (0.039)
INFO:Train: 245 [ 500/625 ( 80%)]  Loss: 0.002724 (0.00343)  Time: 0.713s, 2872.90/s  (0.717s, 2857.64/s)  avg LR: 6.913e-04  iter ratio: 0.0000  Data: 0.031 (0.038)
INFO:Train: 245 [ 550/625 ( 88%)]  Loss: 0.003855 (0.00346)  Time: 0.707s, 2895.93/s  (0.716s, 2861.42/s)  avg LR: 6.913e-04  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 245 [ 600/625 ( 96%)]  Loss: 0.003104 (0.00343)  Time: 0.710s, 2885.06/s  (0.715s, 2865.15/s)  avg LR: 6.913e-04  iter ratio: 0.0000  Data: 0.032 (0.036)
INFO:Train: 245 [ 624/625 (100%)]  Loss: 0.003372 (0.00343)  Time: 0.675s, 3032.04/s  (0.714s, 2867.47/s)  avg LR: 6.913e-04  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.323 (4.323)  Loss:  0.5952 (0.5952)  Acc@1: 86.4746 (86.4746)  Acc@5: 97.7051 (97.7051)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.5449 (0.8930)  Acc@1: 86.7925 (80.1440)  Acc@5: 97.7594 (94.9900)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-245.pth.tar', 80.1440000805664)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-242.pth.tar', 80.10600005615234)

INFO:245-epoch: remaining time 8.33 h
INFO:Train: 246 [   0/625 (  0%)]  Loss: 0.003903 (0.00390)  Time: 4.205s,  487.09/s  (4.205s,  487.09/s)  avg LR: 6.688e-04  iter ratio: 0.0000  Data: 3.521 (3.521)
INFO:Train: 246 [  50/625 (  8%)]  Loss: 0.003158 (0.00353)  Time: 0.700s, 2924.01/s  (0.775s, 2641.34/s)  avg LR: 6.688e-04  iter ratio: 0.0000  Data: 0.026 (0.099)
INFO:Train: 246 [ 100/625 ( 16%)]  Loss: 0.002838 (0.00330)  Time: 0.705s, 2906.33/s  (0.741s, 2763.36/s)  avg LR: 6.688e-04  iter ratio: 0.0000  Data: 0.030 (0.065)
INFO:Train: 246 [ 150/625 ( 24%)]  Loss: 0.002674 (0.00314)  Time: 0.702s, 2916.37/s  (0.729s, 2807.49/s)  avg LR: 6.688e-04  iter ratio: 0.0000  Data: 0.021 (0.053)
INFO:Train: 246 [ 200/625 ( 32%)]  Loss: 0.003370 (0.00319)  Time: 0.705s, 2903.79/s  (0.724s, 2827.46/s)  avg LR: 6.688e-04  iter ratio: 0.0000  Data: 0.031 (0.048)
INFO:Train: 246 [ 250/625 ( 40%)]  Loss: 0.004122 (0.00334)  Time: 0.710s, 2883.27/s  (0.721s, 2841.25/s)  avg LR: 6.688e-04  iter ratio: 0.0000  Data: 0.035 (0.045)
INFO:Train: 246 [ 300/625 ( 48%)]  Loss: 0.003210 (0.00333)  Time: 0.707s, 2895.11/s  (0.718s, 2850.43/s)  avg LR: 6.688e-04  iter ratio: 0.0000  Data: 0.029 (0.042)
INFO:Train: 246 [ 350/625 ( 56%)]  Loss: 0.002939 (0.00328)  Time: 0.705s, 2906.90/s  (0.717s, 2857.22/s)  avg LR: 6.688e-04  iter ratio: 0.0000  Data: 0.030 (0.041)
INFO:Train: 246 [ 400/625 ( 64%)]  Loss: 0.003642 (0.00332)  Time: 0.708s, 2891.95/s  (0.715s, 2862.36/s)  avg LR: 6.688e-04  iter ratio: 0.0000  Data: 0.033 (0.039)
INFO:Train: 246 [ 450/625 ( 72%)]  Loss: 0.003065 (0.00329)  Time: 0.713s, 2873.95/s  (0.714s, 2866.53/s)  avg LR: 6.688e-04  iter ratio: 0.0000  Data: 0.024 (0.038)
INFO:Train: 246 [ 500/625 ( 80%)]  Loss: 0.004009 (0.00336)  Time: 0.704s, 2907.69/s  (0.714s, 2869.93/s)  avg LR: 6.688e-04  iter ratio: 0.0000  Data: 0.029 (0.037)
INFO:Train: 246 [ 550/625 ( 88%)]  Loss: 0.004133 (0.00342)  Time: 0.706s, 2902.21/s  (0.713s, 2871.13/s)  avg LR: 6.688e-04  iter ratio: 0.0000  Data: 0.029 (0.037)
INFO:Train: 246 [ 600/625 ( 96%)]  Loss: 0.003126 (0.00340)  Time: 0.707s, 2897.82/s  (0.713s, 2871.85/s)  avg LR: 6.688e-04  iter ratio: 0.0000  Data: 0.022 (0.037)
INFO:Train: 246 [ 624/625 (100%)]  Loss: 0.003233 (0.00339)  Time: 0.678s, 3022.62/s  (0.713s, 2873.45/s)  avg LR: 6.688e-04  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.299 (4.299)  Loss:  0.5503 (0.5503)  Acc@1: 87.6953 (87.6953)  Acc@5: 98.0469 (98.0469)
INFO:Test: [  24/24]  Time: 0.081 (0.510)  Loss:  0.5312 (0.8662)  Acc@1: 86.7925 (80.3480)  Acc@5: 97.4057 (95.1100)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-246.pth.tar', 80.34800008056641)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-245.pth.tar', 80.1440000805664)

INFO:246-epoch: remaining time 8.18 h
INFO:Train: 247 [   0/625 (  0%)]  Loss: 0.002753 (0.00275)  Time: 4.324s,  473.68/s  (4.324s,  473.68/s)  avg LR: 6.467e-04  iter ratio: 0.0000  Data: 3.631 (3.631)
INFO:Train: 247 [  50/625 (  8%)]  Loss: 0.003185 (0.00297)  Time: 0.706s, 2901.00/s  (0.777s, 2636.41/s)  avg LR: 6.467e-04  iter ratio: 0.0000  Data: 0.028 (0.100)
INFO:Train: 247 [ 100/625 ( 16%)]  Loss: 0.003675 (0.00320)  Time: 0.711s, 2881.70/s  (0.742s, 2760.93/s)  avg LR: 6.467e-04  iter ratio: 0.0000  Data: 0.028 (0.065)
INFO:Train: 247 [ 150/625 ( 24%)]  Loss: 0.003617 (0.00331)  Time: 0.705s, 2904.75/s  (0.730s, 2805.23/s)  avg LR: 6.467e-04  iter ratio: 0.0000  Data: 0.028 (0.053)
INFO:Train: 247 [ 200/625 ( 32%)]  Loss: 0.003491 (0.00334)  Time: 0.706s, 2901.42/s  (0.724s, 2828.08/s)  avg LR: 6.467e-04  iter ratio: 0.0000  Data: 0.026 (0.047)
INFO:Train: 247 [ 250/625 ( 40%)]  Loss: 0.003535 (0.00338)  Time: 0.703s, 2912.28/s  (0.721s, 2839.75/s)  avg LR: 6.467e-04  iter ratio: 0.0000  Data: 0.025 (0.044)
INFO:Train: 247 [ 300/625 ( 48%)]  Loss: 0.002799 (0.00329)  Time: 0.706s, 2901.44/s  (0.719s, 2849.21/s)  avg LR: 6.467e-04  iter ratio: 0.0000  Data: 0.025 (0.042)
INFO:Train: 247 [ 350/625 ( 56%)]  Loss: 0.003810 (0.00336)  Time: 0.706s, 2901.23/s  (0.717s, 2855.01/s)  avg LR: 6.467e-04  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 247 [ 400/625 ( 64%)]  Loss: 0.003288 (0.00335)  Time: 0.712s, 2878.05/s  (0.716s, 2860.62/s)  avg LR: 6.467e-04  iter ratio: 0.0000  Data: 0.033 (0.039)
INFO:Train: 247 [ 450/625 ( 72%)]  Loss: 0.003335 (0.00335)  Time: 0.730s, 2806.54/s  (0.715s, 2863.29/s)  avg LR: 6.467e-04  iter ratio: 0.0000  Data: 0.049 (0.038)
INFO:Train: 247 [ 500/625 ( 80%)]  Loss: 0.003238 (0.00334)  Time: 0.705s, 2905.94/s  (0.715s, 2864.53/s)  avg LR: 6.467e-04  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 247 [ 550/625 ( 88%)]  Loss: 0.002982 (0.00331)  Time: 0.708s, 2891.36/s  (0.714s, 2866.95/s)  avg LR: 6.467e-04  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 247 [ 600/625 ( 96%)]  Loss: 0.002996 (0.00328)  Time: 0.707s, 2895.99/s  (0.714s, 2869.40/s)  avg LR: 6.467e-04  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 247 [ 624/625 (100%)]  Loss: 0.002719 (0.00324)  Time: 0.674s, 3036.85/s  (0.713s, 2871.15/s)  avg LR: 6.467e-04  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.415 (4.415)  Loss:  0.5576 (0.5576)  Acc@1: 86.7188 (86.7188)  Acc@5: 98.0469 (98.0469)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.5181 (0.8670)  Acc@1: 85.8491 (80.1520)  Acc@5: 97.9953 (95.0540)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-246.pth.tar', 80.34800008056641)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-247.pth.tar', 80.15200005859376)

INFO:247-epoch: remaining time 8.06 h
INFO:Train: 248 [   0/625 (  0%)]  Loss: 0.002368 (0.00237)  Time: 4.352s,  470.64/s  (4.352s,  470.64/s)  avg LR: 6.249e-04  iter ratio: 0.0000  Data: 3.647 (3.647)
INFO:Train: 248 [  50/625 (  8%)]  Loss: 0.003679 (0.00302)  Time: 0.700s, 2923.69/s  (0.781s, 2622.39/s)  avg LR: 6.249e-04  iter ratio: 0.0000  Data: 0.024 (0.102)
INFO:Train: 248 [ 100/625 ( 16%)]  Loss: 0.003478 (0.00318)  Time: 0.703s, 2911.59/s  (0.743s, 2756.13/s)  avg LR: 6.249e-04  iter ratio: 0.0000  Data: 0.026 (0.065)
INFO:Train: 248 [ 150/625 ( 24%)]  Loss: 0.002716 (0.00306)  Time: 0.708s, 2891.43/s  (0.731s, 2803.04/s)  avg LR: 6.249e-04  iter ratio: 0.0000  Data: 0.032 (0.053)
INFO:Train: 248 [ 200/625 ( 32%)]  Loss: 0.003465 (0.00314)  Time: 0.699s, 2928.14/s  (0.724s, 2829.70/s)  avg LR: 6.249e-04  iter ratio: 0.0000  Data: 0.025 (0.046)
INFO:Train: 248 [ 250/625 ( 40%)]  Loss: 0.002784 (0.00308)  Time: 0.701s, 2923.47/s  (0.720s, 2844.71/s)  avg LR: 6.249e-04  iter ratio: 0.0000  Data: 0.024 (0.042)
INFO:Train: 248 [ 300/625 ( 48%)]  Loss: 0.003545 (0.00315)  Time: 0.701s, 2920.26/s  (0.717s, 2855.45/s)  avg LR: 6.249e-04  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 248 [ 350/625 ( 56%)]  Loss: 0.003455 (0.00319)  Time: 0.704s, 2907.84/s  (0.715s, 2863.17/s)  avg LR: 6.249e-04  iter ratio: 0.0000  Data: 0.028 (0.038)
INFO:Train: 248 [ 400/625 ( 64%)]  Loss: 0.003031 (0.00317)  Time: 0.705s, 2906.11/s  (0.714s, 2869.33/s)  avg LR: 6.249e-04  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 248 [ 450/625 ( 72%)]  Loss: 0.003094 (0.00316)  Time: 0.707s, 2895.30/s  (0.713s, 2873.97/s)  avg LR: 6.249e-04  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 248 [ 500/625 ( 80%)]  Loss: 0.002800 (0.00313)  Time: 0.703s, 2911.57/s  (0.712s, 2878.14/s)  avg LR: 6.249e-04  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 248 [ 550/625 ( 88%)]  Loss: 0.003386 (0.00315)  Time: 0.704s, 2910.83/s  (0.711s, 2880.43/s)  avg LR: 6.249e-04  iter ratio: 0.0000  Data: 0.025 (0.034)
INFO:Train: 248 [ 600/625 ( 96%)]  Loss: 0.002780 (0.00312)  Time: 0.701s, 2922.82/s  (0.711s, 2882.12/s)  avg LR: 6.249e-04  iter ratio: 0.0000  Data: 0.024 (0.033)
INFO:Train: 248 [ 624/625 (100%)]  Loss: 0.003470 (0.00315)  Time: 0.674s, 3038.24/s  (0.710s, 2883.63/s)  avg LR: 6.249e-04  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.342 (4.342)  Loss:  0.5693 (0.5693)  Acc@1: 86.4258 (86.4258)  Acc@5: 97.5586 (97.5586)
INFO:Test: [  24/24]  Time: 0.080 (0.507)  Loss:  0.5303 (0.8687)  Acc@1: 86.6745 (80.2100)  Acc@5: 97.0519 (95.2180)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-246.pth.tar', 80.34800008056641)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-248.pth.tar', 80.21000002929688)

INFO:248-epoch: remaining time 7.90 h
INFO:Train: 249 [   0/625 (  0%)]  Loss: 0.003144 (0.00314)  Time: 4.357s,  470.01/s  (4.357s,  470.01/s)  avg LR: 6.036e-04  iter ratio: 0.0000  Data: 3.666 (3.666)
INFO:Train: 249 [  50/625 (  8%)]  Loss: 0.002792 (0.00297)  Time: 0.719s, 2848.06/s  (0.784s, 2612.04/s)  avg LR: 6.036e-04  iter ratio: 0.0000  Data: 0.040 (0.105)
INFO:Train: 249 [ 100/625 ( 16%)]  Loss: 0.003739 (0.00323)  Time: 0.720s, 2846.37/s  (0.751s, 2726.75/s)  avg LR: 6.036e-04  iter ratio: 0.0000  Data: 0.041 (0.073)
INFO:Train: 249 [ 150/625 ( 24%)]  Loss: 0.003045 (0.00318)  Time: 0.714s, 2869.04/s  (0.740s, 2769.44/s)  avg LR: 6.036e-04  iter ratio: 0.0000  Data: 0.030 (0.061)
INFO:Train: 249 [ 200/625 ( 32%)]  Loss: 0.003467 (0.00324)  Time: 0.715s, 2864.41/s  (0.734s, 2790.38/s)  avg LR: 6.036e-04  iter ratio: 0.0000  Data: 0.041 (0.056)
INFO:Train: 249 [ 250/625 ( 40%)]  Loss: 0.003314 (0.00325)  Time: 0.706s, 2900.03/s  (0.730s, 2805.39/s)  avg LR: 6.036e-04  iter ratio: 0.0000  Data: 0.030 (0.052)
INFO:Train: 249 [ 300/625 ( 48%)]  Loss: 0.003816 (0.00333)  Time: 0.706s, 2901.91/s  (0.725s, 2822.89/s)  avg LR: 6.036e-04  iter ratio: 0.0000  Data: 0.029 (0.047)
INFO:Train: 249 [ 350/625 ( 56%)]  Loss: 0.002438 (0.00322)  Time: 0.701s, 2921.69/s  (0.722s, 2835.62/s)  avg LR: 6.036e-04  iter ratio: 0.0000  Data: 0.021 (0.044)
INFO:Train: 249 [ 400/625 ( 64%)]  Loss: 0.003252 (0.00322)  Time: 0.722s, 2837.90/s  (0.721s, 2839.83/s)  avg LR: 6.036e-04  iter ratio: 0.0000  Data: 0.046 (0.043)
INFO:Train: 249 [ 450/625 ( 72%)]  Loss: 0.003116 (0.00321)  Time: 0.723s, 2832.01/s  (0.721s, 2841.43/s)  avg LR: 6.036e-04  iter ratio: 0.0000  Data: 0.049 (0.043)
INFO:Train: 249 [ 500/625 ( 80%)]  Loss: 0.003676 (0.00325)  Time: 0.703s, 2911.29/s  (0.720s, 2845.83/s)  avg LR: 6.036e-04  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 249 [ 550/625 ( 88%)]  Loss: 0.003209 (0.00325)  Time: 0.706s, 2900.70/s  (0.718s, 2851.23/s)  avg LR: 6.036e-04  iter ratio: 0.0000  Data: 0.023 (0.041)
INFO:Train: 249 [ 600/625 ( 96%)]  Loss: 0.003628 (0.00328)  Time: 0.707s, 2895.35/s  (0.717s, 2855.78/s)  avg LR: 6.036e-04  iter ratio: 0.0000  Data: 0.021 (0.040)
INFO:Train: 249 [ 624/625 (100%)]  Loss: 0.002901 (0.00325)  Time: 0.679s, 3014.59/s  (0.717s, 2858.04/s)  avg LR: 6.036e-04  iter ratio: 0.0000  Data: 0.000 (0.039)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.341 (4.341)  Loss:  0.5405 (0.5405)  Acc@1: 87.1094 (87.1094)  Acc@5: 97.5586 (97.5586)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.5039 (0.8531)  Acc@1: 87.2642 (80.3320)  Acc@5: 97.2877 (95.1580)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-246.pth.tar', 80.34800008056641)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-249.pth.tar', 80.33200002685547)

INFO:249-epoch: remaining time 7.84 h
INFO:Train: 250 [   0/625 (  0%)]  Loss: 0.003383 (0.00338)  Time: 4.208s,  486.66/s  (4.208s,  486.66/s)  avg LR: 5.825e-04  iter ratio: 0.0000  Data: 3.524 (3.524)
INFO:Train: 250 [  50/625 (  8%)]  Loss: 0.003130 (0.00326)  Time: 0.699s, 2930.16/s  (0.775s, 2644.23/s)  avg LR: 5.825e-04  iter ratio: 0.0000  Data: 0.023 (0.097)
INFO:Train: 250 [ 100/625 ( 16%)]  Loss: 0.003563 (0.00336)  Time: 0.702s, 2919.40/s  (0.740s, 2769.17/s)  avg LR: 5.825e-04  iter ratio: 0.0000  Data: 0.024 (0.061)
INFO:Train: 250 [ 150/625 ( 24%)]  Loss: 0.003628 (0.00343)  Time: 0.704s, 2910.75/s  (0.727s, 2816.66/s)  avg LR: 5.825e-04  iter ratio: 0.0000  Data: 0.026 (0.050)
INFO:Train: 250 [ 200/625 ( 32%)]  Loss: 0.003292 (0.00340)  Time: 0.703s, 2911.76/s  (0.722s, 2836.95/s)  avg LR: 5.825e-04  iter ratio: 0.0000  Data: 0.025 (0.044)
INFO:Train: 250 [ 250/625 ( 40%)]  Loss: 0.003120 (0.00335)  Time: 0.703s, 2912.77/s  (0.719s, 2849.38/s)  avg LR: 5.825e-04  iter ratio: 0.0000  Data: 0.029 (0.041)
INFO:Train: 250 [ 300/625 ( 48%)]  Loss: 0.004457 (0.00351)  Time: 0.710s, 2884.66/s  (0.716s, 2859.05/s)  avg LR: 5.825e-04  iter ratio: 0.0000  Data: 0.035 (0.038)
INFO:Train: 250 [ 350/625 ( 56%)]  Loss: 0.003949 (0.00357)  Time: 0.714s, 2869.14/s  (0.717s, 2857.54/s)  avg LR: 5.825e-04  iter ratio: 0.0000  Data: 0.039 (0.039)
INFO:Train: 250 [ 400/625 ( 64%)]  Loss: 0.003222 (0.00353)  Time: 0.715s, 2865.65/s  (0.717s, 2856.40/s)  avg LR: 5.825e-04  iter ratio: 0.0000  Data: 0.040 (0.039)
INFO:Train: 250 [ 450/625 ( 72%)]  Loss: 0.003592 (0.00353)  Time: 0.712s, 2874.94/s  (0.717s, 2855.81/s)  avg LR: 5.825e-04  iter ratio: 0.0000  Data: 0.038 (0.039)
INFO:Train: 250 [ 500/625 ( 80%)]  Loss: 0.003500 (0.00353)  Time: 0.699s, 2927.97/s  (0.717s, 2857.95/s)  avg LR: 5.825e-04  iter ratio: 0.0000  Data: 0.024 (0.039)
INFO:Train: 250 [ 550/625 ( 88%)]  Loss: 0.002985 (0.00349)  Time: 0.700s, 2927.61/s  (0.716s, 2862.22/s)  avg LR: 5.825e-04  iter ratio: 0.0000  Data: 0.022 (0.038)
INFO:Train: 250 [ 600/625 ( 96%)]  Loss: 0.003475 (0.00348)  Time: 0.715s, 2864.95/s  (0.715s, 2863.69/s)  avg LR: 5.825e-04  iter ratio: 0.0000  Data: 0.039 (0.037)
INFO:Train: 250 [ 624/625 (100%)]  Loss: 0.003579 (0.00349)  Time: 0.676s, 3027.47/s  (0.715s, 2863.86/s)  avg LR: 5.825e-04  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.342 (4.342)  Loss:  0.5591 (0.5591)  Acc@1: 87.0605 (87.0605)  Acc@5: 97.9980 (97.9980)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.5332 (0.8684)  Acc@1: 87.2642 (80.3280)  Acc@5: 97.5236 (95.1340)
INFO:250-epoch: remaining time 7.70 h
INFO:Train: 251 [   0/625 (  0%)]  Loss: 0.002592 (0.00259)  Time: 4.158s,  492.53/s  (4.158s,  492.53/s)  avg LR: 5.619e-04  iter ratio: 0.0000  Data: 3.466 (3.466)
INFO:Train: 251 [  50/625 (  8%)]  Loss: 0.003195 (0.00289)  Time: 0.707s, 2898.72/s  (0.779s, 2630.38/s)  avg LR: 5.619e-04  iter ratio: 0.0000  Data: 0.031 (0.098)
INFO:Train: 251 [ 100/625 ( 16%)]  Loss: 0.003497 (0.00309)  Time: 0.720s, 2843.58/s  (0.744s, 2752.81/s)  avg LR: 5.619e-04  iter ratio: 0.0000  Data: 0.046 (0.066)
INFO:Train: 251 [ 150/625 ( 24%)]  Loss: 0.002863 (0.00304)  Time: 0.720s, 2846.38/s  (0.735s, 2786.33/s)  avg LR: 5.619e-04  iter ratio: 0.0000  Data: 0.043 (0.058)
INFO:Train: 251 [ 200/625 ( 32%)]  Loss: 0.003600 (0.00315)  Time: 0.720s, 2844.93/s  (0.731s, 2802.86/s)  avg LR: 5.619e-04  iter ratio: 0.0000  Data: 0.047 (0.054)
INFO:Train: 251 [ 250/625 ( 40%)]  Loss: 0.002865 (0.00310)  Time: 0.712s, 2876.55/s  (0.728s, 2813.78/s)  avg LR: 5.619e-04  iter ratio: 0.0000  Data: 0.038 (0.052)
INFO:Train: 251 [ 300/625 ( 48%)]  Loss: 0.003034 (0.00309)  Time: 0.718s, 2853.98/s  (0.726s, 2820.81/s)  avg LR: 5.619e-04  iter ratio: 0.0000  Data: 0.039 (0.050)
INFO:Train: 251 [ 350/625 ( 56%)]  Loss: 0.004161 (0.00323)  Time: 0.719s, 2850.07/s  (0.725s, 2825.92/s)  avg LR: 5.619e-04  iter ratio: 0.0000  Data: 0.045 (0.049)
INFO:Train: 251 [ 400/625 ( 64%)]  Loss: 0.002998 (0.00320)  Time: 0.730s, 2805.70/s  (0.724s, 2829.13/s)  avg LR: 5.619e-04  iter ratio: 0.0000  Data: 0.056 (0.048)
INFO:Train: 251 [ 450/625 ( 72%)]  Loss: 0.002806 (0.00316)  Time: 0.706s, 2901.34/s  (0.722s, 2835.67/s)  avg LR: 5.619e-04  iter ratio: 0.0000  Data: 0.024 (0.046)
INFO:Train: 251 [ 500/625 ( 80%)]  Loss: 0.003484 (0.00319)  Time: 0.701s, 2921.29/s  (0.720s, 2842.97/s)  avg LR: 5.619e-04  iter ratio: 0.0000  Data: 0.027 (0.044)
INFO:Train: 251 [ 550/625 ( 88%)]  Loss: 0.003306 (0.00320)  Time: 0.713s, 2870.46/s  (0.719s, 2846.44/s)  avg LR: 5.619e-04  iter ratio: 0.0000  Data: 0.040 (0.043)
INFO:Train: 251 [ 600/625 ( 96%)]  Loss: 0.003094 (0.00319)  Time: 0.713s, 2870.63/s  (0.719s, 2847.45/s)  avg LR: 5.619e-04  iter ratio: 0.0000  Data: 0.040 (0.043)
INFO:Train: 251 [ 624/625 (100%)]  Loss: 0.003644 (0.00322)  Time: 0.673s, 3043.64/s  (0.719s, 2848.86/s)  avg LR: 5.619e-04  iter ratio: 0.0000  Data: 0.000 (0.043)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.340 (4.340)  Loss:  0.5557 (0.5557)  Acc@1: 87.3047 (87.3047)  Acc@5: 98.0957 (98.0957)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.4863 (0.8413)  Acc@1: 86.6745 (80.5420)  Acc@5: 97.4057 (95.1580)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-251.pth.tar', 80.54200002929687)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-246.pth.tar', 80.34800008056641)

INFO:251-epoch: remaining time 7.60 h
INFO:Train: 252 [   0/625 (  0%)]  Loss: 0.003058 (0.00306)  Time: 4.423s,  463.01/s  (4.423s,  463.01/s)  avg LR: 5.417e-04  iter ratio: 0.0000  Data: 3.717 (3.717)
INFO:Train: 252 [  50/625 (  8%)]  Loss: 0.003590 (0.00332)  Time: 0.702s, 2915.56/s  (0.779s, 2628.08/s)  avg LR: 5.417e-04  iter ratio: 0.0000  Data: 0.025 (0.099)
INFO:Train: 252 [ 100/625 ( 16%)]  Loss: 0.003020 (0.00322)  Time: 0.700s, 2923.68/s  (0.743s, 2755.34/s)  avg LR: 5.417e-04  iter ratio: 0.0000  Data: 0.024 (0.064)
INFO:Train: 252 [ 150/625 ( 24%)]  Loss: 0.003119 (0.00320)  Time: 0.705s, 2904.75/s  (0.731s, 2801.87/s)  avg LR: 5.417e-04  iter ratio: 0.0000  Data: 0.028 (0.052)
INFO:Train: 252 [ 200/625 ( 32%)]  Loss: 0.002600 (0.00308)  Time: 0.707s, 2896.94/s  (0.727s, 2818.22/s)  avg LR: 5.417e-04  iter ratio: 0.0000  Data: 0.030 (0.048)
INFO:Train: 252 [ 250/625 ( 40%)]  Loss: 0.003192 (0.00310)  Time: 0.708s, 2891.70/s  (0.724s, 2829.78/s)  avg LR: 5.417e-04  iter ratio: 0.0000  Data: 0.032 (0.045)
INFO:Train: 252 [ 300/625 ( 48%)]  Loss: 0.003471 (0.00315)  Time: 0.706s, 2902.22/s  (0.722s, 2838.12/s)  avg LR: 5.417e-04  iter ratio: 0.0000  Data: 0.029 (0.043)
INFO:Train: 252 [ 350/625 ( 56%)]  Loss: 0.004083 (0.00327)  Time: 0.701s, 2923.04/s  (0.719s, 2846.80/s)  avg LR: 5.417e-04  iter ratio: 0.0000  Data: 0.024 (0.040)
INFO:Train: 252 [ 400/625 ( 64%)]  Loss: 0.003169 (0.00326)  Time: 0.703s, 2914.10/s  (0.718s, 2853.42/s)  avg LR: 5.417e-04  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 252 [ 450/625 ( 72%)]  Loss: 0.002401 (0.00317)  Time: 0.702s, 2918.05/s  (0.716s, 2859.05/s)  avg LR: 5.417e-04  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 252 [ 500/625 ( 80%)]  Loss: 0.003235 (0.00318)  Time: 0.700s, 2925.53/s  (0.715s, 2863.40/s)  avg LR: 5.417e-04  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 252 [ 550/625 ( 88%)]  Loss: 0.003607 (0.00321)  Time: 0.707s, 2896.11/s  (0.715s, 2866.04/s)  avg LR: 5.417e-04  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 252 [ 600/625 ( 96%)]  Loss: 0.003033 (0.00320)  Time: 0.707s, 2897.31/s  (0.714s, 2868.36/s)  avg LR: 5.417e-04  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 252 [ 624/625 (100%)]  Loss: 0.003140 (0.00319)  Time: 0.676s, 3028.65/s  (0.714s, 2869.69/s)  avg LR: 5.417e-04  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.348 (4.348)  Loss:  0.5352 (0.5352)  Acc@1: 87.7441 (87.7441)  Acc@5: 97.8027 (97.8027)
INFO:Test: [  24/24]  Time: 0.080 (0.509)  Loss:  0.5029 (0.8385)  Acc@1: 85.4953 (80.5700)  Acc@5: 97.8774 (95.1920)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-252.pth.tar', 80.57000003417969)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-251.pth.tar', 80.54200002929687)

INFO:252-epoch: remaining time 7.44 h
INFO:Train: 253 [   0/625 (  0%)]  Loss: 0.003640 (0.00364)  Time: 4.446s,  460.59/s  (4.446s,  460.59/s)  avg LR: 5.218e-04  iter ratio: 0.0000  Data: 3.743 (3.743)
INFO:Train: 253 [  50/625 (  8%)]  Loss: 0.003442 (0.00354)  Time: 0.701s, 2923.33/s  (0.779s, 2629.04/s)  avg LR: 5.218e-04  iter ratio: 0.0000  Data: 0.024 (0.101)
INFO:Train: 253 [ 100/625 ( 16%)]  Loss: 0.003199 (0.00343)  Time: 0.700s, 2924.13/s  (0.742s, 2761.37/s)  avg LR: 5.218e-04  iter ratio: 0.0000  Data: 0.023 (0.065)
INFO:Train: 253 [ 150/625 ( 24%)]  Loss: 0.003580 (0.00347)  Time: 0.719s, 2848.92/s  (0.733s, 2794.71/s)  avg LR: 5.218e-04  iter ratio: 0.0000  Data: 0.045 (0.057)
INFO:Train: 253 [ 200/625 ( 32%)]  Loss: 0.002960 (0.00336)  Time: 0.723s, 2831.86/s  (0.729s, 2810.03/s)  avg LR: 5.218e-04  iter ratio: 0.0000  Data: 0.049 (0.053)
INFO:Train: 253 [ 250/625 ( 40%)]  Loss: 0.003121 (0.00332)  Time: 0.718s, 2852.95/s  (0.727s, 2818.70/s)  avg LR: 5.218e-04  iter ratio: 0.0000  Data: 0.044 (0.051)
INFO:Train: 253 [ 300/625 ( 48%)]  Loss: 0.003433 (0.00334)  Time: 0.701s, 2923.61/s  (0.724s, 2829.75/s)  avg LR: 5.218e-04  iter ratio: 0.0000  Data: 0.026 (0.048)
INFO:Train: 253 [ 350/625 ( 56%)]  Loss: 0.002903 (0.00328)  Time: 0.708s, 2893.81/s  (0.721s, 2841.29/s)  avg LR: 5.218e-04  iter ratio: 0.0000  Data: 0.030 (0.045)
INFO:Train: 253 [ 400/625 ( 64%)]  Loss: 0.003530 (0.00331)  Time: 0.703s, 2911.44/s  (0.719s, 2850.11/s)  avg LR: 5.218e-04  iter ratio: 0.0000  Data: 0.024 (0.043)
INFO:Train: 253 [ 450/625 ( 72%)]  Loss: 0.004375 (0.00342)  Time: 0.702s, 2915.79/s  (0.717s, 2856.24/s)  avg LR: 5.218e-04  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 253 [ 500/625 ( 80%)]  Loss: 0.002884 (0.00337)  Time: 0.705s, 2905.95/s  (0.715s, 2862.55/s)  avg LR: 5.218e-04  iter ratio: 0.0000  Data: 0.030 (0.040)
INFO:Train: 253 [ 550/625 ( 88%)]  Loss: 0.002361 (0.00329)  Time: 0.700s, 2926.63/s  (0.714s, 2866.62/s)  avg LR: 5.218e-04  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 253 [ 600/625 ( 96%)]  Loss: 0.003617 (0.00331)  Time: 0.700s, 2924.55/s  (0.714s, 2869.66/s)  avg LR: 5.218e-04  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 253 [ 624/625 (100%)]  Loss: 0.002533 (0.00326)  Time: 0.675s, 3036.25/s  (0.713s, 2871.62/s)  avg LR: 5.218e-04  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.376 (4.376)  Loss:  0.5586 (0.5586)  Acc@1: 86.9629 (86.9629)  Acc@5: 97.6562 (97.6562)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.4883 (0.8453)  Acc@1: 88.2075 (80.6580)  Acc@5: 97.6415 (95.2960)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-253.pth.tar', 80.65799991943359)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-252.pth.tar', 80.57000003417969)

INFO:253-epoch: remaining time 7.29 h
INFO:Train: 254 [   0/625 (  0%)]  Loss: 0.003199 (0.00320)  Time: 4.402s,  465.25/s  (4.402s,  465.25/s)  avg LR: 5.023e-04  iter ratio: 0.0000  Data: 3.703 (3.703)
INFO:Train: 254 [  50/625 (  8%)]  Loss: 0.003434 (0.00332)  Time: 0.718s, 2853.16/s  (0.792s, 2586.66/s)  avg LR: 5.023e-04  iter ratio: 0.0000  Data: 0.043 (0.109)
INFO:Train: 254 [ 100/625 ( 16%)]  Loss: 0.003812 (0.00348)  Time: 0.720s, 2844.64/s  (0.754s, 2715.80/s)  avg LR: 5.023e-04  iter ratio: 0.0000  Data: 0.045 (0.073)
INFO:Train: 254 [ 150/625 ( 24%)]  Loss: 0.002734 (0.00329)  Time: 0.714s, 2868.96/s  (0.742s, 2760.91/s)  avg LR: 5.023e-04  iter ratio: 0.0000  Data: 0.039 (0.062)
INFO:Train: 254 [ 200/625 ( 32%)]  Loss: 0.003173 (0.00327)  Time: 0.715s, 2862.66/s  (0.736s, 2782.58/s)  avg LR: 5.023e-04  iter ratio: 0.0000  Data: 0.040 (0.056)
INFO:Train: 254 [ 250/625 ( 40%)]  Loss: 0.003405 (0.00329)  Time: 0.716s, 2861.21/s  (0.732s, 2796.38/s)  avg LR: 5.023e-04  iter ratio: 0.0000  Data: 0.038 (0.053)
INFO:Train: 254 [ 300/625 ( 48%)]  Loss: 0.003158 (0.00327)  Time: 0.719s, 2849.63/s  (0.730s, 2805.77/s)  avg LR: 5.023e-04  iter ratio: 0.0000  Data: 0.041 (0.051)
INFO:Train: 254 [ 350/625 ( 56%)]  Loss: 0.002675 (0.00320)  Time: 0.718s, 2851.51/s  (0.728s, 2812.50/s)  avg LR: 5.023e-04  iter ratio: 0.0000  Data: 0.043 (0.049)
INFO:Train: 254 [ 400/625 ( 64%)]  Loss: 0.002882 (0.00316)  Time: 0.714s, 2867.38/s  (0.727s, 2817.64/s)  avg LR: 5.023e-04  iter ratio: 0.0000  Data: 0.037 (0.048)
INFO:Train: 254 [ 450/625 ( 72%)]  Loss: 0.002921 (0.00314)  Time: 0.716s, 2858.39/s  (0.726s, 2821.86/s)  avg LR: 5.023e-04  iter ratio: 0.0000  Data: 0.042 (0.047)
INFO:Train: 254 [ 500/625 ( 80%)]  Loss: 0.002928 (0.00312)  Time: 0.709s, 2889.87/s  (0.724s, 2826.91/s)  avg LR: 5.023e-04  iter ratio: 0.0000  Data: 0.032 (0.046)
INFO:Train: 254 [ 550/625 ( 88%)]  Loss: 0.002961 (0.00311)  Time: 0.703s, 2913.38/s  (0.723s, 2833.10/s)  avg LR: 5.023e-04  iter ratio: 0.0000  Data: 0.026 (0.044)
INFO:Train: 254 [ 600/625 ( 96%)]  Loss: 0.003502 (0.00314)  Time: 0.702s, 2918.95/s  (0.721s, 2838.84/s)  avg LR: 5.023e-04  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 254 [ 624/625 (100%)]  Loss: 0.003599 (0.00317)  Time: 0.673s, 3043.71/s  (0.721s, 2841.57/s)  avg LR: 5.023e-04  iter ratio: 0.0000  Data: 0.000 (0.042)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.325 (4.325)  Loss:  0.5791 (0.5791)  Acc@1: 87.2559 (87.2559)  Acc@5: 97.7539 (97.7539)
INFO:Test: [  24/24]  Time: 0.080 (0.507)  Loss:  0.5117 (0.8616)  Acc@1: 87.8538 (80.4920)  Acc@5: 97.6415 (95.2440)
INFO:254-epoch: remaining time 7.24 h
INFO:Train: 255 [   0/625 (  0%)]  Loss: 0.003161 (0.00316)  Time: 4.335s,  472.46/s  (4.335s,  472.46/s)  avg LR: 4.832e-04  iter ratio: 0.0000  Data: 3.637 (3.637)
INFO:Train: 255 [  50/625 (  8%)]  Loss: 0.003124 (0.00314)  Time: 0.707s, 2897.94/s  (0.778s, 2631.48/s)  avg LR: 4.832e-04  iter ratio: 0.0000  Data: 0.029 (0.098)
INFO:Train: 255 [ 100/625 ( 16%)]  Loss: 0.003801 (0.00336)  Time: 0.704s, 2908.59/s  (0.743s, 2758.05/s)  avg LR: 4.832e-04  iter ratio: 0.0000  Data: 0.027 (0.062)
INFO:Train: 255 [ 150/625 ( 24%)]  Loss: 0.003116 (0.00330)  Time: 0.707s, 2898.39/s  (0.731s, 2802.84/s)  avg LR: 4.832e-04  iter ratio: 0.0000  Data: 0.028 (0.050)
INFO:Train: 255 [ 200/625 ( 32%)]  Loss: 0.003493 (0.00334)  Time: 0.710s, 2885.55/s  (0.725s, 2825.63/s)  avg LR: 4.832e-04  iter ratio: 0.0000  Data: 0.030 (0.043)
INFO:Train: 255 [ 250/625 ( 40%)]  Loss: 0.003286 (0.00333)  Time: 0.705s, 2904.58/s  (0.721s, 2839.72/s)  avg LR: 4.832e-04  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 255 [ 300/625 ( 48%)]  Loss: 0.004071 (0.00344)  Time: 0.702s, 2918.34/s  (0.719s, 2848.95/s)  avg LR: 4.832e-04  iter ratio: 0.0000  Data: 0.024 (0.037)
INFO:Train: 255 [ 350/625 ( 56%)]  Loss: 0.004040 (0.00351)  Time: 0.711s, 2881.33/s  (0.718s, 2853.97/s)  avg LR: 4.832e-04  iter ratio: 0.0000  Data: 0.036 (0.036)
INFO:Train: 255 [ 400/625 ( 64%)]  Loss: 0.003239 (0.00348)  Time: 0.712s, 2877.83/s  (0.718s, 2854.17/s)  avg LR: 4.832e-04  iter ratio: 0.0000  Data: 0.037 (0.036)
INFO:Train: 255 [ 450/625 ( 72%)]  Loss: 0.003268 (0.00346)  Time: 0.717s, 2854.63/s  (0.717s, 2854.43/s)  avg LR: 4.832e-04  iter ratio: 0.0000  Data: 0.041 (0.037)
INFO:Train: 255 [ 500/625 ( 80%)]  Loss: 0.003689 (0.00348)  Time: 0.706s, 2899.45/s  (0.717s, 2855.63/s)  avg LR: 4.832e-04  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 255 [ 550/625 ( 88%)]  Loss: 0.003964 (0.00352)  Time: 0.707s, 2898.57/s  (0.716s, 2859.58/s)  avg LR: 4.832e-04  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 255 [ 600/625 ( 96%)]  Loss: 0.003561 (0.00352)  Time: 0.708s, 2891.25/s  (0.715s, 2863.28/s)  avg LR: 4.832e-04  iter ratio: 0.0000  Data: 0.028 (0.035)
INFO:Train: 255 [ 624/625 (100%)]  Loss: 0.003209 (0.00350)  Time: 0.678s, 3021.61/s  (0.715s, 2865.31/s)  avg LR: 4.832e-04  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.328 (4.328)  Loss:  0.5732 (0.5732)  Acc@1: 87.2070 (87.2070)  Acc@5: 97.8027 (97.8027)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.5215 (0.8727)  Acc@1: 87.5000 (80.5680)  Acc@5: 97.8774 (95.1560)
INFO:255-epoch: remaining time 7.05 h
INFO:Train: 256 [   0/625 (  0%)]  Loss: 0.003634 (0.00363)  Time: 4.128s,  496.18/s  (4.128s,  496.18/s)  avg LR: 4.645e-04  iter ratio: 0.0000  Data: 3.427 (3.427)
INFO:Train: 256 [  50/625 (  8%)]  Loss: 0.002713 (0.00317)  Time: 0.709s, 2887.26/s  (0.774s, 2646.21/s)  avg LR: 4.645e-04  iter ratio: 0.0000  Data: 0.032 (0.089)
INFO:Train: 256 [ 100/625 ( 16%)]  Loss: 0.002428 (0.00293)  Time: 0.719s, 2848.68/s  (0.745s, 2749.99/s)  avg LR: 4.645e-04  iter ratio: 0.0000  Data: 0.038 (0.060)
INFO:Train: 256 [ 150/625 ( 24%)]  Loss: 0.003340 (0.00303)  Time: 0.721s, 2842.32/s  (0.736s, 2784.49/s)  avg LR: 4.645e-04  iter ratio: 0.0000  Data: 0.036 (0.051)
INFO:Train: 256 [ 200/625 ( 32%)]  Loss: 0.003945 (0.00321)  Time: 0.714s, 2869.51/s  (0.731s, 2803.48/s)  avg LR: 4.645e-04  iter ratio: 0.0000  Data: 0.030 (0.046)
INFO:Train: 256 [ 250/625 ( 40%)]  Loss: 0.003353 (0.00324)  Time: 0.718s, 2850.89/s  (0.728s, 2814.94/s)  avg LR: 4.645e-04  iter ratio: 0.0000  Data: 0.034 (0.043)
INFO:Train: 256 [ 300/625 ( 48%)]  Loss: 0.003611 (0.00329)  Time: 0.703s, 2911.87/s  (0.725s, 2823.70/s)  avg LR: 4.645e-04  iter ratio: 0.0000  Data: 0.022 (0.041)
INFO:Train: 256 [ 350/625 ( 56%)]  Loss: 0.003363 (0.00330)  Time: 0.705s, 2904.09/s  (0.722s, 2835.04/s)  avg LR: 4.645e-04  iter ratio: 0.0000  Data: 0.023 (0.038)
INFO:Train: 256 [ 400/625 ( 64%)]  Loss: 0.003114 (0.00328)  Time: 0.700s, 2924.04/s  (0.720s, 2843.24/s)  avg LR: 4.645e-04  iter ratio: 0.0000  Data: 0.021 (0.036)
INFO:Train: 256 [ 450/625 ( 72%)]  Loss: 0.003447 (0.00329)  Time: 0.710s, 2883.58/s  (0.719s, 2849.71/s)  avg LR: 4.645e-04  iter ratio: 0.0000  Data: 0.030 (0.035)
INFO:Train: 256 [ 500/625 ( 80%)]  Loss: 0.003945 (0.00335)  Time: 0.705s, 2903.97/s  (0.717s, 2855.24/s)  avg LR: 4.645e-04  iter ratio: 0.0000  Data: 0.030 (0.034)
INFO:Train: 256 [ 550/625 ( 88%)]  Loss: 0.003450 (0.00336)  Time: 0.703s, 2913.85/s  (0.716s, 2859.22/s)  avg LR: 4.645e-04  iter ratio: 0.0000  Data: 0.024 (0.033)
INFO:Train: 256 [ 600/625 ( 96%)]  Loss: 0.003006 (0.00333)  Time: 0.704s, 2910.33/s  (0.715s, 2862.79/s)  avg LR: 4.645e-04  iter ratio: 0.0000  Data: 0.029 (0.033)
INFO:Train: 256 [ 624/625 (100%)]  Loss: 0.002980 (0.00331)  Time: 0.678s, 3021.64/s  (0.715s, 2864.87/s)  avg LR: 4.645e-04  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.339 (4.339)  Loss:  0.5400 (0.5400)  Acc@1: 87.4023 (87.4023)  Acc@5: 97.9492 (97.9492)
INFO:Test: [  24/24]  Time: 0.080 (0.511)  Loss:  0.5156 (0.8393)  Acc@1: 86.4387 (80.7580)  Acc@5: 97.7594 (95.3120)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-256.pth.tar', 80.75800005615234)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-253.pth.tar', 80.65799991943359)

INFO:256-epoch: remaining time 6.93 h
INFO:Train: 257 [   0/625 (  0%)]  Loss: 0.003323 (0.00332)  Time: 4.117s,  497.41/s  (4.117s,  497.41/s)  avg LR: 4.462e-04  iter ratio: 0.0000  Data: 3.431 (3.431)
INFO:Train: 257 [  50/625 (  8%)]  Loss: 0.003700 (0.00351)  Time: 0.701s, 2920.78/s  (0.777s, 2636.28/s)  avg LR: 4.462e-04  iter ratio: 0.0000  Data: 0.026 (0.099)
INFO:Train: 257 [ 100/625 ( 16%)]  Loss: 0.003168 (0.00340)  Time: 0.701s, 2921.36/s  (0.741s, 2765.20/s)  avg LR: 4.462e-04  iter ratio: 0.0000  Data: 0.021 (0.063)
INFO:Train: 257 [ 150/625 ( 24%)]  Loss: 0.003137 (0.00333)  Time: 0.701s, 2921.48/s  (0.729s, 2809.25/s)  avg LR: 4.462e-04  iter ratio: 0.0000  Data: 0.025 (0.052)
INFO:Train: 257 [ 200/625 ( 32%)]  Loss: 0.003497 (0.00337)  Time: 0.702s, 2919.42/s  (0.723s, 2833.51/s)  avg LR: 4.462e-04  iter ratio: 0.0000  Data: 0.025 (0.046)
INFO:Train: 257 [ 250/625 ( 40%)]  Loss: 0.003657 (0.00341)  Time: 0.701s, 2920.51/s  (0.719s, 2848.59/s)  avg LR: 4.462e-04  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 257 [ 300/625 ( 48%)]  Loss: 0.002988 (0.00335)  Time: 0.707s, 2896.91/s  (0.717s, 2858.17/s)  avg LR: 4.462e-04  iter ratio: 0.0000  Data: 0.031 (0.040)
INFO:Train: 257 [ 350/625 ( 56%)]  Loss: 0.003009 (0.00331)  Time: 0.715s, 2864.00/s  (0.715s, 2862.71/s)  avg LR: 4.462e-04  iter ratio: 0.0000  Data: 0.039 (0.039)
INFO:Train: 257 [ 400/625 ( 64%)]  Loss: 0.003944 (0.00338)  Time: 0.721s, 2838.56/s  (0.716s, 2861.41/s)  avg LR: 4.462e-04  iter ratio: 0.0000  Data: 0.046 (0.039)
INFO:Train: 257 [ 450/625 ( 72%)]  Loss: 0.002652 (0.00331)  Time: 0.720s, 2846.38/s  (0.716s, 2860.58/s)  avg LR: 4.462e-04  iter ratio: 0.0000  Data: 0.046 (0.039)
INFO:Train: 257 [ 500/625 ( 80%)]  Loss: 0.003303 (0.00331)  Time: 0.707s, 2896.42/s  (0.716s, 2861.45/s)  avg LR: 4.462e-04  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 257 [ 550/625 ( 88%)]  Loss: 0.003538 (0.00333)  Time: 0.704s, 2908.65/s  (0.715s, 2865.86/s)  avg LR: 4.462e-04  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 257 [ 600/625 ( 96%)]  Loss: 0.002651 (0.00327)  Time: 0.718s, 2851.23/s  (0.715s, 2865.97/s)  avg LR: 4.462e-04  iter ratio: 0.0000  Data: 0.044 (0.038)
INFO:Train: 257 [ 624/625 (100%)]  Loss: 0.003418 (0.00328)  Time: 0.676s, 3030.25/s  (0.715s, 2866.10/s)  avg LR: 4.462e-04  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.333 (4.333)  Loss:  0.5605 (0.5605)  Acc@1: 86.4746 (86.4746)  Acc@5: 97.7051 (97.7051)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.5059 (0.8368)  Acc@1: 86.6745 (80.6600)  Acc@5: 97.1698 (95.1380)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-256.pth.tar', 80.75800005615234)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-257.pth.tar', 80.66000002929688)

INFO:257-epoch: remaining time 6.79 h
INFO:Train: 258 [   0/625 (  0%)]  Loss: 0.003102 (0.00310)  Time: 4.149s,  493.60/s  (4.149s,  493.60/s)  avg LR: 4.283e-04  iter ratio: 0.0000  Data: 3.454 (3.454)
INFO:Train: 258 [  50/625 (  8%)]  Loss: 0.003460 (0.00328)  Time: 0.700s, 2924.48/s  (0.773s, 2648.07/s)  avg LR: 4.283e-04  iter ratio: 0.0000  Data: 0.024 (0.094)
INFO:Train: 258 [ 100/625 ( 16%)]  Loss: 0.003621 (0.00339)  Time: 0.705s, 2906.32/s  (0.739s, 2770.91/s)  avg LR: 4.283e-04  iter ratio: 0.0000  Data: 0.024 (0.060)
INFO:Train: 258 [ 150/625 ( 24%)]  Loss: 0.002935 (0.00328)  Time: 0.703s, 2914.59/s  (0.728s, 2813.40/s)  avg LR: 4.283e-04  iter ratio: 0.0000  Data: 0.027 (0.049)
INFO:Train: 258 [ 200/625 ( 32%)]  Loss: 0.003084 (0.00324)  Time: 0.701s, 2921.52/s  (0.723s, 2833.11/s)  avg LR: 4.283e-04  iter ratio: 0.0000  Data: 0.023 (0.044)
INFO:Train: 258 [ 250/625 ( 40%)]  Loss: 0.002776 (0.00316)  Time: 0.705s, 2903.59/s  (0.719s, 2847.54/s)  avg LR: 4.283e-04  iter ratio: 0.0000  Data: 0.027 (0.040)
INFO:Train: 258 [ 300/625 ( 48%)]  Loss: 0.003770 (0.00325)  Time: 0.700s, 2925.81/s  (0.717s, 2856.16/s)  avg LR: 4.283e-04  iter ratio: 0.0000  Data: 0.024 (0.038)
INFO:Train: 258 [ 350/625 ( 56%)]  Loss: 0.002722 (0.00318)  Time: 0.703s, 2911.92/s  (0.715s, 2862.71/s)  avg LR: 4.283e-04  iter ratio: 0.0000  Data: 0.025 (0.036)
INFO:Train: 258 [ 400/625 ( 64%)]  Loss: 0.003595 (0.00323)  Time: 0.711s, 2880.36/s  (0.714s, 2867.98/s)  avg LR: 4.283e-04  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 258 [ 450/625 ( 72%)]  Loss: 0.003897 (0.00330)  Time: 0.719s, 2849.45/s  (0.714s, 2866.63/s)  avg LR: 4.283e-04  iter ratio: 0.0000  Data: 0.042 (0.035)
INFO:Train: 258 [ 500/625 ( 80%)]  Loss: 0.003132 (0.00328)  Time: 0.701s, 2919.78/s  (0.715s, 2865.97/s)  avg LR: 4.283e-04  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 258 [ 550/625 ( 88%)]  Loss: 0.003813 (0.00333)  Time: 0.704s, 2909.67/s  (0.714s, 2869.16/s)  avg LR: 4.283e-04  iter ratio: 0.0000  Data: 0.027 (0.035)
INFO:Train: 258 [ 600/625 ( 96%)]  Loss: 0.003397 (0.00333)  Time: 0.718s, 2851.89/s  (0.714s, 2869.78/s)  avg LR: 4.283e-04  iter ratio: 0.0000  Data: 0.039 (0.035)
INFO:Train: 258 [ 624/625 (100%)]  Loss: 0.003067 (0.00331)  Time: 0.681s, 3008.15/s  (0.714s, 2869.75/s)  avg LR: 4.283e-04  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.359 (4.359)  Loss:  0.5352 (0.5352)  Acc@1: 87.5977 (87.5977)  Acc@5: 97.8516 (97.8516)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.4917 (0.8305)  Acc@1: 87.0283 (80.9700)  Acc@5: 97.8774 (95.3240)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-258.pth.tar', 80.97000005371093)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-256.pth.tar', 80.75800005615234)

INFO:258-epoch: remaining time 6.67 h
INFO:Train: 259 [   0/625 (  0%)]  Loss: 0.002726 (0.00273)  Time: 4.306s,  475.58/s  (4.306s,  475.58/s)  avg LR: 4.108e-04  iter ratio: 0.0000  Data: 3.609 (3.609)
INFO:Train: 259 [  50/625 (  8%)]  Loss: 0.002489 (0.00261)  Time: 0.707s, 2898.52/s  (0.774s, 2644.82/s)  avg LR: 4.108e-04  iter ratio: 0.0000  Data: 0.028 (0.096)
INFO:Train: 259 [ 100/625 ( 16%)]  Loss: 0.003413 (0.00288)  Time: 0.707s, 2895.16/s  (0.739s, 2771.60/s)  avg LR: 4.108e-04  iter ratio: 0.0000  Data: 0.029 (0.061)
INFO:Train: 259 [ 150/625 ( 24%)]  Loss: 0.003958 (0.00315)  Time: 0.709s, 2889.59/s  (0.727s, 2817.35/s)  avg LR: 4.108e-04  iter ratio: 0.0000  Data: 0.032 (0.049)
INFO:Train: 259 [ 200/625 ( 32%)]  Loss: 0.003420 (0.00320)  Time: 0.708s, 2892.97/s  (0.721s, 2841.04/s)  avg LR: 4.108e-04  iter ratio: 0.0000  Data: 0.033 (0.044)
INFO:Train: 259 [ 250/625 ( 40%)]  Loss: 0.003100 (0.00318)  Time: 0.708s, 2892.95/s  (0.717s, 2854.44/s)  avg LR: 4.108e-04  iter ratio: 0.0000  Data: 0.033 (0.040)
INFO:Train: 259 [ 300/625 ( 48%)]  Loss: 0.003221 (0.00319)  Time: 0.703s, 2913.12/s  (0.715s, 2863.80/s)  avg LR: 4.108e-04  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 259 [ 350/625 ( 56%)]  Loss: 0.002818 (0.00314)  Time: 0.710s, 2883.31/s  (0.713s, 2870.63/s)  avg LR: 4.108e-04  iter ratio: 0.0000  Data: 0.032 (0.037)
INFO:Train: 259 [ 400/625 ( 64%)]  Loss: 0.002818 (0.00311)  Time: 0.704s, 2907.88/s  (0.712s, 2875.98/s)  avg LR: 4.108e-04  iter ratio: 0.0000  Data: 0.031 (0.036)
INFO:Train: 259 [ 450/625 ( 72%)]  Loss: 0.002572 (0.00305)  Time: 0.707s, 2897.39/s  (0.711s, 2879.82/s)  avg LR: 4.108e-04  iter ratio: 0.0000  Data: 0.032 (0.035)
INFO:Train: 259 [ 500/625 ( 80%)]  Loss: 0.003646 (0.00311)  Time: 0.701s, 2920.62/s  (0.710s, 2883.67/s)  avg LR: 4.108e-04  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 259 [ 550/625 ( 88%)]  Loss: 0.002807 (0.00308)  Time: 0.705s, 2903.09/s  (0.710s, 2885.99/s)  avg LR: 4.108e-04  iter ratio: 0.0000  Data: 0.031 (0.033)
INFO:Train: 259 [ 600/625 ( 96%)]  Loss: 0.002308 (0.00302)  Time: 0.705s, 2904.70/s  (0.709s, 2887.19/s)  avg LR: 4.108e-04  iter ratio: 0.0000  Data: 0.027 (0.033)
INFO:Train: 259 [ 624/625 (100%)]  Loss: 0.003411 (0.00305)  Time: 0.675s, 3035.27/s  (0.709s, 2888.18/s)  avg LR: 4.108e-04  iter ratio: 0.0000  Data: 0.000 (0.032)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.319 (4.319)  Loss:  0.5767 (0.5767)  Acc@1: 86.9141 (86.9141)  Acc@5: 97.6074 (97.6074)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.5303 (0.8578)  Acc@1: 86.0849 (80.8380)  Acc@5: 97.8774 (95.3140)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-258.pth.tar', 80.97000005371093)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-259.pth.tar', 80.83799990234375)

INFO:259-epoch: remaining time 6.48 h
INFO:Train: 260 [   0/625 (  0%)]  Loss: 0.003429 (0.00343)  Time: 4.084s,  501.51/s  (4.084s,  501.51/s)  avg LR: 3.937e-04  iter ratio: 0.0000  Data: 3.397 (3.397)
INFO:Train: 260 [  50/625 (  8%)]  Loss: 0.003759 (0.00359)  Time: 0.700s, 2924.99/s  (0.777s, 2636.47/s)  avg LR: 3.937e-04  iter ratio: 0.0000  Data: 0.023 (0.095)
INFO:Train: 260 [ 100/625 ( 16%)]  Loss: 0.003256 (0.00348)  Time: 0.716s, 2859.79/s  (0.744s, 2752.16/s)  avg LR: 3.937e-04  iter ratio: 0.0000  Data: 0.037 (0.062)
INFO:Train: 260 [ 150/625 ( 24%)]  Loss: 0.002947 (0.00335)  Time: 0.712s, 2876.47/s  (0.736s, 2784.45/s)  avg LR: 3.937e-04  iter ratio: 0.0000  Data: 0.037 (0.054)
INFO:Train: 260 [ 200/625 ( 32%)]  Loss: 0.003284 (0.00333)  Time: 0.713s, 2871.10/s  (0.731s, 2800.73/s)  avg LR: 3.937e-04  iter ratio: 0.0000  Data: 0.038 (0.050)
INFO:Train: 260 [ 250/625 ( 40%)]  Loss: 0.003133 (0.00330)  Time: 0.713s, 2871.27/s  (0.728s, 2812.11/s)  avg LR: 3.937e-04  iter ratio: 0.0000  Data: 0.038 (0.047)
INFO:Train: 260 [ 300/625 ( 48%)]  Loss: 0.002599 (0.00320)  Time: 0.714s, 2868.39/s  (0.726s, 2819.35/s)  avg LR: 3.937e-04  iter ratio: 0.0000  Data: 0.038 (0.046)
INFO:Train: 260 [ 350/625 ( 56%)]  Loss: 0.003057 (0.00318)  Time: 0.719s, 2850.19/s  (0.725s, 2824.39/s)  avg LR: 3.937e-04  iter ratio: 0.0000  Data: 0.037 (0.045)
INFO:Train: 260 [ 400/625 ( 64%)]  Loss: 0.004077 (0.00328)  Time: 0.714s, 2866.65/s  (0.724s, 2827.57/s)  avg LR: 3.937e-04  iter ratio: 0.0000  Data: 0.040 (0.044)
INFO:Train: 260 [ 450/625 ( 72%)]  Loss: 0.003641 (0.00332)  Time: 0.713s, 2872.88/s  (0.724s, 2830.02/s)  avg LR: 3.937e-04  iter ratio: 0.0000  Data: 0.031 (0.043)
INFO:Train: 260 [ 500/625 ( 80%)]  Loss: 0.003084 (0.00330)  Time: 0.704s, 2911.04/s  (0.723s, 2834.04/s)  avg LR: 3.937e-04  iter ratio: 0.0000  Data: 0.021 (0.042)
INFO:Train: 260 [ 550/625 ( 88%)]  Loss: 0.003149 (0.00328)  Time: 0.700s, 2924.77/s  (0.721s, 2840.64/s)  avg LR: 3.937e-04  iter ratio: 0.0000  Data: 0.024 (0.040)
INFO:Train: 260 [ 600/625 ( 96%)]  Loss: 0.003595 (0.00331)  Time: 0.718s, 2853.70/s  (0.720s, 2842.89/s)  avg LR: 3.937e-04  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 260 [ 624/625 (100%)]  Loss: 0.003109 (0.00329)  Time: 0.679s, 3016.46/s  (0.720s, 2843.72/s)  avg LR: 3.937e-04  iter ratio: 0.0000  Data: 0.000 (0.039)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.289 (4.289)  Loss:  0.5547 (0.5547)  Acc@1: 87.4512 (87.4512)  Acc@5: 97.9980 (97.9980)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.5283 (0.8373)  Acc@1: 86.3208 (80.9080)  Acc@5: 97.5236 (95.2020)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-258.pth.tar', 80.97000005371093)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-260.pth.tar', 80.90800000488281)

INFO:260-epoch: remaining time 6.46 h
INFO:Train: 261 [   0/625 (  0%)]  Loss: 0.003687 (0.00369)  Time: 4.540s,  451.12/s  (4.540s,  451.12/s)  avg LR: 3.769e-04  iter ratio: 0.0000  Data: 3.849 (3.849)
INFO:Train: 261 [  50/625 (  8%)]  Loss: 0.003127 (0.00341)  Time: 0.711s, 2881.42/s  (0.778s, 2631.48/s)  avg LR: 3.769e-04  iter ratio: 0.0000  Data: 0.028 (0.102)
INFO:Train: 261 [ 100/625 ( 16%)]  Loss: 0.003102 (0.00331)  Time: 0.707s, 2896.82/s  (0.743s, 2754.91/s)  avg LR: 3.769e-04  iter ratio: 0.0000  Data: 0.033 (0.067)
INFO:Train: 261 [ 150/625 ( 24%)]  Loss: 0.003807 (0.00343)  Time: 0.708s, 2891.98/s  (0.730s, 2805.71/s)  avg LR: 3.769e-04  iter ratio: 0.0000  Data: 0.034 (0.054)
INFO:Train: 261 [ 200/625 ( 32%)]  Loss: 0.003474 (0.00344)  Time: 0.709s, 2889.26/s  (0.724s, 2830.53/s)  avg LR: 3.769e-04  iter ratio: 0.0000  Data: 0.035 (0.047)
INFO:Train: 261 [ 250/625 ( 40%)]  Loss: 0.003496 (0.00345)  Time: 0.700s, 2925.30/s  (0.719s, 2846.88/s)  avg LR: 3.769e-04  iter ratio: 0.0000  Data: 0.026 (0.043)
INFO:Train: 261 [ 300/625 ( 48%)]  Loss: 0.003551 (0.00346)  Time: 0.706s, 2898.87/s  (0.717s, 2857.80/s)  avg LR: 3.769e-04  iter ratio: 0.0000  Data: 0.025 (0.041)
INFO:Train: 261 [ 350/625 ( 56%)]  Loss: 0.003129 (0.00342)  Time: 0.720s, 2843.28/s  (0.715s, 2865.21/s)  avg LR: 3.769e-04  iter ratio: 0.0000  Data: 0.043 (0.039)
INFO:Train: 261 [ 400/625 ( 64%)]  Loss: 0.003374 (0.00342)  Time: 0.706s, 2901.39/s  (0.713s, 2870.41/s)  avg LR: 3.769e-04  iter ratio: 0.0000  Data: 0.032 (0.038)
INFO:Train: 261 [ 450/625 ( 72%)]  Loss: 0.002824 (0.00336)  Time: 0.707s, 2895.11/s  (0.712s, 2874.43/s)  avg LR: 3.769e-04  iter ratio: 0.0000  Data: 0.032 (0.037)
INFO:Train: 261 [ 500/625 ( 80%)]  Loss: 0.003249 (0.00335)  Time: 0.714s, 2866.49/s  (0.712s, 2878.36/s)  avg LR: 3.769e-04  iter ratio: 0.0000  Data: 0.038 (0.036)
INFO:Train: 261 [ 550/625 ( 88%)]  Loss: 0.002466 (0.00327)  Time: 0.707s, 2897.80/s  (0.711s, 2881.40/s)  avg LR: 3.769e-04  iter ratio: 0.0000  Data: 0.031 (0.035)
INFO:Train: 261 [ 600/625 ( 96%)]  Loss: 0.003812 (0.00332)  Time: 0.711s, 2880.95/s  (0.710s, 2883.27/s)  avg LR: 3.769e-04  iter ratio: 0.0000  Data: 0.036 (0.034)
INFO:Train: 261 [ 624/625 (100%)]  Loss: 0.003303 (0.00331)  Time: 0.678s, 3018.43/s  (0.710s, 2884.75/s)  avg LR: 3.769e-04  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.346 (4.346)  Loss:  0.5439 (0.5439)  Acc@1: 86.9629 (86.9629)  Acc@5: 97.7539 (97.7539)
INFO:Test: [  24/24]  Time: 0.080 (0.502)  Loss:  0.5015 (0.8320)  Acc@1: 86.7924 (81.0400)  Acc@5: 97.5236 (95.3200)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-261.pth.tar', 81.03999995117188)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-258.pth.tar', 80.97000005371093)

INFO:261-epoch: remaining time 6.24 h
INFO:Train: 262 [   0/625 (  0%)]  Loss: 0.003549 (0.00355)  Time: 4.168s,  491.34/s  (4.168s,  491.34/s)  avg LR: 3.606e-04  iter ratio: 0.0000  Data: 3.473 (3.473)
INFO:Train: 262 [  50/625 (  8%)]  Loss: 0.003591 (0.00357)  Time: 0.706s, 2899.06/s  (0.775s, 2643.89/s)  avg LR: 3.606e-04  iter ratio: 0.0000  Data: 0.022 (0.092)
INFO:Train: 262 [ 100/625 ( 16%)]  Loss: 0.002927 (0.00336)  Time: 0.718s, 2853.30/s  (0.744s, 2752.51/s)  avg LR: 3.606e-04  iter ratio: 0.0000  Data: 0.044 (0.063)
INFO:Train: 262 [ 150/625 ( 24%)]  Loss: 0.003287 (0.00334)  Time: 0.719s, 2847.81/s  (0.736s, 2783.57/s)  avg LR: 3.606e-04  iter ratio: 0.0000  Data: 0.044 (0.056)
INFO:Train: 262 [ 200/625 ( 32%)]  Loss: 0.003472 (0.00336)  Time: 0.721s, 2840.34/s  (0.732s, 2798.82/s)  avg LR: 3.606e-04  iter ratio: 0.0000  Data: 0.047 (0.053)
INFO:Train: 262 [ 250/625 ( 40%)]  Loss: 0.002812 (0.00327)  Time: 0.720s, 2846.00/s  (0.729s, 2808.01/s)  avg LR: 3.606e-04  iter ratio: 0.0000  Data: 0.045 (0.051)
INFO:Train: 262 [ 300/625 ( 48%)]  Loss: 0.003135 (0.00325)  Time: 0.720s, 2844.87/s  (0.728s, 2814.13/s)  avg LR: 3.606e-04  iter ratio: 0.0000  Data: 0.046 (0.049)
INFO:Train: 262 [ 350/625 ( 56%)]  Loss: 0.003309 (0.00326)  Time: 0.720s, 2846.30/s  (0.727s, 2818.26/s)  avg LR: 3.606e-04  iter ratio: 0.0000  Data: 0.045 (0.049)
INFO:Train: 262 [ 400/625 ( 64%)]  Loss: 0.002851 (0.00321)  Time: 0.719s, 2848.26/s  (0.726s, 2821.42/s)  avg LR: 3.606e-04  iter ratio: 0.0000  Data: 0.045 (0.048)
INFO:Train: 262 [ 450/625 ( 72%)]  Loss: 0.003441 (0.00324)  Time: 0.719s, 2846.83/s  (0.725s, 2824.12/s)  avg LR: 3.606e-04  iter ratio: 0.0000  Data: 0.045 (0.048)
INFO:Train: 262 [ 500/625 ( 80%)]  Loss: 0.002657 (0.00318)  Time: 0.717s, 2857.75/s  (0.725s, 2826.51/s)  avg LR: 3.606e-04  iter ratio: 0.0000  Data: 0.042 (0.047)
INFO:Train: 262 [ 550/625 ( 88%)]  Loss: 0.003330 (0.00320)  Time: 0.704s, 2908.53/s  (0.723s, 2832.26/s)  avg LR: 3.606e-04  iter ratio: 0.0000  Data: 0.025 (0.046)
INFO:Train: 262 [ 600/625 ( 96%)]  Loss: 0.003534 (0.00322)  Time: 0.705s, 2903.33/s  (0.722s, 2837.74/s)  avg LR: 3.606e-04  iter ratio: 0.0000  Data: 0.026 (0.044)
INFO:Train: 262 [ 624/625 (100%)]  Loss: 0.003245 (0.00322)  Time: 0.675s, 3034.25/s  (0.721s, 2840.63/s)  avg LR: 3.606e-04  iter ratio: 0.0000  Data: 0.000 (0.043)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.311 (4.311)  Loss:  0.5483 (0.5483)  Acc@1: 87.3047 (87.3047)  Acc@5: 97.8516 (97.8516)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.4954 (0.8307)  Acc@1: 86.0849 (81.0440)  Acc@5: 97.6415 (95.3860)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-262.pth.tar', 81.04400003173828)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-261.pth.tar', 81.03999995117188)

INFO:262-epoch: remaining time 6.21 h
INFO:Train: 263 [   0/625 (  0%)]  Loss: 0.003117 (0.00312)  Time: 4.291s,  477.28/s  (4.291s,  477.28/s)  avg LR: 3.447e-04  iter ratio: 0.0000  Data: 3.599 (3.599)
INFO:Train: 263 [  50/625 (  8%)]  Loss: 0.003510 (0.00331)  Time: 0.706s, 2902.63/s  (0.781s, 2623.91/s)  avg LR: 3.447e-04  iter ratio: 0.0000  Data: 0.023 (0.098)
INFO:Train: 263 [ 100/625 ( 16%)]  Loss: 0.003370 (0.00333)  Time: 0.704s, 2908.89/s  (0.744s, 2754.27/s)  avg LR: 3.447e-04  iter ratio: 0.0000  Data: 0.026 (0.062)
INFO:Train: 263 [ 150/625 ( 24%)]  Loss: 0.003601 (0.00340)  Time: 0.704s, 2907.51/s  (0.731s, 2803.31/s)  avg LR: 3.447e-04  iter ratio: 0.0000  Data: 0.021 (0.049)
INFO:Train: 263 [ 200/625 ( 32%)]  Loss: 0.003138 (0.00335)  Time: 0.707s, 2894.96/s  (0.725s, 2826.48/s)  avg LR: 3.447e-04  iter ratio: 0.0000  Data: 0.024 (0.042)
INFO:Train: 263 [ 250/625 ( 40%)]  Loss: 0.003479 (0.00337)  Time: 0.709s, 2889.00/s  (0.721s, 2841.09/s)  avg LR: 3.447e-04  iter ratio: 0.0000  Data: 0.023 (0.038)
INFO:Train: 263 [ 300/625 ( 48%)]  Loss: 0.003444 (0.00338)  Time: 0.708s, 2892.13/s  (0.718s, 2850.64/s)  avg LR: 3.447e-04  iter ratio: 0.0000  Data: 0.023 (0.035)
INFO:Train: 263 [ 350/625 ( 56%)]  Loss: 0.003105 (0.00335)  Time: 0.708s, 2892.12/s  (0.717s, 2857.55/s)  avg LR: 3.447e-04  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 263 [ 400/625 ( 64%)]  Loss: 0.003228 (0.00333)  Time: 0.707s, 2895.23/s  (0.715s, 2862.50/s)  avg LR: 3.447e-04  iter ratio: 0.0000  Data: 0.029 (0.033)
INFO:Train: 263 [ 450/625 ( 72%)]  Loss: 0.003760 (0.00338)  Time: 0.706s, 2899.21/s  (0.714s, 2866.77/s)  avg LR: 3.447e-04  iter ratio: 0.0000  Data: 0.027 (0.032)
INFO:Train: 263 [ 500/625 ( 80%)]  Loss: 0.003996 (0.00343)  Time: 0.705s, 2906.97/s  (0.714s, 2870.19/s)  avg LR: 3.447e-04  iter ratio: 0.0000  Data: 0.024 (0.031)
INFO:Train: 263 [ 550/625 ( 88%)]  Loss: 0.002726 (0.00337)  Time: 0.709s, 2889.37/s  (0.713s, 2873.06/s)  avg LR: 3.447e-04  iter ratio: 0.0000  Data: 0.024 (0.031)
INFO:Train: 263 [ 600/625 ( 96%)]  Loss: 0.003649 (0.00339)  Time: 0.709s, 2887.39/s  (0.712s, 2875.38/s)  avg LR: 3.447e-04  iter ratio: 0.0000  Data: 0.029 (0.030)
INFO:Train: 263 [ 624/625 (100%)]  Loss: 0.003394 (0.00339)  Time: 0.679s, 3014.51/s  (0.712s, 2876.95/s)  avg LR: 3.447e-04  iter ratio: 0.0000  Data: 0.000 (0.030)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.363 (4.363)  Loss:  0.5479 (0.5479)  Acc@1: 86.9629 (86.9629)  Acc@5: 97.9004 (97.9004)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.5078 (0.8250)  Acc@1: 86.3208 (81.0400)  Acc@5: 97.8774 (95.3340)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-262.pth.tar', 81.04400003173828)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-263.pth.tar', 81.04000000488281)

INFO:263-epoch: remaining time 6.00 h
INFO:Train: 264 [   0/625 (  0%)]  Loss: 0.003715 (0.00372)  Time: 4.142s,  494.45/s  (4.142s,  494.45/s)  avg LR: 3.291e-04  iter ratio: 0.0000  Data: 3.442 (3.442)
INFO:Train: 264 [  50/625 (  8%)]  Loss: 0.003879 (0.00380)  Time: 0.706s, 2901.55/s  (0.776s, 2639.74/s)  avg LR: 3.291e-04  iter ratio: 0.0000  Data: 0.029 (0.097)
INFO:Train: 264 [ 100/625 ( 16%)]  Loss: 0.002798 (0.00346)  Time: 0.705s, 2905.20/s  (0.743s, 2757.48/s)  avg LR: 3.291e-04  iter ratio: 0.0000  Data: 0.029 (0.064)
INFO:Train: 264 [ 150/625 ( 24%)]  Loss: 0.004100 (0.00362)  Time: 0.710s, 2885.70/s  (0.731s, 2799.82/s)  avg LR: 3.291e-04  iter ratio: 0.0000  Data: 0.032 (0.053)
INFO:Train: 264 [ 200/625 ( 32%)]  Loss: 0.002594 (0.00342)  Time: 0.704s, 2909.65/s  (0.726s, 2821.49/s)  avg LR: 3.291e-04  iter ratio: 0.0000  Data: 0.029 (0.047)
INFO:Train: 264 [ 250/625 ( 40%)]  Loss: 0.003055 (0.00336)  Time: 0.713s, 2873.39/s  (0.722s, 2834.71/s)  avg LR: 3.291e-04  iter ratio: 0.0000  Data: 0.037 (0.044)
INFO:Train: 264 [ 300/625 ( 48%)]  Loss: 0.002773 (0.00327)  Time: 0.713s, 2874.32/s  (0.720s, 2843.22/s)  avg LR: 3.291e-04  iter ratio: 0.0000  Data: 0.037 (0.042)
INFO:Train: 264 [ 350/625 ( 56%)]  Loss: 0.003350 (0.00328)  Time: 0.712s, 2876.46/s  (0.719s, 2849.16/s)  avg LR: 3.291e-04  iter ratio: 0.0000  Data: 0.037 (0.040)
INFO:Train: 264 [ 400/625 ( 64%)]  Loss: 0.002897 (0.00324)  Time: 0.714s, 2867.46/s  (0.718s, 2853.84/s)  avg LR: 3.291e-04  iter ratio: 0.0000  Data: 0.038 (0.039)
INFO:Train: 264 [ 450/625 ( 72%)]  Loss: 0.003244 (0.00324)  Time: 0.712s, 2877.02/s  (0.717s, 2857.30/s)  avg LR: 3.291e-04  iter ratio: 0.0000  Data: 0.036 (0.038)
INFO:Train: 264 [ 500/625 ( 80%)]  Loss: 0.003315 (0.00325)  Time: 0.712s, 2875.03/s  (0.716s, 2859.92/s)  avg LR: 3.291e-04  iter ratio: 0.0000  Data: 0.037 (0.038)
INFO:Train: 264 [ 550/625 ( 88%)]  Loss: 0.003370 (0.00326)  Time: 0.714s, 2869.93/s  (0.715s, 2863.82/s)  avg LR: 3.291e-04  iter ratio: 0.0000  Data: 0.039 (0.037)
INFO:Train: 264 [ 600/625 ( 96%)]  Loss: 0.003177 (0.00325)  Time: 0.701s, 2920.10/s  (0.714s, 2866.84/s)  avg LR: 3.291e-04  iter ratio: 0.0000  Data: 0.023 (0.036)
INFO:Train: 264 [ 624/625 (100%)]  Loss: 0.003712 (0.00328)  Time: 0.679s, 3018.24/s  (0.714s, 2869.01/s)  avg LR: 3.291e-04  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.310 (4.310)  Loss:  0.5469 (0.5469)  Acc@1: 86.9629 (86.9629)  Acc@5: 97.7539 (97.7539)
INFO:Test: [  24/24]  Time: 0.080 (0.507)  Loss:  0.4944 (0.8211)  Acc@1: 86.6745 (81.2000)  Acc@5: 97.6415 (95.3180)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-264.pth.tar', 81.20000002929687)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-262.pth.tar', 81.04400003173828)

INFO:264-epoch: remaining time 5.89 h
INFO:Train: 265 [   0/625 (  0%)]  Loss: 0.003060 (0.00306)  Time: 4.429s,  462.38/s  (4.429s,  462.38/s)  avg LR: 3.140e-04  iter ratio: 0.0000  Data: 3.728 (3.728)
INFO:Train: 265 [  50/625 (  8%)]  Loss: 0.004140 (0.00360)  Time: 0.710s, 2885.19/s  (0.777s, 2636.34/s)  avg LR: 3.140e-04  iter ratio: 0.0000  Data: 0.035 (0.099)
INFO:Train: 265 [ 100/625 ( 16%)]  Loss: 0.003072 (0.00342)  Time: 0.704s, 2910.95/s  (0.740s, 2766.46/s)  avg LR: 3.140e-04  iter ratio: 0.0000  Data: 0.025 (0.063)
INFO:Train: 265 [ 150/625 ( 24%)]  Loss: 0.002914 (0.00330)  Time: 0.701s, 2922.55/s  (0.727s, 2815.32/s)  avg LR: 3.140e-04  iter ratio: 0.0000  Data: 0.026 (0.050)
INFO:Train: 265 [ 200/625 ( 32%)]  Loss: 0.002528 (0.00314)  Time: 0.703s, 2913.09/s  (0.721s, 2839.15/s)  avg LR: 3.140e-04  iter ratio: 0.0000  Data: 0.020 (0.044)
INFO:Train: 265 [ 250/625 ( 40%)]  Loss: 0.003460 (0.00320)  Time: 0.702s, 2918.63/s  (0.718s, 2854.04/s)  avg LR: 3.140e-04  iter ratio: 0.0000  Data: 0.025 (0.040)
INFO:Train: 265 [ 300/625 ( 48%)]  Loss: 0.002823 (0.00314)  Time: 0.700s, 2924.59/s  (0.715s, 2863.13/s)  avg LR: 3.140e-04  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 265 [ 350/625 ( 56%)]  Loss: 0.003441 (0.00318)  Time: 0.702s, 2915.58/s  (0.714s, 2870.04/s)  avg LR: 3.140e-04  iter ratio: 0.0000  Data: 0.025 (0.037)
INFO:Train: 265 [ 400/625 ( 64%)]  Loss: 0.003153 (0.00318)  Time: 0.697s, 2938.97/s  (0.713s, 2872.89/s)  avg LR: 3.140e-04  iter ratio: 0.0000  Data: 0.022 (0.036)
INFO:Train: 265 [ 450/625 ( 72%)]  Loss: 0.003310 (0.00319)  Time: 0.701s, 2922.62/s  (0.712s, 2877.19/s)  avg LR: 3.140e-04  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 265 [ 500/625 ( 80%)]  Loss: 0.003147 (0.00319)  Time: 0.702s, 2915.60/s  (0.712s, 2878.13/s)  avg LR: 3.140e-04  iter ratio: 0.0000  Data: 0.023 (0.034)
INFO:Train: 265 [ 550/625 ( 88%)]  Loss: 0.003367 (0.00320)  Time: 0.704s, 2908.37/s  (0.711s, 2881.30/s)  avg LR: 3.140e-04  iter ratio: 0.0000  Data: 0.027 (0.034)
INFO:Train: 265 [ 600/625 ( 96%)]  Loss: 0.002681 (0.00316)  Time: 0.720s, 2845.99/s  (0.710s, 2883.31/s)  avg LR: 3.140e-04  iter ratio: 0.0000  Data: 0.046 (0.033)
INFO:Train: 265 [ 624/625 (100%)]  Loss: 0.003780 (0.00321)  Time: 0.672s, 3047.34/s  (0.710s, 2883.75/s)  avg LR: 3.140e-04  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.361 (4.361)  Loss:  0.5850 (0.5850)  Acc@1: 86.8164 (86.8164)  Acc@5: 97.9004 (97.9004)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.5400 (0.8517)  Acc@1: 86.4387 (81.0980)  Acc@5: 97.4057 (95.2960)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-264.pth.tar', 81.20000002929687)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-265.pth.tar', 81.09799992675781)

INFO:265-epoch: remaining time 5.74 h
INFO:Train: 266 [   0/625 (  0%)]  Loss: 0.003180 (0.00318)  Time: 4.261s,  480.65/s  (4.261s,  480.65/s)  avg LR: 2.993e-04  iter ratio: 0.0000  Data: 3.568 (3.568)
INFO:Train: 266 [  50/625 (  8%)]  Loss: 0.003285 (0.00323)  Time: 0.707s, 2894.79/s  (0.780s, 2625.95/s)  avg LR: 2.993e-04  iter ratio: 0.0000  Data: 0.029 (0.102)
INFO:Train: 266 [ 100/625 ( 16%)]  Loss: 0.003428 (0.00330)  Time: 0.703s, 2912.61/s  (0.743s, 2757.38/s)  avg LR: 2.993e-04  iter ratio: 0.0000  Data: 0.026 (0.065)
INFO:Train: 266 [ 150/625 ( 24%)]  Loss: 0.002641 (0.00313)  Time: 0.706s, 2901.10/s  (0.730s, 2805.55/s)  avg LR: 2.993e-04  iter ratio: 0.0000  Data: 0.030 (0.053)
INFO:Train: 266 [ 200/625 ( 32%)]  Loss: 0.003400 (0.00319)  Time: 0.703s, 2913.58/s  (0.724s, 2830.50/s)  avg LR: 2.993e-04  iter ratio: 0.0000  Data: 0.028 (0.047)
INFO:Train: 266 [ 250/625 ( 40%)]  Loss: 0.002616 (0.00309)  Time: 0.706s, 2901.61/s  (0.720s, 2845.56/s)  avg LR: 2.993e-04  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 266 [ 300/625 ( 48%)]  Loss: 0.003969 (0.00322)  Time: 0.705s, 2905.25/s  (0.717s, 2856.22/s)  avg LR: 2.993e-04  iter ratio: 0.0000  Data: 0.029 (0.041)
INFO:Train: 266 [ 350/625 ( 56%)]  Loss: 0.003054 (0.00320)  Time: 0.707s, 2898.71/s  (0.715s, 2864.12/s)  avg LR: 2.993e-04  iter ratio: 0.0000  Data: 0.031 (0.039)
INFO:Train: 266 [ 400/625 ( 64%)]  Loss: 0.002654 (0.00314)  Time: 0.704s, 2907.81/s  (0.714s, 2869.71/s)  avg LR: 2.993e-04  iter ratio: 0.0000  Data: 0.029 (0.037)
INFO:Train: 266 [ 450/625 ( 72%)]  Loss: 0.003504 (0.00317)  Time: 0.703s, 2912.93/s  (0.713s, 2874.16/s)  avg LR: 2.993e-04  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 266 [ 500/625 ( 80%)]  Loss: 0.002868 (0.00315)  Time: 0.704s, 2909.27/s  (0.712s, 2878.18/s)  avg LR: 2.993e-04  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 266 [ 550/625 ( 88%)]  Loss: 0.004048 (0.00322)  Time: 0.705s, 2903.18/s  (0.711s, 2881.22/s)  avg LR: 2.993e-04  iter ratio: 0.0000  Data: 0.030 (0.035)
INFO:Train: 266 [ 600/625 ( 96%)]  Loss: 0.003196 (0.00322)  Time: 0.702s, 2918.71/s  (0.710s, 2883.82/s)  avg LR: 2.993e-04  iter ratio: 0.0000  Data: 0.026 (0.034)
INFO:Train: 266 [ 624/625 (100%)]  Loss: 0.003346 (0.00323)  Time: 0.672s, 3046.49/s  (0.710s, 2885.40/s)  avg LR: 2.993e-04  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.325 (4.325)  Loss:  0.5586 (0.5586)  Acc@1: 87.3535 (87.3535)  Acc@5: 97.9492 (97.9492)
INFO:Test: [  24/24]  Time: 0.081 (0.507)  Loss:  0.5024 (0.8316)  Acc@1: 87.0283 (81.1940)  Acc@5: 97.4057 (95.4000)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-264.pth.tar', 81.20000002929687)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-266.pth.tar', 81.1939999243164)

INFO:266-epoch: remaining time 5.60 h
INFO:Train: 267 [   0/625 (  0%)]  Loss: 0.003241 (0.00324)  Time: 4.364s,  469.34/s  (4.364s,  469.34/s)  avg LR: 2.850e-04  iter ratio: 0.0000  Data: 3.668 (3.668)
INFO:Train: 267 [  50/625 (  8%)]  Loss: 0.003594 (0.00342)  Time: 0.702s, 2917.26/s  (0.775s, 2642.28/s)  avg LR: 2.850e-04  iter ratio: 0.0000  Data: 0.026 (0.098)
INFO:Train: 267 [ 100/625 ( 16%)]  Loss: 0.003631 (0.00349)  Time: 0.712s, 2876.84/s  (0.739s, 2770.23/s)  avg LR: 2.850e-04  iter ratio: 0.0000  Data: 0.036 (0.062)
INFO:Train: 267 [ 150/625 ( 24%)]  Loss: 0.002920 (0.00335)  Time: 0.717s, 2857.29/s  (0.732s, 2798.06/s)  avg LR: 2.850e-04  iter ratio: 0.0000  Data: 0.041 (0.055)
INFO:Train: 267 [ 200/625 ( 32%)]  Loss: 0.003355 (0.00335)  Time: 0.717s, 2856.20/s  (0.728s, 2811.74/s)  avg LR: 2.850e-04  iter ratio: 0.0000  Data: 0.040 (0.051)
INFO:Train: 267 [ 250/625 ( 40%)]  Loss: 0.003122 (0.00331)  Time: 0.701s, 2920.45/s  (0.724s, 2827.18/s)  avg LR: 2.850e-04  iter ratio: 0.0000  Data: 0.026 (0.047)
INFO:Train: 267 [ 300/625 ( 48%)]  Loss: 0.002858 (0.00325)  Time: 0.701s, 2919.48/s  (0.721s, 2840.70/s)  avg LR: 2.850e-04  iter ratio: 0.0000  Data: 0.025 (0.044)
INFO:Train: 267 [ 350/625 ( 56%)]  Loss: 0.003434 (0.00327)  Time: 0.721s, 2839.32/s  (0.719s, 2848.41/s)  avg LR: 2.850e-04  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 267 [ 400/625 ( 64%)]  Loss: 0.003693 (0.00332)  Time: 0.716s, 2862.26/s  (0.719s, 2849.21/s)  avg LR: 2.850e-04  iter ratio: 0.0000  Data: 0.041 (0.042)
INFO:Train: 267 [ 450/625 ( 72%)]  Loss: 0.004178 (0.00340)  Time: 0.716s, 2858.81/s  (0.719s, 2849.66/s)  avg LR: 2.850e-04  iter ratio: 0.0000  Data: 0.037 (0.042)
INFO:Train: 267 [ 500/625 ( 80%)]  Loss: 0.003738 (0.00343)  Time: 0.707s, 2896.68/s  (0.718s, 2853.94/s)  avg LR: 2.850e-04  iter ratio: 0.0000  Data: 0.028 (0.041)
INFO:Train: 267 [ 550/625 ( 88%)]  Loss: 0.002814 (0.00338)  Time: 0.711s, 2881.69/s  (0.716s, 2859.42/s)  avg LR: 2.850e-04  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 267 [ 600/625 ( 96%)]  Loss: 0.003327 (0.00338)  Time: 0.708s, 2891.57/s  (0.715s, 2862.48/s)  avg LR: 2.850e-04  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 267 [ 624/625 (100%)]  Loss: 0.002900 (0.00334)  Time: 0.677s, 3025.31/s  (0.715s, 2864.01/s)  avg LR: 2.850e-04  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.339 (4.339)  Loss:  0.5508 (0.5508)  Acc@1: 87.3535 (87.3535)  Acc@5: 98.0957 (98.0957)
INFO:Test: [  24/24]  Time: 0.080 (0.502)  Loss:  0.5259 (0.8234)  Acc@1: 87.1462 (81.2820)  Acc@5: 97.6415 (95.4740)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-267.pth.tar', 81.28199997558593)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-264.pth.tar', 81.20000002929687)

INFO:267-epoch: remaining time 5.51 h
INFO:Train: 268 [   0/625 (  0%)]  Loss: 0.003232 (0.00323)  Time: 4.220s,  485.27/s  (4.220s,  485.27/s)  avg LR: 2.711e-04  iter ratio: 0.0000  Data: 3.525 (3.525)
INFO:Train: 268 [  50/625 (  8%)]  Loss: 0.003004 (0.00312)  Time: 0.708s, 2894.65/s  (0.774s, 2646.23/s)  avg LR: 2.711e-04  iter ratio: 0.0000  Data: 0.019 (0.095)
INFO:Train: 268 [ 100/625 ( 16%)]  Loss: 0.002767 (0.00300)  Time: 0.700s, 2924.83/s  (0.741s, 2764.15/s)  avg LR: 2.711e-04  iter ratio: 0.0000  Data: 0.025 (0.061)
INFO:Train: 268 [ 150/625 ( 24%)]  Loss: 0.003861 (0.00322)  Time: 0.708s, 2892.18/s  (0.729s, 2809.24/s)  avg LR: 2.711e-04  iter ratio: 0.0000  Data: 0.033 (0.050)
INFO:Train: 268 [ 200/625 ( 32%)]  Loss: 0.003432 (0.00326)  Time: 0.717s, 2855.69/s  (0.723s, 2832.24/s)  avg LR: 2.711e-04  iter ratio: 0.0000  Data: 0.043 (0.045)
INFO:Train: 268 [ 250/625 ( 40%)]  Loss: 0.002873 (0.00319)  Time: 0.703s, 2913.50/s  (0.722s, 2836.37/s)  avg LR: 2.711e-04  iter ratio: 0.0000  Data: 0.024 (0.045)
INFO:Train: 268 [ 300/625 ( 48%)]  Loss: 0.003708 (0.00327)  Time: 0.702s, 2918.28/s  (0.719s, 2848.68/s)  avg LR: 2.711e-04  iter ratio: 0.0000  Data: 0.025 (0.042)
INFO:Train: 268 [ 350/625 ( 56%)]  Loss: 0.003192 (0.00326)  Time: 0.701s, 2921.08/s  (0.717s, 2857.35/s)  avg LR: 2.711e-04  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 268 [ 400/625 ( 64%)]  Loss: 0.002362 (0.00316)  Time: 0.706s, 2902.10/s  (0.717s, 2857.41/s)  avg LR: 2.711e-04  iter ratio: 0.0000  Data: 0.031 (0.040)
INFO:Train: 268 [ 450/625 ( 72%)]  Loss: 0.003849 (0.00323)  Time: 0.712s, 2874.80/s  (0.717s, 2856.90/s)  avg LR: 2.711e-04  iter ratio: 0.0000  Data: 0.038 (0.040)
INFO:Train: 268 [ 500/625 ( 80%)]  Loss: 0.003573 (0.00326)  Time: 0.717s, 2856.17/s  (0.717s, 2856.59/s)  avg LR: 2.711e-04  iter ratio: 0.0000  Data: 0.043 (0.040)
INFO:Train: 268 [ 550/625 ( 88%)]  Loss: 0.003625 (0.00329)  Time: 0.695s, 2945.38/s  (0.716s, 2861.66/s)  avg LR: 2.711e-04  iter ratio: 0.0000  Data: 0.022 (0.039)
INFO:Train: 268 [ 600/625 ( 96%)]  Loss: 0.002650 (0.00324)  Time: 0.702s, 2918.00/s  (0.715s, 2865.78/s)  avg LR: 2.711e-04  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 268 [ 624/625 (100%)]  Loss: 0.003160 (0.00323)  Time: 0.675s, 3032.46/s  (0.714s, 2868.33/s)  avg LR: 2.711e-04  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.413 (4.413)  Loss:  0.5439 (0.5439)  Acc@1: 87.3535 (87.3535)  Acc@5: 97.9492 (97.9492)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.5278 (0.8280)  Acc@1: 86.4387 (81.3580)  Acc@5: 97.6415 (95.4460)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-268.pth.tar', 81.35799992675781)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-267.pth.tar', 81.28199997558593)

INFO:268-epoch: remaining time 5.38 h
INFO:Train: 269 [   0/625 (  0%)]  Loss: 0.002996 (0.00300)  Time: 4.184s,  489.48/s  (4.184s,  489.48/s)  avg LR: 2.576e-04  iter ratio: 0.0000  Data: 3.490 (3.490)
INFO:Train: 269 [  50/625 (  8%)]  Loss: 0.003347 (0.00317)  Time: 0.702s, 2919.38/s  (0.779s, 2629.06/s)  avg LR: 2.576e-04  iter ratio: 0.0000  Data: 0.028 (0.101)
INFO:Train: 269 [ 100/625 ( 16%)]  Loss: 0.002980 (0.00311)  Time: 0.705s, 2905.16/s  (0.743s, 2756.68/s)  avg LR: 2.576e-04  iter ratio: 0.0000  Data: 0.030 (0.066)
INFO:Train: 269 [ 150/625 ( 24%)]  Loss: 0.003070 (0.00310)  Time: 0.705s, 2903.48/s  (0.730s, 2804.55/s)  avg LR: 2.576e-04  iter ratio: 0.0000  Data: 0.029 (0.054)
INFO:Train: 269 [ 200/625 ( 32%)]  Loss: 0.003166 (0.00311)  Time: 0.708s, 2892.56/s  (0.724s, 2829.72/s)  avg LR: 2.576e-04  iter ratio: 0.0000  Data: 0.032 (0.047)
INFO:Train: 269 [ 250/625 ( 40%)]  Loss: 0.003121 (0.00311)  Time: 0.704s, 2909.76/s  (0.720s, 2844.73/s)  avg LR: 2.576e-04  iter ratio: 0.0000  Data: 0.025 (0.044)
INFO:Train: 269 [ 300/625 ( 48%)]  Loss: 0.003640 (0.00319)  Time: 0.723s, 2834.20/s  (0.720s, 2845.69/s)  avg LR: 2.576e-04  iter ratio: 0.0000  Data: 0.048 (0.043)
INFO:Train: 269 [ 350/625 ( 56%)]  Loss: 0.002400 (0.00309)  Time: 0.719s, 2848.07/s  (0.720s, 2845.99/s)  avg LR: 2.576e-04  iter ratio: 0.0000  Data: 0.044 (0.043)
INFO:Train: 269 [ 400/625 ( 64%)]  Loss: 0.003281 (0.00311)  Time: 0.726s, 2821.18/s  (0.720s, 2846.18/s)  avg LR: 2.576e-04  iter ratio: 0.0000  Data: 0.051 (0.044)
INFO:Train: 269 [ 450/625 ( 72%)]  Loss: 0.003745 (0.00317)  Time: 0.727s, 2818.80/s  (0.719s, 2846.46/s)  avg LR: 2.576e-04  iter ratio: 0.0000  Data: 0.052 (0.044)
INFO:Train: 269 [ 500/625 ( 80%)]  Loss: 0.003861 (0.00324)  Time: 0.725s, 2824.92/s  (0.719s, 2846.93/s)  avg LR: 2.576e-04  iter ratio: 0.0000  Data: 0.049 (0.044)
INFO:Train: 269 [ 550/625 ( 88%)]  Loss: 0.003204 (0.00323)  Time: 0.713s, 2873.98/s  (0.718s, 2850.91/s)  avg LR: 2.576e-04  iter ratio: 0.0000  Data: 0.038 (0.043)
INFO:Train: 269 [ 600/625 ( 96%)]  Loss: 0.003076 (0.00322)  Time: 0.702s, 2916.07/s  (0.717s, 2855.39/s)  avg LR: 2.576e-04  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 269 [ 624/625 (100%)]  Loss: 0.003561 (0.00325)  Time: 0.677s, 3023.51/s  (0.717s, 2857.87/s)  avg LR: 2.576e-04  iter ratio: 0.0000  Data: 0.000 (0.041)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.337 (4.337)  Loss:  0.5464 (0.5464)  Acc@1: 87.7441 (87.7441)  Acc@5: 98.0469 (98.0469)
INFO:Test: [  24/24]  Time: 0.080 (0.498)  Loss:  0.5181 (0.8235)  Acc@1: 86.6745 (81.2960)  Acc@5: 97.5236 (95.4660)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-268.pth.tar', 81.35799992675781)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-269.pth.tar', 81.29600002929688)

INFO:269-epoch: remaining time 5.27 h
INFO:Train: 270 [   0/625 (  0%)]  Loss: 0.003157 (0.00316)  Time: 4.197s,  487.92/s  (4.197s,  487.92/s)  avg LR: 2.446e-04  iter ratio: 0.0000  Data: 3.512 (3.512)
INFO:Train: 270 [  50/625 (  8%)]  Loss: 0.002493 (0.00282)  Time: 0.707s, 2896.85/s  (0.778s, 2632.20/s)  avg LR: 2.446e-04  iter ratio: 0.0000  Data: 0.030 (0.099)
INFO:Train: 270 [ 100/625 ( 16%)]  Loss: 0.003287 (0.00298)  Time: 0.703s, 2912.87/s  (0.743s, 2755.69/s)  avg LR: 2.446e-04  iter ratio: 0.0000  Data: 0.023 (0.064)
INFO:Train: 270 [ 150/625 ( 24%)]  Loss: 0.003424 (0.00309)  Time: 0.712s, 2878.11/s  (0.731s, 2800.02/s)  avg LR: 2.446e-04  iter ratio: 0.0000  Data: 0.026 (0.051)
INFO:Train: 270 [ 200/625 ( 32%)]  Loss: 0.003038 (0.00308)  Time: 0.706s, 2901.27/s  (0.726s, 2821.39/s)  avg LR: 2.446e-04  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 270 [ 250/625 ( 40%)]  Loss: 0.003300 (0.00312)  Time: 0.713s, 2872.72/s  (0.722s, 2835.88/s)  avg LR: 2.446e-04  iter ratio: 0.0000  Data: 0.024 (0.041)
INFO:Train: 270 [ 300/625 ( 48%)]  Loss: 0.003250 (0.00314)  Time: 0.709s, 2887.07/s  (0.720s, 2846.09/s)  avg LR: 2.446e-04  iter ratio: 0.0000  Data: 0.024 (0.039)
INFO:Train: 270 [ 350/625 ( 56%)]  Loss: 0.002924 (0.00311)  Time: 0.708s, 2892.70/s  (0.718s, 2853.79/s)  avg LR: 2.446e-04  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 270 [ 400/625 ( 64%)]  Loss: 0.002491 (0.00304)  Time: 0.708s, 2891.44/s  (0.716s, 2858.52/s)  avg LR: 2.446e-04  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 270 [ 450/625 ( 72%)]  Loss: 0.002798 (0.00302)  Time: 0.704s, 2911.05/s  (0.715s, 2862.52/s)  avg LR: 2.446e-04  iter ratio: 0.0000  Data: 0.025 (0.035)
INFO:Train: 270 [ 500/625 ( 80%)]  Loss: 0.002949 (0.00301)  Time: 0.707s, 2897.75/s  (0.715s, 2865.73/s)  avg LR: 2.446e-04  iter ratio: 0.0000  Data: 0.030 (0.034)
INFO:Train: 270 [ 550/625 ( 88%)]  Loss: 0.003670 (0.00307)  Time: 0.711s, 2881.59/s  (0.714s, 2869.34/s)  avg LR: 2.446e-04  iter ratio: 0.0000  Data: 0.030 (0.034)
INFO:Train: 270 [ 600/625 ( 96%)]  Loss: 0.003097 (0.00307)  Time: 0.713s, 2872.29/s  (0.713s, 2870.94/s)  avg LR: 2.446e-04  iter ratio: 0.0000  Data: 0.028 (0.033)
INFO:Train: 270 [ 624/625 (100%)]  Loss: 0.003444 (0.00309)  Time: 0.680s, 3012.93/s  (0.713s, 2872.32/s)  avg LR: 2.446e-04  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.473 (4.473)  Loss:  0.5386 (0.5386)  Acc@1: 87.1094 (87.1094)  Acc@5: 97.7051 (97.7051)
INFO:Test: [  24/24]  Time: 0.080 (0.507)  Loss:  0.5107 (0.8254)  Acc@1: 87.2642 (81.3360)  Acc@5: 97.7594 (95.5180)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-268.pth.tar', 81.35799992675781)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-270.pth.tar', 81.33600002685547)

INFO:270-epoch: remaining time 5.12 h
INFO:Train: 271 [   0/625 (  0%)]  Loss: 0.003461 (0.00346)  Time: 4.397s,  465.75/s  (4.397s,  465.75/s)  avg LR: 2.319e-04  iter ratio: 0.0000  Data: 3.696 (3.696)
INFO:Train: 271 [  50/625 (  8%)]  Loss: 0.003671 (0.00357)  Time: 0.723s, 2833.20/s  (0.781s, 2622.79/s)  avg LR: 2.319e-04  iter ratio: 0.0000  Data: 0.048 (0.102)
INFO:Train: 271 [ 100/625 ( 16%)]  Loss: 0.002644 (0.00326)  Time: 0.707s, 2896.87/s  (0.747s, 2740.61/s)  avg LR: 2.319e-04  iter ratio: 0.0000  Data: 0.029 (0.069)
INFO:Train: 271 [ 150/625 ( 24%)]  Loss: 0.002854 (0.00316)  Time: 0.709s, 2887.89/s  (0.733s, 2794.48/s)  avg LR: 2.319e-04  iter ratio: 0.0000  Data: 0.032 (0.055)
INFO:Train: 271 [ 200/625 ( 32%)]  Loss: 0.004049 (0.00334)  Time: 0.722s, 2836.87/s  (0.726s, 2819.88/s)  avg LR: 2.319e-04  iter ratio: 0.0000  Data: 0.027 (0.049)
INFO:Train: 271 [ 250/625 ( 40%)]  Loss: 0.002467 (0.00319)  Time: 0.703s, 2911.66/s  (0.722s, 2837.36/s)  avg LR: 2.319e-04  iter ratio: 0.0000  Data: 0.024 (0.045)
INFO:Train: 271 [ 300/625 ( 48%)]  Loss: 0.003646 (0.00326)  Time: 0.720s, 2846.00/s  (0.721s, 2840.37/s)  avg LR: 2.319e-04  iter ratio: 0.0000  Data: 0.045 (0.044)
INFO:Train: 271 [ 350/625 ( 56%)]  Loss: 0.003070 (0.00323)  Time: 0.717s, 2857.22/s  (0.721s, 2841.70/s)  avg LR: 2.319e-04  iter ratio: 0.0000  Data: 0.042 (0.044)
INFO:Train: 271 [ 400/625 ( 64%)]  Loss: 0.003201 (0.00323)  Time: 0.700s, 2924.84/s  (0.719s, 2846.47/s)  avg LR: 2.319e-04  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 271 [ 450/625 ( 72%)]  Loss: 0.003105 (0.00322)  Time: 0.705s, 2904.33/s  (0.718s, 2853.54/s)  avg LR: 2.319e-04  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 271 [ 500/625 ( 80%)]  Loss: 0.002991 (0.00320)  Time: 0.702s, 2917.05/s  (0.716s, 2858.82/s)  avg LR: 2.319e-04  iter ratio: 0.0000  Data: 0.025 (0.040)
INFO:Train: 271 [ 550/625 ( 88%)]  Loss: 0.002639 (0.00315)  Time: 0.700s, 2924.62/s  (0.715s, 2863.06/s)  avg LR: 2.319e-04  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 271 [ 600/625 ( 96%)]  Loss: 0.002679 (0.00311)  Time: 0.705s, 2906.23/s  (0.714s, 2866.43/s)  avg LR: 2.319e-04  iter ratio: 0.0000  Data: 0.030 (0.038)
INFO:Train: 271 [ 624/625 (100%)]  Loss: 0.003268 (0.00312)  Time: 0.675s, 3034.66/s  (0.714s, 2868.52/s)  avg LR: 2.319e-04  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.376 (4.376)  Loss:  0.5312 (0.5312)  Acc@1: 87.7441 (87.7441)  Acc@5: 98.0469 (98.0469)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.5205 (0.8152)  Acc@1: 86.7924 (81.3440)  Acc@5: 97.2877 (95.4620)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-268.pth.tar', 81.35799992675781)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-271.pth.tar', 81.34399995117188)

INFO:271-epoch: remaining time 5.00 h
INFO:Train: 272 [   0/625 (  0%)]  Loss: 0.003133 (0.00313)  Time: 4.086s,  501.18/s  (4.086s,  501.18/s)  avg LR: 2.197e-04  iter ratio: 0.0000  Data: 3.397 (3.397)
INFO:Train: 272 [  50/625 (  8%)]  Loss: 0.002853 (0.00299)  Time: 0.721s, 2839.06/s  (0.780s, 2625.08/s)  avg LR: 2.197e-04  iter ratio: 0.0000  Data: 0.040 (0.098)
INFO:Train: 272 [ 100/625 ( 16%)]  Loss: 0.002557 (0.00285)  Time: 0.722s, 2837.27/s  (0.746s, 2744.83/s)  avg LR: 2.197e-04  iter ratio: 0.0000  Data: 0.039 (0.066)
INFO:Train: 272 [ 150/625 ( 24%)]  Loss: 0.002368 (0.00273)  Time: 0.721s, 2838.89/s  (0.734s, 2790.10/s)  avg LR: 2.197e-04  iter ratio: 0.0000  Data: 0.037 (0.054)
INFO:Train: 272 [ 200/625 ( 32%)]  Loss: 0.003172 (0.00282)  Time: 0.718s, 2851.13/s  (0.728s, 2814.74/s)  avg LR: 2.197e-04  iter ratio: 0.0000  Data: 0.036 (0.048)
INFO:Train: 272 [ 250/625 ( 40%)]  Loss: 0.002566 (0.00277)  Time: 0.718s, 2853.56/s  (0.724s, 2827.57/s)  avg LR: 2.197e-04  iter ratio: 0.0000  Data: 0.036 (0.045)
INFO:Train: 272 [ 300/625 ( 48%)]  Loss: 0.003656 (0.00290)  Time: 0.720s, 2844.42/s  (0.722s, 2835.64/s)  avg LR: 2.197e-04  iter ratio: 0.0000  Data: 0.043 (0.043)
INFO:Train: 272 [ 350/625 ( 56%)]  Loss: 0.003538 (0.00298)  Time: 0.718s, 2851.33/s  (0.720s, 2843.90/s)  avg LR: 2.197e-04  iter ratio: 0.0000  Data: 0.038 (0.041)
INFO:Train: 272 [ 400/625 ( 64%)]  Loss: 0.003091 (0.00299)  Time: 0.720s, 2845.32/s  (0.719s, 2848.16/s)  avg LR: 2.197e-04  iter ratio: 0.0000  Data: 0.040 (0.040)
INFO:Train: 272 [ 450/625 ( 72%)]  Loss: 0.002723 (0.00297)  Time: 0.718s, 2853.07/s  (0.718s, 2851.12/s)  avg LR: 2.197e-04  iter ratio: 0.0000  Data: 0.035 (0.039)
INFO:Train: 272 [ 500/625 ( 80%)]  Loss: 0.003437 (0.00301)  Time: 0.723s, 2834.02/s  (0.718s, 2852.85/s)  avg LR: 2.197e-04  iter ratio: 0.0000  Data: 0.040 (0.039)
INFO:Train: 272 [ 550/625 ( 88%)]  Loss: 0.003652 (0.00306)  Time: 0.706s, 2899.14/s  (0.717s, 2855.04/s)  avg LR: 2.197e-04  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 272 [ 600/625 ( 96%)]  Loss: 0.003455 (0.00309)  Time: 0.704s, 2908.17/s  (0.716s, 2858.75/s)  avg LR: 2.197e-04  iter ratio: 0.0000  Data: 0.024 (0.038)
INFO:Train: 272 [ 624/625 (100%)]  Loss: 0.003699 (0.00314)  Time: 0.678s, 3019.57/s  (0.716s, 2861.14/s)  avg LR: 2.197e-04  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.345 (4.345)  Loss:  0.5552 (0.5552)  Acc@1: 86.8164 (86.8164)  Acc@5: 98.1445 (98.1445)
INFO:Test: [  24/24]  Time: 0.080 (0.511)  Loss:  0.5107 (0.8219)  Acc@1: 87.1462 (81.3760)  Acc@5: 97.5236 (95.4780)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-272.pth.tar', 81.37599997558594)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-268.pth.tar', 81.35799992675781)

INFO:272-epoch: remaining time 4.88 h
INFO:Train: 273 [   0/625 (  0%)]  Loss: 0.003637 (0.00364)  Time: 4.163s,  491.90/s  (4.163s,  491.90/s)  avg LR: 2.078e-04  iter ratio: 0.0000  Data: 3.474 (3.474)
INFO:Train: 273 [  50/625 (  8%)]  Loss: 0.003858 (0.00375)  Time: 0.702s, 2916.66/s  (0.775s, 2642.00/s)  avg LR: 2.078e-04  iter ratio: 0.0000  Data: 0.027 (0.097)
INFO:Train: 273 [ 100/625 ( 16%)]  Loss: 0.002644 (0.00338)  Time: 0.716s, 2859.28/s  (0.743s, 2756.36/s)  avg LR: 2.078e-04  iter ratio: 0.0000  Data: 0.042 (0.066)
INFO:Train: 273 [ 150/625 ( 24%)]  Loss: 0.003332 (0.00337)  Time: 0.716s, 2858.81/s  (0.735s, 2787.10/s)  avg LR: 2.078e-04  iter ratio: 0.0000  Data: 0.042 (0.058)
INFO:Train: 273 [ 200/625 ( 32%)]  Loss: 0.003876 (0.00347)  Time: 0.719s, 2847.64/s  (0.731s, 2802.78/s)  avg LR: 2.078e-04  iter ratio: 0.0000  Data: 0.045 (0.054)
INFO:Train: 273 [ 250/625 ( 40%)]  Loss: 0.003702 (0.00351)  Time: 0.697s, 2936.97/s  (0.728s, 2812.56/s)  avg LR: 2.078e-04  iter ratio: 0.0000  Data: 0.017 (0.052)
INFO:Train: 273 [ 300/625 ( 48%)]  Loss: 0.003322 (0.00348)  Time: 0.729s, 2811.00/s  (0.726s, 2820.68/s)  avg LR: 2.078e-04  iter ratio: 0.0000  Data: 0.050 (0.050)
INFO:Train: 273 [ 350/625 ( 56%)]  Loss: 0.003606 (0.00350)  Time: 0.720s, 2843.63/s  (0.725s, 2824.79/s)  avg LR: 2.078e-04  iter ratio: 0.0000  Data: 0.045 (0.049)
INFO:Train: 273 [ 400/625 ( 64%)]  Loss: 0.003277 (0.00347)  Time: 0.720s, 2845.34/s  (0.724s, 2828.04/s)  avg LR: 2.078e-04  iter ratio: 0.0000  Data: 0.045 (0.048)
INFO:Train: 273 [ 450/625 ( 72%)]  Loss: 0.003351 (0.00346)  Time: 0.715s, 2862.96/s  (0.723s, 2830.92/s)  avg LR: 2.078e-04  iter ratio: 0.0000  Data: 0.041 (0.047)
INFO:Train: 273 [ 500/625 ( 80%)]  Loss: 0.002509 (0.00337)  Time: 0.702s, 2916.21/s  (0.722s, 2836.63/s)  avg LR: 2.078e-04  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 273 [ 550/625 ( 88%)]  Loss: 0.003146 (0.00335)  Time: 0.703s, 2913.73/s  (0.720s, 2843.16/s)  avg LR: 2.078e-04  iter ratio: 0.0000  Data: 0.029 (0.044)
INFO:Train: 273 [ 600/625 ( 96%)]  Loss: 0.003343 (0.00335)  Time: 0.704s, 2908.35/s  (0.719s, 2847.85/s)  avg LR: 2.078e-04  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 273 [ 624/625 (100%)]  Loss: 0.003674 (0.00338)  Time: 0.675s, 3034.85/s  (0.718s, 2850.91/s)  avg LR: 2.078e-04  iter ratio: 0.0000  Data: 0.000 (0.042)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.474 (4.474)  Loss:  0.5815 (0.5815)  Acc@1: 86.3770 (86.3770)  Acc@5: 97.8027 (97.8027)
INFO:Test: [  24/24]  Time: 0.080 (0.500)  Loss:  0.5498 (0.8545)  Acc@1: 86.2028 (81.2260)  Acc@5: 97.5236 (95.3400)
INFO:273-epoch: remaining time 4.77 h
INFO:Train: 274 [   0/625 (  0%)]  Loss: 0.003263 (0.00326)  Time: 4.127s,  496.30/s  (4.127s,  496.30/s)  avg LR: 1.964e-04  iter ratio: 0.0000  Data: 3.411 (3.411)
INFO:Train: 274 [  50/625 (  8%)]  Loss: 0.002680 (0.00297)  Time: 0.706s, 2901.02/s  (0.774s, 2644.96/s)  avg LR: 1.964e-04  iter ratio: 0.0000  Data: 0.028 (0.096)
INFO:Train: 274 [ 100/625 ( 16%)]  Loss: 0.003120 (0.00302)  Time: 0.722s, 2836.36/s  (0.740s, 2766.09/s)  avg LR: 1.964e-04  iter ratio: 0.0000  Data: 0.045 (0.062)
INFO:Train: 274 [ 150/625 ( 24%)]  Loss: 0.003443 (0.00313)  Time: 0.722s, 2836.36/s  (0.733s, 2795.58/s)  avg LR: 1.964e-04  iter ratio: 0.0000  Data: 0.041 (0.055)
INFO:Train: 274 [ 200/625 ( 32%)]  Loss: 0.003687 (0.00324)  Time: 0.719s, 2848.34/s  (0.729s, 2810.58/s)  avg LR: 1.964e-04  iter ratio: 0.0000  Data: 0.041 (0.052)
INFO:Train: 274 [ 250/625 ( 40%)]  Loss: 0.004324 (0.00342)  Time: 0.723s, 2833.73/s  (0.726s, 2819.57/s)  avg LR: 1.964e-04  iter ratio: 0.0000  Data: 0.046 (0.049)
INFO:Train: 274 [ 300/625 ( 48%)]  Loss: 0.002995 (0.00336)  Time: 0.718s, 2853.34/s  (0.725s, 2825.79/s)  avg LR: 1.964e-04  iter ratio: 0.0000  Data: 0.040 (0.048)
INFO:Train: 274 [ 350/625 ( 56%)]  Loss: 0.003056 (0.00332)  Time: 0.722s, 2835.90/s  (0.724s, 2830.25/s)  avg LR: 1.964e-04  iter ratio: 0.0000  Data: 0.041 (0.047)
INFO:Train: 274 [ 400/625 ( 64%)]  Loss: 0.003001 (0.00329)  Time: 0.721s, 2839.76/s  (0.723s, 2833.69/s)  avg LR: 1.964e-04  iter ratio: 0.0000  Data: 0.043 (0.046)
INFO:Train: 274 [ 450/625 ( 72%)]  Loss: 0.003198 (0.00328)  Time: 0.723s, 2834.41/s  (0.722s, 2836.40/s)  avg LR: 1.964e-04  iter ratio: 0.0000  Data: 0.041 (0.045)
INFO:Train: 274 [ 500/625 ( 80%)]  Loss: 0.003330 (0.00328)  Time: 0.723s, 2833.74/s  (0.721s, 2838.55/s)  avg LR: 1.964e-04  iter ratio: 0.0000  Data: 0.046 (0.045)
INFO:Train: 274 [ 550/625 ( 88%)]  Loss: 0.002555 (0.00322)  Time: 0.705s, 2905.49/s  (0.721s, 2841.17/s)  avg LR: 1.964e-04  iter ratio: 0.0000  Data: 0.023 (0.044)
INFO:Train: 274 [ 600/625 ( 96%)]  Loss: 0.003423 (0.00324)  Time: 0.703s, 2912.43/s  (0.720s, 2846.39/s)  avg LR: 1.964e-04  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 274 [ 624/625 (100%)]  Loss: 0.002771 (0.00320)  Time: 0.675s, 3033.45/s  (0.719s, 2849.58/s)  avg LR: 1.964e-04  iter ratio: 0.0000  Data: 0.000 (0.042)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.365 (4.365)  Loss:  0.5410 (0.5410)  Acc@1: 87.6953 (87.6953)  Acc@5: 97.9004 (97.9004)
INFO:Test: [  24/24]  Time: 0.082 (0.511)  Loss:  0.5034 (0.8185)  Acc@1: 86.9104 (81.4520)  Acc@5: 97.7594 (95.4660)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-274.pth.tar', 81.45200013183593)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-272.pth.tar', 81.37599997558594)

INFO:274-epoch: remaining time 4.64 h
INFO:Train: 275 [   0/625 (  0%)]  Loss: 0.003500 (0.00350)  Time: 4.267s,  479.91/s  (4.267s,  479.91/s)  avg LR: 1.854e-04  iter ratio: 0.0000  Data: 3.572 (3.572)
INFO:Train: 275 [  50/625 (  8%)]  Loss: 0.003516 (0.00351)  Time: 0.702s, 2918.48/s  (0.781s, 2623.28/s)  avg LR: 1.854e-04  iter ratio: 0.0000  Data: 0.027 (0.101)
INFO:Train: 275 [ 100/625 ( 16%)]  Loss: 0.003012 (0.00334)  Time: 0.702s, 2919.16/s  (0.743s, 2757.07/s)  avg LR: 1.854e-04  iter ratio: 0.0000  Data: 0.026 (0.064)
INFO:Train: 275 [ 150/625 ( 24%)]  Loss: 0.002456 (0.00312)  Time: 0.702s, 2917.93/s  (0.730s, 2805.09/s)  avg LR: 1.854e-04  iter ratio: 0.0000  Data: 0.027 (0.052)
INFO:Train: 275 [ 200/625 ( 32%)]  Loss: 0.003590 (0.00321)  Time: 0.720s, 2845.14/s  (0.724s, 2829.01/s)  avg LR: 1.854e-04  iter ratio: 0.0000  Data: 0.045 (0.046)
INFO:Train: 275 [ 250/625 ( 40%)]  Loss: 0.002631 (0.00312)  Time: 0.704s, 2910.74/s  (0.720s, 2844.88/s)  avg LR: 1.854e-04  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 275 [ 300/625 ( 48%)]  Loss: 0.003025 (0.00310)  Time: 0.704s, 2908.43/s  (0.717s, 2855.35/s)  avg LR: 1.854e-04  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 275 [ 350/625 ( 56%)]  Loss: 0.003395 (0.00314)  Time: 0.705s, 2905.45/s  (0.715s, 2862.87/s)  avg LR: 1.854e-04  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 275 [ 400/625 ( 64%)]  Loss: 0.003248 (0.00315)  Time: 0.705s, 2904.57/s  (0.714s, 2867.66/s)  avg LR: 1.854e-04  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 275 [ 450/625 ( 72%)]  Loss: 0.002638 (0.00310)  Time: 0.705s, 2905.72/s  (0.713s, 2871.73/s)  avg LR: 1.854e-04  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 275 [ 500/625 ( 80%)]  Loss: 0.003075 (0.00310)  Time: 0.706s, 2900.77/s  (0.712s, 2875.24/s)  avg LR: 1.854e-04  iter ratio: 0.0000  Data: 0.030 (0.035)
INFO:Train: 275 [ 550/625 ( 88%)]  Loss: 0.003124 (0.00310)  Time: 0.703s, 2914.40/s  (0.712s, 2878.13/s)  avg LR: 1.854e-04  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 275 [ 600/625 ( 96%)]  Loss: 0.003181 (0.00311)  Time: 0.720s, 2843.62/s  (0.711s, 2878.93/s)  avg LR: 1.854e-04  iter ratio: 0.0000  Data: 0.045 (0.034)
INFO:Train: 275 [ 624/625 (100%)]  Loss: 0.003468 (0.00313)  Time: 0.674s, 3040.01/s  (0.711s, 2880.10/s)  avg LR: 1.854e-04  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.340 (4.340)  Loss:  0.5454 (0.5454)  Acc@1: 87.5488 (87.5488)  Acc@5: 97.9980 (97.9980)
INFO:Test: [  24/24]  Time: 0.080 (0.499)  Loss:  0.4854 (0.8095)  Acc@1: 87.0283 (81.5060)  Acc@5: 97.6415 (95.5160)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-275.pth.tar', 81.50600005371093)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-274.pth.tar', 81.45200013183593)

INFO:275-epoch: remaining time 4.46 h
INFO:Train: 276 [   0/625 (  0%)]  Loss: 0.003713 (0.00371)  Time: 4.445s,  460.78/s  (4.445s,  460.78/s)  avg LR: 1.749e-04  iter ratio: 0.0000  Data: 3.742 (3.742)
INFO:Train: 276 [  50/625 (  8%)]  Loss: 0.003908 (0.00381)  Time: 0.696s, 2941.43/s  (0.778s, 2633.75/s)  avg LR: 1.749e-04  iter ratio: 0.0000  Data: 0.021 (0.101)
INFO:Train: 276 [ 100/625 ( 16%)]  Loss: 0.003182 (0.00360)  Time: 0.707s, 2896.33/s  (0.745s, 2750.70/s)  avg LR: 1.749e-04  iter ratio: 0.0000  Data: 0.033 (0.067)
INFO:Train: 276 [ 150/625 ( 24%)]  Loss: 0.003672 (0.00362)  Time: 0.719s, 2849.55/s  (0.736s, 2783.21/s)  avg LR: 1.749e-04  iter ratio: 0.0000  Data: 0.045 (0.059)
INFO:Train: 276 [ 200/625 ( 32%)]  Loss: 0.003440 (0.00358)  Time: 0.722s, 2835.88/s  (0.732s, 2799.41/s)  avg LR: 1.749e-04  iter ratio: 0.0000  Data: 0.048 (0.055)
INFO:Train: 276 [ 250/625 ( 40%)]  Loss: 0.003141 (0.00351)  Time: 0.720s, 2843.84/s  (0.729s, 2809.29/s)  avg LR: 1.749e-04  iter ratio: 0.0000  Data: 0.045 (0.053)
INFO:Train: 276 [ 300/625 ( 48%)]  Loss: 0.003529 (0.00351)  Time: 0.705s, 2903.68/s  (0.725s, 2826.26/s)  avg LR: 1.749e-04  iter ratio: 0.0000  Data: 0.029 (0.049)
INFO:Train: 276 [ 350/625 ( 56%)]  Loss: 0.003035 (0.00345)  Time: 0.716s, 2862.00/s  (0.722s, 2837.45/s)  avg LR: 1.749e-04  iter ratio: 0.0000  Data: 0.041 (0.046)
INFO:Train: 276 [ 400/625 ( 64%)]  Loss: 0.003700 (0.00348)  Time: 0.714s, 2869.12/s  (0.721s, 2839.41/s)  avg LR: 1.749e-04  iter ratio: 0.0000  Data: 0.040 (0.046)
INFO:Train: 276 [ 450/625 ( 72%)]  Loss: 0.002666 (0.00340)  Time: 0.718s, 2853.85/s  (0.721s, 2840.59/s)  avg LR: 1.749e-04  iter ratio: 0.0000  Data: 0.043 (0.045)
INFO:Train: 276 [ 500/625 ( 80%)]  Loss: 0.003582 (0.00342)  Time: 0.702s, 2918.17/s  (0.720s, 2844.96/s)  avg LR: 1.749e-04  iter ratio: 0.0000  Data: 0.026 (0.044)
INFO:Train: 276 [ 550/625 ( 88%)]  Loss: 0.003119 (0.00339)  Time: 0.701s, 2922.47/s  (0.718s, 2851.14/s)  avg LR: 1.749e-04  iter ratio: 0.0000  Data: 0.026 (0.043)
INFO:Train: 276 [ 600/625 ( 96%)]  Loss: 0.003060 (0.00337)  Time: 0.705s, 2905.43/s  (0.717s, 2856.37/s)  avg LR: 1.749e-04  iter ratio: 0.0000  Data: 0.030 (0.041)
INFO:Train: 276 [ 624/625 (100%)]  Loss: 0.003300 (0.00336)  Time: 0.672s, 3048.18/s  (0.716s, 2858.50/s)  avg LR: 1.749e-04  iter ratio: 0.0000  Data: 0.000 (0.041)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.336 (4.336)  Loss:  0.5376 (0.5376)  Acc@1: 87.5977 (87.5977)  Acc@5: 98.0469 (98.0469)
INFO:Test: [  24/24]  Time: 0.080 (0.510)  Loss:  0.5249 (0.8218)  Acc@1: 86.9104 (81.4140)  Acc@5: 97.5236 (95.4740)
INFO:276-epoch: remaining time 4.37 h
INFO:Train: 277 [   0/625 (  0%)]  Loss: 0.002666 (0.00267)  Time: 4.039s,  507.07/s  (4.039s,  507.07/s)  avg LR: 1.647e-04  iter ratio: 0.0000  Data: 3.356 (3.356)
INFO:Train: 277 [  50/625 (  8%)]  Loss: 0.003249 (0.00296)  Time: 0.705s, 2906.29/s  (0.770s, 2660.62/s)  avg LR: 1.647e-04  iter ratio: 0.0000  Data: 0.028 (0.092)
INFO:Train: 277 [ 100/625 ( 16%)]  Loss: 0.003400 (0.00310)  Time: 0.697s, 2937.74/s  (0.737s, 2778.69/s)  avg LR: 1.647e-04  iter ratio: 0.0000  Data: 0.023 (0.060)
INFO:Train: 277 [ 150/625 ( 24%)]  Loss: 0.003016 (0.00308)  Time: 0.715s, 2863.08/s  (0.729s, 2809.38/s)  avg LR: 1.647e-04  iter ratio: 0.0000  Data: 0.041 (0.052)
INFO:Train: 277 [ 200/625 ( 32%)]  Loss: 0.003570 (0.00318)  Time: 0.718s, 2854.20/s  (0.726s, 2820.63/s)  avg LR: 1.647e-04  iter ratio: 0.0000  Data: 0.043 (0.050)
INFO:Train: 277 [ 250/625 ( 40%)]  Loss: 0.003122 (0.00317)  Time: 0.715s, 2863.79/s  (0.724s, 2827.44/s)  avg LR: 1.647e-04  iter ratio: 0.0000  Data: 0.041 (0.048)
INFO:Train: 277 [ 300/625 ( 48%)]  Loss: 0.003103 (0.00316)  Time: 0.711s, 2881.30/s  (0.723s, 2832.19/s)  avg LR: 1.647e-04  iter ratio: 0.0000  Data: 0.037 (0.047)
INFO:Train: 277 [ 350/625 ( 56%)]  Loss: 0.002409 (0.00307)  Time: 0.716s, 2861.26/s  (0.722s, 2835.33/s)  avg LR: 1.647e-04  iter ratio: 0.0000  Data: 0.042 (0.047)
INFO:Train: 277 [ 400/625 ( 64%)]  Loss: 0.002445 (0.00300)  Time: 0.717s, 2856.45/s  (0.722s, 2837.70/s)  avg LR: 1.647e-04  iter ratio: 0.0000  Data: 0.043 (0.046)
INFO:Train: 277 [ 450/625 ( 72%)]  Loss: 0.003360 (0.00303)  Time: 0.714s, 2869.64/s  (0.721s, 2839.49/s)  avg LR: 1.647e-04  iter ratio: 0.0000  Data: 0.040 (0.046)
INFO:Train: 277 [ 500/625 ( 80%)]  Loss: 0.002911 (0.00302)  Time: 0.716s, 2859.57/s  (0.721s, 2841.25/s)  avg LR: 1.647e-04  iter ratio: 0.0000  Data: 0.042 (0.045)
INFO:Train: 277 [ 550/625 ( 88%)]  Loss: 0.003208 (0.00304)  Time: 0.698s, 2932.22/s  (0.720s, 2843.87/s)  avg LR: 1.647e-04  iter ratio: 0.0000  Data: 0.024 (0.045)
INFO:Train: 277 [ 600/625 ( 96%)]  Loss: 0.003053 (0.00304)  Time: 0.709s, 2888.05/s  (0.719s, 2848.37/s)  avg LR: 1.647e-04  iter ratio: 0.0000  Data: 0.025 (0.043)
INFO:Train: 277 [ 624/625 (100%)]  Loss: 0.002536 (0.00300)  Time: 0.676s, 3030.40/s  (0.718s, 2850.57/s)  avg LR: 1.647e-04  iter ratio: 0.0000  Data: 0.000 (0.042)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.339 (4.339)  Loss:  0.5542 (0.5542)  Acc@1: 87.5488 (87.5488)  Acc@5: 97.9004 (97.9004)
INFO:Test: [  24/24]  Time: 0.081 (0.500)  Loss:  0.5293 (0.8246)  Acc@1: 86.4387 (81.5440)  Acc@5: 97.2877 (95.5340)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-277.pth.tar', 81.5439999267578)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-275.pth.tar', 81.50600005371093)

INFO:277-epoch: remaining time 4.25 h
INFO:Train: 278 [   0/625 (  0%)]  Loss: 0.003033 (0.00303)  Time: 4.442s,  461.06/s  (4.442s,  461.06/s)  avg LR: 1.550e-04  iter ratio: 0.0000  Data: 3.757 (3.757)
INFO:Train: 278 [  50/625 (  8%)]  Loss: 0.003163 (0.00310)  Time: 0.704s, 2908.38/s  (0.785s, 2608.69/s)  avg LR: 1.550e-04  iter ratio: 0.0000  Data: 0.029 (0.106)
INFO:Train: 278 [ 100/625 ( 16%)]  Loss: 0.002652 (0.00295)  Time: 0.719s, 2849.60/s  (0.748s, 2737.59/s)  avg LR: 1.550e-04  iter ratio: 0.0000  Data: 0.044 (0.070)
INFO:Train: 278 [ 150/625 ( 24%)]  Loss: 0.004001 (0.00321)  Time: 0.718s, 2852.72/s  (0.739s, 2772.95/s)  avg LR: 1.550e-04  iter ratio: 0.0000  Data: 0.042 (0.061)
INFO:Train: 278 [ 200/625 ( 32%)]  Loss: 0.002188 (0.00301)  Time: 0.717s, 2855.69/s  (0.734s, 2791.58/s)  avg LR: 1.550e-04  iter ratio: 0.0000  Data: 0.042 (0.057)
INFO:Train: 278 [ 250/625 ( 40%)]  Loss: 0.003936 (0.00316)  Time: 0.702s, 2917.84/s  (0.730s, 2805.97/s)  avg LR: 1.550e-04  iter ratio: 0.0000  Data: 0.025 (0.053)
INFO:Train: 278 [ 300/625 ( 48%)]  Loss: 0.002722 (0.00310)  Time: 0.704s, 2907.19/s  (0.726s, 2822.33/s)  avg LR: 1.550e-04  iter ratio: 0.0000  Data: 0.027 (0.049)
INFO:Train: 278 [ 350/625 ( 56%)]  Loss: 0.003128 (0.00310)  Time: 0.716s, 2859.65/s  (0.723s, 2834.45/s)  avg LR: 1.550e-04  iter ratio: 0.0000  Data: 0.042 (0.046)
INFO:Train: 278 [ 400/625 ( 64%)]  Loss: 0.003160 (0.00311)  Time: 0.702s, 2919.06/s  (0.721s, 2838.75/s)  avg LR: 1.550e-04  iter ratio: 0.0000  Data: 0.024 (0.045)
INFO:Train: 278 [ 450/625 ( 72%)]  Loss: 0.003491 (0.00315)  Time: 0.703s, 2912.75/s  (0.719s, 2846.78/s)  avg LR: 1.550e-04  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 278 [ 500/625 ( 80%)]  Loss: 0.003084 (0.00314)  Time: 0.718s, 2853.18/s  (0.718s, 2851.09/s)  avg LR: 1.550e-04  iter ratio: 0.0000  Data: 0.043 (0.042)
INFO:Train: 278 [ 550/625 ( 88%)]  Loss: 0.002619 (0.00310)  Time: 0.713s, 2870.84/s  (0.718s, 2851.34/s)  avg LR: 1.550e-04  iter ratio: 0.0000  Data: 0.040 (0.042)
INFO:Train: 278 [ 600/625 ( 96%)]  Loss: 0.003119 (0.00310)  Time: 0.701s, 2921.11/s  (0.717s, 2856.61/s)  avg LR: 1.550e-04  iter ratio: 0.0000  Data: 0.019 (0.041)
INFO:Train: 278 [ 624/625 (100%)]  Loss: 0.003149 (0.00310)  Time: 0.675s, 3035.76/s  (0.716s, 2859.09/s)  avg LR: 1.550e-04  iter ratio: 0.0000  Data: 0.000 (0.040)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.376 (4.376)  Loss:  0.5454 (0.5454)  Acc@1: 87.1094 (87.1094)  Acc@5: 98.1445 (98.1445)
INFO:Test: [  24/24]  Time: 0.080 (0.509)  Loss:  0.5127 (0.8199)  Acc@1: 86.9104 (81.5980)  Acc@5: 97.9953 (95.5580)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-278.pth.tar', 81.59800000244141)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-277.pth.tar', 81.5439999267578)

INFO:278-epoch: remaining time 4.12 h
INFO:Train: 279 [   0/625 (  0%)]  Loss: 0.003440 (0.00344)  Time: 4.296s,  476.77/s  (4.296s,  476.77/s)  avg LR: 1.457e-04  iter ratio: 0.0000  Data: 3.607 (3.607)
INFO:Train: 279 [  50/625 (  8%)]  Loss: 0.002625 (0.00303)  Time: 0.703s, 2913.93/s  (0.776s, 2640.67/s)  avg LR: 1.457e-04  iter ratio: 0.0000  Data: 0.028 (0.099)
INFO:Train: 279 [ 100/625 ( 16%)]  Loss: 0.003331 (0.00313)  Time: 0.708s, 2892.87/s  (0.742s, 2761.19/s)  avg LR: 1.457e-04  iter ratio: 0.0000  Data: 0.031 (0.065)
INFO:Train: 279 [ 150/625 ( 24%)]  Loss: 0.003260 (0.00316)  Time: 0.709s, 2888.63/s  (0.733s, 2793.83/s)  avg LR: 1.457e-04  iter ratio: 0.0000  Data: 0.034 (0.056)
INFO:Train: 279 [ 200/625 ( 32%)]  Loss: 0.003060 (0.00314)  Time: 0.712s, 2876.13/s  (0.729s, 2810.03/s)  avg LR: 1.457e-04  iter ratio: 0.0000  Data: 0.036 (0.052)
INFO:Train: 279 [ 250/625 ( 40%)]  Loss: 0.003127 (0.00314)  Time: 0.725s, 2823.22/s  (0.726s, 2819.76/s)  avg LR: 1.457e-04  iter ratio: 0.0000  Data: 0.050 (0.050)
INFO:Train: 279 [ 300/625 ( 48%)]  Loss: 0.002872 (0.00310)  Time: 0.718s, 2850.51/s  (0.725s, 2826.35/s)  avg LR: 1.457e-04  iter ratio: 0.0000  Data: 0.043 (0.048)
INFO:Train: 279 [ 350/625 ( 56%)]  Loss: 0.003083 (0.00310)  Time: 0.717s, 2857.06/s  (0.723s, 2831.64/s)  avg LR: 1.457e-04  iter ratio: 0.0000  Data: 0.041 (0.046)
INFO:Train: 279 [ 400/625 ( 64%)]  Loss: 0.003170 (0.00311)  Time: 0.719s, 2849.84/s  (0.722s, 2835.27/s)  avg LR: 1.457e-04  iter ratio: 0.0000  Data: 0.043 (0.046)
INFO:Train: 279 [ 450/625 ( 72%)]  Loss: 0.002845 (0.00308)  Time: 0.718s, 2850.43/s  (0.722s, 2838.23/s)  avg LR: 1.457e-04  iter ratio: 0.0000  Data: 0.042 (0.045)
INFO:Train: 279 [ 500/625 ( 80%)]  Loss: 0.003281 (0.00310)  Time: 0.714s, 2866.92/s  (0.721s, 2840.56/s)  avg LR: 1.457e-04  iter ratio: 0.0000  Data: 0.039 (0.044)
INFO:Train: 279 [ 550/625 ( 88%)]  Loss: 0.003295 (0.00312)  Time: 0.707s, 2895.49/s  (0.720s, 2842.55/s)  avg LR: 1.457e-04  iter ratio: 0.0000  Data: 0.030 (0.044)
INFO:Train: 279 [ 600/625 ( 96%)]  Loss: 0.003172 (0.00312)  Time: 0.704s, 2908.49/s  (0.719s, 2847.83/s)  avg LR: 1.457e-04  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 279 [ 624/625 (100%)]  Loss: 0.002907 (0.00310)  Time: 0.676s, 3028.77/s  (0.718s, 2850.82/s)  avg LR: 1.457e-04  iter ratio: 0.0000  Data: 0.000 (0.042)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.331 (4.331)  Loss:  0.5342 (0.5342)  Acc@1: 87.9395 (87.9395)  Acc@5: 98.0957 (98.0957)
INFO:Test: [  24/24]  Time: 0.080 (0.500)  Loss:  0.4917 (0.8042)  Acc@1: 87.0283 (81.6440)  Acc@5: 97.7594 (95.5920)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-279.pth.tar', 81.64400005371094)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-278.pth.tar', 81.59800000244141)

INFO:279-epoch: remaining time 3.99 h
INFO:Train: 280 [   0/625 (  0%)]  Loss: 0.003417 (0.00342)  Time: 4.224s,  484.89/s  (4.224s,  484.89/s)  avg LR: 1.369e-04  iter ratio: 0.0000  Data: 3.531 (3.531)
INFO:Train: 280 [  50/625 (  8%)]  Loss: 0.003571 (0.00349)  Time: 0.703s, 2914.34/s  (0.772s, 2652.58/s)  avg LR: 1.369e-04  iter ratio: 0.0000  Data: 0.025 (0.095)
INFO:Train: 280 [ 100/625 ( 16%)]  Loss: 0.003263 (0.00342)  Time: 0.702s, 2917.56/s  (0.739s, 2771.96/s)  avg LR: 1.369e-04  iter ratio: 0.0000  Data: 0.025 (0.062)
INFO:Train: 280 [ 150/625 ( 24%)]  Loss: 0.003299 (0.00339)  Time: 0.704s, 2907.59/s  (0.727s, 2817.40/s)  avg LR: 1.369e-04  iter ratio: 0.0000  Data: 0.023 (0.049)
INFO:Train: 280 [ 200/625 ( 32%)]  Loss: 0.002760 (0.00326)  Time: 0.707s, 2896.33/s  (0.721s, 2839.03/s)  avg LR: 1.369e-04  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 280 [ 250/625 ( 40%)]  Loss: 0.003836 (0.00336)  Time: 0.708s, 2892.29/s  (0.720s, 2843.25/s)  avg LR: 1.369e-04  iter ratio: 0.0000  Data: 0.034 (0.043)
INFO:Train: 280 [ 300/625 ( 48%)]  Loss: 0.003533 (0.00338)  Time: 0.706s, 2899.11/s  (0.720s, 2845.14/s)  avg LR: 1.369e-04  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 280 [ 350/625 ( 56%)]  Loss: 0.002891 (0.00332)  Time: 0.706s, 2899.24/s  (0.719s, 2847.30/s)  avg LR: 1.369e-04  iter ratio: 0.0000  Data: 0.025 (0.042)
INFO:Train: 280 [ 400/625 ( 64%)]  Loss: 0.003463 (0.00334)  Time: 0.714s, 2866.75/s  (0.719s, 2848.84/s)  avg LR: 1.369e-04  iter ratio: 0.0000  Data: 0.040 (0.041)
INFO:Train: 280 [ 450/625 ( 72%)]  Loss: 0.002436 (0.00325)  Time: 0.700s, 2925.34/s  (0.718s, 2854.07/s)  avg LR: 1.369e-04  iter ratio: 0.0000  Data: 0.025 (0.040)
INFO:Train: 280 [ 500/625 ( 80%)]  Loss: 0.003552 (0.00327)  Time: 0.700s, 2925.22/s  (0.716s, 2858.87/s)  avg LR: 1.369e-04  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 280 [ 550/625 ( 88%)]  Loss: 0.003259 (0.00327)  Time: 0.700s, 2924.26/s  (0.715s, 2863.30/s)  avg LR: 1.369e-04  iter ratio: 0.0000  Data: 0.020 (0.038)
INFO:Train: 280 [ 600/625 ( 96%)]  Loss: 0.003471 (0.00329)  Time: 0.702s, 2916.22/s  (0.714s, 2867.04/s)  avg LR: 1.369e-04  iter ratio: 0.0000  Data: 0.018 (0.037)
INFO:Train: 280 [ 624/625 (100%)]  Loss: 0.003672 (0.00332)  Time: 0.676s, 3029.24/s  (0.714s, 2867.53/s)  avg LR: 1.369e-04  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.400 (4.400)  Loss:  0.5508 (0.5508)  Acc@1: 87.5000 (87.5000)  Acc@5: 97.7051 (97.7051)
INFO:Test: [  24/24]  Time: 0.080 (0.512)  Loss:  0.4988 (0.8192)  Acc@1: 87.0283 (81.5520)  Acc@5: 97.7594 (95.4920)
INFO:280-epoch: remaining time 3.85 h
INFO:Train: 281 [   0/625 (  0%)]  Loss: 0.003389 (0.00339)  Time: 4.556s,  449.52/s  (4.556s,  449.52/s)  avg LR: 1.284e-04  iter ratio: 0.0000  Data: 3.864 (3.864)
INFO:Train: 281 [  50/625 (  8%)]  Loss: 0.002888 (0.00314)  Time: 0.701s, 2921.41/s  (0.785s, 2609.83/s)  avg LR: 1.284e-04  iter ratio: 0.0000  Data: 0.025 (0.107)
INFO:Train: 281 [ 100/625 ( 16%)]  Loss: 0.003395 (0.00322)  Time: 0.714s, 2867.47/s  (0.749s, 2735.55/s)  avg LR: 1.284e-04  iter ratio: 0.0000  Data: 0.040 (0.072)
INFO:Train: 281 [ 150/625 ( 24%)]  Loss: 0.003109 (0.00320)  Time: 0.720s, 2844.33/s  (0.738s, 2775.88/s)  avg LR: 1.284e-04  iter ratio: 0.0000  Data: 0.044 (0.061)
INFO:Train: 281 [ 200/625 ( 32%)]  Loss: 0.002632 (0.00308)  Time: 0.719s, 2848.24/s  (0.732s, 2796.56/s)  avg LR: 1.284e-04  iter ratio: 0.0000  Data: 0.044 (0.056)
INFO:Train: 281 [ 250/625 ( 40%)]  Loss: 0.003437 (0.00314)  Time: 0.716s, 2860.59/s  (0.729s, 2809.14/s)  avg LR: 1.284e-04  iter ratio: 0.0000  Data: 0.040 (0.053)
INFO:Train: 281 [ 300/625 ( 48%)]  Loss: 0.003119 (0.00314)  Time: 0.719s, 2850.08/s  (0.727s, 2817.66/s)  avg LR: 1.284e-04  iter ratio: 0.0000  Data: 0.042 (0.051)
INFO:Train: 281 [ 350/625 ( 56%)]  Loss: 0.003170 (0.00314)  Time: 0.716s, 2860.49/s  (0.725s, 2824.36/s)  avg LR: 1.284e-04  iter ratio: 0.0000  Data: 0.040 (0.049)
INFO:Train: 281 [ 400/625 ( 64%)]  Loss: 0.002719 (0.00310)  Time: 0.710s, 2884.70/s  (0.724s, 2829.83/s)  avg LR: 1.284e-04  iter ratio: 0.0000  Data: 0.035 (0.048)
INFO:Train: 281 [ 450/625 ( 72%)]  Loss: 0.002673 (0.00305)  Time: 0.710s, 2884.60/s  (0.723s, 2833.82/s)  avg LR: 1.284e-04  iter ratio: 0.0000  Data: 0.035 (0.047)
INFO:Train: 281 [ 500/625 ( 80%)]  Loss: 0.003015 (0.00305)  Time: 0.715s, 2862.73/s  (0.722s, 2836.80/s)  avg LR: 1.284e-04  iter ratio: 0.0000  Data: 0.040 (0.046)
INFO:Train: 281 [ 550/625 ( 88%)]  Loss: 0.002357 (0.00299)  Time: 0.703s, 2913.88/s  (0.721s, 2840.03/s)  avg LR: 1.284e-04  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 281 [ 600/625 ( 96%)]  Loss: 0.003706 (0.00305)  Time: 0.720s, 2843.14/s  (0.720s, 2844.74/s)  avg LR: 1.284e-04  iter ratio: 0.0000  Data: 0.045 (0.044)
INFO:Train: 281 [ 624/625 (100%)]  Loss: 0.002718 (0.00302)  Time: 0.676s, 3028.23/s  (0.720s, 2846.28/s)  avg LR: 1.284e-04  iter ratio: 0.0000  Data: 0.000 (0.044)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.313 (4.313)  Loss:  0.5322 (0.5322)  Acc@1: 87.2070 (87.2070)  Acc@5: 98.0469 (98.0469)
INFO:Test: [  24/24]  Time: 0.080 (0.501)  Loss:  0.5127 (0.8117)  Acc@1: 87.5000 (81.6560)  Acc@5: 97.6415 (95.5320)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-281.pth.tar', 81.656)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-279.pth.tar', 81.64400005371094)

INFO:281-epoch: remaining time 3.74 h
INFO:Train: 282 [   0/625 (  0%)]  Loss: 0.002627 (0.00263)  Time: 4.435s,  461.80/s  (4.435s,  461.80/s)  avg LR: 1.204e-04  iter ratio: 0.0000  Data: 3.736 (3.736)
INFO:Train: 282 [  50/625 (  8%)]  Loss: 0.002859 (0.00274)  Time: 0.704s, 2907.56/s  (0.779s, 2627.52/s)  avg LR: 1.204e-04  iter ratio: 0.0000  Data: 0.028 (0.102)
INFO:Train: 282 [ 100/625 ( 16%)]  Loss: 0.002566 (0.00268)  Time: 0.701s, 2923.00/s  (0.743s, 2756.57/s)  avg LR: 1.204e-04  iter ratio: 0.0000  Data: 0.026 (0.066)
INFO:Train: 282 [ 150/625 ( 24%)]  Loss: 0.003571 (0.00291)  Time: 0.703s, 2912.30/s  (0.731s, 2803.12/s)  avg LR: 1.204e-04  iter ratio: 0.0000  Data: 0.028 (0.054)
INFO:Train: 282 [ 200/625 ( 32%)]  Loss: 0.003447 (0.00301)  Time: 0.715s, 2865.44/s  (0.724s, 2828.80/s)  avg LR: 1.204e-04  iter ratio: 0.0000  Data: 0.040 (0.047)
INFO:Train: 282 [ 250/625 ( 40%)]  Loss: 0.002886 (0.00299)  Time: 0.715s, 2863.29/s  (0.722s, 2835.40/s)  avg LR: 1.204e-04  iter ratio: 0.0000  Data: 0.041 (0.046)
INFO:Train: 282 [ 300/625 ( 48%)]  Loss: 0.003234 (0.00303)  Time: 0.714s, 2868.49/s  (0.721s, 2839.36/s)  avg LR: 1.204e-04  iter ratio: 0.0000  Data: 0.036 (0.045)
INFO:Train: 282 [ 350/625 ( 56%)]  Loss: 0.003813 (0.00313)  Time: 0.716s, 2861.58/s  (0.720s, 2842.86/s)  avg LR: 1.204e-04  iter ratio: 0.0000  Data: 0.041 (0.044)
INFO:Train: 282 [ 400/625 ( 64%)]  Loss: 0.002886 (0.00310)  Time: 0.713s, 2871.32/s  (0.720s, 2845.90/s)  avg LR: 1.204e-04  iter ratio: 0.0000  Data: 0.040 (0.043)
INFO:Train: 282 [ 450/625 ( 72%)]  Loss: 0.003138 (0.00310)  Time: 0.716s, 2861.81/s  (0.719s, 2848.56/s)  avg LR: 1.204e-04  iter ratio: 0.0000  Data: 0.041 (0.042)
INFO:Train: 282 [ 500/625 ( 80%)]  Loss: 0.003859 (0.00317)  Time: 0.713s, 2871.62/s  (0.719s, 2850.07/s)  avg LR: 1.204e-04  iter ratio: 0.0000  Data: 0.039 (0.042)
INFO:Train: 282 [ 550/625 ( 88%)]  Loss: 0.003019 (0.00316)  Time: 0.711s, 2880.74/s  (0.718s, 2851.47/s)  avg LR: 1.204e-04  iter ratio: 0.0000  Data: 0.036 (0.042)
INFO:Train: 282 [ 600/625 ( 96%)]  Loss: 0.002389 (0.00310)  Time: 0.707s, 2897.90/s  (0.717s, 2855.67/s)  avg LR: 1.204e-04  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 282 [ 624/625 (100%)]  Loss: 0.003528 (0.00313)  Time: 0.671s, 3050.79/s  (0.716s, 2858.49/s)  avg LR: 1.204e-04  iter ratio: 0.0000  Data: 0.000 (0.040)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.330 (4.330)  Loss:  0.5356 (0.5356)  Acc@1: 87.2559 (87.2559)  Acc@5: 97.9492 (97.9492)
INFO:Test: [  24/24]  Time: 0.080 (0.507)  Loss:  0.4912 (0.8060)  Acc@1: 87.0283 (81.5980)  Acc@5: 97.7594 (95.5160)
INFO:282-epoch: remaining time 3.60 h
INFO:Train: 283 [   0/625 (  0%)]  Loss: 0.003350 (0.00335)  Time: 4.292s,  477.12/s  (4.292s,  477.12/s)  avg LR: 1.128e-04  iter ratio: 0.0000  Data: 3.597 (3.597)
INFO:Train: 283 [  50/625 (  8%)]  Loss: 0.003578 (0.00346)  Time: 0.706s, 2899.19/s  (0.778s, 2633.83/s)  avg LR: 1.128e-04  iter ratio: 0.0000  Data: 0.029 (0.101)
INFO:Train: 283 [ 100/625 ( 16%)]  Loss: 0.002480 (0.00314)  Time: 0.705s, 2906.74/s  (0.740s, 2767.25/s)  avg LR: 1.128e-04  iter ratio: 0.0000  Data: 0.030 (0.064)
INFO:Train: 283 [ 150/625 ( 24%)]  Loss: 0.003173 (0.00315)  Time: 0.704s, 2909.67/s  (0.727s, 2815.15/s)  avg LR: 1.128e-04  iter ratio: 0.0000  Data: 0.028 (0.052)
INFO:Train: 283 [ 200/625 ( 32%)]  Loss: 0.003358 (0.00319)  Time: 0.712s, 2876.59/s  (0.722s, 2835.37/s)  avg LR: 1.128e-04  iter ratio: 0.0000  Data: 0.033 (0.046)
INFO:Train: 283 [ 250/625 ( 40%)]  Loss: 0.003597 (0.00326)  Time: 0.705s, 2905.33/s  (0.719s, 2848.78/s)  avg LR: 1.128e-04  iter ratio: 0.0000  Data: 0.029 (0.042)
INFO:Train: 283 [ 300/625 ( 48%)]  Loss: 0.003126 (0.00324)  Time: 0.703s, 2914.89/s  (0.716s, 2858.74/s)  avg LR: 1.128e-04  iter ratio: 0.0000  Data: 0.028 (0.040)
INFO:Train: 283 [ 350/625 ( 56%)]  Loss: 0.002579 (0.00316)  Time: 0.721s, 2842.02/s  (0.714s, 2866.70/s)  avg LR: 1.128e-04  iter ratio: 0.0000  Data: 0.045 (0.038)
INFO:Train: 283 [ 400/625 ( 64%)]  Loss: 0.003041 (0.00314)  Time: 0.712s, 2876.79/s  (0.714s, 2866.74/s)  avg LR: 1.128e-04  iter ratio: 0.0000  Data: 0.037 (0.038)
INFO:Train: 283 [ 450/625 ( 72%)]  Loss: 0.003387 (0.00317)  Time: 0.719s, 2846.55/s  (0.714s, 2866.49/s)  avg LR: 1.128e-04  iter ratio: 0.0000  Data: 0.043 (0.038)
INFO:Train: 283 [ 500/625 ( 80%)]  Loss: 0.002974 (0.00315)  Time: 0.717s, 2855.71/s  (0.715s, 2866.14/s)  avg LR: 1.128e-04  iter ratio: 0.0000  Data: 0.042 (0.038)
INFO:Train: 283 [ 550/625 ( 88%)]  Loss: 0.003235 (0.00316)  Time: 0.703s, 2914.51/s  (0.714s, 2866.59/s)  avg LR: 1.128e-04  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 283 [ 600/625 ( 96%)]  Loss: 0.003714 (0.00320)  Time: 0.704s, 2909.34/s  (0.714s, 2869.46/s)  avg LR: 1.128e-04  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 283 [ 624/625 (100%)]  Loss: 0.003032 (0.00319)  Time: 0.675s, 3034.33/s  (0.713s, 2871.96/s)  avg LR: 1.128e-04  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.364 (4.364)  Loss:  0.5479 (0.5479)  Acc@1: 87.5000 (87.5000)  Acc@5: 97.8516 (97.8516)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.5078 (0.8247)  Acc@1: 87.1462 (81.6660)  Acc@5: 97.6415 (95.5200)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-283.pth.tar', 81.66600010498047)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-281.pth.tar', 81.656)

INFO:283-epoch: remaining time 3.46 h
INFO:Train: 284 [   0/625 (  0%)]  Loss: 0.002928 (0.00293)  Time: 4.605s,  444.75/s  (4.605s,  444.75/s)  avg LR: 1.057e-04  iter ratio: 0.0000  Data: 3.909 (3.909)
INFO:Train: 284 [  50/625 (  8%)]  Loss: 0.003485 (0.00321)  Time: 0.702s, 2917.78/s  (0.786s, 2605.22/s)  avg LR: 1.057e-04  iter ratio: 0.0000  Data: 0.027 (0.108)
INFO:Train: 284 [ 100/625 ( 16%)]  Loss: 0.003365 (0.00326)  Time: 0.702s, 2917.94/s  (0.745s, 2748.87/s)  avg LR: 1.057e-04  iter ratio: 0.0000  Data: 0.025 (0.068)
INFO:Train: 284 [ 150/625 ( 24%)]  Loss: 0.002979 (0.00319)  Time: 0.701s, 2923.10/s  (0.732s, 2796.38/s)  avg LR: 1.057e-04  iter ratio: 0.0000  Data: 0.026 (0.055)
INFO:Train: 284 [ 200/625 ( 32%)]  Loss: 0.002855 (0.00312)  Time: 0.704s, 2910.75/s  (0.725s, 2825.90/s)  avg LR: 1.057e-04  iter ratio: 0.0000  Data: 0.028 (0.048)
INFO:Train: 284 [ 250/625 ( 40%)]  Loss: 0.002805 (0.00307)  Time: 0.700s, 2925.61/s  (0.720s, 2843.18/s)  avg LR: 1.057e-04  iter ratio: 0.0000  Data: 0.025 (0.044)
INFO:Train: 284 [ 300/625 ( 48%)]  Loss: 0.002347 (0.00297)  Time: 0.713s, 2874.32/s  (0.718s, 2850.77/s)  avg LR: 1.057e-04  iter ratio: 0.0000  Data: 0.031 (0.042)
INFO:Train: 284 [ 350/625 ( 56%)]  Loss: 0.002684 (0.00293)  Time: 0.700s, 2924.94/s  (0.717s, 2855.50/s)  avg LR: 1.057e-04  iter ratio: 0.0000  Data: 0.026 (0.040)
INFO:Train: 284 [ 400/625 ( 64%)]  Loss: 0.003477 (0.00299)  Time: 0.702s, 2917.36/s  (0.715s, 2862.93/s)  avg LR: 1.057e-04  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 284 [ 450/625 ( 72%)]  Loss: 0.002987 (0.00299)  Time: 0.703s, 2914.07/s  (0.714s, 2868.43/s)  avg LR: 1.057e-04  iter ratio: 0.0000  Data: 0.026 (0.037)
INFO:Train: 284 [ 500/625 ( 80%)]  Loss: 0.003626 (0.00305)  Time: 0.715s, 2863.03/s  (0.714s, 2869.99/s)  avg LR: 1.057e-04  iter ratio: 0.0000  Data: 0.037 (0.037)
INFO:Train: 284 [ 550/625 ( 88%)]  Loss: 0.003301 (0.00307)  Time: 0.698s, 2935.61/s  (0.713s, 2871.16/s)  avg LR: 1.057e-04  iter ratio: 0.0000  Data: 0.024 (0.036)
INFO:Train: 284 [ 600/625 ( 96%)]  Loss: 0.003867 (0.00313)  Time: 0.707s, 2895.54/s  (0.713s, 2874.03/s)  avg LR: 1.057e-04  iter ratio: 0.0000  Data: 0.031 (0.036)
INFO:Train: 284 [ 624/625 (100%)]  Loss: 0.003471 (0.00316)  Time: 0.676s, 3028.06/s  (0.712s, 2875.39/s)  avg LR: 1.057e-04  iter ratio: 0.0000  Data: 0.000 (0.035)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.317 (4.317)  Loss:  0.5396 (0.5396)  Acc@1: 87.5488 (87.5488)  Acc@5: 97.9492 (97.9492)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.5049 (0.8128)  Acc@1: 86.5566 (81.7380)  Acc@5: 97.6415 (95.6020)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-284.pth.tar', 81.73799997802735)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-283.pth.tar', 81.66600010498047)

INFO:284-epoch: remaining time 3.32 h
INFO:Train: 285 [   0/625 (  0%)]  Loss: 0.002917 (0.00292)  Time: 4.297s,  476.58/s  (4.297s,  476.58/s)  avg LR: 9.894e-05  iter ratio: 0.0000  Data: 3.592 (3.592)
INFO:Train: 285 [  50/625 (  8%)]  Loss: 0.003555 (0.00324)  Time: 0.712s, 2877.43/s  (0.779s, 2628.18/s)  avg LR: 9.894e-05  iter ratio: 0.0000  Data: 0.034 (0.101)
INFO:Train: 285 [ 100/625 ( 16%)]  Loss: 0.003471 (0.00331)  Time: 0.713s, 2872.82/s  (0.744s, 2752.53/s)  avg LR: 9.894e-05  iter ratio: 0.0000  Data: 0.035 (0.066)
INFO:Train: 285 [ 150/625 ( 24%)]  Loss: 0.003575 (0.00338)  Time: 0.710s, 2886.06/s  (0.732s, 2796.89/s)  avg LR: 9.894e-05  iter ratio: 0.0000  Data: 0.029 (0.055)
INFO:Train: 285 [ 200/625 ( 32%)]  Loss: 0.002956 (0.00329)  Time: 0.708s, 2892.73/s  (0.727s, 2818.44/s)  avg LR: 9.894e-05  iter ratio: 0.0000  Data: 0.030 (0.049)
INFO:Train: 285 [ 250/625 ( 40%)]  Loss: 0.002268 (0.00312)  Time: 0.710s, 2884.20/s  (0.723s, 2832.01/s)  avg LR: 9.894e-05  iter ratio: 0.0000  Data: 0.028 (0.046)
INFO:Train: 285 [ 300/625 ( 48%)]  Loss: 0.002592 (0.00305)  Time: 0.709s, 2888.72/s  (0.721s, 2841.72/s)  avg LR: 9.894e-05  iter ratio: 0.0000  Data: 0.032 (0.043)
INFO:Train: 285 [ 350/625 ( 56%)]  Loss: 0.003865 (0.00315)  Time: 0.707s, 2895.36/s  (0.719s, 2849.00/s)  avg LR: 9.894e-05  iter ratio: 0.0000  Data: 0.031 (0.042)
INFO:Train: 285 [ 400/625 ( 64%)]  Loss: 0.002702 (0.00310)  Time: 0.710s, 2884.39/s  (0.718s, 2854.07/s)  avg LR: 9.894e-05  iter ratio: 0.0000  Data: 0.034 (0.040)
INFO:Train: 285 [ 450/625 ( 72%)]  Loss: 0.003682 (0.00316)  Time: 0.711s, 2881.37/s  (0.717s, 2858.19/s)  avg LR: 9.894e-05  iter ratio: 0.0000  Data: 0.034 (0.039)
INFO:Train: 285 [ 500/625 ( 80%)]  Loss: 0.003344 (0.00318)  Time: 0.708s, 2892.29/s  (0.716s, 2861.43/s)  avg LR: 9.894e-05  iter ratio: 0.0000  Data: 0.030 (0.039)
INFO:Train: 285 [ 550/625 ( 88%)]  Loss: 0.003596 (0.00321)  Time: 0.710s, 2883.07/s  (0.715s, 2864.16/s)  avg LR: 9.894e-05  iter ratio: 0.0000  Data: 0.033 (0.038)
INFO:Train: 285 [ 600/625 ( 96%)]  Loss: 0.002968 (0.00319)  Time: 0.714s, 2866.87/s  (0.714s, 2866.59/s)  avg LR: 9.894e-05  iter ratio: 0.0000  Data: 0.036 (0.037)
INFO:Train: 285 [ 624/625 (100%)]  Loss: 0.003428 (0.00321)  Time: 0.677s, 3024.39/s  (0.714s, 2868.04/s)  avg LR: 9.894e-05  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.347 (4.347)  Loss:  0.5474 (0.5474)  Acc@1: 87.2070 (87.2070)  Acc@5: 97.9492 (97.9492)
INFO:Test: [  24/24]  Time: 0.080 (0.502)  Loss:  0.5078 (0.8144)  Acc@1: 86.7925 (81.6240)  Acc@5: 97.8774 (95.6300)
INFO:285-epoch: remaining time 3.20 h
INFO:Train: 286 [   0/625 (  0%)]  Loss: 0.002584 (0.00258)  Time: 4.299s,  476.43/s  (4.299s,  476.43/s)  avg LR: 9.264e-05  iter ratio: 0.0000  Data: 3.611 (3.611)
INFO:Train: 286 [  50/625 (  8%)]  Loss: 0.003565 (0.00307)  Time: 0.713s, 2873.73/s  (0.776s, 2639.20/s)  avg LR: 9.264e-05  iter ratio: 0.0000  Data: 0.039 (0.100)
INFO:Train: 286 [ 100/625 ( 16%)]  Loss: 0.002831 (0.00299)  Time: 0.711s, 2880.76/s  (0.747s, 2743.44/s)  avg LR: 9.264e-05  iter ratio: 0.0000  Data: 0.037 (0.071)
INFO:Train: 286 [ 150/625 ( 24%)]  Loss: 0.002848 (0.00296)  Time: 0.705s, 2903.13/s  (0.737s, 2780.01/s)  avg LR: 9.264e-05  iter ratio: 0.0000  Data: 0.030 (0.061)
INFO:Train: 286 [ 200/625 ( 32%)]  Loss: 0.003154 (0.00300)  Time: 0.711s, 2881.86/s  (0.732s, 2798.56/s)  avg LR: 9.264e-05  iter ratio: 0.0000  Data: 0.036 (0.057)
INFO:Train: 286 [ 250/625 ( 40%)]  Loss: 0.002998 (0.00300)  Time: 0.700s, 2927.46/s  (0.728s, 2813.55/s)  avg LR: 9.264e-05  iter ratio: 0.0000  Data: 0.024 (0.053)
INFO:Train: 286 [ 300/625 ( 48%)]  Loss: 0.003089 (0.00301)  Time: 0.702s, 2919.37/s  (0.724s, 2830.12/s)  avg LR: 9.264e-05  iter ratio: 0.0000  Data: 0.027 (0.049)
INFO:Train: 286 [ 350/625 ( 56%)]  Loss: 0.002865 (0.00299)  Time: 0.702s, 2916.51/s  (0.721s, 2840.52/s)  avg LR: 9.264e-05  iter ratio: 0.0000  Data: 0.027 (0.046)
INFO:Train: 286 [ 400/625 ( 64%)]  Loss: 0.003697 (0.00307)  Time: 0.704s, 2908.16/s  (0.719s, 2848.46/s)  avg LR: 9.264e-05  iter ratio: 0.0000  Data: 0.029 (0.044)
INFO:Train: 286 [ 450/625 ( 72%)]  Loss: 0.003336 (0.00310)  Time: 0.698s, 2935.41/s  (0.717s, 2854.95/s)  avg LR: 9.264e-05  iter ratio: 0.0000  Data: 0.023 (0.042)
INFO:Train: 286 [ 500/625 ( 80%)]  Loss: 0.003784 (0.00316)  Time: 0.708s, 2894.43/s  (0.716s, 2859.27/s)  avg LR: 9.264e-05  iter ratio: 0.0000  Data: 0.034 (0.041)
INFO:Train: 286 [ 550/625 ( 88%)]  Loss: 0.003795 (0.00321)  Time: 0.701s, 2923.62/s  (0.716s, 2861.05/s)  avg LR: 9.264e-05  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 286 [ 600/625 ( 96%)]  Loss: 0.002602 (0.00317)  Time: 0.706s, 2900.65/s  (0.715s, 2865.19/s)  avg LR: 9.264e-05  iter ratio: 0.0000  Data: 0.031 (0.040)
INFO:Train: 286 [ 624/625 (100%)]  Loss: 0.002914 (0.00315)  Time: 0.672s, 3048.96/s  (0.714s, 2867.05/s)  avg LR: 9.264e-05  iter ratio: 0.0000  Data: 0.000 (0.039)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.393 (4.393)  Loss:  0.5557 (0.5557)  Acc@1: 87.5488 (87.5488)  Acc@5: 97.9004 (97.9004)
INFO:Test: [  24/24]  Time: 0.080 (0.511)  Loss:  0.5039 (0.8144)  Acc@1: 87.2642 (81.7460)  Acc@5: 97.6415 (95.5780)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-286.pth.tar', 81.74600002685547)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-284.pth.tar', 81.73799997802735)

INFO:286-epoch: remaining time 3.08 h
INFO:Train: 287 [   0/625 (  0%)]  Loss: 0.002684 (0.00268)  Time: 4.334s,  472.56/s  (4.334s,  472.56/s)  avg LR: 8.678e-05  iter ratio: 0.0000  Data: 3.638 (3.638)
INFO:Train: 287 [  50/625 (  8%)]  Loss: 0.003468 (0.00308)  Time: 0.701s, 2920.63/s  (0.785s, 2610.53/s)  avg LR: 8.678e-05  iter ratio: 0.0000  Data: 0.024 (0.106)
INFO:Train: 287 [ 100/625 ( 16%)]  Loss: 0.003402 (0.00318)  Time: 0.708s, 2892.37/s  (0.746s, 2746.24/s)  avg LR: 8.678e-05  iter ratio: 0.0000  Data: 0.023 (0.068)
INFO:Train: 287 [ 150/625 ( 24%)]  Loss: 0.003247 (0.00320)  Time: 0.700s, 2924.28/s  (0.732s, 2797.70/s)  avg LR: 8.678e-05  iter ratio: 0.0000  Data: 0.021 (0.054)
INFO:Train: 287 [ 200/625 ( 32%)]  Loss: 0.003184 (0.00320)  Time: 0.704s, 2910.86/s  (0.725s, 2823.73/s)  avg LR: 8.678e-05  iter ratio: 0.0000  Data: 0.024 (0.047)
INFO:Train: 287 [ 250/625 ( 40%)]  Loss: 0.003043 (0.00317)  Time: 0.703s, 2911.23/s  (0.721s, 2839.61/s)  avg LR: 8.678e-05  iter ratio: 0.0000  Data: 0.021 (0.043)
INFO:Train: 287 [ 300/625 ( 48%)]  Loss: 0.003377 (0.00320)  Time: 0.706s, 2901.93/s  (0.719s, 2850.12/s)  avg LR: 8.678e-05  iter ratio: 0.0000  Data: 0.019 (0.040)
INFO:Train: 287 [ 350/625 ( 56%)]  Loss: 0.002689 (0.00314)  Time: 0.705s, 2904.85/s  (0.717s, 2857.71/s)  avg LR: 8.678e-05  iter ratio: 0.0000  Data: 0.021 (0.038)
INFO:Train: 287 [ 400/625 ( 64%)]  Loss: 0.003205 (0.00314)  Time: 0.702s, 2918.51/s  (0.715s, 2863.83/s)  avg LR: 8.678e-05  iter ratio: 0.0000  Data: 0.021 (0.036)
INFO:Train: 287 [ 450/625 ( 72%)]  Loss: 0.003883 (0.00322)  Time: 0.706s, 2900.98/s  (0.714s, 2868.19/s)  avg LR: 8.678e-05  iter ratio: 0.0000  Data: 0.022 (0.035)
INFO:Train: 287 [ 500/625 ( 80%)]  Loss: 0.003598 (0.00325)  Time: 0.702s, 2916.11/s  (0.713s, 2871.83/s)  avg LR: 8.678e-05  iter ratio: 0.0000  Data: 0.022 (0.034)
INFO:Train: 287 [ 550/625 ( 88%)]  Loss: 0.002816 (0.00322)  Time: 0.705s, 2905.63/s  (0.712s, 2874.76/s)  avg LR: 8.678e-05  iter ratio: 0.0000  Data: 0.022 (0.034)
INFO:Train: 287 [ 600/625 ( 96%)]  Loss: 0.003099 (0.00321)  Time: 0.705s, 2906.56/s  (0.712s, 2876.76/s)  avg LR: 8.678e-05  iter ratio: 0.0000  Data: 0.024 (0.033)
INFO:Train: 287 [ 624/625 (100%)]  Loss: 0.002292 (0.00314)  Time: 0.674s, 3036.84/s  (0.712s, 2878.05/s)  avg LR: 8.678e-05  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.354 (4.354)  Loss:  0.5454 (0.5454)  Acc@1: 87.4023 (87.4023)  Acc@5: 97.9980 (97.9980)
INFO:Test: [  24/24]  Time: 0.080 (0.499)  Loss:  0.5049 (0.8126)  Acc@1: 87.2642 (81.7260)  Acc@5: 97.4057 (95.5500)
INFO:287-epoch: remaining time 2.94 h
INFO:Train: 288 [   0/625 (  0%)]  Loss: 0.002674 (0.00267)  Time: 4.526s,  452.52/s  (4.526s,  452.52/s)  avg LR: 8.134e-05  iter ratio: 0.0000  Data: 3.840 (3.840)
INFO:Train: 288 [  50/625 (  8%)]  Loss: 0.003366 (0.00302)  Time: 0.706s, 2900.09/s  (0.781s, 2622.84/s)  avg LR: 8.134e-05  iter ratio: 0.0000  Data: 0.031 (0.105)
INFO:Train: 288 [ 100/625 ( 16%)]  Loss: 0.003107 (0.00305)  Time: 0.704s, 2908.84/s  (0.745s, 2749.65/s)  avg LR: 8.134e-05  iter ratio: 0.0000  Data: 0.028 (0.068)
INFO:Train: 288 [ 150/625 ( 24%)]  Loss: 0.002719 (0.00297)  Time: 0.707s, 2895.46/s  (0.732s, 2797.79/s)  avg LR: 8.134e-05  iter ratio: 0.0000  Data: 0.031 (0.056)
INFO:Train: 288 [ 200/625 ( 32%)]  Loss: 0.003596 (0.00309)  Time: 0.706s, 2901.56/s  (0.726s, 2821.66/s)  avg LR: 8.134e-05  iter ratio: 0.0000  Data: 0.031 (0.050)
INFO:Train: 288 [ 250/625 ( 40%)]  Loss: 0.003144 (0.00310)  Time: 0.705s, 2905.12/s  (0.722s, 2836.31/s)  avg LR: 8.134e-05  iter ratio: 0.0000  Data: 0.027 (0.046)
INFO:Train: 288 [ 300/625 ( 48%)]  Loss: 0.003455 (0.00315)  Time: 0.702s, 2917.76/s  (0.719s, 2847.05/s)  avg LR: 8.134e-05  iter ratio: 0.0000  Data: 0.026 (0.043)
INFO:Train: 288 [ 350/625 ( 56%)]  Loss: 0.003275 (0.00317)  Time: 0.715s, 2864.16/s  (0.718s, 2851.52/s)  avg LR: 8.134e-05  iter ratio: 0.0000  Data: 0.040 (0.042)
INFO:Train: 288 [ 400/625 ( 64%)]  Loss: 0.003537 (0.00321)  Time: 0.713s, 2873.17/s  (0.718s, 2851.28/s)  avg LR: 8.134e-05  iter ratio: 0.0000  Data: 0.035 (0.042)
INFO:Train: 288 [ 450/625 ( 72%)]  Loss: 0.003057 (0.00319)  Time: 0.711s, 2880.38/s  (0.718s, 2851.39/s)  avg LR: 8.134e-05  iter ratio: 0.0000  Data: 0.035 (0.042)
INFO:Train: 288 [ 500/625 ( 80%)]  Loss: 0.003223 (0.00320)  Time: 0.706s, 2902.71/s  (0.718s, 2851.68/s)  avg LR: 8.134e-05  iter ratio: 0.0000  Data: 0.030 (0.042)
INFO:Train: 288 [ 550/625 ( 88%)]  Loss: 0.002994 (0.00318)  Time: 0.708s, 2891.89/s  (0.718s, 2851.85/s)  avg LR: 8.134e-05  iter ratio: 0.0000  Data: 0.033 (0.042)
INFO:Train: 288 [ 600/625 ( 96%)]  Loss: 0.003165 (0.00318)  Time: 0.705s, 2905.77/s  (0.717s, 2854.96/s)  avg LR: 8.134e-05  iter ratio: 0.0000  Data: 0.029 (0.041)
INFO:Train: 288 [ 624/625 (100%)]  Loss: 0.003300 (0.00319)  Time: 0.677s, 3025.86/s  (0.717s, 2857.05/s)  avg LR: 8.134e-05  iter ratio: 0.0000  Data: 0.000 (0.041)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.354 (4.354)  Loss:  0.5479 (0.5479)  Acc@1: 87.1094 (87.1094)  Acc@5: 98.1445 (98.1445)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.5034 (0.8112)  Acc@1: 87.0283 (81.6780)  Acc@5: 97.6415 (95.6240)
INFO:288-epoch: remaining time 2.83 h
INFO:Train: 289 [   0/625 (  0%)]  Loss: 0.003439 (0.00344)  Time: 4.152s,  493.25/s  (4.152s,  493.25/s)  avg LR: 7.634e-05  iter ratio: 0.0000  Data: 3.456 (3.456)
INFO:Train: 289 [  50/625 (  8%)]  Loss: 0.002802 (0.00312)  Time: 0.707s, 2896.34/s  (0.776s, 2638.87/s)  avg LR: 7.634e-05  iter ratio: 0.0000  Data: 0.027 (0.099)
INFO:Train: 289 [ 100/625 ( 16%)]  Loss: 0.003111 (0.00312)  Time: 0.703s, 2911.83/s  (0.742s, 2759.78/s)  avg LR: 7.634e-05  iter ratio: 0.0000  Data: 0.027 (0.066)
INFO:Train: 289 [ 150/625 ( 24%)]  Loss: 0.003501 (0.00321)  Time: 0.707s, 2895.28/s  (0.731s, 2802.76/s)  avg LR: 7.634e-05  iter ratio: 0.0000  Data: 0.029 (0.054)
INFO:Train: 289 [ 200/625 ( 32%)]  Loss: 0.003762 (0.00332)  Time: 0.705s, 2904.17/s  (0.725s, 2824.76/s)  avg LR: 7.634e-05  iter ratio: 0.0000  Data: 0.030 (0.049)
INFO:Train: 289 [ 250/625 ( 40%)]  Loss: 0.003459 (0.00335)  Time: 0.704s, 2909.73/s  (0.722s, 2837.83/s)  avg LR: 7.634e-05  iter ratio: 0.0000  Data: 0.028 (0.046)
INFO:Train: 289 [ 300/625 ( 48%)]  Loss: 0.003077 (0.00331)  Time: 0.707s, 2895.95/s  (0.719s, 2846.56/s)  avg LR: 7.634e-05  iter ratio: 0.0000  Data: 0.028 (0.043)
INFO:Train: 289 [ 350/625 ( 56%)]  Loss: 0.003475 (0.00333)  Time: 0.706s, 2902.38/s  (0.718s, 2852.47/s)  avg LR: 7.634e-05  iter ratio: 0.0000  Data: 0.029 (0.042)
INFO:Train: 289 [ 400/625 ( 64%)]  Loss: 0.002525 (0.00324)  Time: 0.704s, 2908.40/s  (0.717s, 2857.27/s)  avg LR: 7.634e-05  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 289 [ 450/625 ( 72%)]  Loss: 0.003836 (0.00330)  Time: 0.705s, 2904.78/s  (0.716s, 2861.40/s)  avg LR: 7.634e-05  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 289 [ 500/625 ( 80%)]  Loss: 0.003314 (0.00330)  Time: 0.703s, 2912.01/s  (0.715s, 2864.62/s)  avg LR: 7.634e-05  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 289 [ 550/625 ( 88%)]  Loss: 0.003001 (0.00328)  Time: 0.703s, 2912.84/s  (0.714s, 2867.29/s)  avg LR: 7.634e-05  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 289 [ 600/625 ( 96%)]  Loss: 0.002869 (0.00324)  Time: 0.712s, 2875.55/s  (0.714s, 2869.50/s)  avg LR: 7.634e-05  iter ratio: 0.0000  Data: 0.020 (0.037)
INFO:Train: 289 [ 624/625 (100%)]  Loss: 0.003525 (0.00326)  Time: 0.676s, 3029.97/s  (0.713s, 2871.25/s)  avg LR: 7.634e-05  iter ratio: 0.0000  Data: 0.000 (0.037)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.383 (4.383)  Loss:  0.5547 (0.5547)  Acc@1: 87.4023 (87.4023)  Acc@5: 98.0957 (98.0957)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.5137 (0.8195)  Acc@1: 87.0283 (81.7060)  Acc@5: 97.4057 (95.5780)
INFO:289-epoch: remaining time 2.69 h
INFO:Train: 290 [   0/625 (  0%)]  Loss: 0.003183 (0.00318)  Time: 4.152s,  493.21/s  (4.152s,  493.21/s)  avg LR: 7.178e-05  iter ratio: 0.0000  Data: 3.459 (3.459)
INFO:Train: 290 [  50/625 (  8%)]  Loss: 0.002881 (0.00303)  Time: 0.707s, 2897.39/s  (0.781s, 2621.32/s)  avg LR: 7.178e-05  iter ratio: 0.0000  Data: 0.023 (0.096)
INFO:Train: 290 [ 100/625 ( 16%)]  Loss: 0.003002 (0.00302)  Time: 0.714s, 2869.07/s  (0.745s, 2748.27/s)  avg LR: 7.178e-05  iter ratio: 0.0000  Data: 0.027 (0.061)
INFO:Train: 290 [ 150/625 ( 24%)]  Loss: 0.003288 (0.00309)  Time: 0.708s, 2892.53/s  (0.733s, 2794.58/s)  avg LR: 7.178e-05  iter ratio: 0.0000  Data: 0.024 (0.049)
INFO:Train: 290 [ 200/625 ( 32%)]  Loss: 0.002965 (0.00306)  Time: 0.709s, 2888.10/s  (0.727s, 2817.50/s)  avg LR: 7.178e-05  iter ratio: 0.0000  Data: 0.024 (0.043)
INFO:Train: 290 [ 250/625 ( 40%)]  Loss: 0.003569 (0.00315)  Time: 0.716s, 2859.63/s  (0.723s, 2831.47/s)  avg LR: 7.178e-05  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 290 [ 300/625 ( 48%)]  Loss: 0.004163 (0.00329)  Time: 0.709s, 2886.91/s  (0.721s, 2840.40/s)  avg LR: 7.178e-05  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 290 [ 350/625 ( 56%)]  Loss: 0.003427 (0.00331)  Time: 0.710s, 2884.67/s  (0.719s, 2847.43/s)  avg LR: 7.178e-05  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 290 [ 400/625 ( 64%)]  Loss: 0.003748 (0.00336)  Time: 0.709s, 2886.81/s  (0.718s, 2852.53/s)  avg LR: 7.178e-05  iter ratio: 0.0000  Data: 0.024 (0.034)
INFO:Train: 290 [ 450/625 ( 72%)]  Loss: 0.003205 (0.00334)  Time: 0.708s, 2893.57/s  (0.717s, 2856.77/s)  avg LR: 7.178e-05  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 290 [ 500/625 ( 80%)]  Loss: 0.003418 (0.00335)  Time: 0.708s, 2894.26/s  (0.716s, 2860.03/s)  avg LR: 7.178e-05  iter ratio: 0.0000  Data: 0.025 (0.032)
INFO:Train: 290 [ 550/625 ( 88%)]  Loss: 0.002889 (0.00331)  Time: 0.709s, 2887.27/s  (0.715s, 2862.70/s)  avg LR: 7.178e-05  iter ratio: 0.0000  Data: 0.028 (0.032)
INFO:Train: 290 [ 600/625 ( 96%)]  Loss: 0.002828 (0.00327)  Time: 0.707s, 2897.47/s  (0.715s, 2865.33/s)  avg LR: 7.178e-05  iter ratio: 0.0000  Data: 0.024 (0.031)
INFO:Train: 290 [ 624/625 (100%)]  Loss: 0.002665 (0.00323)  Time: 0.676s, 3028.66/s  (0.714s, 2867.09/s)  avg LR: 7.178e-05  iter ratio: 0.0000  Data: 0.000 (0.031)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.365 (4.365)  Loss:  0.5522 (0.5522)  Acc@1: 87.5488 (87.5488)  Acc@5: 98.1445 (98.1445)
INFO:Test: [  24/24]  Time: 0.080 (0.509)  Loss:  0.5171 (0.8241)  Acc@1: 87.3821 (81.7060)  Acc@5: 97.7594 (95.5880)
INFO:290-epoch: remaining time 2.56 h
INFO:Train: 291 [   0/625 (  0%)]  Loss: 0.003243 (0.00324)  Time: 4.455s,  459.70/s  (4.455s,  459.70/s)  avg LR: 6.764e-05  iter ratio: 0.0000  Data: 3.771 (3.771)
INFO:Train: 291 [  50/625 (  8%)]  Loss: 0.002624 (0.00293)  Time: 0.710s, 2885.46/s  (0.780s, 2626.40/s)  avg LR: 6.764e-05  iter ratio: 0.0000  Data: 0.030 (0.103)
INFO:Train: 291 [ 100/625 ( 16%)]  Loss: 0.003463 (0.00311)  Time: 0.708s, 2894.27/s  (0.743s, 2755.14/s)  avg LR: 6.764e-05  iter ratio: 0.0000  Data: 0.029 (0.067)
INFO:Train: 291 [ 150/625 ( 24%)]  Loss: 0.002995 (0.00308)  Time: 0.724s, 2828.96/s  (0.734s, 2789.18/s)  avg LR: 6.764e-05  iter ratio: 0.0000  Data: 0.047 (0.058)
INFO:Train: 291 [ 200/625 ( 32%)]  Loss: 0.003266 (0.00312)  Time: 0.719s, 2846.78/s  (0.730s, 2803.96/s)  avg LR: 6.764e-05  iter ratio: 0.0000  Data: 0.044 (0.054)
INFO:Train: 291 [ 250/625 ( 40%)]  Loss: 0.003373 (0.00316)  Time: 0.710s, 2883.19/s  (0.726s, 2821.03/s)  avg LR: 6.764e-05  iter ratio: 0.0000  Data: 0.032 (0.050)
INFO:Train: 291 [ 300/625 ( 48%)]  Loss: 0.002993 (0.00314)  Time: 0.708s, 2891.62/s  (0.722s, 2835.36/s)  avg LR: 6.764e-05  iter ratio: 0.0000  Data: 0.029 (0.046)
INFO:Train: 291 [ 350/625 ( 56%)]  Loss: 0.002979 (0.00312)  Time: 0.706s, 2899.66/s  (0.720s, 2846.04/s)  avg LR: 6.764e-05  iter ratio: 0.0000  Data: 0.032 (0.043)
INFO:Train: 291 [ 400/625 ( 64%)]  Loss: 0.003522 (0.00316)  Time: 0.704s, 2909.36/s  (0.718s, 2853.96/s)  avg LR: 6.764e-05  iter ratio: 0.0000  Data: 0.029 (0.041)
INFO:Train: 291 [ 450/625 ( 72%)]  Loss: 0.003258 (0.00317)  Time: 0.706s, 2902.57/s  (0.716s, 2860.01/s)  avg LR: 6.764e-05  iter ratio: 0.0000  Data: 0.031 (0.040)
INFO:Train: 291 [ 500/625 ( 80%)]  Loss: 0.003120 (0.00317)  Time: 0.708s, 2890.91/s  (0.715s, 2864.78/s)  avg LR: 6.764e-05  iter ratio: 0.0000  Data: 0.032 (0.039)
INFO:Train: 291 [ 550/625 ( 88%)]  Loss: 0.002989 (0.00315)  Time: 0.705s, 2904.17/s  (0.714s, 2868.85/s)  avg LR: 6.764e-05  iter ratio: 0.0000  Data: 0.027 (0.038)
INFO:Train: 291 [ 600/625 ( 96%)]  Loss: 0.003124 (0.00315)  Time: 0.710s, 2884.42/s  (0.713s, 2872.51/s)  avg LR: 6.764e-05  iter ratio: 0.0000  Data: 0.034 (0.037)
INFO:Train: 291 [ 624/625 (100%)]  Loss: 0.003923 (0.00321)  Time: 0.672s, 3046.11/s  (0.712s, 2874.48/s)  avg LR: 6.764e-05  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.366 (4.366)  Loss:  0.5410 (0.5410)  Acc@1: 87.8418 (87.8418)  Acc@5: 98.0957 (98.0957)
INFO:Test: [  24/24]  Time: 0.080 (0.500)  Loss:  0.5063 (0.8071)  Acc@1: 87.0283 (81.6800)  Acc@5: 97.6415 (95.6060)
INFO:291-epoch: remaining time 2.43 h
INFO:Train: 292 [   0/625 (  0%)]  Loss: 0.002945 (0.00294)  Time: 4.400s,  465.49/s  (4.400s,  465.49/s)  avg LR: 6.394e-05  iter ratio: 0.0000  Data: 3.714 (3.714)
INFO:Train: 292 [  50/625 (  8%)]  Loss: 0.002518 (0.00273)  Time: 0.701s, 2920.85/s  (0.778s, 2632.05/s)  avg LR: 6.394e-05  iter ratio: 0.0000  Data: 0.026 (0.100)
INFO:Train: 292 [ 100/625 ( 16%)]  Loss: 0.003307 (0.00292)  Time: 0.701s, 2921.01/s  (0.741s, 2762.45/s)  avg LR: 6.394e-05  iter ratio: 0.0000  Data: 0.022 (0.064)
INFO:Train: 292 [ 150/625 ( 24%)]  Loss: 0.002959 (0.00293)  Time: 0.714s, 2869.06/s  (0.731s, 2801.09/s)  avg LR: 6.394e-05  iter ratio: 0.0000  Data: 0.039 (0.054)
INFO:Train: 292 [ 200/625 ( 32%)]  Loss: 0.002925 (0.00293)  Time: 0.716s, 2861.02/s  (0.728s, 2814.69/s)  avg LR: 6.394e-05  iter ratio: 0.0000  Data: 0.041 (0.050)
INFO:Train: 292 [ 250/625 ( 40%)]  Loss: 0.002582 (0.00287)  Time: 0.719s, 2849.74/s  (0.725s, 2823.06/s)  avg LR: 6.394e-05  iter ratio: 0.0000  Data: 0.042 (0.048)
INFO:Train: 292 [ 300/625 ( 48%)]  Loss: 0.003604 (0.00298)  Time: 0.718s, 2850.61/s  (0.724s, 2828.83/s)  avg LR: 6.394e-05  iter ratio: 0.0000  Data: 0.043 (0.047)
INFO:Train: 292 [ 350/625 ( 56%)]  Loss: 0.003000 (0.00298)  Time: 0.716s, 2859.74/s  (0.723s, 2833.18/s)  avg LR: 6.394e-05  iter ratio: 0.0000  Data: 0.042 (0.046)
INFO:Train: 292 [ 400/625 ( 64%)]  Loss: 0.003958 (0.00309)  Time: 0.717s, 2858.09/s  (0.722s, 2836.46/s)  avg LR: 6.394e-05  iter ratio: 0.0000  Data: 0.042 (0.045)
INFO:Train: 292 [ 450/625 ( 72%)]  Loss: 0.003737 (0.00315)  Time: 0.718s, 2850.71/s  (0.721s, 2838.84/s)  avg LR: 6.394e-05  iter ratio: 0.0000  Data: 0.044 (0.045)
INFO:Train: 292 [ 500/625 ( 80%)]  Loss: 0.003091 (0.00315)  Time: 0.714s, 2866.74/s  (0.721s, 2840.86/s)  avg LR: 6.394e-05  iter ratio: 0.0000  Data: 0.040 (0.044)
INFO:Train: 292 [ 550/625 ( 88%)]  Loss: 0.002649 (0.00311)  Time: 0.718s, 2853.49/s  (0.721s, 2842.41/s)  avg LR: 6.394e-05  iter ratio: 0.0000  Data: 0.043 (0.044)
INFO:Train: 292 [ 600/625 ( 96%)]  Loss: 0.004037 (0.00318)  Time: 0.703s, 2914.91/s  (0.719s, 2846.78/s)  avg LR: 6.394e-05  iter ratio: 0.0000  Data: 0.027 (0.043)
INFO:Train: 292 [ 624/625 (100%)]  Loss: 0.002970 (0.00316)  Time: 0.673s, 3041.69/s  (0.719s, 2849.40/s)  avg LR: 6.394e-05  iter ratio: 0.0000  Data: 0.000 (0.042)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.334 (4.334)  Loss:  0.5493 (0.5493)  Acc@1: 86.9629 (86.9629)  Acc@5: 98.0957 (98.0957)
INFO:Test: [  24/24]  Time: 0.080 (0.510)  Loss:  0.5078 (0.8109)  Acc@1: 87.2642 (81.6840)  Acc@5: 97.2877 (95.6360)
INFO:292-epoch: remaining time 2.32 h
INFO:Train: 293 [   0/625 (  0%)]  Loss: 0.002587 (0.00259)  Time: 4.273s,  479.26/s  (4.273s,  479.26/s)  avg LR: 6.067e-05  iter ratio: 0.0000  Data: 3.586 (3.586)
INFO:Train: 293 [  50/625 (  8%)]  Loss: 0.003316 (0.00295)  Time: 0.730s, 2806.73/s  (0.784s, 2611.17/s)  avg LR: 6.067e-05  iter ratio: 0.0000  Data: 0.048 (0.102)
INFO:Train: 293 [ 100/625 ( 16%)]  Loss: 0.002998 (0.00297)  Time: 0.709s, 2890.47/s  (0.748s, 2738.88/s)  avg LR: 6.067e-05  iter ratio: 0.0000  Data: 0.025 (0.066)
INFO:Train: 293 [ 150/625 ( 24%)]  Loss: 0.003112 (0.00300)  Time: 0.710s, 2885.33/s  (0.734s, 2790.34/s)  avg LR: 6.067e-05  iter ratio: 0.0000  Data: 0.031 (0.053)
INFO:Train: 293 [ 200/625 ( 32%)]  Loss: 0.003263 (0.00306)  Time: 0.706s, 2899.56/s  (0.727s, 2816.97/s)  avg LR: 6.067e-05  iter ratio: 0.0000  Data: 0.028 (0.046)
INFO:Train: 293 [ 250/625 ( 40%)]  Loss: 0.003329 (0.00310)  Time: 0.708s, 2892.91/s  (0.723s, 2833.70/s)  avg LR: 6.067e-05  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 293 [ 300/625 ( 48%)]  Loss: 0.002629 (0.00303)  Time: 0.711s, 2881.73/s  (0.720s, 2845.27/s)  avg LR: 6.067e-05  iter ratio: 0.0000  Data: 0.027 (0.039)
INFO:Train: 293 [ 350/625 ( 56%)]  Loss: 0.003354 (0.00307)  Time: 0.711s, 2882.22/s  (0.718s, 2853.46/s)  avg LR: 6.067e-05  iter ratio: 0.0000  Data: 0.028 (0.037)
INFO:Train: 293 [ 400/625 ( 64%)]  Loss: 0.003393 (0.00311)  Time: 0.709s, 2886.98/s  (0.716s, 2859.76/s)  avg LR: 6.067e-05  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 293 [ 450/625 ( 72%)]  Loss: 0.003334 (0.00313)  Time: 0.709s, 2889.00/s  (0.715s, 2864.77/s)  avg LR: 6.067e-05  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 293 [ 500/625 ( 80%)]  Loss: 0.002800 (0.00310)  Time: 0.710s, 2883.45/s  (0.714s, 2868.73/s)  avg LR: 6.067e-05  iter ratio: 0.0000  Data: 0.031 (0.034)
INFO:Train: 293 [ 550/625 ( 88%)]  Loss: 0.002312 (0.00304)  Time: 0.706s, 2901.21/s  (0.713s, 2872.08/s)  avg LR: 6.067e-05  iter ratio: 0.0000  Data: 0.026 (0.033)
INFO:Train: 293 [ 600/625 ( 96%)]  Loss: 0.003098 (0.00304)  Time: 0.711s, 2881.80/s  (0.712s, 2875.57/s)  avg LR: 6.067e-05  iter ratio: 0.0000  Data: 0.036 (0.033)
INFO:Train: 293 [ 624/625 (100%)]  Loss: 0.003420 (0.00307)  Time: 0.672s, 3045.47/s  (0.712s, 2877.30/s)  avg LR: 6.067e-05  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.371 (4.371)  Loss:  0.5625 (0.5625)  Acc@1: 87.0117 (87.0117)  Acc@5: 98.0957 (98.0957)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.5264 (0.8278)  Acc@1: 86.7925 (81.6480)  Acc@5: 97.6415 (95.5900)
INFO:293-epoch: remaining time 2.17 h
INFO:Train: 294 [   0/625 (  0%)]  Loss: 0.003202 (0.00320)  Time: 4.540s,  451.05/s  (4.540s,  451.05/s)  avg LR: 5.784e-05  iter ratio: 0.0000  Data: 3.853 (3.853)
INFO:Train: 294 [  50/625 (  8%)]  Loss: 0.003196 (0.00320)  Time: 0.700s, 2923.89/s  (0.779s, 2627.82/s)  avg LR: 5.784e-05  iter ratio: 0.0000  Data: 0.026 (0.102)
INFO:Train: 294 [ 100/625 ( 16%)]  Loss: 0.002942 (0.00311)  Time: 0.702s, 2917.20/s  (0.742s, 2760.71/s)  avg LR: 5.784e-05  iter ratio: 0.0000  Data: 0.026 (0.065)
INFO:Train: 294 [ 150/625 ( 24%)]  Loss: 0.002977 (0.00308)  Time: 0.704s, 2910.46/s  (0.729s, 2810.78/s)  avg LR: 5.784e-05  iter ratio: 0.0000  Data: 0.026 (0.052)
INFO:Train: 294 [ 200/625 ( 32%)]  Loss: 0.003674 (0.00320)  Time: 0.697s, 2938.85/s  (0.722s, 2836.09/s)  avg LR: 5.784e-05  iter ratio: 0.0000  Data: 0.023 (0.046)
INFO:Train: 294 [ 250/625 ( 40%)]  Loss: 0.004129 (0.00335)  Time: 0.708s, 2891.36/s  (0.720s, 2845.39/s)  avg LR: 5.784e-05  iter ratio: 0.0000  Data: 0.029 (0.043)
INFO:Train: 294 [ 300/625 ( 48%)]  Loss: 0.002924 (0.00329)  Time: 0.711s, 2879.81/s  (0.719s, 2847.45/s)  avg LR: 5.784e-05  iter ratio: 0.0000  Data: 0.037 (0.043)
INFO:Train: 294 [ 350/625 ( 56%)]  Loss: 0.003271 (0.00329)  Time: 0.713s, 2871.46/s  (0.719s, 2848.94/s)  avg LR: 5.784e-05  iter ratio: 0.0000  Data: 0.038 (0.043)
INFO:Train: 294 [ 400/625 ( 64%)]  Loss: 0.003436 (0.00331)  Time: 0.708s, 2891.21/s  (0.719s, 2850.22/s)  avg LR: 5.784e-05  iter ratio: 0.0000  Data: 0.035 (0.042)
INFO:Train: 294 [ 450/625 ( 72%)]  Loss: 0.003776 (0.00335)  Time: 0.712s, 2875.34/s  (0.718s, 2850.98/s)  avg LR: 5.784e-05  iter ratio: 0.0000  Data: 0.038 (0.042)
INFO:Train: 294 [ 500/625 ( 80%)]  Loss: 0.003000 (0.00332)  Time: 0.707s, 2895.30/s  (0.718s, 2852.00/s)  avg LR: 5.784e-05  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 294 [ 550/625 ( 88%)]  Loss: 0.003142 (0.00331)  Time: 0.714s, 2870.16/s  (0.718s, 2852.68/s)  avg LR: 5.784e-05  iter ratio: 0.0000  Data: 0.039 (0.042)
INFO:Train: 294 [ 600/625 ( 96%)]  Loss: 0.002922 (0.00328)  Time: 0.703s, 2914.39/s  (0.717s, 2855.96/s)  avg LR: 5.784e-05  iter ratio: 0.0000  Data: 0.026 (0.041)
INFO:Train: 294 [ 624/625 (100%)]  Loss: 0.003264 (0.00328)  Time: 0.675s, 3034.85/s  (0.717s, 2858.28/s)  avg LR: 5.784e-05  iter ratio: 0.0000  Data: 0.000 (0.040)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.282 (4.282)  Loss:  0.5396 (0.5396)  Acc@1: 87.4512 (87.4512)  Acc@5: 98.2422 (98.2422)
INFO:Test: [  24/24]  Time: 0.080 (0.505)  Loss:  0.4958 (0.8017)  Acc@1: 87.0283 (81.7800)  Acc@5: 97.5236 (95.6340)
ERROR:Exception '[Errno 2] No such file or directory: './exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-284.pth.tar'' while deleting checkpoint
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-294.pth.tar', 81.78000005371094)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-286.pth.tar', 81.74600002685547)

INFO:294-epoch: remaining time 2.06 h
INFO:Train: 295 [   0/625 (  0%)]  Loss: 0.003781 (0.00378)  Time: 4.197s,  487.97/s  (4.197s,  487.97/s)  avg LR: 5.545e-05  iter ratio: 0.0000  Data: 3.510 (3.510)
INFO:Train: 295 [  50/625 (  8%)]  Loss: 0.003137 (0.00346)  Time: 0.703s, 2914.19/s  (0.772s, 2652.44/s)  avg LR: 5.545e-05  iter ratio: 0.0000  Data: 0.025 (0.096)
INFO:Train: 295 [ 100/625 ( 16%)]  Loss: 0.002674 (0.00320)  Time: 0.703s, 2915.27/s  (0.739s, 2769.52/s)  avg LR: 5.545e-05  iter ratio: 0.0000  Data: 0.026 (0.063)
INFO:Train: 295 [ 150/625 ( 24%)]  Loss: 0.002761 (0.00309)  Time: 0.703s, 2913.13/s  (0.728s, 2813.61/s)  avg LR: 5.545e-05  iter ratio: 0.0000  Data: 0.028 (0.051)
INFO:Train: 295 [ 200/625 ( 32%)]  Loss: 0.003055 (0.00308)  Time: 0.711s, 2881.92/s  (0.722s, 2836.81/s)  avg LR: 5.545e-05  iter ratio: 0.0000  Data: 0.023 (0.045)
INFO:Train: 295 [ 250/625 ( 40%)]  Loss: 0.003474 (0.00315)  Time: 0.702s, 2919.23/s  (0.718s, 2850.63/s)  avg LR: 5.545e-05  iter ratio: 0.0000  Data: 0.022 (0.041)
INFO:Train: 295 [ 300/625 ( 48%)]  Loss: 0.003808 (0.00324)  Time: 0.720s, 2845.74/s  (0.717s, 2855.93/s)  avg LR: 5.545e-05  iter ratio: 0.0000  Data: 0.044 (0.040)
INFO:Train: 295 [ 350/625 ( 56%)]  Loss: 0.002871 (0.00320)  Time: 0.728s, 2812.61/s  (0.717s, 2856.13/s)  avg LR: 5.545e-05  iter ratio: 0.0000  Data: 0.053 (0.040)
INFO:Train: 295 [ 400/625 ( 64%)]  Loss: 0.002846 (0.00316)  Time: 0.725s, 2824.45/s  (0.717s, 2856.22/s)  avg LR: 5.545e-05  iter ratio: 0.0000  Data: 0.050 (0.040)
INFO:Train: 295 [ 450/625 ( 72%)]  Loss: 0.002578 (0.00310)  Time: 0.701s, 2921.19/s  (0.715s, 2862.39/s)  avg LR: 5.545e-05  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 295 [ 500/625 ( 80%)]  Loss: 0.003151 (0.00310)  Time: 0.705s, 2902.99/s  (0.714s, 2866.69/s)  avg LR: 5.545e-05  iter ratio: 0.0000  Data: 0.030 (0.037)
INFO:Train: 295 [ 550/625 ( 88%)]  Loss: 0.003096 (0.00310)  Time: 0.706s, 2900.04/s  (0.714s, 2869.72/s)  avg LR: 5.545e-05  iter ratio: 0.0000  Data: 0.029 (0.037)
INFO:Train: 295 [ 600/625 ( 96%)]  Loss: 0.003098 (0.00310)  Time: 0.712s, 2874.70/s  (0.713s, 2873.09/s)  avg LR: 5.545e-05  iter ratio: 0.0000  Data: 0.037 (0.036)
INFO:Train: 295 [ 624/625 (100%)]  Loss: 0.002798 (0.00308)  Time: 0.673s, 3041.15/s  (0.712s, 2874.96/s)  avg LR: 5.545e-05  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.418 (4.418)  Loss:  0.5581 (0.5581)  Acc@1: 87.6953 (87.6953)  Acc@5: 98.0957 (98.0957)
INFO:Test: [  24/24]  Time: 0.080 (0.505)  Loss:  0.5322 (0.8258)  Acc@1: 86.6745 (81.6820)  Acc@5: 97.4057 (95.6020)
INFO:295-epoch: remaining time 1.92 h
INFO:Train: 296 [   0/625 (  0%)]  Loss: 0.002773 (0.00277)  Time: 4.465s,  458.73/s  (4.465s,  458.73/s)  avg LR: 5.349e-05  iter ratio: 0.0000  Data: 3.764 (3.764)
INFO:Train: 296 [  50/625 (  8%)]  Loss: 0.003203 (0.00299)  Time: 0.708s, 2892.87/s  (0.785s, 2608.11/s)  avg LR: 5.349e-05  iter ratio: 0.0000  Data: 0.023 (0.100)
INFO:Train: 296 [ 100/625 ( 16%)]  Loss: 0.002946 (0.00297)  Time: 0.706s, 2902.74/s  (0.746s, 2745.94/s)  avg LR: 5.349e-05  iter ratio: 0.0000  Data: 0.022 (0.061)
INFO:Train: 296 [ 150/625 ( 24%)]  Loss: 0.003239 (0.00304)  Time: 0.708s, 2893.22/s  (0.732s, 2796.98/s)  avg LR: 5.349e-05  iter ratio: 0.0000  Data: 0.021 (0.048)
INFO:Train: 296 [ 200/625 ( 32%)]  Loss: 0.002892 (0.00301)  Time: 0.714s, 2868.62/s  (0.727s, 2816.22/s)  avg LR: 5.349e-05  iter ratio: 0.0000  Data: 0.039 (0.045)
INFO:Train: 296 [ 250/625 ( 40%)]  Loss: 0.002813 (0.00298)  Time: 0.716s, 2862.22/s  (0.725s, 2823.91/s)  avg LR: 5.349e-05  iter ratio: 0.0000  Data: 0.040 (0.044)
INFO:Train: 296 [ 300/625 ( 48%)]  Loss: 0.003548 (0.00306)  Time: 0.715s, 2863.82/s  (0.724s, 2828.85/s)  avg LR: 5.349e-05  iter ratio: 0.0000  Data: 0.040 (0.044)
INFO:Train: 296 [ 350/625 ( 56%)]  Loss: 0.003952 (0.00317)  Time: 0.716s, 2859.42/s  (0.723s, 2832.06/s)  avg LR: 5.349e-05  iter ratio: 0.0000  Data: 0.040 (0.044)
INFO:Train: 296 [ 400/625 ( 64%)]  Loss: 0.002778 (0.00313)  Time: 0.716s, 2861.25/s  (0.723s, 2834.52/s)  avg LR: 5.349e-05  iter ratio: 0.0000  Data: 0.041 (0.043)
INFO:Train: 296 [ 450/625 ( 72%)]  Loss: 0.002786 (0.00309)  Time: 0.720s, 2845.88/s  (0.722s, 2836.37/s)  avg LR: 5.349e-05  iter ratio: 0.0000  Data: 0.045 (0.043)
INFO:Train: 296 [ 500/625 ( 80%)]  Loss: 0.003091 (0.00309)  Time: 0.717s, 2855.55/s  (0.722s, 2837.79/s)  avg LR: 5.349e-05  iter ratio: 0.0000  Data: 0.042 (0.043)
INFO:Train: 296 [ 550/625 ( 88%)]  Loss: 0.003142 (0.00310)  Time: 0.706s, 2902.40/s  (0.721s, 2839.28/s)  avg LR: 5.349e-05  iter ratio: 0.0000  Data: 0.029 (0.043)
INFO:Train: 296 [ 600/625 ( 96%)]  Loss: 0.003526 (0.00313)  Time: 0.708s, 2894.03/s  (0.720s, 2845.39/s)  avg LR: 5.349e-05  iter ratio: 0.0000  Data: 0.032 (0.042)
INFO:Train: 296 [ 624/625 (100%)]  Loss: 0.003455 (0.00315)  Time: 0.679s, 3015.14/s  (0.719s, 2848.11/s)  avg LR: 5.349e-05  iter ratio: 0.0000  Data: 0.000 (0.041)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.346 (4.346)  Loss:  0.5430 (0.5430)  Acc@1: 87.4023 (87.4023)  Acc@5: 98.0469 (98.0469)
INFO:Test: [  24/24]  Time: 0.080 (0.511)  Loss:  0.5098 (0.8082)  Acc@1: 87.2642 (81.7740)  Acc@5: 97.6415 (95.6380)
ERROR:Exception '[Errno 2] No such file or directory: './exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-286.pth.tar'' while deleting checkpoint
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-294.pth.tar', 81.78000005371094)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-296.pth.tar', 81.77400002685548)

INFO:296-epoch: remaining time 1.81 h
INFO:Train: 297 [   0/625 (  0%)]  Loss: 0.002807 (0.00281)  Time: 4.381s,  467.50/s  (4.381s,  467.50/s)  avg LR: 5.196e-05  iter ratio: 0.0000  Data: 3.697 (3.697)
INFO:Train: 297 [  50/625 (  8%)]  Loss: 0.003522 (0.00316)  Time: 0.707s, 2898.02/s  (0.778s, 2633.44/s)  avg LR: 5.196e-05  iter ratio: 0.0000  Data: 0.031 (0.100)
INFO:Train: 297 [ 100/625 ( 16%)]  Loss: 0.002839 (0.00306)  Time: 0.701s, 2921.29/s  (0.741s, 2765.04/s)  avg LR: 5.196e-05  iter ratio: 0.0000  Data: 0.025 (0.064)
INFO:Train: 297 [ 150/625 ( 24%)]  Loss: 0.002931 (0.00302)  Time: 0.706s, 2900.81/s  (0.729s, 2811.08/s)  avg LR: 5.196e-05  iter ratio: 0.0000  Data: 0.027 (0.052)
INFO:Train: 297 [ 200/625 ( 32%)]  Loss: 0.002858 (0.00299)  Time: 0.716s, 2862.19/s  (0.722s, 2835.04/s)  avg LR: 5.196e-05  iter ratio: 0.0000  Data: 0.036 (0.045)
INFO:Train: 297 [ 250/625 ( 40%)]  Loss: 0.002949 (0.00298)  Time: 0.714s, 2868.05/s  (0.721s, 2839.38/s)  avg LR: 5.196e-05  iter ratio: 0.0000  Data: 0.035 (0.044)
INFO:Train: 297 [ 300/625 ( 48%)]  Loss: 0.003053 (0.00299)  Time: 0.718s, 2851.07/s  (0.720s, 2842.51/s)  avg LR: 5.196e-05  iter ratio: 0.0000  Data: 0.044 (0.043)
INFO:Train: 297 [ 350/625 ( 56%)]  Loss: 0.003201 (0.00302)  Time: 0.713s, 2873.45/s  (0.720s, 2844.86/s)  avg LR: 5.196e-05  iter ratio: 0.0000  Data: 0.036 (0.042)
INFO:Train: 297 [ 400/625 ( 64%)]  Loss: 0.002774 (0.00299)  Time: 0.709s, 2888.01/s  (0.719s, 2846.97/s)  avg LR: 5.196e-05  iter ratio: 0.0000  Data: 0.032 (0.042)
INFO:Train: 297 [ 450/625 ( 72%)]  Loss: 0.002404 (0.00293)  Time: 0.703s, 2913.06/s  (0.717s, 2854.54/s)  avg LR: 5.196e-05  iter ratio: 0.0000  Data: 0.029 (0.040)
INFO:Train: 297 [ 500/625 ( 80%)]  Loss: 0.002653 (0.00291)  Time: 0.711s, 2881.08/s  (0.716s, 2860.12/s)  avg LR: 5.196e-05  iter ratio: 0.0000  Data: 0.035 (0.039)
INFO:Train: 297 [ 550/625 ( 88%)]  Loss: 0.002282 (0.00286)  Time: 0.699s, 2928.96/s  (0.715s, 2864.60/s)  avg LR: 5.196e-05  iter ratio: 0.0000  Data: 0.025 (0.038)
INFO:Train: 297 [ 600/625 ( 96%)]  Loss: 0.002603 (0.00284)  Time: 0.703s, 2913.89/s  (0.714s, 2869.18/s)  avg LR: 5.196e-05  iter ratio: 0.0000  Data: 0.027 (0.037)
INFO:Train: 297 [ 624/625 (100%)]  Loss: 0.002982 (0.00285)  Time: 0.675s, 3035.06/s  (0.713s, 2870.73/s)  avg LR: 5.196e-05  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.397 (4.397)  Loss:  0.5381 (0.5381)  Acc@1: 87.2070 (87.2070)  Acc@5: 97.9980 (97.9980)
INFO:Test: [  24/24]  Time: 0.081 (0.502)  Loss:  0.5068 (0.8033)  Acc@1: 86.9104 (81.7840)  Acc@5: 97.4057 (95.6540)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-297.pth.tar', 81.7840000024414)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-294.pth.tar', 81.78000005371094)

INFO:297-epoch: remaining time 1.66 h
INFO:Train: 298 [   0/625 (  0%)]  Loss: 0.003197 (0.00320)  Time: 4.321s,  473.92/s  (4.321s,  473.92/s)  avg LR: 5.087e-05  iter ratio: 0.0000  Data: 3.631 (3.631)
INFO:Train: 298 [  50/625 (  8%)]  Loss: 0.002928 (0.00306)  Time: 0.698s, 2933.18/s  (0.773s, 2648.28/s)  avg LR: 5.087e-05  iter ratio: 0.0000  Data: 0.023 (0.097)
INFO:Train: 298 [ 100/625 ( 16%)]  Loss: 0.003508 (0.00321)  Time: 0.698s, 2935.61/s  (0.738s, 2774.75/s)  avg LR: 5.087e-05  iter ratio: 0.0000  Data: 0.023 (0.062)
INFO:Train: 298 [ 150/625 ( 24%)]  Loss: 0.003832 (0.00337)  Time: 0.702s, 2915.88/s  (0.726s, 2819.06/s)  avg LR: 5.087e-05  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 298 [ 200/625 ( 32%)]  Loss: 0.003253 (0.00334)  Time: 0.701s, 2919.50/s  (0.720s, 2842.57/s)  avg LR: 5.087e-05  iter ratio: 0.0000  Data: 0.027 (0.045)
INFO:Train: 298 [ 250/625 ( 40%)]  Loss: 0.003820 (0.00342)  Time: 0.704s, 2910.55/s  (0.717s, 2855.84/s)  avg LR: 5.087e-05  iter ratio: 0.0000  Data: 0.030 (0.042)
INFO:Train: 298 [ 300/625 ( 48%)]  Loss: 0.002767 (0.00333)  Time: 0.704s, 2909.11/s  (0.715s, 2865.41/s)  avg LR: 5.087e-05  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 298 [ 350/625 ( 56%)]  Loss: 0.002281 (0.00320)  Time: 0.703s, 2913.41/s  (0.713s, 2872.00/s)  avg LR: 5.087e-05  iter ratio: 0.0000  Data: 0.023 (0.038)
INFO:Train: 298 [ 400/625 ( 64%)]  Loss: 0.002813 (0.00316)  Time: 0.701s, 2919.55/s  (0.712s, 2877.26/s)  avg LR: 5.087e-05  iter ratio: 0.0000  Data: 0.026 (0.036)
INFO:Train: 298 [ 450/625 ( 72%)]  Loss: 0.002963 (0.00314)  Time: 0.698s, 2934.46/s  (0.711s, 2881.33/s)  avg LR: 5.087e-05  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 298 [ 500/625 ( 80%)]  Loss: 0.003354 (0.00316)  Time: 0.693s, 2957.32/s  (0.710s, 2884.46/s)  avg LR: 5.087e-05  iter ratio: 0.0000  Data: 0.018 (0.034)
INFO:Train: 298 [ 550/625 ( 88%)]  Loss: 0.003618 (0.00319)  Time: 0.700s, 2923.96/s  (0.709s, 2887.31/s)  avg LR: 5.087e-05  iter ratio: 0.0000  Data: 0.023 (0.034)
INFO:Train: 298 [ 600/625 ( 96%)]  Loss: 0.002750 (0.00316)  Time: 0.698s, 2932.41/s  (0.709s, 2889.92/s)  avg LR: 5.087e-05  iter ratio: 0.0000  Data: 0.025 (0.033)
INFO:Train: 298 [ 624/625 (100%)]  Loss: 0.002459 (0.00311)  Time: 0.672s, 3046.36/s  (0.708s, 2891.31/s)  avg LR: 5.087e-05  iter ratio: 0.0000  Data: 0.000 (0.033)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.314 (4.314)  Loss:  0.5410 (0.5410)  Acc@1: 87.5488 (87.5488)  Acc@5: 97.9492 (97.9492)
INFO:Test: [  24/24]  Time: 0.080 (0.509)  Loss:  0.4993 (0.8036)  Acc@1: 87.3821 (81.8820)  Acc@5: 97.6415 (95.6340)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-298.pth.tar', 81.882000078125)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-297.pth.tar', 81.7840000024414)

INFO:298-epoch: remaining time 1.52 h
INFO:Train: 299 [   0/625 (  0%)]  Loss: 0.002743 (0.00274)  Time: 4.374s,  468.20/s  (4.374s,  468.20/s)  avg LR: 5.022e-05  iter ratio: 0.0000  Data: 3.671 (3.671)
INFO:Train: 299 [  50/625 (  8%)]  Loss: 0.002572 (0.00266)  Time: 0.706s, 2900.21/s  (0.783s, 2614.75/s)  avg LR: 5.022e-05  iter ratio: 0.0000  Data: 0.029 (0.103)
INFO:Train: 299 [ 100/625 ( 16%)]  Loss: 0.003597 (0.00297)  Time: 0.712s, 2876.06/s  (0.743s, 2754.56/s)  avg LR: 5.022e-05  iter ratio: 0.0000  Data: 0.038 (0.065)
INFO:Train: 299 [ 150/625 ( 24%)]  Loss: 0.002828 (0.00294)  Time: 0.718s, 2850.95/s  (0.734s, 2788.69/s)  avg LR: 5.022e-05  iter ratio: 0.0000  Data: 0.044 (0.057)
INFO:Train: 299 [ 200/625 ( 32%)]  Loss: 0.003240 (0.00300)  Time: 0.701s, 2920.96/s  (0.727s, 2815.32/s)  avg LR: 5.022e-05  iter ratio: 0.0000  Data: 0.027 (0.050)
INFO:Train: 299 [ 250/625 ( 40%)]  Loss: 0.003218 (0.00303)  Time: 0.706s, 2900.50/s  (0.723s, 2833.78/s)  avg LR: 5.022e-05  iter ratio: 0.0000  Data: 0.028 (0.045)
INFO:Train: 299 [ 300/625 ( 48%)]  Loss: 0.003128 (0.00305)  Time: 0.707s, 2897.49/s  (0.719s, 2847.37/s)  avg LR: 5.022e-05  iter ratio: 0.0000  Data: 0.021 (0.042)
INFO:Train: 299 [ 350/625 ( 56%)]  Loss: 0.002612 (0.00299)  Time: 0.720s, 2843.43/s  (0.718s, 2854.20/s)  avg LR: 5.022e-05  iter ratio: 0.0000  Data: 0.046 (0.040)
INFO:Train: 299 [ 400/625 ( 64%)]  Loss: 0.003422 (0.00304)  Time: 0.721s, 2838.98/s  (0.718s, 2853.97/s)  avg LR: 5.022e-05  iter ratio: 0.0000  Data: 0.047 (0.040)
INFO:Train: 299 [ 450/625 ( 72%)]  Loss: 0.003074 (0.00304)  Time: 0.722s, 2836.60/s  (0.718s, 2853.91/s)  avg LR: 5.022e-05  iter ratio: 0.0000  Data: 0.047 (0.041)
INFO:Train: 299 [ 500/625 ( 80%)]  Loss: 0.002747 (0.00302)  Time: 0.721s, 2842.03/s  (0.718s, 2854.00/s)  avg LR: 5.022e-05  iter ratio: 0.0000  Data: 0.046 (0.041)
INFO:Train: 299 [ 550/625 ( 88%)]  Loss: 0.003306 (0.00304)  Time: 0.718s, 2853.27/s  (0.718s, 2853.86/s)  avg LR: 5.022e-05  iter ratio: 0.0000  Data: 0.044 (0.041)
INFO:Train: 299 [ 600/625 ( 96%)]  Loss: 0.003321 (0.00306)  Time: 0.704s, 2908.89/s  (0.717s, 2855.83/s)  avg LR: 5.022e-05  iter ratio: 0.0000  Data: 0.029 (0.041)
INFO:Train: 299 [ 624/625 (100%)]  Loss: 0.003230 (0.00307)  Time: 0.673s, 3043.24/s  (0.716s, 2858.39/s)  avg LR: 5.022e-05  iter ratio: 0.0000  Data: 0.000 (0.040)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.466 (4.466)  Loss:  0.5400 (0.5400)  Acc@1: 87.3535 (87.3535)  Acc@5: 98.1445 (98.1445)
INFO:Test: [  24/24]  Time: 0.080 (0.529)  Loss:  0.5049 (0.8078)  Acc@1: 86.7924 (81.7340)  Acc@5: 97.4057 (95.6440)
INFO:299-epoch: remaining time 1.41 h
INFO:Train: 300 [   0/625 (  0%)]  Loss: 0.002341 (0.00234)  Time: 4.238s,  483.22/s  (4.238s,  483.22/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 3.541 (3.541)
INFO:Train: 300 [  50/625 (  8%)]  Loss: 0.003739 (0.00304)  Time: 0.715s, 2863.66/s  (0.777s, 2636.26/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.035 (0.099)
INFO:Train: 300 [ 100/625 ( 16%)]  Loss: 0.002813 (0.00296)  Time: 0.717s, 2857.13/s  (0.746s, 2746.01/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.039 (0.068)
INFO:Train: 300 [ 150/625 ( 24%)]  Loss: 0.003229 (0.00303)  Time: 0.718s, 2854.09/s  (0.735s, 2785.13/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.042 (0.058)
INFO:Train: 300 [ 200/625 ( 32%)]  Loss: 0.003078 (0.00304)  Time: 0.717s, 2858.13/s  (0.731s, 2803.36/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.040 (0.054)
INFO:Train: 300 [ 250/625 ( 40%)]  Loss: 0.003120 (0.00305)  Time: 0.718s, 2853.65/s  (0.728s, 2814.00/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.039 (0.051)
INFO:Train: 300 [ 300/625 ( 48%)]  Loss: 0.003008 (0.00305)  Time: 0.710s, 2882.78/s  (0.726s, 2821.98/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.035 (0.049)
INFO:Train: 300 [ 350/625 ( 56%)]  Loss: 0.003743 (0.00313)  Time: 0.710s, 2885.93/s  (0.724s, 2827.16/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.035 (0.048)
INFO:Train: 300 [ 400/625 ( 64%)]  Loss: 0.003726 (0.00320)  Time: 0.711s, 2881.91/s  (0.723s, 2831.61/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.036 (0.047)
INFO:Train: 300 [ 450/625 ( 72%)]  Loss: 0.002622 (0.00314)  Time: 0.715s, 2866.23/s  (0.722s, 2834.63/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.040 (0.046)
INFO:Train: 300 [ 500/625 ( 80%)]  Loss: 0.003220 (0.00315)  Time: 0.705s, 2904.82/s  (0.722s, 2837.34/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.029 (0.046)
INFO:Train: 300 [ 550/625 ( 88%)]  Loss: 0.003107 (0.00315)  Time: 0.708s, 2890.66/s  (0.721s, 2840.23/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.034 (0.045)
INFO:Train: 300 [ 600/625 ( 96%)]  Loss: 0.003755 (0.00319)  Time: 0.700s, 2925.61/s  (0.720s, 2843.87/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.026 (0.044)
INFO:Train: 300 [ 624/625 (100%)]  Loss: 0.002477 (0.00314)  Time: 0.672s, 3049.68/s  (0.719s, 2846.96/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.000 (0.043)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.391 (4.391)  Loss:  0.5405 (0.5405)  Acc@1: 87.3535 (87.3535)  Acc@5: 98.0469 (98.0469)
INFO:Test: [  24/24]  Time: 0.080 (0.509)  Loss:  0.4961 (0.8027)  Acc@1: 87.1462 (81.8220)  Acc@5: 97.5236 (95.6300)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-298.pth.tar', 81.882000078125)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-300.pth.tar', 81.82200010498048)

INFO:300-epoch: remaining time 1.29 h
INFO:Train: 301 [   0/625 (  0%)]  Loss: 0.003224 (0.00322)  Time: 4.271s,  479.46/s  (4.271s,  479.46/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 3.577 (3.577)
INFO:Train: 301 [  50/625 (  8%)]  Loss: 0.003644 (0.00343)  Time: 0.705s, 2906.86/s  (0.775s, 2642.61/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.028 (0.097)
INFO:Train: 301 [ 100/625 ( 16%)]  Loss: 0.003552 (0.00347)  Time: 0.704s, 2909.78/s  (0.739s, 2769.52/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.024 (0.062)
INFO:Train: 301 [ 150/625 ( 24%)]  Loss: 0.003757 (0.00354)  Time: 0.730s, 2806.11/s  (0.731s, 2801.01/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.053 (0.054)
INFO:Train: 301 [ 200/625 ( 32%)]  Loss: 0.004547 (0.00374)  Time: 0.721s, 2838.99/s  (0.728s, 2814.96/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.047 (0.051)
INFO:Train: 301 [ 250/625 ( 40%)]  Loss: 0.002688 (0.00357)  Time: 0.723s, 2833.08/s  (0.725s, 2823.63/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.046 (0.049)
INFO:Train: 301 [ 300/625 ( 48%)]  Loss: 0.003080 (0.00350)  Time: 0.723s, 2830.71/s  (0.724s, 2829.68/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.048 (0.048)
INFO:Train: 301 [ 350/625 ( 56%)]  Loss: 0.002988 (0.00344)  Time: 0.721s, 2839.62/s  (0.723s, 2833.76/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.046 (0.047)
INFO:Train: 301 [ 400/625 ( 64%)]  Loss: 0.002983 (0.00338)  Time: 0.717s, 2856.51/s  (0.722s, 2837.28/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.040 (0.046)
INFO:Train: 301 [ 450/625 ( 72%)]  Loss: 0.002621 (0.00331)  Time: 0.715s, 2862.47/s  (0.721s, 2839.66/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.040 (0.046)
INFO:Train: 301 [ 500/625 ( 80%)]  Loss: 0.002758 (0.00326)  Time: 0.720s, 2845.94/s  (0.721s, 2841.47/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.039 (0.045)
INFO:Train: 301 [ 550/625 ( 88%)]  Loss: 0.003086 (0.00324)  Time: 0.703s, 2912.27/s  (0.720s, 2844.28/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.024 (0.045)
INFO:Train: 301 [ 600/625 ( 96%)]  Loss: 0.002532 (0.00319)  Time: 0.707s, 2896.77/s  (0.719s, 2848.89/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.033 (0.043)
INFO:Train: 301 [ 624/625 (100%)]  Loss: 0.003045 (0.00318)  Time: 0.674s, 3038.26/s  (0.718s, 2851.63/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.000 (0.043)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.384 (4.384)  Loss:  0.5503 (0.5503)  Acc@1: 87.4512 (87.4512)  Acc@5: 98.1934 (98.1934)
INFO:Test: [  24/24]  Time: 0.080 (0.503)  Loss:  0.5210 (0.8201)  Acc@1: 86.7925 (81.7900)  Acc@5: 97.2877 (95.5980)
INFO:301-epoch: remaining time 1.16 h
INFO:Train: 302 [   0/625 (  0%)]  Loss: 0.003420 (0.00342)  Time: 4.159s,  492.42/s  (4.159s,  492.42/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 3.470 (3.470)
INFO:Train: 302 [  50/625 (  8%)]  Loss: 0.003547 (0.00348)  Time: 0.711s, 2878.94/s  (0.781s, 2623.57/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.038 (0.102)
INFO:Train: 302 [ 100/625 ( 16%)]  Loss: 0.004028 (0.00367)  Time: 0.714s, 2869.62/s  (0.749s, 2733.25/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.039 (0.072)
INFO:Train: 302 [ 150/625 ( 24%)]  Loss: 0.003546 (0.00364)  Time: 0.714s, 2868.99/s  (0.739s, 2772.82/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.039 (0.062)
INFO:Train: 302 [ 200/625 ( 32%)]  Loss: 0.003182 (0.00354)  Time: 0.711s, 2880.13/s  (0.733s, 2792.88/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.037 (0.057)
INFO:Train: 302 [ 250/625 ( 40%)]  Loss: 0.003687 (0.00357)  Time: 0.713s, 2873.44/s  (0.730s, 2804.89/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.039 (0.054)
INFO:Train: 302 [ 300/625 ( 48%)]  Loss: 0.003631 (0.00358)  Time: 0.698s, 2934.63/s  (0.726s, 2822.29/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.024 (0.050)
INFO:Train: 302 [ 350/625 ( 56%)]  Loss: 0.002704 (0.00347)  Time: 0.701s, 2921.02/s  (0.723s, 2834.58/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.025 (0.047)
INFO:Train: 302 [ 400/625 ( 64%)]  Loss: 0.003125 (0.00343)  Time: 0.712s, 2878.06/s  (0.720s, 2843.33/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.033 (0.044)
INFO:Train: 302 [ 450/625 ( 72%)]  Loss: 0.003330 (0.00342)  Time: 0.701s, 2920.04/s  (0.718s, 2850.92/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.026 (0.042)
INFO:Train: 302 [ 500/625 ( 80%)]  Loss: 0.002462 (0.00333)  Time: 0.698s, 2933.59/s  (0.717s, 2857.03/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.024 (0.041)
INFO:Train: 302 [ 550/625 ( 88%)]  Loss: 0.002742 (0.00328)  Time: 0.696s, 2941.09/s  (0.716s, 2861.21/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.023 (0.040)
INFO:Train: 302 [ 600/625 ( 96%)]  Loss: 0.003419 (0.00329)  Time: 0.720s, 2844.28/s  (0.715s, 2865.83/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.040 (0.039)
INFO:Train: 302 [ 624/625 (100%)]  Loss: 0.002953 (0.00327)  Time: 0.676s, 3030.69/s  (0.714s, 2868.03/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.366 (4.366)  Loss:  0.5547 (0.5547)  Acc@1: 87.7441 (87.7441)  Acc@5: 98.0957 (98.0957)
INFO:Test: [  24/24]  Time: 0.080 (0.507)  Loss:  0.5088 (0.8155)  Acc@1: 87.3821 (81.8320)  Acc@5: 97.4057 (95.6620)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-298.pth.tar', 81.882000078125)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-302.pth.tar', 81.832000078125)

INFO:302-epoch: remaining time 1.02 h
INFO:Train: 303 [   0/625 (  0%)]  Loss: 0.002339 (0.00234)  Time: 4.288s,  477.60/s  (4.288s,  477.60/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 3.580 (3.580)
INFO:Train: 303 [  50/625 (  8%)]  Loss: 0.002590 (0.00246)  Time: 0.703s, 2912.87/s  (0.775s, 2644.16/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.026 (0.093)
INFO:Train: 303 [ 100/625 ( 16%)]  Loss: 0.003352 (0.00276)  Time: 0.703s, 2912.01/s  (0.740s, 2768.39/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.023 (0.059)
INFO:Train: 303 [ 150/625 ( 24%)]  Loss: 0.002672 (0.00274)  Time: 0.704s, 2910.77/s  (0.728s, 2812.89/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.024 (0.047)
INFO:Train: 303 [ 200/625 ( 32%)]  Loss: 0.003025 (0.00280)  Time: 0.705s, 2906.83/s  (0.722s, 2835.50/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.028 (0.042)
INFO:Train: 303 [ 250/625 ( 40%)]  Loss: 0.002603 (0.00276)  Time: 0.709s, 2889.41/s  (0.719s, 2849.65/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.031 (0.038)
INFO:Train: 303 [ 300/625 ( 48%)]  Loss: 0.002693 (0.00275)  Time: 0.698s, 2932.77/s  (0.716s, 2859.14/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.019 (0.036)
INFO:Train: 303 [ 350/625 ( 56%)]  Loss: 0.002461 (0.00272)  Time: 0.717s, 2857.61/s  (0.716s, 2861.17/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.043 (0.036)
INFO:Train: 303 [ 400/625 ( 64%)]  Loss: 0.003221 (0.00277)  Time: 0.712s, 2877.54/s  (0.716s, 2861.26/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.036 (0.037)
INFO:Train: 303 [ 450/625 ( 72%)]  Loss: 0.002808 (0.00278)  Time: 0.705s, 2905.38/s  (0.715s, 2863.94/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 303 [ 500/625 ( 80%)]  Loss: 0.002700 (0.00277)  Time: 0.705s, 2903.65/s  (0.714s, 2868.80/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.029 (0.036)
INFO:Train: 303 [ 550/625 ( 88%)]  Loss: 0.003490 (0.00283)  Time: 0.704s, 2910.09/s  (0.713s, 2872.50/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.029 (0.035)
INFO:Train: 303 [ 600/625 ( 96%)]  Loss: 0.003312 (0.00287)  Time: 0.703s, 2914.11/s  (0.712s, 2875.76/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.028 (0.034)
INFO:Train: 303 [ 624/625 (100%)]  Loss: 0.003193 (0.00289)  Time: 0.677s, 3023.81/s  (0.712s, 2876.94/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.400 (4.400)  Loss:  0.5513 (0.5513)  Acc@1: 87.4023 (87.4023)  Acc@5: 98.2422 (98.2422)
INFO:Test: [  24/24]  Time: 0.080 (0.504)  Loss:  0.5098 (0.8166)  Acc@1: 86.6745 (81.7620)  Acc@5: 97.4057 (95.6280)
INFO:303-epoch: remaining time 0.90 h
INFO:Train: 304 [   0/625 (  0%)]  Loss: 0.002937 (0.00294)  Time: 4.355s,  470.26/s  (4.355s,  470.26/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 3.665 (3.665)
INFO:Train: 304 [  50/625 (  8%)]  Loss: 0.003193 (0.00306)  Time: 0.711s, 2880.23/s  (0.778s, 2633.69/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.036 (0.101)
INFO:Train: 304 [ 100/625 ( 16%)]  Loss: 0.002740 (0.00296)  Time: 0.714s, 2868.81/s  (0.748s, 2739.23/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.040 (0.072)
INFO:Train: 304 [ 150/625 ( 24%)]  Loss: 0.002809 (0.00292)  Time: 0.702s, 2916.75/s  (0.733s, 2793.17/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.024 (0.057)
INFO:Train: 304 [ 200/625 ( 32%)]  Loss: 0.003384 (0.00301)  Time: 0.699s, 2928.63/s  (0.726s, 2820.22/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.023 (0.050)
INFO:Train: 304 [ 250/625 ( 40%)]  Loss: 0.003156 (0.00304)  Time: 0.700s, 2923.78/s  (0.722s, 2838.29/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.023 (0.045)
INFO:Train: 304 [ 300/625 ( 48%)]  Loss: 0.002811 (0.00300)  Time: 0.701s, 2921.24/s  (0.719s, 2849.59/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.025 (0.042)
INFO:Train: 304 [ 350/625 ( 56%)]  Loss: 0.003514 (0.00307)  Time: 0.699s, 2927.87/s  (0.716s, 2858.44/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.023 (0.040)
INFO:Train: 304 [ 400/625 ( 64%)]  Loss: 0.003512 (0.00312)  Time: 0.705s, 2903.69/s  (0.715s, 2864.87/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.029 (0.038)
INFO:Train: 304 [ 450/625 ( 72%)]  Loss: 0.003670 (0.00317)  Time: 0.708s, 2893.24/s  (0.714s, 2869.95/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.031 (0.037)
INFO:Train: 304 [ 500/625 ( 80%)]  Loss: 0.003028 (0.00316)  Time: 0.706s, 2902.59/s  (0.713s, 2874.02/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.030 (0.036)
INFO:Train: 304 [ 550/625 ( 88%)]  Loss: 0.002788 (0.00313)  Time: 0.701s, 2921.17/s  (0.712s, 2877.38/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.021 (0.035)
INFO:Train: 304 [ 600/625 ( 96%)]  Loss: 0.002931 (0.00311)  Time: 0.711s, 2881.79/s  (0.711s, 2880.20/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.034 (0.035)
INFO:Train: 304 [ 624/625 (100%)]  Loss: 0.002983 (0.00310)  Time: 0.674s, 3036.95/s  (0.711s, 2881.68/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.394 (4.394)  Loss:  0.5430 (0.5430)  Acc@1: 87.5000 (87.5000)  Acc@5: 98.2910 (98.2910)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.4924 (0.8037)  Acc@1: 87.6179 (81.8480)  Acc@5: 97.6415 (95.6560)
INFO:Current checkpoints:
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-298.pth.tar', 81.882000078125)
 ('./exp_lamb_resnet101_6/resnet101-lamb4-win2-1--cos-0.50-300-2048-lr-8.00e-03-1.00e-10-30-5.00e-05-1.00e-02-beta-0.900_0.999_2.000_8.000_-0.9-ep-0.00e+00-1.00e+00-aug-0.0-0.10-3-0.10-rand-m7-mstd0.5-inc1-de-0-0.00-sm-0.10-0-bce-1-amp-1-dp-0.0/checkpoint-304.pth.tar', 81.84800005126954)

INFO:304-epoch: remaining time 0.76 h
INFO:Train: 305 [   0/625 (  0%)]  Loss: 0.003143 (0.00314)  Time: 4.309s,  475.33/s  (4.309s,  475.33/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 3.623 (3.623)
INFO:Train: 305 [  50/625 (  8%)]  Loss: 0.003133 (0.00314)  Time: 0.717s, 2856.47/s  (0.789s, 2594.30/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.042 (0.112)
INFO:Train: 305 [ 100/625 ( 16%)]  Loss: 0.003141 (0.00314)  Time: 0.713s, 2871.34/s  (0.754s, 2717.80/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.039 (0.077)
INFO:Train: 305 [ 150/625 ( 24%)]  Loss: 0.003052 (0.00312)  Time: 0.716s, 2858.88/s  (0.741s, 2763.02/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.041 (0.065)
INFO:Train: 305 [ 200/625 ( 32%)]  Loss: 0.002733 (0.00304)  Time: 0.720s, 2843.53/s  (0.735s, 2785.88/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.045 (0.059)
INFO:Train: 305 [ 250/625 ( 40%)]  Loss: 0.003516 (0.00312)  Time: 0.713s, 2873.95/s  (0.731s, 2800.54/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.037 (0.055)
INFO:Train: 305 [ 300/625 ( 48%)]  Loss: 0.002981 (0.00310)  Time: 0.718s, 2854.25/s  (0.729s, 2809.38/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.042 (0.053)
INFO:Train: 305 [ 350/625 ( 56%)]  Loss: 0.003093 (0.00310)  Time: 0.721s, 2842.31/s  (0.727s, 2815.83/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.046 (0.051)
INFO:Train: 305 [ 400/625 ( 64%)]  Loss: 0.003447 (0.00314)  Time: 0.719s, 2850.08/s  (0.726s, 2820.55/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.043 (0.050)
INFO:Train: 305 [ 450/625 ( 72%)]  Loss: 0.002615 (0.00309)  Time: 0.719s, 2850.02/s  (0.725s, 2824.30/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.043 (0.049)
INFO:Train: 305 [ 500/625 ( 80%)]  Loss: 0.003679 (0.00314)  Time: 0.716s, 2861.05/s  (0.724s, 2827.48/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.040 (0.048)
INFO:Train: 305 [ 550/625 ( 88%)]  Loss: 0.003257 (0.00315)  Time: 0.715s, 2865.75/s  (0.724s, 2830.01/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.039 (0.048)
INFO:Train: 305 [ 600/625 ( 96%)]  Loss: 0.003030 (0.00314)  Time: 0.726s, 2820.94/s  (0.723s, 2834.09/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.037 (0.047)
INFO:Train: 305 [ 624/625 (100%)]  Loss: 0.002976 (0.00313)  Time: 0.676s, 3028.03/s  (0.722s, 2837.33/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.000 (0.046)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.391 (4.391)  Loss:  0.5576 (0.5576)  Acc@1: 87.6465 (87.6465)  Acc@5: 98.0469 (98.0469)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.5171 (0.8188)  Acc@1: 87.1462 (81.7700)  Acc@5: 97.4057 (95.6340)
INFO:305-epoch: remaining time 0.65 h
INFO:Train: 306 [   0/625 (  0%)]  Loss: 0.002367 (0.00237)  Time: 4.346s,  471.24/s  (4.346s,  471.24/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 3.637 (3.637)
INFO:Train: 306 [  50/625 (  8%)]  Loss: 0.003862 (0.00311)  Time: 0.701s, 2920.76/s  (0.775s, 2641.48/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.026 (0.100)
INFO:Train: 306 [ 100/625 ( 16%)]  Loss: 0.003460 (0.00323)  Time: 0.705s, 2906.88/s  (0.740s, 2769.29/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.030 (0.065)
INFO:Train: 306 [ 150/625 ( 24%)]  Loss: 0.003032 (0.00318)  Time: 0.701s, 2922.43/s  (0.727s, 2816.32/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.025 (0.052)
INFO:Train: 306 [ 200/625 ( 32%)]  Loss: 0.003086 (0.00316)  Time: 0.702s, 2915.86/s  (0.721s, 2838.60/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.026 (0.046)
INFO:Train: 306 [ 250/625 ( 40%)]  Loss: 0.003384 (0.00320)  Time: 0.703s, 2913.00/s  (0.718s, 2853.25/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.027 (0.042)
INFO:Train: 306 [ 300/625 ( 48%)]  Loss: 0.002382 (0.00308)  Time: 0.706s, 2900.13/s  (0.715s, 2862.84/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 306 [ 350/625 ( 56%)]  Loss: 0.002632 (0.00303)  Time: 0.716s, 2858.80/s  (0.714s, 2866.64/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.041 (0.038)
INFO:Train: 306 [ 400/625 ( 64%)]  Loss: 0.002697 (0.00299)  Time: 0.716s, 2859.27/s  (0.715s, 2865.18/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.035 (0.039)
INFO:Train: 306 [ 450/625 ( 72%)]  Loss: 0.003236 (0.00301)  Time: 0.718s, 2853.62/s  (0.715s, 2864.35/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.040 (0.039)
INFO:Train: 306 [ 500/625 ( 80%)]  Loss: 0.003102 (0.00302)  Time: 0.714s, 2866.62/s  (0.715s, 2863.86/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.039 (0.039)
INFO:Train: 306 [ 550/625 ( 88%)]  Loss: 0.003500 (0.00306)  Time: 0.704s, 2908.85/s  (0.715s, 2863.35/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.029 (0.039)
INFO:Train: 306 [ 600/625 ( 96%)]  Loss: 0.003164 (0.00307)  Time: 0.709s, 2890.22/s  (0.715s, 2864.94/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.031 (0.039)
INFO:Train: 306 [ 624/625 (100%)]  Loss: 0.002933 (0.00306)  Time: 0.674s, 3039.52/s  (0.714s, 2867.33/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.403 (4.403)  Loss:  0.5513 (0.5513)  Acc@1: 87.4512 (87.4512)  Acc@5: 98.1445 (98.1445)
INFO:Test: [  24/24]  Time: 0.080 (0.506)  Loss:  0.5107 (0.8177)  Acc@1: 87.3821 (81.7420)  Acc@5: 97.5236 (95.6640)
INFO:306-epoch: remaining time 0.51 h
INFO:Train: 307 [   0/625 (  0%)]  Loss: 0.002882 (0.00288)  Time: 4.368s,  468.87/s  (4.368s,  468.87/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 3.678 (3.678)
INFO:Train: 307 [  50/625 (  8%)]  Loss: 0.002378 (0.00263)  Time: 0.706s, 2900.97/s  (0.777s, 2636.92/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.025 (0.101)
INFO:Train: 307 [ 100/625 ( 16%)]  Loss: 0.003089 (0.00278)  Time: 0.698s, 2936.01/s  (0.740s, 2766.84/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.021 (0.064)
INFO:Train: 307 [ 150/625 ( 24%)]  Loss: 0.003458 (0.00295)  Time: 0.706s, 2898.97/s  (0.729s, 2809.57/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.024 (0.053)
INFO:Train: 307 [ 200/625 ( 32%)]  Loss: 0.003697 (0.00310)  Time: 0.707s, 2896.39/s  (0.722s, 2835.46/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.027 (0.047)
INFO:Train: 307 [ 250/625 ( 40%)]  Loss: 0.003082 (0.00310)  Time: 0.706s, 2898.95/s  (0.718s, 2850.88/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.031 (0.043)
INFO:Train: 307 [ 300/625 ( 48%)]  Loss: 0.003476 (0.00315)  Time: 0.708s, 2891.15/s  (0.716s, 2859.73/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.033 (0.041)
INFO:Train: 307 [ 350/625 ( 56%)]  Loss: 0.003478 (0.00319)  Time: 0.701s, 2921.99/s  (0.714s, 2867.16/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.025 (0.039)
INFO:Train: 307 [ 400/625 ( 64%)]  Loss: 0.002650 (0.00313)  Time: 0.705s, 2903.35/s  (0.713s, 2873.09/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.029 (0.037)
INFO:Train: 307 [ 450/625 ( 72%)]  Loss: 0.003681 (0.00319)  Time: 0.702s, 2916.47/s  (0.712s, 2876.77/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.027 (0.036)
INFO:Train: 307 [ 500/625 ( 80%)]  Loss: 0.002581 (0.00313)  Time: 0.699s, 2929.25/s  (0.711s, 2880.16/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.021 (0.036)
INFO:Train: 307 [ 550/625 ( 88%)]  Loss: 0.003910 (0.00320)  Time: 0.699s, 2930.29/s  (0.710s, 2882.74/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.024 (0.035)
INFO:Train: 307 [ 600/625 ( 96%)]  Loss: 0.003404 (0.00321)  Time: 0.697s, 2938.25/s  (0.710s, 2885.40/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.023 (0.034)
INFO:Train: 307 [ 624/625 (100%)]  Loss: 0.003381 (0.00322)  Time: 0.674s, 3037.76/s  (0.709s, 2886.84/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.000 (0.034)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.411 (4.411)  Loss:  0.5547 (0.5547)  Acc@1: 87.3535 (87.3535)  Acc@5: 98.1934 (98.1934)
INFO:Test: [  24/24]  Time: 0.080 (0.508)  Loss:  0.5249 (0.8181)  Acc@1: 86.5566 (81.8440)  Acc@5: 97.6415 (95.6220)
INFO:307-epoch: remaining time 0.38 h
INFO:Train: 308 [   0/625 (  0%)]  Loss: 0.003654 (0.00365)  Time: 4.033s,  507.82/s  (4.033s,  507.82/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 3.331 (3.331)
INFO:Train: 308 [  50/625 (  8%)]  Loss: 0.003097 (0.00338)  Time: 0.705s, 2905.86/s  (0.778s, 2633.83/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.027 (0.097)
INFO:Train: 308 [ 100/625 ( 16%)]  Loss: 0.002748 (0.00317)  Time: 0.703s, 2913.58/s  (0.742s, 2761.66/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.028 (0.063)
INFO:Train: 308 [ 150/625 ( 24%)]  Loss: 0.003454 (0.00324)  Time: 0.703s, 2913.43/s  (0.729s, 2810.61/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.027 (0.051)
INFO:Train: 308 [ 200/625 ( 32%)]  Loss: 0.002700 (0.00313)  Time: 0.718s, 2852.89/s  (0.725s, 2823.15/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.042 (0.048)
INFO:Train: 308 [ 250/625 ( 40%)]  Loss: 0.003400 (0.00318)  Time: 0.714s, 2869.38/s  (0.724s, 2829.79/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.040 (0.047)
INFO:Train: 308 [ 300/625 ( 48%)]  Loss: 0.003181 (0.00318)  Time: 0.717s, 2856.94/s  (0.723s, 2834.08/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.042 (0.046)
INFO:Train: 308 [ 350/625 ( 56%)]  Loss: 0.003385 (0.00320)  Time: 0.715s, 2865.68/s  (0.722s, 2837.33/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.041 (0.046)
INFO:Train: 308 [ 400/625 ( 64%)]  Loss: 0.002612 (0.00314)  Time: 0.708s, 2892.75/s  (0.721s, 2840.19/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.028 (0.045)
INFO:Train: 308 [ 450/625 ( 72%)]  Loss: 0.003347 (0.00316)  Time: 0.708s, 2894.64/s  (0.719s, 2848.92/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.033 (0.043)
INFO:Train: 308 [ 500/625 ( 80%)]  Loss: 0.002487 (0.00310)  Time: 0.702s, 2917.51/s  (0.717s, 2854.94/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 308 [ 550/625 ( 88%)]  Loss: 0.002279 (0.00303)  Time: 0.711s, 2880.97/s  (0.716s, 2860.33/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.035 (0.040)
INFO:Train: 308 [ 600/625 ( 96%)]  Loss: 0.003101 (0.00303)  Time: 0.701s, 2922.72/s  (0.715s, 2865.19/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.026 (0.039)
INFO:Train: 308 [ 624/625 (100%)]  Loss: 0.002880 (0.00302)  Time: 0.676s, 3027.61/s  (0.714s, 2867.39/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.000 (0.038)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.382 (4.382)  Loss:  0.5513 (0.5513)  Acc@1: 86.9629 (86.9629)  Acc@5: 98.1934 (98.1934)
INFO:Test: [  24/24]  Time: 0.080 (0.513)  Loss:  0.4988 (0.8043)  Acc@1: 86.7924 (81.8200)  Acc@5: 97.5236 (95.6520)
INFO:308-epoch: remaining time 0.26 h
INFO:Train: 309 [   0/625 (  0%)]  Loss: 0.003026 (0.00303)  Time: 4.190s,  488.82/s  (4.190s,  488.82/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 3.489 (3.489)
INFO:Train: 309 [  50/625 (  8%)]  Loss: 0.002824 (0.00292)  Time: 0.703s, 2913.62/s  (0.774s, 2647.23/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.027 (0.095)
INFO:Train: 309 [ 100/625 ( 16%)]  Loss: 0.003098 (0.00298)  Time: 0.712s, 2877.04/s  (0.740s, 2767.98/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.036 (0.062)
INFO:Train: 309 [ 150/625 ( 24%)]  Loss: 0.003081 (0.00301)  Time: 0.701s, 2920.31/s  (0.728s, 2811.34/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.026 (0.051)
INFO:Train: 309 [ 200/625 ( 32%)]  Loss: 0.003630 (0.00313)  Time: 0.715s, 2865.72/s  (0.722s, 2836.07/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.042 (0.045)
INFO:Train: 309 [ 250/625 ( 40%)]  Loss: 0.003341 (0.00317)  Time: 0.720s, 2844.93/s  (0.721s, 2840.16/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.047 (0.045)
INFO:Train: 309 [ 300/625 ( 48%)]  Loss: 0.003835 (0.00326)  Time: 0.712s, 2876.38/s  (0.720s, 2842.91/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.038 (0.044)
INFO:Train: 309 [ 350/625 ( 56%)]  Loss: 0.003150 (0.00325)  Time: 0.705s, 2906.21/s  (0.718s, 2852.27/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.030 (0.042)
INFO:Train: 309 [ 400/625 ( 64%)]  Loss: 0.003671 (0.00330)  Time: 0.701s, 2919.59/s  (0.716s, 2859.28/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.027 (0.041)
INFO:Train: 309 [ 450/625 ( 72%)]  Loss: 0.003097 (0.00328)  Time: 0.703s, 2911.54/s  (0.715s, 2865.35/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.028 (0.039)
INFO:Train: 309 [ 500/625 ( 80%)]  Loss: 0.002631 (0.00322)  Time: 0.700s, 2926.62/s  (0.714s, 2869.55/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.026 (0.038)
INFO:Train: 309 [ 550/625 ( 88%)]  Loss: 0.002670 (0.00317)  Time: 0.704s, 2911.08/s  (0.713s, 2873.45/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.029 (0.037)
INFO:Train: 309 [ 600/625 ( 96%)]  Loss: 0.002909 (0.00315)  Time: 0.702s, 2916.04/s  (0.712s, 2876.61/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.028 (0.036)
INFO:Train: 309 [ 624/625 (100%)]  Loss: 0.002766 (0.00312)  Time: 0.675s, 3034.39/s  (0.711s, 2878.57/s)  avg LR: 5.000e-05  iter ratio: 0.0000  Data: 0.000 (0.036)
INFO:Distributing BatchNorm running means and vars
INFO:Test: [   0/24]  Time: 4.411 (4.411)  Loss:  0.5547 (0.5547)  Acc@1: 87.2070 (87.2070)  Acc@5: 98.1934 (98.1934)
INFO:Test: [  24/24]  Time: 0.080 (0.510)  Loss:  0.5068 (0.8163)  Acc@1: 87.3821 (81.7640)  Acc@5: 97.7594 (95.6540)
INFO:309-epoch: remaining time 0.13 h
INFO:*** Best metric: 81.882000078125 (epoch 298)
